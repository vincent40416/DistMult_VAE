WARNING:tensorflow:From ./src/testers.py:1069: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From ./src/models.py:41: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ./src/models.py:42: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From ./src/models.py:44: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From ./src/models.py:54: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ./src/models.py:2100: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From ./src/models.py:2143: The name tf.random_normal is deprecated. Please use tf.random.normal instead.

WARNING:tensorflow:From ./src/models.py:2066: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

WARNING:tensorflow:From ./src/models.py:2068: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From ./src/models.py:2072: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING:tensorflow:From ./src/models.py:183: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /storage/ssd3/wchao/anaconda3/envs/ukge/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ./src/models.py:192: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ./src/trainer.py:621: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

Trained models will be stored in:  train_model_d512_b512/nl27k/DistMult_VAE_1001
file_psl: ./data/nl27k/softlogic.tsv
Read train.tsv from ./data/nl27k
Now using model:  ModelList.DistMult_VAE
define main loss
Number of batches per epoch: 291
process: 50 / 291. Epoch 1
process: 100 / 291. Epoch 1
process: 150 / 291. Epoch 1
process: 200 / 291. Epoch 1
process: 250 / 291. Epoch 1
process: 291 / 291. Epoch 1
Loss of epoch 1 = 1119.7844716494844
process: 50 / 291. Epoch 2
process: 100 / 291. Epoch 2
process: 150 / 291. Epoch 2
process: 200 / 291. Epoch 2
process: 250 / 291. Epoch 2
process: 291 / 291. Epoch 2
Loss of epoch 2 = 240.35867697594503
process: 50 / 291. Epoch 3
process: 100 / 291. Epoch 3
process: 150 / 291. Epoch 3
process: 200 / 291. Epoch 3
process: 250 / 291. Epoch 3
process: 291 / 291. Epoch 3
Loss of epoch 3 = 198.48920747422682
process: 50 / 291. Epoch 4
process: 100 / 291. Epoch 4
process: 150 / 291. Epoch 4
process: 200 / 291. Epoch 4
process: 250 / 291. Epoch 4
process: 291 / 291. Epoch 4
Loss of epoch 4 = 181.35995221219932
process: 50 / 291. Epoch 5
process: 100 / 291. Epoch 5
process: 150 / 291. Epoch 5
process: 200 / 291. Epoch 5
process: 250 / 291. Epoch 5
process: 291 / 291. Epoch 5
Loss of epoch 5 = 171.63730938573883
process: 50 / 291. Epoch 6
process: 100 / 291. Epoch 6
process: 150 / 291. Epoch 6
process: 200 / 291. Epoch 6
process: 250 / 291. Epoch 6
process: 291 / 291. Epoch 6
Loss of epoch 6 = 166.73809332044672
process: 50 / 291. Epoch 7
process: 100 / 291. Epoch 7
process: 150 / 291. Epoch 7
process: 200 / 291. Epoch 7
process: 250 / 291. Epoch 7
process: 291 / 291. Epoch 7
Loss of epoch 7 = 162.42647927405497
process: 50 / 291. Epoch 8
process: 100 / 291. Epoch 8
process: 150 / 291. Epoch 8
process: 200 / 291. Epoch 8
process: 250 / 291. Epoch 8
process: 291 / 291. Epoch 8
Loss of epoch 8 = 158.88533612542955
process: 50 / 291. Epoch 9
process: 100 / 291. Epoch 9
process: 150 / 291. Epoch 9
process: 200 / 291. Epoch 9
process: 250 / 291. Epoch 9
process: 291 / 291. Epoch 9
Loss of epoch 9 = 154.52640410223367
process: 50 / 291. Epoch 10
process: 100 / 291. Epoch 10
process: 150 / 291. Epoch 10
process: 200 / 291. Epoch 10
process: 250 / 291. Epoch 10
process: 291 / 291. Epoch 10
Loss of epoch 10 = 148.6789089347079
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-10. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
Loaded ranking test queries. Number of (h,r,?t) queries: 8455
The mean of prediced scores: 0.809638
   epoch  training_loss
5      6     166.738093
6      7     162.426479
7      8     158.885336
8      9     154.526404
9     10     148.678909
   val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
0         10  0.032626  0.527959       0.19183   0.189773
   val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6  Acc_0.7
0       10.0  0.795499  0.829581  ...  0.806565  0.828474  0.82489

[1 rows x 13 columns]
process: 50 / 291. Epoch 11
process: 100 / 291. Epoch 11
process: 150 / 291. Epoch 11
process: 200 / 291. Epoch 11
process: 250 / 291. Epoch 11
process: 291 / 291. Epoch 11
Loss of epoch 11 = 140.78844501718214
process: 50 / 291. Epoch 12
process: 100 / 291. Epoch 12
process: 150 / 291. Epoch 12
process: 200 / 291. Epoch 12
process: 250 / 291. Epoch 12
process: 291 / 291. Epoch 12
Loss of epoch 12 = 130.91054553264604
process: 50 / 291. Epoch 13
process: 100 / 291. Epoch 13
process: 150 / 291. Epoch 13
process: 200 / 291. Epoch 13
process: 250 / 291. Epoch 13
process: 291 / 291. Epoch 13
Loss of epoch 13 = 119.90700171821305
process: 50 / 291. Epoch 14
process: 100 / 291. Epoch 14
process: 150 / 291. Epoch 14
process: 200 / 291. Epoch 14
process: 250 / 291. Epoch 14
process: 291 / 291. Epoch 14
Loss of epoch 14 = 108.94260765678695
process: 50 / 291. Epoch 15
process: 100 / 291. Epoch 15
process: 150 / 291. Epoch 15
process: 200 / 291. Epoch 15
process: 250 / 291. Epoch 15
process: 291 / 291. Epoch 15
Loss of epoch 15 = 98.70362167096219
process: 50 / 291. Epoch 16
process: 100 / 291. Epoch 16
process: 150 / 291. Epoch 16
process: 200 / 291. Epoch 16
process: 250 / 291. Epoch 16
process: 291 / 291. Epoch 16
Loss of epoch 16 = 88.95502443084193
process: 50 / 291. Epoch 17
process: 100 / 291. Epoch 17
process: 150 / 291. Epoch 17
process: 200 / 291. Epoch 17
process: 250 / 291. Epoch 17
process: 291 / 291. Epoch 17
Loss of epoch 17 = 79.71024618771477
process: 50 / 291. Epoch 18
process: 100 / 291. Epoch 18
process: 150 / 291. Epoch 18
process: 200 / 291. Epoch 18
process: 250 / 291. Epoch 18
process: 291 / 291. Epoch 18
Loss of epoch 18 = 71.76592031786942
process: 50 / 291. Epoch 19
process: 100 / 291. Epoch 19
process: 150 / 291. Epoch 19
process: 200 / 291. Epoch 19
process: 250 / 291. Epoch 19
process: 291 / 291. Epoch 19
Loss of epoch 19 = 64.62589937714776
process: 50 / 291. Epoch 20
process: 100 / 291. Epoch 20
process: 150 / 291. Epoch 20
process: 200 / 291. Epoch 20
process: 250 / 291. Epoch 20
process: 291 / 291. Epoch 20
Loss of epoch 20 = 58.22901900773196
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-20. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.808271
    epoch  training_loss
15     16      88.955024
16     17      79.710246
17     18      71.765920
18     19      64.625899
19     20      58.229019
   val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
0         10  0.032626  0.527959      0.191830   0.189773
1         20  0.020118  0.433219      0.209224   0.207818
   val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
0       10.0  0.795499  0.829581  ...  0.806565  0.828474  0.824890
1       20.0  0.855763  0.910053  ...  0.869197  0.907151  0.899414

[2 rows x 13 columns]
process: 50 / 291. Epoch 21
process: 100 / 291. Epoch 21
process: 150 / 291. Epoch 21
process: 200 / 291. Epoch 21
process: 250 / 291. Epoch 21
process: 291 / 291. Epoch 21
Loss of epoch 21 = 52.84201836340206
process: 50 / 291. Epoch 22
process: 100 / 291. Epoch 22
process: 150 / 291. Epoch 22
process: 200 / 291. Epoch 22
process: 250 / 291. Epoch 22
process: 291 / 291. Epoch 22
Loss of epoch 22 = 48.11801640356529
process: 50 / 291. Epoch 23
process: 100 / 291. Epoch 23
process: 150 / 291. Epoch 23
process: 200 / 291. Epoch 23
process: 250 / 291. Epoch 23
process: 291 / 291. Epoch 23
Loss of epoch 23 = 43.66960642182131
process: 50 / 291. Epoch 24
process: 100 / 291. Epoch 24
process: 150 / 291. Epoch 24
process: 200 / 291. Epoch 24
process: 250 / 291. Epoch 24
process: 291 / 291. Epoch 24
Loss of epoch 24 = 40.04637497315292
process: 50 / 291. Epoch 25
process: 100 / 291. Epoch 25
process: 150 / 291. Epoch 25
process: 200 / 291. Epoch 25
process: 250 / 291. Epoch 25
process: 291 / 291. Epoch 25
Loss of epoch 25 = 36.833561533505154
process: 50 / 291. Epoch 26
process: 100 / 291. Epoch 26
process: 150 / 291. Epoch 26
process: 200 / 291. Epoch 26
process: 250 / 291. Epoch 26
process: 291 / 291. Epoch 26
Loss of epoch 26 = 33.944070822594504
process: 50 / 291. Epoch 27
process: 100 / 291. Epoch 27
process: 150 / 291. Epoch 27
process: 200 / 291. Epoch 27
process: 250 / 291. Epoch 27
process: 291 / 291. Epoch 27
Loss of epoch 27 = 31.500416129725085
process: 50 / 291. Epoch 28
process: 100 / 291. Epoch 28
process: 150 / 291. Epoch 28
process: 200 / 291. Epoch 28
process: 250 / 291. Epoch 28
process: 291 / 291. Epoch 28
Loss of epoch 28 = 29.4626422895189
process: 50 / 291. Epoch 29
process: 100 / 291. Epoch 29
process: 150 / 291. Epoch 29
process: 200 / 291. Epoch 29
process: 250 / 291. Epoch 29
process: 291 / 291. Epoch 29
Loss of epoch 29 = 27.491781437929554
process: 50 / 291. Epoch 30
process: 100 / 291. Epoch 30
process: 150 / 291. Epoch 30
process: 200 / 291. Epoch 30
process: 250 / 291. Epoch 30
process: 291 / 291. Epoch 30
Loss of epoch 30 = 25.6045257463488
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-30. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.793811
    epoch  training_loss
25     26      33.944071
26     27      31.500416
27     28      29.462642
28     29      27.491781
29     30      25.604526
   val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
0         10  0.032626  0.527959      0.191830   0.189773
1         20  0.020118  0.433219      0.209224   0.207818
2         30  0.015637  0.329168      0.220073   0.218728
   val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
0       10.0  0.795499  0.829581  ...  0.806565  0.828474  0.824890
1       20.0  0.855763  0.910053  ...  0.869197  0.907151  0.899414
2       30.0  0.916237  0.955948  ...  0.921404  0.944453  0.923929

[3 rows x 13 columns]
process: 50 / 291. Epoch 31
process: 100 / 291. Epoch 31
process: 150 / 291. Epoch 31
process: 200 / 291. Epoch 31
process: 250 / 291. Epoch 31
process: 291 / 291. Epoch 31
Loss of epoch 31 = 24.16503570661512
process: 50 / 291. Epoch 32
process: 100 / 291. Epoch 32
process: 150 / 291. Epoch 32
process: 200 / 291. Epoch 32
process: 250 / 291. Epoch 32
process: 291 / 291. Epoch 32
Loss of epoch 32 = 22.640594797036083
process: 50 / 291. Epoch 33
process: 100 / 291. Epoch 33
process: 150 / 291. Epoch 33
process: 200 / 291. Epoch 33
process: 250 / 291. Epoch 33
process: 291 / 291. Epoch 33
Loss of epoch 33 = 21.302798136812715
process: 50 / 291. Epoch 34
process: 100 / 291. Epoch 34
process: 150 / 291. Epoch 34
process: 200 / 291. Epoch 34
process: 250 / 291. Epoch 34
process: 291 / 291. Epoch 34
Loss of epoch 34 = 20.348797250859107
process: 50 / 291. Epoch 35
process: 100 / 291. Epoch 35
process: 150 / 291. Epoch 35
process: 200 / 291. Epoch 35
process: 250 / 291. Epoch 35
process: 291 / 291. Epoch 35
Loss of epoch 35 = 19.33189533666237
process: 50 / 291. Epoch 36
process: 100 / 291. Epoch 36
process: 150 / 291. Epoch 36
process: 200 / 291. Epoch 36
process: 250 / 291. Epoch 36
process: 291 / 291. Epoch 36
Loss of epoch 36 = 18.40683392396907
process: 50 / 291. Epoch 37
process: 100 / 291. Epoch 37
process: 150 / 291. Epoch 37
process: 200 / 291. Epoch 37
process: 250 / 291. Epoch 37
process: 291 / 291. Epoch 37
Loss of epoch 37 = 17.621298458977662
process: 50 / 291. Epoch 38
process: 100 / 291. Epoch 38
process: 150 / 291. Epoch 38
process: 200 / 291. Epoch 38
process: 250 / 291. Epoch 38
process: 291 / 291. Epoch 38
Loss of epoch 38 = 16.943746979703608
process: 50 / 291. Epoch 39
process: 100 / 291. Epoch 39
process: 150 / 291. Epoch 39
process: 200 / 291. Epoch 39
process: 250 / 291. Epoch 39
process: 291 / 291. Epoch 39
Loss of epoch 39 = 16.192208306486254
process: 50 / 291. Epoch 40
process: 100 / 291. Epoch 40
process: 150 / 291. Epoch 40
process: 200 / 291. Epoch 40
process: 250 / 291. Epoch 40
process: 291 / 291. Epoch 40
Loss of epoch 40 = 15.585007919888316
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-40. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.803269
    epoch  training_loss
35     36      18.406834
36     37      17.621298
37     38      16.943747
38     39      16.192208
39     40      15.585008
   val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
0         10  0.032626  0.527959      0.191830   0.189773
1         20  0.020118  0.433219      0.209224   0.207818
2         30  0.015637  0.329168      0.220073   0.218728
3         40  0.014362  0.282029      0.228977   0.227690
   val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
0       10.0  0.795499  0.829581  ...  0.806565  0.828474  0.824890
1       20.0  0.855763  0.910053  ...  0.869197  0.907151  0.899414
2       30.0  0.916237  0.955948  ...  0.921404  0.944453  0.923929
3       40.0  0.936828  0.966494  ...  0.938019  0.952761  0.934028

[4 rows x 13 columns]
process: 50 / 291. Epoch 41
process: 100 / 291. Epoch 41
process: 150 / 291. Epoch 41
process: 200 / 291. Epoch 41
process: 250 / 291. Epoch 41
process: 291 / 291. Epoch 41
Loss of epoch 41 = 15.055479488831615
process: 50 / 291. Epoch 42
process: 100 / 291. Epoch 42
process: 150 / 291. Epoch 42
process: 200 / 291. Epoch 42
process: 250 / 291. Epoch 42
process: 291 / 291. Epoch 42
Loss of epoch 42 = 14.539476951782646
process: 50 / 291. Epoch 43
process: 100 / 291. Epoch 43
process: 150 / 291. Epoch 43
process: 200 / 291. Epoch 43
process: 250 / 291. Epoch 43
process: 291 / 291. Epoch 43
Loss of epoch 43 = 14.07020930653995
process: 50 / 291. Epoch 44
process: 100 / 291. Epoch 44
process: 150 / 291. Epoch 44
process: 200 / 291. Epoch 44
process: 250 / 291. Epoch 44
process: 291 / 291. Epoch 44
Loss of epoch 44 = 13.7297237435567
process: 50 / 291. Epoch 45
process: 100 / 291. Epoch 45
process: 150 / 291. Epoch 45
process: 200 / 291. Epoch 45
process: 250 / 291. Epoch 45
process: 291 / 291. Epoch 45
Loss of epoch 45 = 13.293921821305842
process: 50 / 291. Epoch 46
process: 100 / 291. Epoch 46
process: 150 / 291. Epoch 46
process: 200 / 291. Epoch 46
process: 250 / 291. Epoch 46
process: 291 / 291. Epoch 46
Loss of epoch 46 = 13.021712575171822
process: 50 / 291. Epoch 47
process: 100 / 291. Epoch 47
process: 150 / 291. Epoch 47
process: 200 / 291. Epoch 47
process: 250 / 291. Epoch 47
process: 291 / 291. Epoch 47
Loss of epoch 47 = 12.63465488079897
process: 50 / 291. Epoch 48
process: 100 / 291. Epoch 48
process: 150 / 291. Epoch 48
process: 200 / 291. Epoch 48
process: 250 / 291. Epoch 48
process: 291 / 291. Epoch 48
Loss of epoch 48 = 12.217603965313574
process: 50 / 291. Epoch 49
process: 100 / 291. Epoch 49
process: 150 / 291. Epoch 49
process: 200 / 291. Epoch 49
process: 250 / 291. Epoch 49
process: 291 / 291. Epoch 49
Loss of epoch 49 = 12.062810419351374
process: 50 / 291. Epoch 50
process: 100 / 291. Epoch 50
process: 150 / 291. Epoch 50
process: 200 / 291. Epoch 50
process: 250 / 291. Epoch 50
process: 291 / 291. Epoch 50
Loss of epoch 50 = 11.729153243127147
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-50. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.794520
    epoch  training_loss
45     46      13.021713
46     47      12.634655
47     48      12.217604
48     49      12.062810
49     50      11.729153
   val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
0         10  0.032626  0.527959      0.191830   0.189773
1         20  0.020118  0.433219      0.209224   0.207818
2         30  0.015637  0.329168      0.220073   0.218728
3         40  0.014362  0.282029      0.228977   0.227690
4         50  0.014161  0.244009      0.238013   0.236925
   val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
0       10.0  0.795499  0.829581  ...  0.806565  0.828474  0.824890
1       20.0  0.855763  0.910053  ...  0.869197  0.907151  0.899414
2       30.0  0.916237  0.955948  ...  0.921404  0.944453  0.923929
3       40.0  0.936828  0.966494  ...  0.938019  0.952761  0.934028
4       50.0  0.949352  0.972290  ...  0.946897  0.954634  0.930852

[5 rows x 13 columns]
process: 50 / 291. Epoch 51
process: 100 / 291. Epoch 51
process: 150 / 291. Epoch 51
process: 200 / 291. Epoch 51
process: 250 / 291. Epoch 51
process: 291 / 291. Epoch 51
Loss of epoch 51 = 11.492378785438145
process: 50 / 291. Epoch 52
process: 100 / 291. Epoch 52
process: 150 / 291. Epoch 52
process: 200 / 291. Epoch 52
process: 250 / 291. Epoch 52
process: 291 / 291. Epoch 52
Loss of epoch 52 = 11.204413659793815
process: 50 / 291. Epoch 53
process: 100 / 291. Epoch 53
process: 150 / 291. Epoch 53
process: 200 / 291. Epoch 53
process: 250 / 291. Epoch 53
process: 291 / 291. Epoch 53
Loss of epoch 53 = 11.07508289035653
process: 50 / 291. Epoch 54
process: 100 / 291. Epoch 54
process: 150 / 291. Epoch 54
process: 200 / 291. Epoch 54
process: 250 / 291. Epoch 54
process: 291 / 291. Epoch 54
Loss of epoch 54 = 10.918505691580757
process: 50 / 291. Epoch 55
process: 100 / 291. Epoch 55
process: 150 / 291. Epoch 55
process: 200 / 291. Epoch 55
process: 250 / 291. Epoch 55
process: 291 / 291. Epoch 55
Loss of epoch 55 = 10.609393457366838
process: 50 / 291. Epoch 56
process: 100 / 291. Epoch 56
process: 150 / 291. Epoch 56
process: 200 / 291. Epoch 56
process: 250 / 291. Epoch 56
process: 291 / 291. Epoch 56
Loss of epoch 56 = 10.661906343964777
process: 50 / 291. Epoch 57
process: 100 / 291. Epoch 57
process: 150 / 291. Epoch 57
process: 200 / 291. Epoch 57
process: 250 / 291. Epoch 57
process: 291 / 291. Epoch 57
Loss of epoch 57 = 10.442972609267612
process: 50 / 291. Epoch 58
process: 100 / 291. Epoch 58
process: 150 / 291. Epoch 58
process: 200 / 291. Epoch 58
process: 250 / 291. Epoch 58
process: 291 / 291. Epoch 58
Loss of epoch 58 = 10.181003845844073
process: 50 / 291. Epoch 59
process: 100 / 291. Epoch 59
process: 150 / 291. Epoch 59
process: 200 / 291. Epoch 59
process: 250 / 291. Epoch 59
process: 291 / 291. Epoch 59
Loss of epoch 59 = 10.148593548646907
process: 50 / 291. Epoch 60
process: 100 / 291. Epoch 60
process: 150 / 291. Epoch 60
process: 200 / 291. Epoch 60
process: 250 / 291. Epoch 60
process: 291 / 291. Epoch 60
Loss of epoch 60 = 9.974460877094073
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-60. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.797310
    epoch  training_loss
55     56      10.661906
56     57      10.442973
57     58      10.181004
58     59      10.148594
59     60       9.974461
   val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
1         20  0.020118  0.433219      0.209224   0.207818
2         30  0.015637  0.329168      0.220073   0.218728
3         40  0.014362  0.282029      0.228977   0.227690
4         50  0.014161  0.244009      0.238013   0.236925
5         60  0.013753  0.224492      0.244905   0.243901
   val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
1       20.0  0.855763  0.910053  ...  0.869197  0.907151  0.899414
2       30.0  0.916237  0.955948  ...  0.921404  0.944453  0.923929
3       40.0  0.936828  0.966494  ...  0.938019  0.952761  0.934028
4       50.0  0.949352  0.972290  ...  0.946897  0.954634  0.930852
5       60.0  0.956414  0.974342  ...  0.952435  0.955937  0.935250

[5 rows x 13 columns]
process: 50 / 291. Epoch 61
process: 100 / 291. Epoch 61
process: 150 / 291. Epoch 61
process: 200 / 291. Epoch 61
process: 250 / 291. Epoch 61
process: 291 / 291. Epoch 61
Loss of epoch 61 = 9.650178365281358
process: 50 / 291. Epoch 62
process: 100 / 291. Epoch 62
process: 150 / 291. Epoch 62
process: 200 / 291. Epoch 62
process: 250 / 291. Epoch 62
process: 291 / 291. Epoch 62
Loss of epoch 62 = 9.494550881926546
process: 50 / 291. Epoch 63
process: 100 / 291. Epoch 63
process: 150 / 291. Epoch 63
process: 200 / 291. Epoch 63
process: 250 / 291. Epoch 63
process: 291 / 291. Epoch 63
Loss of epoch 63 = 9.550801385309278
process: 50 / 291. Epoch 64
process: 100 / 291. Epoch 64
process: 150 / 291. Epoch 64
process: 200 / 291. Epoch 64
process: 250 / 291. Epoch 64
process: 291 / 291. Epoch 64
Loss of epoch 64 = 9.347595844072165
process: 50 / 291. Epoch 65
process: 100 / 291. Epoch 65
process: 150 / 291. Epoch 65
process: 200 / 291. Epoch 65
process: 250 / 291. Epoch 65
process: 291 / 291. Epoch 65
Loss of epoch 65 = 9.160678090098797
process: 50 / 291. Epoch 66
process: 100 / 291. Epoch 66
process: 150 / 291. Epoch 66
process: 200 / 291. Epoch 66
process: 250 / 291. Epoch 66
process: 291 / 291. Epoch 66
Loss of epoch 66 = 8.9907268511061
process: 50 / 291. Epoch 67
process: 100 / 291. Epoch 67
process: 150 / 291. Epoch 67
process: 200 / 291. Epoch 67
process: 250 / 291. Epoch 67
process: 291 / 291. Epoch 67
Loss of epoch 67 = 8.937199648303265
process: 50 / 291. Epoch 68
process: 100 / 291. Epoch 68
process: 150 / 291. Epoch 68
process: 200 / 291. Epoch 68
process: 250 / 291. Epoch 68
process: 291 / 291. Epoch 68
Loss of epoch 68 = 9.053123657646049
process: 50 / 291. Epoch 69
process: 100 / 291. Epoch 69
process: 150 / 291. Epoch 69
process: 200 / 291. Epoch 69
process: 250 / 291. Epoch 69
process: 291 / 291. Epoch 69
Loss of epoch 69 = 8.914961877147766
process: 50 / 291. Epoch 70
process: 100 / 291. Epoch 70
process: 150 / 291. Epoch 70
process: 200 / 291. Epoch 70
process: 250 / 291. Epoch 70
process: 291 / 291. Epoch 70
Loss of epoch 70 = 8.826020021209192
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-70. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.793633
    epoch  training_loss
65     66       8.990727
66     67       8.937200
67     68       9.053124
68     69       8.914962
69     70       8.826020
   val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
2         30  0.015637  0.329168      0.220073   0.218728
3         40  0.014362  0.282029      0.228977   0.227690
4         50  0.014161  0.244009      0.238013   0.236925
5         60  0.013753  0.224492      0.244905   0.243901
6         70  0.013539  0.205179      0.250161   0.249224
   val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
2       30.0  0.916237  0.955948  ...  0.921404  0.944453  0.923929
3       40.0  0.936828  0.966494  ...  0.938019  0.952761  0.934028
4       50.0  0.949352  0.972290  ...  0.946897  0.954634  0.930852
5       60.0  0.956414  0.974342  ...  0.952435  0.955937  0.935250
6       70.0  0.962082  0.976193  ...  0.956100  0.957322  0.935820

[5 rows x 13 columns]
process: 50 / 291. Epoch 71
process: 100 / 291. Epoch 71
process: 150 / 291. Epoch 71
process: 200 / 291. Epoch 71
process: 250 / 291. Epoch 71
process: 291 / 291. Epoch 71
Loss of epoch 71 = 8.655259174989261
process: 50 / 291. Epoch 72
process: 100 / 291. Epoch 72
process: 150 / 291. Epoch 72
process: 200 / 291. Epoch 72
process: 250 / 291. Epoch 72
process: 291 / 291. Epoch 72
Loss of epoch 72 = 8.475181553371993
process: 50 / 291. Epoch 73
process: 100 / 291. Epoch 73
process: 150 / 291. Epoch 73
process: 200 / 291. Epoch 73
process: 250 / 291. Epoch 73
process: 291 / 291. Epoch 73
Loss of epoch 73 = 8.35914008805842
process: 50 / 291. Epoch 74
process: 100 / 291. Epoch 74
process: 150 / 291. Epoch 74
process: 200 / 291. Epoch 74
process: 250 / 291. Epoch 74
process: 291 / 291. Epoch 74
Loss of epoch 74 = 8.309733072916666
process: 50 / 291. Epoch 75
process: 100 / 291. Epoch 75
process: 150 / 291. Epoch 75
process: 200 / 291. Epoch 75
process: 250 / 291. Epoch 75
process: 291 / 291. Epoch 75
Loss of epoch 75 = 8.234543633215207
process: 50 / 291. Epoch 76
process: 100 / 291. Epoch 76
process: 150 / 291. Epoch 76
process: 200 / 291. Epoch 76
process: 250 / 291. Epoch 76
process: 291 / 291. Epoch 76
Loss of epoch 76 = 8.202582185620704
process: 50 / 291. Epoch 77
process: 100 / 291. Epoch 77
process: 150 / 291. Epoch 77
process: 200 / 291. Epoch 77
process: 250 / 291. Epoch 77
process: 291 / 291. Epoch 77
Loss of epoch 77 = 8.257466843857388
process: 50 / 291. Epoch 78
process: 100 / 291. Epoch 78
process: 150 / 291. Epoch 78
process: 200 / 291. Epoch 78
process: 250 / 291. Epoch 78
process: 291 / 291. Epoch 78
Loss of epoch 78 = 8.140052821628007
process: 50 / 291. Epoch 79
process: 100 / 291. Epoch 79
process: 150 / 291. Epoch 79
process: 200 / 291. Epoch 79
process: 250 / 291. Epoch 79
process: 291 / 291. Epoch 79
Loss of epoch 79 = 7.912258711877148
process: 50 / 291. Epoch 80
process: 100 / 291. Epoch 80
process: 150 / 291. Epoch 80
process: 200 / 291. Epoch 80
process: 250 / 291. Epoch 80
process: 291 / 291. Epoch 80
Loss of epoch 80 = 7.986044552727663
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-80. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.790433
    epoch  training_loss
75     76       8.202582
76     77       8.257467
77     78       8.140053
78     79       7.912259
79     80       7.986045
   val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
3         40  0.014362  0.282029      0.228977   0.227690
4         50  0.014161  0.244009      0.238013   0.236925
5         60  0.013753  0.224492      0.244905   0.243901
6         70  0.013539  0.205179      0.250161   0.249224
7         80  0.013606  0.191185      0.255732   0.254909
   val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
3       40.0  0.936828  0.966494  ...  0.938019  0.952761  0.934028
4       50.0  0.949352  0.972290  ...  0.946897  0.954634  0.930852
5       60.0  0.956414  0.974342  ...  0.952435  0.955937  0.935250
6       70.0  0.962082  0.976193  ...  0.956100  0.957322  0.935820
7       80.0  0.963858  0.976468  ...  0.957403  0.955937  0.933377

[5 rows x 13 columns]
process: 50 / 291. Epoch 81
process: 100 / 291. Epoch 81
process: 150 / 291. Epoch 81
process: 200 / 291. Epoch 81
process: 250 / 291. Epoch 81
process: 291 / 291. Epoch 81
Loss of epoch 81 = 7.916486287854381
process: 50 / 291. Epoch 82
process: 100 / 291. Epoch 82
process: 150 / 291. Epoch 82
process: 200 / 291. Epoch 82
process: 250 / 291. Epoch 82
process: 291 / 291. Epoch 82
Loss of epoch 82 = 7.899299123442869
process: 50 / 291. Epoch 83
process: 100 / 291. Epoch 83
process: 150 / 291. Epoch 83
process: 200 / 291. Epoch 83
process: 250 / 291. Epoch 83
process: 291 / 291. Epoch 83
Loss of epoch 83 = 7.684463763155069
process: 50 / 291. Epoch 84
process: 100 / 291. Epoch 84
process: 150 / 291. Epoch 84
process: 200 / 291. Epoch 84
process: 250 / 291. Epoch 84
process: 291 / 291. Epoch 84
Loss of epoch 84 = 7.676610153565292
process: 50 / 291. Epoch 85
process: 100 / 291. Epoch 85
process: 150 / 291. Epoch 85
process: 200 / 291. Epoch 85
process: 250 / 291. Epoch 85
process: 291 / 291. Epoch 85
Loss of epoch 85 = 7.5936677808204465
process: 50 / 291. Epoch 86
process: 100 / 291. Epoch 86
process: 150 / 291. Epoch 86
process: 200 / 291. Epoch 86
process: 250 / 291. Epoch 86
process: 291 / 291. Epoch 86
Loss of epoch 86 = 7.538884638101375
process: 50 / 291. Epoch 87
process: 100 / 291. Epoch 87
process: 150 / 291. Epoch 87
process: 200 / 291. Epoch 87
process: 250 / 291. Epoch 87
process: 291 / 291. Epoch 87
Loss of epoch 87 = 7.696862918814433
process: 50 / 291. Epoch 88
process: 100 / 291. Epoch 88
process: 150 / 291. Epoch 88
process: 200 / 291. Epoch 88
process: 250 / 291. Epoch 88
process: 291 / 291. Epoch 88
Loss of epoch 88 = 7.429776430949313
process: 50 / 291. Epoch 89
process: 100 / 291. Epoch 89
process: 150 / 291. Epoch 89
process: 200 / 291. Epoch 89
process: 250 / 291. Epoch 89
process: 291 / 291. Epoch 89
Loss of epoch 89 = 7.299049613402062
process: 50 / 291. Epoch 90
process: 100 / 291. Epoch 90
process: 150 / 291. Epoch 90
process: 200 / 291. Epoch 90
process: 250 / 291. Epoch 90
process: 291 / 291. Epoch 90
Loss of epoch 90 = 7.230558519920533
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-90. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.787159
    epoch  training_loss
85     86       7.538885
86     87       7.696863
87     88       7.429776
88     89       7.299050
89     90       7.230559
   val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
4         50  0.014161  0.244009      0.238013   0.236925
5         60  0.013753  0.224492      0.244905   0.243901
6         70  0.013539  0.205179      0.250161   0.249224
7         80  0.013606  0.191185      0.255732   0.254909
8         90  0.013714  0.181101      0.260905   0.260142
   val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
4       50.0  0.949352  0.972290  ...  0.946897  0.954634  0.930852
5       60.0  0.956414  0.974342  ...  0.952435  0.955937  0.935250
6       70.0  0.962082  0.976193  ...  0.956100  0.957322  0.935820
7       80.0  0.963858  0.976468  ...  0.957403  0.955937  0.933377
8       90.0  0.966015  0.976335  ...  0.957974  0.955123  0.930852

[5 rows x 13 columns]
process: 50 / 291. Epoch 91
process: 100 / 291. Epoch 91
process: 150 / 291. Epoch 91
process: 200 / 291. Epoch 91
process: 250 / 291. Epoch 91
process: 291 / 291. Epoch 91
Loss of epoch 91 = 7.286043881550687
process: 50 / 291. Epoch 92
process: 100 / 291. Epoch 92
process: 150 / 291. Epoch 92
process: 200 / 291. Epoch 92
process: 250 / 291. Epoch 92
process: 291 / 291. Epoch 92
Loss of epoch 92 = 7.242028095468213
process: 50 / 291. Epoch 93
process: 100 / 291. Epoch 93
process: 150 / 291. Epoch 93
process: 200 / 291. Epoch 93
process: 250 / 291. Epoch 93
process: 291 / 291. Epoch 93
Loss of epoch 93 = 7.182883980347938
process: 50 / 291. Epoch 94
process: 100 / 291. Epoch 94
process: 150 / 291. Epoch 94
process: 200 / 291. Epoch 94
process: 250 / 291. Epoch 94
process: 291 / 291. Epoch 94
Loss of epoch 94 = 7.136789223582475
process: 50 / 291. Epoch 95
process: 100 / 291. Epoch 95
process: 150 / 291. Epoch 95
process: 200 / 291. Epoch 95
process: 250 / 291. Epoch 95
process: 291 / 291. Epoch 95
Loss of epoch 95 = 7.194540646477663
process: 50 / 291. Epoch 96
process: 100 / 291. Epoch 96
process: 150 / 291. Epoch 96
process: 200 / 291. Epoch 96
process: 250 / 291. Epoch 96
process: 291 / 291. Epoch 96
Loss of epoch 96 = 7.0967912706722505
process: 50 / 291. Epoch 97
process: 100 / 291. Epoch 97
process: 150 / 291. Epoch 97
process: 200 / 291. Epoch 97
process: 250 / 291. Epoch 97
process: 291 / 291. Epoch 97
Loss of epoch 97 = 7.081641128382732
process: 50 / 291. Epoch 98
process: 100 / 291. Epoch 98
process: 150 / 291. Epoch 98
process: 200 / 291. Epoch 98
process: 250 / 291. Epoch 98
process: 291 / 291. Epoch 98
Loss of epoch 98 = 6.9885337803372
process: 50 / 291. Epoch 99
process: 100 / 291. Epoch 99
process: 150 / 291. Epoch 99
process: 200 / 291. Epoch 99
process: 250 / 291. Epoch 99
process: 291 / 291. Epoch 99
Loss of epoch 99 = 6.87145618556701
process: 50 / 291. Epoch 100
process: 100 / 291. Epoch 100
process: 150 / 291. Epoch 100
process: 200 / 291. Epoch 100
process: 250 / 291. Epoch 100
process: 291 / 291. Epoch 100
Loss of epoch 100 = 6.830575634933419
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-100. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.789216
    epoch  training_loss
95     96       7.096791
96     97       7.081641
97     98       6.988534
98     99       6.871456
99    100       6.830576
   val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
5         60  0.013753  0.224492      0.244905   0.243901
6         70  0.013539  0.205179      0.250161   0.249224
7         80  0.013606  0.191185      0.255732   0.254909
8         90  0.013714  0.181101      0.260905   0.260142
9        100  0.013655  0.172171      0.265447   0.264766
   val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
5       60.0  0.956414  0.974342  ...  0.952435  0.955937  0.935250
6       70.0  0.962082  0.976193  ...  0.956100  0.957322  0.935820
7       80.0  0.963858  0.976468  ...  0.957403  0.955937  0.933377
8       90.0  0.966015  0.976335  ...  0.957974  0.955123  0.930852
9      100.0  0.966342  0.976655  ...  0.958462  0.955123  0.935739

[5 rows x 13 columns]
process: 50 / 291. Epoch 101
process: 100 / 291. Epoch 101
process: 150 / 291. Epoch 101
process: 200 / 291. Epoch 101
process: 250 / 291. Epoch 101
process: 291 / 291. Epoch 101
Loss of epoch 101 = 6.843762584568299
process: 50 / 291. Epoch 102
process: 100 / 291. Epoch 102
process: 150 / 291. Epoch 102
process: 200 / 291. Epoch 102
process: 250 / 291. Epoch 102
process: 291 / 291. Epoch 102
Loss of epoch 102 = 6.690618456024485
process: 50 / 291. Epoch 103
process: 100 / 291. Epoch 103
process: 150 / 291. Epoch 103
process: 200 / 291. Epoch 103
process: 250 / 291. Epoch 103
process: 291 / 291. Epoch 103
Loss of epoch 103 = 6.88903598850945
process: 50 / 291. Epoch 104
process: 100 / 291. Epoch 104
process: 150 / 291. Epoch 104
process: 200 / 291. Epoch 104
process: 250 / 291. Epoch 104
process: 291 / 291. Epoch 104
Loss of epoch 104 = 6.721389403457904
process: 50 / 291. Epoch 105
process: 100 / 291. Epoch 105
process: 150 / 291. Epoch 105
process: 200 / 291. Epoch 105
process: 250 / 291. Epoch 105
process: 291 / 291. Epoch 105
Loss of epoch 105 = 6.726759658236684
process: 50 / 291. Epoch 106
process: 100 / 291. Epoch 106
process: 150 / 291. Epoch 106
process: 200 / 291. Epoch 106
process: 250 / 291. Epoch 106
process: 291 / 291. Epoch 106
Loss of epoch 106 = 6.861764390034364
process: 50 / 291. Epoch 107
process: 100 / 291. Epoch 107
process: 150 / 291. Epoch 107
process: 200 / 291. Epoch 107
process: 250 / 291. Epoch 107
process: 291 / 291. Epoch 107
Loss of epoch 107 = 6.6980299277813575
process: 50 / 291. Epoch 108
process: 100 / 291. Epoch 108
process: 150 / 291. Epoch 108
process: 200 / 291. Epoch 108
process: 250 / 291. Epoch 108
process: 291 / 291. Epoch 108
Loss of epoch 108 = 6.48461662371134
process: 50 / 291. Epoch 109
process: 100 / 291. Epoch 109
process: 150 / 291. Epoch 109
process: 200 / 291. Epoch 109
process: 250 / 291. Epoch 109
process: 291 / 291. Epoch 109
Loss of epoch 109 = 6.665824339561856
process: 50 / 291. Epoch 110
process: 100 / 291. Epoch 110
process: 150 / 291. Epoch 110
process: 200 / 291. Epoch 110
process: 250 / 291. Epoch 110
process: 291 / 291. Epoch 110
Loss of epoch 110 = 6.404000718159364
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-110. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.792231
     epoch  training_loss
105    106       6.861764
106    107       6.698030
107    108       6.484617
108    109       6.665824
109    110       6.404001
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
6          70  0.013539  0.205179      0.250161   0.249224
7          80  0.013606  0.191185      0.255732   0.254909
8          90  0.013714  0.181101      0.260905   0.260142
9         100  0.013655  0.172171      0.265447   0.264766
10        110  0.013559  0.168085      0.270182   0.269590
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
6        70.0  0.962082  0.976193  ...  0.956100  0.957322  0.935820
7        80.0  0.963858  0.976468  ...  0.957403  0.955937  0.933377
8        90.0  0.966015  0.976335  ...  0.957974  0.955123  0.930852
9       100.0  0.966342  0.976655  ...  0.958462  0.955123  0.935739
10      110.0  0.968250  0.976888  ...  0.960010  0.955693  0.935169

[5 rows x 13 columns]
process: 50 / 291. Epoch 111
process: 100 / 291. Epoch 111
process: 150 / 291. Epoch 111
process: 200 / 291. Epoch 111
process: 250 / 291. Epoch 111
process: 291 / 291. Epoch 111
Loss of epoch 111 = 6.396702507517182
process: 50 / 291. Epoch 112
process: 100 / 291. Epoch 112
process: 150 / 291. Epoch 112
process: 200 / 291. Epoch 112
process: 250 / 291. Epoch 112
process: 291 / 291. Epoch 112
Loss of epoch 112 = 6.300385255584192
process: 50 / 291. Epoch 113
process: 100 / 291. Epoch 113
process: 150 / 291. Epoch 113
process: 200 / 291. Epoch 113
process: 250 / 291. Epoch 113
process: 291 / 291. Epoch 113
Loss of epoch 113 = 6.3512361401954465
process: 50 / 291. Epoch 114
process: 100 / 291. Epoch 114
process: 150 / 291. Epoch 114
process: 200 / 291. Epoch 114
process: 250 / 291. Epoch 114
process: 291 / 291. Epoch 114
Loss of epoch 114 = 6.5298384309224655
process: 50 / 291. Epoch 115
process: 100 / 291. Epoch 115
process: 150 / 291. Epoch 115
process: 200 / 291. Epoch 115
process: 250 / 291. Epoch 115
process: 291 / 291. Epoch 115
Loss of epoch 115 = 6.468396373630799
process: 50 / 291. Epoch 116
process: 100 / 291. Epoch 116
process: 150 / 291. Epoch 116
process: 200 / 291. Epoch 116
process: 250 / 291. Epoch 116
process: 291 / 291. Epoch 116
Loss of epoch 116 = 6.353280713058419
process: 50 / 291. Epoch 117
process: 100 / 291. Epoch 117
process: 150 / 291. Epoch 117
process: 200 / 291. Epoch 117
process: 250 / 291. Epoch 117
process: 291 / 291. Epoch 117
Loss of epoch 117 = 6.338229569372852
process: 50 / 291. Epoch 118
process: 100 / 291. Epoch 118
process: 150 / 291. Epoch 118
process: 200 / 291. Epoch 118
process: 250 / 291. Epoch 118
process: 291 / 291. Epoch 118
Loss of epoch 118 = 6.24438224871134
process: 50 / 291. Epoch 119
process: 100 / 291. Epoch 119
process: 150 / 291. Epoch 119
process: 200 / 291. Epoch 119
process: 250 / 291. Epoch 119
process: 291 / 291. Epoch 119
Loss of epoch 119 = 6.141736636866409
process: 50 / 291. Epoch 120
process: 100 / 291. Epoch 120
process: 150 / 291. Epoch 120
process: 200 / 291. Epoch 120
process: 250 / 291. Epoch 120
process: 291 / 291. Epoch 120
Loss of epoch 120 = 6.278712951030927
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-120. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.797386
     epoch  training_loss
115    116       6.353281
116    117       6.338230
117    118       6.244382
118    119       6.141737
119    120       6.278713
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
7          80  0.013606  0.191185      0.255732   0.254909
8          90  0.013714  0.181101      0.260905   0.260142
9         100  0.013655  0.172171      0.265447   0.264766
10        110  0.013559  0.168085      0.270182   0.269590
11        120  0.013527  0.162151      0.273893   0.273397
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
7        80.0  0.963858  0.976468  ...  0.957403  0.955937  0.933377
8        90.0  0.966015  0.976335  ...  0.957974  0.955123  0.930852
9       100.0  0.966342  0.976655  ...  0.958462  0.955123  0.935739
10      110.0  0.968250  0.976888  ...  0.960010  0.955693  0.935169
11      120.0  0.966889  0.977000  ...  0.959277  0.955856  0.941114

[5 rows x 13 columns]
process: 50 / 291. Epoch 121
process: 100 / 291. Epoch 121
process: 150 / 291. Epoch 121
process: 200 / 291. Epoch 121
process: 250 / 291. Epoch 121
process: 291 / 291. Epoch 121
Loss of epoch 121 = 6.262361401954467
process: 50 / 291. Epoch 122
process: 100 / 291. Epoch 122
process: 150 / 291. Epoch 122
process: 200 / 291. Epoch 122
process: 250 / 291. Epoch 122
process: 291 / 291. Epoch 122
Loss of epoch 122 = 6.1322050848367695
process: 50 / 291. Epoch 123
process: 100 / 291. Epoch 123
process: 150 / 291. Epoch 123
process: 200 / 291. Epoch 123
process: 250 / 291. Epoch 123
process: 291 / 291. Epoch 123
Loss of epoch 123 = 6.0863687312070445
process: 50 / 291. Epoch 124
process: 100 / 291. Epoch 124
process: 150 / 291. Epoch 124
process: 200 / 291. Epoch 124
process: 250 / 291. Epoch 124
process: 291 / 291. Epoch 124
Loss of epoch 124 = 6.107669371509879
process: 50 / 291. Epoch 125
process: 100 / 291. Epoch 125
process: 150 / 291. Epoch 125
process: 200 / 291. Epoch 125
process: 250 / 291. Epoch 125
process: 291 / 291. Epoch 125
Loss of epoch 125 = 6.168801848421392
process: 50 / 291. Epoch 126
process: 100 / 291. Epoch 126
process: 150 / 291. Epoch 126
process: 200 / 291. Epoch 126
process: 250 / 291. Epoch 126
process: 291 / 291. Epoch 126
Loss of epoch 126 = 5.946323040834407
process: 50 / 291. Epoch 127
process: 100 / 291. Epoch 127
process: 150 / 291. Epoch 127
process: 200 / 291. Epoch 127
process: 250 / 291. Epoch 127
process: 291 / 291. Epoch 127
Loss of epoch 127 = 5.956692305627148
process: 50 / 291. Epoch 128
process: 100 / 291. Epoch 128
process: 150 / 291. Epoch 128
process: 200 / 291. Epoch 128
process: 250 / 291. Epoch 128
process: 291 / 291. Epoch 128
Loss of epoch 128 = 5.9213548378436425
process: 50 / 291. Epoch 129
process: 100 / 291. Epoch 129
process: 150 / 291. Epoch 129
process: 200 / 291. Epoch 129
process: 250 / 291. Epoch 129
process: 291 / 291. Epoch 129
Loss of epoch 129 = 6.205529072030713
process: 50 / 291. Epoch 130
process: 100 / 291. Epoch 130
process: 150 / 291. Epoch 130
process: 200 / 291. Epoch 130
process: 250 / 291. Epoch 130
process: 291 / 291. Epoch 130
Loss of epoch 130 = 6.052786810701246
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-130. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.798531
     epoch  training_loss
125    126       5.946323
126    127       5.956692
127    128       5.921355
128    129       6.205529
129    130       6.052787
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
8          90  0.013714  0.181101      0.260905   0.260142
9         100  0.013655  0.172171      0.265447   0.264766
10        110  0.013559  0.168085      0.270182   0.269590
11        120  0.013527  0.162151      0.273893   0.273397
12        130  0.013608  0.157694      0.275936   0.275421
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
8        90.0  0.966015  0.976335  ...  0.957974  0.955123  0.930852
9       100.0  0.966342  0.976655  ...  0.958462  0.955123  0.935739
10      110.0  0.968250  0.976888  ...  0.960010  0.955693  0.935169
11      120.0  0.966889  0.977000  ...  0.959277  0.955856  0.941114
12      130.0  0.968049  0.976877  ...  0.960091  0.955367  0.941766

[5 rows x 13 columns]
process: 50 / 291. Epoch 131
process: 100 / 291. Epoch 131
process: 150 / 291. Epoch 131
process: 200 / 291. Epoch 131
process: 250 / 291. Epoch 131
process: 291 / 291. Epoch 131
Loss of epoch 131 = 5.906898524753007
process: 50 / 291. Epoch 132
process: 100 / 291. Epoch 132
process: 150 / 291. Epoch 132
process: 200 / 291. Epoch 132
process: 250 / 291. Epoch 132
process: 291 / 291. Epoch 132
Loss of epoch 132 = 5.935194926573239
process: 50 / 291. Epoch 133
process: 100 / 291. Epoch 133
process: 150 / 291. Epoch 133
process: 200 / 291. Epoch 133
process: 250 / 291. Epoch 133
process: 291 / 291. Epoch 133
Loss of epoch 133 = 5.752912488589992
process: 50 / 291. Epoch 134
process: 100 / 291. Epoch 134
process: 150 / 291. Epoch 134
process: 200 / 291. Epoch 134
process: 250 / 291. Epoch 134
process: 291 / 291. Epoch 134
Loss of epoch 134 = 5.799489653806916
process: 50 / 291. Epoch 135
process: 100 / 291. Epoch 135
process: 150 / 291. Epoch 135
process: 200 / 291. Epoch 135
process: 250 / 291. Epoch 135
process: 291 / 291. Epoch 135
Loss of epoch 135 = 5.728118791612973
process: 50 / 291. Epoch 136
process: 100 / 291. Epoch 136
process: 150 / 291. Epoch 136
process: 200 / 291. Epoch 136
process: 250 / 291. Epoch 136
process: 291 / 291. Epoch 136
Loss of epoch 136 = 5.761219562124141
process: 50 / 291. Epoch 137
process: 100 / 291. Epoch 137
process: 150 / 291. Epoch 137
process: 200 / 291. Epoch 137
process: 250 / 291. Epoch 137
process: 291 / 291. Epoch 137
Loss of epoch 137 = 5.973225911458333
process: 50 / 291. Epoch 138
process: 100 / 291. Epoch 138
process: 150 / 291. Epoch 138
process: 200 / 291. Epoch 138
process: 250 / 291. Epoch 138
process: 291 / 291. Epoch 138
Loss of epoch 138 = 5.913976924935567
process: 50 / 291. Epoch 139
process: 100 / 291. Epoch 139
process: 150 / 291. Epoch 139
process: 200 / 291. Epoch 139
process: 250 / 291. Epoch 139
process: 291 / 291. Epoch 139
Loss of epoch 139 = 5.801787176492698
process: 50 / 291. Epoch 140
process: 100 / 291. Epoch 140
process: 150 / 291. Epoch 140
process: 200 / 291. Epoch 140
process: 250 / 291. Epoch 140
process: 291 / 291. Epoch 140
Loss of epoch 140 = 5.941320674935567
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-140. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.800818
     epoch  training_loss
135    136       5.761220
136    137       5.973226
137    138       5.913977
138    139       5.801787
139    140       5.941321
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
9         100  0.013655  0.172171      0.265447   0.264766
10        110  0.013559  0.168085      0.270182   0.269590
11        120  0.013527  0.162151      0.273893   0.273397
12        130  0.013608  0.157694      0.275936   0.275421
13        140  0.013649  0.154271      0.279618   0.279196
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
9       100.0  0.966342  0.976655  ...  0.958462  0.955123  0.935739
10      110.0  0.968250  0.976888  ...  0.960010  0.955693  0.935169
11      120.0  0.966889  0.977000  ...  0.959277  0.955856  0.941114
12      130.0  0.968049  0.976877  ...  0.960091  0.955367  0.941766
13      140.0  0.968986  0.976908  ...  0.960417  0.956345  0.943150

[5 rows x 13 columns]
process: 50 / 291. Epoch 141
process: 100 / 291. Epoch 141
process: 150 / 291. Epoch 141
process: 200 / 291. Epoch 141
process: 250 / 291. Epoch 141
process: 291 / 291. Epoch 141
Loss of epoch 141 = 5.903262004000215
process: 50 / 291. Epoch 142
process: 100 / 291. Epoch 142
process: 150 / 291. Epoch 142
process: 200 / 291. Epoch 142
process: 250 / 291. Epoch 142
process: 291 / 291. Epoch 142
Loss of epoch 142 = 5.5049226636329465
process: 50 / 291. Epoch 143
process: 100 / 291. Epoch 143
process: 150 / 291. Epoch 143
process: 200 / 291. Epoch 143
process: 250 / 291. Epoch 143
process: 291 / 291. Epoch 143
Loss of epoch 143 = 5.48669559439433
process: 50 / 291. Epoch 144
process: 100 / 291. Epoch 144
process: 150 / 291. Epoch 144
process: 200 / 291. Epoch 144
process: 250 / 291. Epoch 144
process: 291 / 291. Epoch 144
Loss of epoch 144 = 5.6329916203554555
process: 50 / 291. Epoch 145
process: 100 / 291. Epoch 145
process: 150 / 291. Epoch 145
process: 200 / 291. Epoch 145
process: 250 / 291. Epoch 145
process: 291 / 291. Epoch 145
Loss of epoch 145 = 5.6710247026686
process: 50 / 291. Epoch 146
process: 100 / 291. Epoch 146
process: 150 / 291. Epoch 146
process: 200 / 291. Epoch 146
process: 250 / 291. Epoch 146
process: 291 / 291. Epoch 146
Loss of epoch 146 = 5.588856280874141
process: 50 / 291. Epoch 147
process: 100 / 291. Epoch 147
process: 150 / 291. Epoch 147
process: 200 / 291. Epoch 147
process: 250 / 291. Epoch 147
process: 291 / 291. Epoch 147
Loss of epoch 147 = 5.559012396638746
process: 50 / 291. Epoch 148
process: 100 / 291. Epoch 148
process: 150 / 291. Epoch 148
process: 200 / 291. Epoch 148
process: 250 / 291. Epoch 148
process: 291 / 291. Epoch 148
Loss of epoch 148 = 5.602620442708333
process: 50 / 291. Epoch 149
process: 100 / 291. Epoch 149
process: 150 / 291. Epoch 149
process: 200 / 291. Epoch 149
process: 250 / 291. Epoch 149
process: 291 / 291. Epoch 149
Loss of epoch 149 = 5.607418519115121
process: 50 / 291. Epoch 150
process: 100 / 291. Epoch 150
process: 150 / 291. Epoch 150
process: 200 / 291. Epoch 150
process: 250 / 291. Epoch 150
process: 291 / 291. Epoch 150
Loss of epoch 150 = 5.470528618986254
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-150. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.795953
     epoch  training_loss
145    146       5.588856
146    147       5.559012
147    148       5.602620
148    149       5.607419
149    150       5.470529
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
10        110  0.013559  0.168085      0.270182   0.269590
11        120  0.013527  0.162151      0.273893   0.273397
12        130  0.013608  0.157694      0.275936   0.275421
13        140  0.013649  0.154271      0.279618   0.279196
14        150  0.013743  0.148190      0.282687   0.282336
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
10      110.0  0.968250  0.976888  ...  0.960010  0.955693  0.935169
11      120.0  0.966889  0.977000  ...  0.959277  0.955856  0.941114
12      130.0  0.968049  0.976877  ...  0.960091  0.955367  0.941766
13      140.0  0.968986  0.976908  ...  0.960417  0.956345  0.943150
14      150.0  0.969817  0.977855  ...  0.960580  0.955775  0.940951

[5 rows x 13 columns]
process: 50 / 291. Epoch 151
process: 100 / 291. Epoch 151
process: 150 / 291. Epoch 151
process: 200 / 291. Epoch 151
process: 250 / 291. Epoch 151
process: 291 / 291. Epoch 151
Loss of epoch 151 = 5.536525031545318
process: 50 / 291. Epoch 152
process: 100 / 291. Epoch 152
process: 150 / 291. Epoch 152
process: 200 / 291. Epoch 152
process: 250 / 291. Epoch 152
process: 291 / 291. Epoch 152
Loss of epoch 152 = 5.653891651900773
process: 50 / 291. Epoch 153
process: 100 / 291. Epoch 153
process: 150 / 291. Epoch 153
process: 200 / 291. Epoch 153
process: 250 / 291. Epoch 153
process: 291 / 291. Epoch 153
Loss of epoch 153 = 5.6349913082581615
process: 50 / 291. Epoch 154
process: 100 / 291. Epoch 154
process: 150 / 291. Epoch 154
process: 200 / 291. Epoch 154
process: 250 / 291. Epoch 154
process: 291 / 291. Epoch 154
Loss of epoch 154 = 5.376402759879725
process: 50 / 291. Epoch 155
process: 100 / 291. Epoch 155
process: 150 / 291. Epoch 155
process: 200 / 291. Epoch 155
process: 250 / 291. Epoch 155
process: 291 / 291. Epoch 155
Loss of epoch 155 = 5.38745578621671
process: 50 / 291. Epoch 156
process: 100 / 291. Epoch 156
process: 150 / 291. Epoch 156
process: 200 / 291. Epoch 156
process: 250 / 291. Epoch 156
process: 291 / 291. Epoch 156
Loss of epoch 156 = 5.4085043156679555
process: 50 / 291. Epoch 157
process: 100 / 291. Epoch 157
process: 150 / 291. Epoch 157
process: 200 / 291. Epoch 157
process: 250 / 291. Epoch 157
process: 291 / 291. Epoch 157
Loss of epoch 157 = 5.349824151632302
process: 50 / 291. Epoch 158
process: 100 / 291. Epoch 158
process: 150 / 291. Epoch 158
process: 200 / 291. Epoch 158
process: 250 / 291. Epoch 158
process: 291 / 291. Epoch 158
Loss of epoch 158 = 5.4589311003275345
process: 50 / 291. Epoch 159
process: 100 / 291. Epoch 159
process: 150 / 291. Epoch 159
process: 200 / 291. Epoch 159
process: 250 / 291. Epoch 159
process: 291 / 291. Epoch 159
Loss of epoch 159 = 5.388949154988187
process: 50 / 291. Epoch 160
process: 100 / 291. Epoch 160
process: 150 / 291. Epoch 160
process: 200 / 291. Epoch 160
process: 250 / 291. Epoch 160
process: 291 / 291. Epoch 160
Loss of epoch 160 = 5.386789643068084
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-160. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.795824
     epoch  training_loss
155    156       5.408504
156    157       5.349824
157    158       5.458931
158    159       5.388949
159    160       5.386790
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
11        120  0.013527  0.162151      0.273893   0.273397
12        130  0.013608  0.157694      0.275936   0.275421
13        140  0.013649  0.154271      0.279618   0.279196
14        150  0.013743  0.148190      0.282687   0.282336
15        160  0.013809  0.143862      0.284193   0.283876
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
11      120.0  0.966889  0.977000  ...  0.959277  0.955856  0.941114
12      130.0  0.968049  0.976877  ...  0.960091  0.955367  0.941766
13      140.0  0.968986  0.976908  ...  0.960417  0.956345  0.943150
14      150.0  0.969817  0.977855  ...  0.960580  0.955775  0.940951
15      160.0  0.971187  0.977416  ...  0.961231  0.955449  0.939892

[5 rows x 13 columns]
process: 50 / 291. Epoch 161
process: 100 / 291. Epoch 161
process: 150 / 291. Epoch 161
process: 200 / 291. Epoch 161
process: 250 / 291. Epoch 161
process: 291 / 291. Epoch 161
Loss of epoch 161 = 5.502282001718213
process: 50 / 291. Epoch 162
process: 100 / 291. Epoch 162
process: 150 / 291. Epoch 162
process: 200 / 291. Epoch 162
process: 250 / 291. Epoch 162
process: 291 / 291. Epoch 162
Loss of epoch 162 = 5.262058533344073
process: 50 / 291. Epoch 163
process: 100 / 291. Epoch 163
process: 150 / 291. Epoch 163
process: 200 / 291. Epoch 163
process: 250 / 291. Epoch 163
process: 291 / 291. Epoch 163
Loss of epoch 163 = 5.309005684868986
process: 50 / 291. Epoch 164
process: 100 / 291. Epoch 164
process: 150 / 291. Epoch 164
process: 200 / 291. Epoch 164
process: 250 / 291. Epoch 164
process: 291 / 291. Epoch 164
Loss of epoch 164 = 5.315819809117268
process: 50 / 291. Epoch 165
process: 100 / 291. Epoch 165
process: 150 / 291. Epoch 165
process: 200 / 291. Epoch 165
process: 250 / 291. Epoch 165
process: 291 / 291. Epoch 165
Loss of epoch 165 = 5.250867496241409
process: 50 / 291. Epoch 166
process: 100 / 291. Epoch 166
process: 150 / 291. Epoch 166
process: 200 / 291. Epoch 166
process: 250 / 291. Epoch 166
process: 291 / 291. Epoch 166
Loss of epoch 166 = 5.3311234831400345
process: 50 / 291. Epoch 167
process: 100 / 291. Epoch 167
process: 150 / 291. Epoch 167
process: 200 / 291. Epoch 167
process: 250 / 291. Epoch 167
process: 291 / 291. Epoch 167
Loss of epoch 167 = 5.417691889497423
process: 50 / 291. Epoch 168
process: 100 / 291. Epoch 168
process: 150 / 291. Epoch 168
process: 200 / 291. Epoch 168
process: 250 / 291. Epoch 168
process: 291 / 291. Epoch 168
Loss of epoch 168 = 5.2422273511329465
process: 50 / 291. Epoch 169
process: 100 / 291. Epoch 169
process: 150 / 291. Epoch 169
process: 200 / 291. Epoch 169
process: 250 / 291. Epoch 169
process: 291 / 291. Epoch 169
Loss of epoch 169 = 5.283482082930627
process: 50 / 291. Epoch 170
process: 100 / 291. Epoch 170
process: 150 / 291. Epoch 170
process: 200 / 291. Epoch 170
process: 250 / 291. Epoch 170
process: 291 / 291. Epoch 170
Loss of epoch 170 = 5.2641748382463485
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-170. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.783753
     epoch  training_loss
165    166       5.331123
166    167       5.417692
167    168       5.242227
168    169       5.283482
169    170       5.264175
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
12        130  0.013608  0.157694      0.275936   0.275421
13        140  0.013649  0.154271      0.279618   0.279196
14        150  0.013743  0.148190      0.282687   0.282336
15        160  0.013809  0.143862      0.284193   0.283876
16        170  0.014108  0.136505      0.287358   0.287087
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
12      130.0  0.968049  0.976877  ...  0.960091  0.955367  0.941766
13      140.0  0.968986  0.976908  ...  0.960417  0.956345  0.943150
14      150.0  0.969817  0.977855  ...  0.960580  0.955775  0.940951
15      160.0  0.971187  0.977416  ...  0.961231  0.955449  0.939892
16      170.0  0.971598  0.978349  ...  0.961150  0.954309  0.932481

[5 rows x 13 columns]
process: 50 / 291. Epoch 171
process: 100 / 291. Epoch 171
process: 150 / 291. Epoch 171
process: 200 / 291. Epoch 171
process: 250 / 291. Epoch 171
process: 291 / 291. Epoch 171
Loss of epoch 171 = 5.245035807291667
process: 50 / 291. Epoch 172
process: 100 / 291. Epoch 172
process: 150 / 291. Epoch 172
process: 200 / 291. Epoch 172
process: 250 / 291. Epoch 172
process: 291 / 291. Epoch 172
Loss of epoch 172 = 5.161683597105885
process: 50 / 291. Epoch 173
process: 100 / 291. Epoch 173
process: 150 / 291. Epoch 173
process: 200 / 291. Epoch 173
process: 250 / 291. Epoch 173
process: 291 / 291. Epoch 173
Loss of epoch 173 = 5.135029481448669
process: 50 / 291. Epoch 174
process: 100 / 291. Epoch 174
process: 150 / 291. Epoch 174
process: 200 / 291. Epoch 174
process: 250 / 291. Epoch 174
process: 291 / 291. Epoch 174
Loss of epoch 174 = 5.162283461528136
process: 50 / 291. Epoch 175
process: 100 / 291. Epoch 175
process: 150 / 291. Epoch 175
process: 200 / 291. Epoch 175
process: 250 / 291. Epoch 175
process: 291 / 291. Epoch 175
Loss of epoch 175 = 5.172602388047681
process: 50 / 291. Epoch 176
process: 100 / 291. Epoch 176
process: 150 / 291. Epoch 176
process: 200 / 291. Epoch 176
process: 250 / 291. Epoch 176
process: 291 / 291. Epoch 176
Loss of epoch 176 = 5.257085111952319
process: 50 / 291. Epoch 177
process: 100 / 291. Epoch 177
process: 150 / 291. Epoch 177
process: 200 / 291. Epoch 177
process: 250 / 291. Epoch 177
process: 291 / 291. Epoch 177
Loss of epoch 177 = 5.140523903967998
process: 50 / 291. Epoch 178
process: 100 / 291. Epoch 178
process: 150 / 291. Epoch 178
process: 200 / 291. Epoch 178
process: 250 / 291. Epoch 178
process: 291 / 291. Epoch 178
Loss of epoch 178 = 5.119381409740121
process: 50 / 291. Epoch 179
process: 100 / 291. Epoch 179
process: 150 / 291. Epoch 179
process: 200 / 291. Epoch 179
process: 250 / 291. Epoch 179
process: 291 / 291. Epoch 179
Loss of epoch 179 = 5.08081516121671
process: 50 / 291. Epoch 180
process: 100 / 291. Epoch 180
process: 150 / 291. Epoch 180
process: 200 / 291. Epoch 180
process: 250 / 291. Epoch 180
process: 291 / 291. Epoch 180
Loss of epoch 180 = 4.9724557358784365
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-180. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.798704
     epoch  training_loss
175    176       5.257085
176    177       5.140524
177    178       5.119381
178    179       5.080815
179    180       4.972456
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
13        140  0.013649  0.154271      0.279618   0.279196
14        150  0.013743  0.148190      0.282687   0.282336
15        160  0.013809  0.143862      0.284193   0.283876
16        170  0.014108  0.136505      0.287358   0.287087
17        180  0.013813  0.137627      0.289620   0.289402
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
13      140.0  0.968986  0.976908  ...  0.960417  0.956345  0.943150
14      150.0  0.969817  0.977855  ...  0.960580  0.955775  0.940951
15      160.0  0.971187  0.977416  ...  0.961231  0.955449  0.939892
16      170.0  0.971598  0.978349  ...  0.961150  0.954309  0.932481
17      180.0  0.969907  0.977383  ...  0.960254  0.954390  0.943150

[5 rows x 13 columns]
process: 50 / 291. Epoch 181
process: 100 / 291. Epoch 181
process: 150 / 291. Epoch 181
process: 200 / 291. Epoch 181
process: 250 / 291. Epoch 181
process: 291 / 291. Epoch 181
Loss of epoch 181 = 5.138830860046177
process: 50 / 291. Epoch 182
process: 100 / 291. Epoch 182
process: 150 / 291. Epoch 182
process: 200 / 291. Epoch 182
process: 250 / 291. Epoch 182
process: 291 / 291. Epoch 182
Loss of epoch 182 = 5.245567715045103
process: 50 / 291. Epoch 183
process: 100 / 291. Epoch 183
process: 150 / 291. Epoch 183
process: 200 / 291. Epoch 183
process: 250 / 291. Epoch 183
process: 291 / 291. Epoch 183
Loss of epoch 183 = 5.053262926868556
process: 50 / 291. Epoch 184
process: 100 / 291. Epoch 184
process: 150 / 291. Epoch 184
process: 200 / 291. Epoch 184
process: 250 / 291. Epoch 184
process: 291 / 291. Epoch 184
Loss of epoch 184 = 4.935278404209622
process: 50 / 291. Epoch 185
process: 100 / 291. Epoch 185
process: 150 / 291. Epoch 185
process: 200 / 291. Epoch 185
process: 250 / 291. Epoch 185
process: 291 / 291. Epoch 185
Loss of epoch 185 = 4.98949943621134
process: 50 / 291. Epoch 186
process: 100 / 291. Epoch 186
process: 150 / 291. Epoch 186
process: 200 / 291. Epoch 186
process: 250 / 291. Epoch 186
process: 291 / 291. Epoch 186
Loss of epoch 186 = 5.124687902706185
process: 50 / 291. Epoch 187
process: 100 / 291. Epoch 187
process: 150 / 291. Epoch 187
process: 200 / 291. Epoch 187
process: 250 / 291. Epoch 187
process: 291 / 291. Epoch 187
Loss of epoch 187 = 5.140060372368986
process: 50 / 291. Epoch 188
process: 100 / 291. Epoch 188
process: 150 / 291. Epoch 188
process: 200 / 291. Epoch 188
process: 250 / 291. Epoch 188
process: 291 / 291. Epoch 188
Loss of epoch 188 = 4.976625842327105
process: 50 / 291. Epoch 189
process: 100 / 291. Epoch 189
process: 150 / 291. Epoch 189
process: 200 / 291. Epoch 189
process: 250 / 291. Epoch 189
process: 291 / 291. Epoch 189
Loss of epoch 189 = 5.001018511060996
process: 50 / 291. Epoch 190
process: 100 / 291. Epoch 190
process: 150 / 291. Epoch 190
process: 200 / 291. Epoch 190
process: 250 / 291. Epoch 190
process: 291 / 291. Epoch 190
Loss of epoch 190 = 4.804865361898625
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-190. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.793575
     epoch  training_loss
185    186       5.124688
186    187       5.140060
187    188       4.976626
188    189       5.001019
189    190       4.804865
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
14        150  0.013743  0.148190      0.282687   0.282336
15        160  0.013809  0.143862      0.284193   0.283876
16        170  0.014108  0.136505      0.287358   0.287087
17        180  0.013813  0.137627      0.289620   0.289402
18        190  0.013951  0.133178      0.291195   0.291024
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
14      150.0  0.969817  0.977855  ...  0.960580  0.955775  0.940951
15      160.0  0.971187  0.977416  ...  0.961231  0.955449  0.939892
16      170.0  0.971598  0.978349  ...  0.961150  0.954309  0.932481
17      180.0  0.969907  0.977383  ...  0.960254  0.954390  0.943150
18      190.0  0.970750  0.977388  ...  0.960661  0.954553  0.940626

[5 rows x 13 columns]
process: 50 / 291. Epoch 191
process: 100 / 291. Epoch 191
process: 150 / 291. Epoch 191
process: 200 / 291. Epoch 191
process: 250 / 291. Epoch 191
process: 291 / 291. Epoch 191
Loss of epoch 191 = 4.998199567762027
process: 50 / 291. Epoch 192
process: 100 / 291. Epoch 192
process: 150 / 291. Epoch 192
process: 200 / 291. Epoch 192
process: 250 / 291. Epoch 192
process: 291 / 291. Epoch 192
Loss of epoch 192 = 5.09594978253866
process: 50 / 291. Epoch 193
process: 100 / 291. Epoch 193
process: 150 / 291. Epoch 193
process: 200 / 291. Epoch 193
process: 250 / 291. Epoch 193
process: 291 / 291. Epoch 193
Loss of epoch 193 = 4.983797787800687
process: 50 / 291. Epoch 194
process: 100 / 291. Epoch 194
process: 150 / 291. Epoch 194
process: 200 / 291. Epoch 194
process: 250 / 291. Epoch 194
process: 291 / 291. Epoch 194
Loss of epoch 194 = 4.89818748657646
process: 50 / 291. Epoch 195
process: 100 / 291. Epoch 195
process: 150 / 291. Epoch 195
process: 200 / 291. Epoch 195
process: 250 / 291. Epoch 195
process: 291 / 291. Epoch 195
Loss of epoch 195 = 4.808273262993986
process: 50 / 291. Epoch 196
process: 100 / 291. Epoch 196
process: 150 / 291. Epoch 196
process: 200 / 291. Epoch 196
process: 250 / 291. Epoch 196
process: 291 / 291. Epoch 196
Loss of epoch 196 = 4.884018101643041
process: 50 / 291. Epoch 197
process: 100 / 291. Epoch 197
process: 150 / 291. Epoch 197
process: 200 / 291. Epoch 197
process: 250 / 291. Epoch 197
process: 291 / 291. Epoch 197
Loss of epoch 197 = 4.8226288995382305
process: 50 / 291. Epoch 198
process: 100 / 291. Epoch 198
process: 150 / 291. Epoch 198
process: 200 / 291. Epoch 198
process: 250 / 291. Epoch 198
process: 291 / 291. Epoch 198
Loss of epoch 198 = 4.906045291022337
process: 50 / 291. Epoch 199
process: 100 / 291. Epoch 199
process: 150 / 291. Epoch 199
process: 200 / 291. Epoch 199
process: 250 / 291. Epoch 199
process: 291 / 291. Epoch 199
Loss of epoch 199 = 4.974311540216925
process: 50 / 291. Epoch 200
process: 100 / 291. Epoch 200
process: 150 / 291. Epoch 200
process: 200 / 291. Epoch 200
process: 250 / 291. Epoch 200
process: 291 / 291. Epoch 200
Loss of epoch 200 = 5.137618546633377
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-200. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.798178
     epoch  training_loss
195    196       4.884018
196    197       4.822629
197    198       4.906045
198    199       4.974312
199    200       5.137619
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
15        160  0.013809  0.143862      0.284193   0.283876
16        170  0.014108  0.136505      0.287358   0.287087
17        180  0.013813  0.137627      0.289620   0.289402
18        190  0.013951  0.133178      0.291195   0.291024
19        200  0.014033  0.132805      0.292523   0.292333
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
15      160.0  0.971187  0.977416  ...  0.961231  0.955449  0.939892
16      170.0  0.971598  0.978349  ...  0.961150  0.954309  0.932481
17      180.0  0.969907  0.977383  ...  0.960254  0.954390  0.943150
18      190.0  0.970750  0.977388  ...  0.960661  0.954553  0.940626
19      200.0  0.970844  0.977615  ...  0.960417  0.954960  0.941766

[5 rows x 13 columns]
process: 50 / 291. Epoch 201
process: 100 / 291. Epoch 201
process: 150 / 291. Epoch 201
process: 200 / 291. Epoch 201
process: 250 / 291. Epoch 201
process: 291 / 291. Epoch 201
Loss of epoch 201 = 4.8515478180036515
process: 50 / 291. Epoch 202
process: 100 / 291. Epoch 202
process: 150 / 291. Epoch 202
process: 200 / 291. Epoch 202
process: 250 / 291. Epoch 202
process: 291 / 291. Epoch 202
Loss of epoch 202 = 4.711634685083763
process: 50 / 291. Epoch 203
process: 100 / 291. Epoch 203
process: 150 / 291. Epoch 203
process: 200 / 291. Epoch 203
process: 250 / 291. Epoch 203
process: 291 / 291. Epoch 203
Loss of epoch 203 = 4.893486730831185
process: 50 / 291. Epoch 204
process: 100 / 291. Epoch 204
process: 150 / 291. Epoch 204
process: 200 / 291. Epoch 204
process: 250 / 291. Epoch 204
process: 291 / 291. Epoch 204
Loss of epoch 204 = 4.742413602743771
process: 50 / 291. Epoch 205
process: 100 / 291. Epoch 205
process: 150 / 291. Epoch 205
process: 200 / 291. Epoch 205
process: 250 / 291. Epoch 205
process: 291 / 291. Epoch 205
Loss of epoch 205 = 4.947221579010954
process: 50 / 291. Epoch 206
process: 100 / 291. Epoch 206
process: 150 / 291. Epoch 206
process: 200 / 291. Epoch 206
process: 250 / 291. Epoch 206
process: 291 / 291. Epoch 206
Loss of epoch 206 = 4.808374778511598
process: 50 / 291. Epoch 207
process: 100 / 291. Epoch 207
process: 150 / 291. Epoch 207
process: 200 / 291. Epoch 207
process: 250 / 291. Epoch 207
process: 291 / 291. Epoch 207
Loss of epoch 207 = 4.858813728253866
process: 50 / 291. Epoch 208
process: 100 / 291. Epoch 208
process: 150 / 291. Epoch 208
process: 200 / 291. Epoch 208
process: 250 / 291. Epoch 208
process: 291 / 291. Epoch 208
Loss of epoch 208 = 4.846166237113402
process: 50 / 291. Epoch 209
process: 100 / 291. Epoch 209
process: 150 / 291. Epoch 209
process: 200 / 291. Epoch 209
process: 250 / 291. Epoch 209
process: 291 / 291. Epoch 209
Loss of epoch 209 = 4.780968105670103
process: 50 / 291. Epoch 210
process: 100 / 291. Epoch 210
process: 150 / 291. Epoch 210
process: 200 / 291. Epoch 210
process: 250 / 291. Epoch 210
process: 291 / 291. Epoch 210
Loss of epoch 210 = 4.731697423351589
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-210. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.792560
     epoch  training_loss
205    206       4.808375
206    207       4.858814
207    208       4.846166
208    209       4.780968
209    210       4.731697
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
16        170  0.014108  0.136505      0.287358   0.287087
17        180  0.013813  0.137627      0.289620   0.289402
18        190  0.013951  0.133178      0.291195   0.291024
19        200  0.014033  0.132805      0.292523   0.292333
20        210  0.014154  0.128106      0.295840   0.295770
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
16      170.0  0.971598  0.978349  ...  0.961150  0.954309  0.932481
17      180.0  0.969907  0.977383  ...  0.960254  0.954390  0.943150
18      190.0  0.970750  0.977388  ...  0.960661  0.954553  0.940626
19      200.0  0.970844  0.977615  ...  0.960417  0.954960  0.941766
20      210.0  0.971791  0.977928  ...  0.960743  0.954634  0.938264

[5 rows x 13 columns]
process: 50 / 291. Epoch 211
process: 100 / 291. Epoch 211
process: 150 / 291. Epoch 211
process: 200 / 291. Epoch 211
process: 250 / 291. Epoch 211
process: 291 / 291. Epoch 211
Loss of epoch 211 = 4.689038673217354
process: 50 / 291. Epoch 212
process: 100 / 291. Epoch 212
process: 150 / 291. Epoch 212
process: 200 / 291. Epoch 212
process: 250 / 291. Epoch 212
process: 291 / 291. Epoch 212
Loss of epoch 212 = 4.71789089347079
process: 50 / 291. Epoch 213
process: 100 / 291. Epoch 213
process: 150 / 291. Epoch 213
process: 200 / 291. Epoch 213
process: 250 / 291. Epoch 213
process: 291 / 291. Epoch 213
Loss of epoch 213 = 4.875184573668385
process: 50 / 291. Epoch 214
process: 100 / 291. Epoch 214
process: 150 / 291. Epoch 214
process: 200 / 291. Epoch 214
process: 250 / 291. Epoch 214
process: 291 / 291. Epoch 214
Loss of epoch 214 = 4.83069434936104
process: 50 / 291. Epoch 215
process: 100 / 291. Epoch 215
process: 150 / 291. Epoch 215
process: 200 / 291. Epoch 215
process: 250 / 291. Epoch 215
process: 291 / 291. Epoch 215
Loss of epoch 215 = 4.650946443433204
process: 50 / 291. Epoch 216
process: 100 / 291. Epoch 216
process: 150 / 291. Epoch 216
process: 200 / 291. Epoch 216
process: 250 / 291. Epoch 216
process: 291 / 291. Epoch 216
Loss of epoch 216 = 4.611537028833763
process: 50 / 291. Epoch 217
process: 100 / 291. Epoch 217
process: 150 / 291. Epoch 217
process: 200 / 291. Epoch 217
process: 250 / 291. Epoch 217
process: 291 / 291. Epoch 217
Loss of epoch 217 = 4.574356341280069
process: 50 / 291. Epoch 218
process: 100 / 291. Epoch 218
process: 150 / 291. Epoch 218
process: 200 / 291. Epoch 218
process: 250 / 291. Epoch 218
process: 291 / 291. Epoch 218
Loss of epoch 218 = 4.783468239905498
process: 50 / 291. Epoch 219
process: 100 / 291. Epoch 219
process: 150 / 291. Epoch 219
process: 200 / 291. Epoch 219
process: 250 / 291. Epoch 219
process: 291 / 291. Epoch 219
Loss of epoch 219 = 4.829204755960052
process: 50 / 291. Epoch 220
process: 100 / 291. Epoch 220
process: 150 / 291. Epoch 220
process: 200 / 291. Epoch 220
process: 250 / 291. Epoch 220
process: 291 / 291. Epoch 220
Loss of epoch 220 = 4.6518990952534365
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-220. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.795672
     epoch  training_loss
215    216       4.611537
216    217       4.574356
217    218       4.783468
218    219       4.829205
219    220       4.651899
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
17        180  0.013813  0.137627      0.289620   0.289402
18        190  0.013951  0.133178      0.291195   0.291024
19        200  0.014033  0.132805      0.292523   0.292333
20        210  0.014154  0.128106      0.295840   0.295770
21        220  0.014147  0.125990      0.296253   0.296131
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
17      180.0  0.969907  0.977383  ...  0.960254  0.954390  0.943150
18      190.0  0.970750  0.977388  ...  0.960661  0.954553  0.940626
19      200.0  0.970844  0.977615  ...  0.960417  0.954960  0.941766
20      210.0  0.971791  0.977928  ...  0.960743  0.954634  0.938264
21      220.0  0.971589  0.978041  ...  0.960906  0.954797  0.941603

[5 rows x 13 columns]
process: 50 / 291. Epoch 221
process: 100 / 291. Epoch 221
process: 150 / 291. Epoch 221
process: 200 / 291. Epoch 221
process: 250 / 291. Epoch 221
process: 291 / 291. Epoch 221
Loss of epoch 221 = 4.666414555815077
process: 50 / 291. Epoch 222
process: 100 / 291. Epoch 222
process: 150 / 291. Epoch 222
process: 200 / 291. Epoch 222
process: 250 / 291. Epoch 222
process: 291 / 291. Epoch 222
Loss of epoch 222 = 4.6360979112972505
process: 50 / 291. Epoch 223
process: 100 / 291. Epoch 223
process: 150 / 291. Epoch 223
process: 200 / 291. Epoch 223
process: 250 / 291. Epoch 223
process: 291 / 291. Epoch 223
Loss of epoch 223 = 4.6687116590152495
process: 50 / 291. Epoch 224
process: 100 / 291. Epoch 224
process: 150 / 291. Epoch 224
process: 200 / 291. Epoch 224
process: 250 / 291. Epoch 224
process: 291 / 291. Epoch 224
Loss of epoch 224 = 4.801427257839347
process: 50 / 291. Epoch 225
process: 100 / 291. Epoch 225
process: 150 / 291. Epoch 225
process: 200 / 291. Epoch 225
process: 250 / 291. Epoch 225
process: 291 / 291. Epoch 225
Loss of epoch 225 = 4.690257698399914
process: 50 / 291. Epoch 226
process: 100 / 291. Epoch 226
process: 150 / 291. Epoch 226
process: 200 / 291. Epoch 226
process: 250 / 291. Epoch 226
process: 291 / 291. Epoch 226
Loss of epoch 226 = 4.575124419431916
process: 50 / 291. Epoch 227
process: 100 / 291. Epoch 227
process: 150 / 291. Epoch 227
process: 200 / 291. Epoch 227
process: 250 / 291. Epoch 227
process: 291 / 291. Epoch 227
Loss of epoch 227 = 4.583288867858677
process: 50 / 291. Epoch 228
process: 100 / 291. Epoch 228
process: 150 / 291. Epoch 228
process: 200 / 291. Epoch 228
process: 250 / 291. Epoch 228
process: 291 / 291. Epoch 228
Loss of epoch 228 = 4.5868607878275345
process: 50 / 291. Epoch 229
process: 100 / 291. Epoch 229
process: 150 / 291. Epoch 229
process: 200 / 291. Epoch 229
process: 250 / 291. Epoch 229
process: 291 / 291. Epoch 229
Loss of epoch 229 = 4.6776441855938575
process: 50 / 291. Epoch 230
process: 100 / 291. Epoch 230
process: 150 / 291. Epoch 230
process: 200 / 291. Epoch 230
process: 250 / 291. Epoch 230
process: 291 / 291. Epoch 230
Loss of epoch 230 = 4.658534938117483
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-230. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.795837
     epoch  training_loss
225    226       4.575124
226    227       4.583289
227    228       4.586861
228    229       4.677644
229    230       4.658535
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
18        190  0.013951  0.133178      0.291195   0.291024
19        200  0.014033  0.132805      0.292523   0.292333
20        210  0.014154  0.128106      0.295840   0.295770
21        220  0.014147  0.125990      0.296253   0.296131
22        230  0.014296  0.124160      0.298329   0.298275
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
18      190.0  0.970750  0.977388  ...  0.960661  0.954553  0.940626
19      200.0  0.970844  0.977615  ...  0.960417  0.954960  0.941766
20      210.0  0.971791  0.977928  ...  0.960743  0.954634  0.938264
21      220.0  0.971589  0.978041  ...  0.960906  0.954797  0.941603
22      230.0  0.970536  0.977810  ...  0.960498  0.954309  0.941277

[5 rows x 13 columns]
process: 50 / 291. Epoch 231
process: 100 / 291. Epoch 231
process: 150 / 291. Epoch 231
process: 200 / 291. Epoch 231
process: 250 / 291. Epoch 231
process: 291 / 291. Epoch 231
Loss of epoch 231 = 4.596766940506873
process: 50 / 291. Epoch 232
process: 100 / 291. Epoch 232
process: 150 / 291. Epoch 232
process: 200 / 291. Epoch 232
process: 250 / 291. Epoch 232
process: 291 / 291. Epoch 232
Loss of epoch 232 = 4.577857368180842
process: 50 / 291. Epoch 233
process: 100 / 291. Epoch 233
process: 150 / 291. Epoch 233
process: 200 / 291. Epoch 233
process: 250 / 291. Epoch 233
process: 291 / 291. Epoch 233
Loss of epoch 233 = 4.57141490818299
process: 50 / 291. Epoch 234
process: 100 / 291. Epoch 234
process: 150 / 291. Epoch 234
process: 200 / 291. Epoch 234
process: 250 / 291. Epoch 234
process: 291 / 291. Epoch 234
Loss of epoch 234 = 4.559183546767612
process: 50 / 291. Epoch 235
process: 100 / 291. Epoch 235
process: 150 / 291. Epoch 235
process: 200 / 291. Epoch 235
process: 250 / 291. Epoch 235
process: 291 / 291. Epoch 235
Loss of epoch 235 = 4.524953520994416
process: 50 / 291. Epoch 236
process: 100 / 291. Epoch 236
process: 150 / 291. Epoch 236
process: 200 / 291. Epoch 236
process: 250 / 291. Epoch 236
process: 291 / 291. Epoch 236
Loss of epoch 236 = 4.538515490764605
process: 50 / 291. Epoch 237
process: 100 / 291. Epoch 237
process: 150 / 291. Epoch 237
process: 200 / 291. Epoch 237
process: 250 / 291. Epoch 237
process: 291 / 291. Epoch 237
Loss of epoch 237 = 4.42029060285116
process: 50 / 291. Epoch 238
process: 100 / 291. Epoch 238
process: 150 / 291. Epoch 238
process: 200 / 291. Epoch 238
process: 250 / 291. Epoch 238
process: 291 / 291. Epoch 238
Loss of epoch 238 = 4.4723626100730245
process: 50 / 291. Epoch 239
process: 100 / 291. Epoch 239
process: 150 / 291. Epoch 239
process: 200 / 291. Epoch 239
process: 250 / 291. Epoch 239
process: 291 / 291. Epoch 239
Loss of epoch 239 = 4.511544243986254
process: 50 / 291. Epoch 240
process: 100 / 291. Epoch 240
process: 150 / 291. Epoch 240
process: 200 / 291. Epoch 240
process: 250 / 291. Epoch 240
process: 291 / 291. Epoch 240
Loss of epoch 240 = 4.744817255288875
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-240. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.789842
     epoch  training_loss
235    236       4.538515
236    237       4.420291
237    238       4.472363
238    239       4.511544
239    240       4.744817
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
19        200  0.014033  0.132805      0.292523   0.292333
20        210  0.014154  0.128106      0.295840   0.295770
21        220  0.014147  0.125990      0.296253   0.296131
22        230  0.014296  0.124160      0.298329   0.298275
23        240  0.014306  0.120709      0.300009   0.299982
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
19      200.0  0.970844  0.977615  ...  0.960417  0.954960  0.941766
20      210.0  0.971791  0.977928  ...  0.960743  0.954634  0.938264
21      220.0  0.971589  0.978041  ...  0.960906  0.954797  0.941603
22      230.0  0.970536  0.977810  ...  0.960498  0.954309  0.941277
23      240.0  0.971567  0.978464  ...  0.960336  0.954553  0.938182

[5 rows x 13 columns]
process: 50 / 291. Epoch 241
process: 100 / 291. Epoch 241
process: 150 / 291. Epoch 241
process: 200 / 291. Epoch 241
process: 250 / 291. Epoch 241
process: 291 / 291. Epoch 241
Loss of epoch 241 = 4.485977435030069
process: 50 / 291. Epoch 242
process: 100 / 291. Epoch 242
process: 150 / 291. Epoch 242
process: 200 / 291. Epoch 242
process: 250 / 291. Epoch 242
process: 291 / 291. Epoch 242
Loss of epoch 242 = 4.453512604703608
process: 50 / 291. Epoch 243
process: 100 / 291. Epoch 243
process: 150 / 291. Epoch 243
process: 200 / 291. Epoch 243
process: 250 / 291. Epoch 243
process: 291 / 291. Epoch 243
Loss of epoch 243 = 4.499592259987113
process: 50 / 291. Epoch 244
process: 100 / 291. Epoch 244
process: 150 / 291. Epoch 244
process: 200 / 291. Epoch 244
process: 250 / 291. Epoch 244
process: 291 / 291. Epoch 244
Loss of epoch 244 = 4.616031397658935
process: 50 / 291. Epoch 245
process: 100 / 291. Epoch 245
process: 150 / 291. Epoch 245
process: 200 / 291. Epoch 245
process: 250 / 291. Epoch 245
process: 291 / 291. Epoch 245
Loss of epoch 245 = 4.439020215850515
process: 50 / 291. Epoch 246
process: 100 / 291. Epoch 246
process: 150 / 291. Epoch 246
process: 200 / 291. Epoch 246
process: 250 / 291. Epoch 246
process: 291 / 291. Epoch 246
Loss of epoch 246 = 4.395578286082475
process: 50 / 291. Epoch 247
process: 100 / 291. Epoch 247
process: 150 / 291. Epoch 247
process: 200 / 291. Epoch 247
process: 250 / 291. Epoch 247
process: 291 / 291. Epoch 247
Loss of epoch 247 = 4.433929338487973
process: 50 / 291. Epoch 248
process: 100 / 291. Epoch 248
process: 150 / 291. Epoch 248
process: 200 / 291. Epoch 248
process: 250 / 291. Epoch 248
process: 291 / 291. Epoch 248
Loss of epoch 248 = 4.552704172036083
process: 50 / 291. Epoch 249
process: 100 / 291. Epoch 249
process: 150 / 291. Epoch 249
process: 200 / 291. Epoch 249
process: 250 / 291. Epoch 249
process: 291 / 291. Epoch 249
Loss of epoch 249 = 4.525126349065721
process: 50 / 291. Epoch 250
process: 100 / 291. Epoch 250
process: 150 / 291. Epoch 250
process: 200 / 291. Epoch 250
process: 250 / 291. Epoch 250
process: 291 / 291. Epoch 250
Loss of epoch 250 = 4.49109264255799
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-250. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.793730
     epoch  training_loss
245    246       4.395578
246    247       4.433929
247    248       4.552704
248    249       4.525126
249    250       4.491093
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
20        210  0.014154  0.128106      0.295840   0.295770
21        220  0.014147  0.125990      0.296253   0.296131
22        230  0.014296  0.124160      0.298329   0.298275
23        240  0.014306  0.120709      0.300009   0.299982
24        250  0.014276  0.119984      0.300835   0.300806
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
20      210.0  0.971791  0.977928  ...  0.960743  0.954634  0.938264
21      220.0  0.971589  0.978041  ...  0.960906  0.954797  0.941603
22      230.0  0.970536  0.977810  ...  0.960498  0.954309  0.941277
23      240.0  0.971567  0.978464  ...  0.960336  0.954553  0.938182
24      250.0  0.971129  0.977820  ...  0.959765  0.954634  0.940463

[5 rows x 13 columns]
process: 50 / 291. Epoch 251
process: 100 / 291. Epoch 251
process: 150 / 291. Epoch 251
process: 200 / 291. Epoch 251
process: 250 / 291. Epoch 251
process: 291 / 291. Epoch 251
Loss of epoch 251 = 4.319324611388531
process: 50 / 291. Epoch 252
process: 100 / 291. Epoch 252
process: 150 / 291. Epoch 252
process: 200 / 291. Epoch 252
process: 250 / 291. Epoch 252
process: 291 / 291. Epoch 252
Loss of epoch 252 = 4.462070950118127
process: 50 / 291. Epoch 253
process: 100 / 291. Epoch 253
process: 150 / 291. Epoch 253
process: 200 / 291. Epoch 253
process: 250 / 291. Epoch 253
process: 291 / 291. Epoch 253
Loss of epoch 253 = 4.474647548190507
process: 50 / 291. Epoch 254
process: 100 / 291. Epoch 254
process: 150 / 291. Epoch 254
process: 200 / 291. Epoch 254
process: 250 / 291. Epoch 254
process: 291 / 291. Epoch 254
Loss of epoch 254 = 4.4693708387027495
process: 50 / 291. Epoch 255
process: 100 / 291. Epoch 255
process: 150 / 291. Epoch 255
process: 200 / 291. Epoch 255
process: 250 / 291. Epoch 255
process: 291 / 291. Epoch 255
Loss of epoch 255 = 4.36255092555305
process: 50 / 291. Epoch 256
process: 100 / 291. Epoch 256
process: 150 / 291. Epoch 256
process: 200 / 291. Epoch 256
process: 250 / 291. Epoch 256
process: 291 / 291. Epoch 256
Loss of epoch 256 = 4.274324292579467
process: 50 / 291. Epoch 257
process: 100 / 291. Epoch 257
process: 150 / 291. Epoch 257
process: 200 / 291. Epoch 257
process: 250 / 291. Epoch 257
process: 291 / 291. Epoch 257
Loss of epoch 257 = 4.474457101723583
process: 50 / 291. Epoch 258
process: 100 / 291. Epoch 258
process: 150 / 291. Epoch 258
process: 200 / 291. Epoch 258
process: 250 / 291. Epoch 258
process: 291 / 291. Epoch 258
Loss of epoch 258 = 4.426096703178694
process: 50 / 291. Epoch 259
process: 100 / 291. Epoch 259
process: 150 / 291. Epoch 259
process: 200 / 291. Epoch 259
process: 250 / 291. Epoch 259
process: 291 / 291. Epoch 259
Loss of epoch 259 = 4.359355703661942
process: 50 / 291. Epoch 260
process: 100 / 291. Epoch 260
process: 150 / 291. Epoch 260
process: 200 / 291. Epoch 260
process: 250 / 291. Epoch 260
process: 291 / 291. Epoch 260
Loss of epoch 260 = 4.428354374731529
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-260. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.797704
     epoch  training_loss
255    256       4.274324
256    257       4.474457
257    258       4.426097
258    259       4.359356
259    260       4.428354
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
21        220  0.014147  0.125990      0.296253   0.296131
22        230  0.014296  0.124160      0.298329   0.298275
23        240  0.014306  0.120709      0.300009   0.299982
24        250  0.014276  0.119984      0.300835   0.300806
25        260  0.014256  0.119473      0.302099   0.302078
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
21      220.0  0.971589  0.978041  ...  0.960906  0.954797  0.941603
22      230.0  0.970536  0.977810  ...  0.960498  0.954309  0.941277
23      240.0  0.971567  0.978464  ...  0.960336  0.954553  0.938182
24      250.0  0.971129  0.977820  ...  0.959765  0.954634  0.940463
25      260.0  0.970427  0.977715  ...  0.960336  0.954716  0.941766

[5 rows x 13 columns]
process: 50 / 291. Epoch 261
process: 100 / 291. Epoch 261
process: 150 / 291. Epoch 261
process: 200 / 291. Epoch 261
process: 250 / 291. Epoch 261
process: 291 / 291. Epoch 261
Loss of epoch 261 = 4.377014369899055
process: 50 / 291. Epoch 262
process: 100 / 291. Epoch 262
process: 150 / 291. Epoch 262
process: 200 / 291. Epoch 262
process: 250 / 291. Epoch 262
process: 291 / 291. Epoch 262
Loss of epoch 262 = 4.379627765249141
process: 50 / 291. Epoch 263
process: 100 / 291. Epoch 263
process: 150 / 291. Epoch 263
process: 200 / 291. Epoch 263
process: 250 / 291. Epoch 263
process: 291 / 291. Epoch 263
Loss of epoch 263 = 4.348640363240979
process: 50 / 291. Epoch 264
process: 100 / 291. Epoch 264
process: 150 / 291. Epoch 264
process: 200 / 291. Epoch 264
process: 250 / 291. Epoch 264
process: 291 / 291. Epoch 264
Loss of epoch 264 = 4.329285297197165
process: 50 / 291. Epoch 265
process: 100 / 291. Epoch 265
process: 150 / 291. Epoch 265
process: 200 / 291. Epoch 265
process: 250 / 291. Epoch 265
process: 291 / 291. Epoch 265
Loss of epoch 265 = 4.456654971407861
process: 50 / 291. Epoch 266
process: 100 / 291. Epoch 266
process: 150 / 291. Epoch 266
process: 200 / 291. Epoch 266
process: 250 / 291. Epoch 266
process: 291 / 291. Epoch 266
Loss of epoch 266 = 4.4898765537747
process: 50 / 291. Epoch 267
process: 100 / 291. Epoch 267
process: 150 / 291. Epoch 267
process: 200 / 291. Epoch 267
process: 250 / 291. Epoch 267
process: 291 / 291. Epoch 267
Loss of epoch 267 = 4.354223716709622
process: 50 / 291. Epoch 268
process: 100 / 291. Epoch 268
process: 150 / 291. Epoch 268
process: 200 / 291. Epoch 268
process: 250 / 291. Epoch 268
process: 291 / 291. Epoch 268
Loss of epoch 268 = 4.3149984562929555
process: 50 / 291. Epoch 269
process: 100 / 291. Epoch 269
process: 150 / 291. Epoch 269
process: 200 / 291. Epoch 269
process: 250 / 291. Epoch 269
process: 291 / 291. Epoch 269
Loss of epoch 269 = 4.216999486549613
process: 50 / 291. Epoch 270
process: 100 / 291. Epoch 270
process: 150 / 291. Epoch 270
process: 200 / 291. Epoch 270
process: 250 / 291. Epoch 270
process: 291 / 291. Epoch 270
Loss of epoch 270 = 4.180887648330112
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-270. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.795248
     epoch  training_loss
265    266       4.489877
266    267       4.354224
267    268       4.314998
268    269       4.216999
269    270       4.180888
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
22        230  0.014296  0.124160      0.298329   0.298275
23        240  0.014306  0.120709      0.300009   0.299982
24        250  0.014276  0.119984      0.300835   0.300806
25        260  0.014256  0.119473      0.302099   0.302078
26        270  0.014302  0.116999      0.303358   0.303364
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
22      230.0  0.970536  0.977810  ...  0.960498  0.954309  0.941277
23      240.0  0.971567  0.978464  ...  0.960336  0.954553  0.938182
24      250.0  0.971129  0.977820  ...  0.959765  0.954634  0.940463
25      260.0  0.970427  0.977715  ...  0.960336  0.954716  0.941766
26      270.0  0.970802  0.977695  ...  0.959358  0.954064  0.942743

[5 rows x 13 columns]
process: 50 / 291. Epoch 271
process: 100 / 291. Epoch 271
process: 150 / 291. Epoch 271
process: 200 / 291. Epoch 271
process: 250 / 291. Epoch 271
process: 291 / 291. Epoch 271
Loss of epoch 271 = 4.387471726669888
process: 50 / 291. Epoch 272
process: 100 / 291. Epoch 272
process: 150 / 291. Epoch 272
process: 200 / 291. Epoch 272
process: 250 / 291. Epoch 272
process: 291 / 291. Epoch 272
Loss of epoch 272 = 4.411931932586985
process: 50 / 291. Epoch 273
process: 100 / 291. Epoch 273
process: 150 / 291. Epoch 273
process: 200 / 291. Epoch 273
process: 250 / 291. Epoch 273
process: 291 / 291. Epoch 273
Loss of epoch 273 = 4.242020544727234
process: 50 / 291. Epoch 274
process: 100 / 291. Epoch 274
process: 150 / 291. Epoch 274
process: 200 / 291. Epoch 274
process: 250 / 291. Epoch 274
process: 291 / 291. Epoch 274
Loss of epoch 274 = 4.343041908290378
process: 50 / 291. Epoch 275
process: 100 / 291. Epoch 275
process: 150 / 291. Epoch 275
process: 200 / 291. Epoch 275
process: 250 / 291. Epoch 275
process: 291 / 291. Epoch 275
Loss of epoch 275 = 4.221750161082475
process: 50 / 291. Epoch 276
process: 100 / 291. Epoch 276
process: 150 / 291. Epoch 276
process: 200 / 291. Epoch 276
process: 250 / 291. Epoch 276
process: 291 / 291. Epoch 276
Loss of epoch 276 = 4.23913616167311
process: 50 / 291. Epoch 277
process: 100 / 291. Epoch 277
process: 150 / 291. Epoch 277
process: 200 / 291. Epoch 277
process: 250 / 291. Epoch 277
process: 291 / 291. Epoch 277
Loss of epoch 277 = 4.285483448775773
process: 50 / 291. Epoch 278
process: 100 / 291. Epoch 278
process: 150 / 291. Epoch 278
process: 200 / 291. Epoch 278
process: 250 / 291. Epoch 278
process: 291 / 291. Epoch 278
Loss of epoch 278 = 4.300037921499141
process: 50 / 291. Epoch 279
process: 100 / 291. Epoch 279
process: 150 / 291. Epoch 279
process: 200 / 291. Epoch 279
process: 250 / 291. Epoch 279
process: 291 / 291. Epoch 279
Loss of epoch 279 = 4.312933748120704
process: 50 / 291. Epoch 280
process: 100 / 291. Epoch 280
process: 150 / 291. Epoch 280
process: 200 / 291. Epoch 280
process: 250 / 291. Epoch 280
process: 291 / 291. Epoch 280
Loss of epoch 280 = 4.166267735851589
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-280. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.784602
     epoch  training_loss
275    276       4.239136
276    277       4.285483
277    278       4.300038
278    279       4.312934
279    280       4.166268
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
23        240  0.014306  0.120709      0.300009   0.299982
24        250  0.014276  0.119984      0.300835   0.300806
25        260  0.014256  0.119473      0.302099   0.302078
26        270  0.014302  0.116999      0.303358   0.303364
27        280  0.014547  0.112656      0.305048   0.305105
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
23      240.0  0.971567  0.978464  ...  0.960336  0.954553  0.938182
24      250.0  0.971129  0.977820  ...  0.959765  0.954634  0.940463
25      260.0  0.970427  0.977715  ...  0.960336  0.954716  0.941766
26      270.0  0.970802  0.977695  ...  0.959358  0.954064  0.942743
27      280.0  0.972078  0.978656  ...  0.960091  0.953738  0.934354

[5 rows x 13 columns]
process: 50 / 291. Epoch 281
process: 100 / 291. Epoch 281
process: 150 / 291. Epoch 281
process: 200 / 291. Epoch 281
process: 250 / 291. Epoch 281
process: 291 / 291. Epoch 281
Loss of epoch 281 = 4.253023232791023
process: 50 / 291. Epoch 282
process: 100 / 291. Epoch 282
process: 150 / 291. Epoch 282
process: 200 / 291. Epoch 282
process: 250 / 291. Epoch 282
process: 291 / 291. Epoch 282
Loss of epoch 282 = 4.254867711018041
process: 50 / 291. Epoch 283
process: 100 / 291. Epoch 283
process: 150 / 291. Epoch 283
process: 200 / 291. Epoch 283
process: 250 / 291. Epoch 283
process: 291 / 291. Epoch 283
Loss of epoch 283 = 4.266091467998282
process: 50 / 291. Epoch 284
process: 100 / 291. Epoch 284
process: 150 / 291. Epoch 284
process: 200 / 291. Epoch 284
process: 250 / 291. Epoch 284
process: 291 / 291. Epoch 284
Loss of epoch 284 = 4.202215135711985
process: 50 / 291. Epoch 285
process: 100 / 291. Epoch 285
process: 150 / 291. Epoch 285
process: 200 / 291. Epoch 285
process: 250 / 291. Epoch 285
process: 291 / 291. Epoch 285
Loss of epoch 285 = 4.320878386087844
process: 50 / 291. Epoch 286
process: 100 / 291. Epoch 286
process: 150 / 291. Epoch 286
process: 200 / 291. Epoch 286
process: 250 / 291. Epoch 286
process: 291 / 291. Epoch 286
Loss of epoch 286 = 4.272450869845361
process: 50 / 291. Epoch 287
process: 100 / 291. Epoch 287
process: 150 / 291. Epoch 287
process: 200 / 291. Epoch 287
process: 250 / 291. Epoch 287
process: 291 / 291. Epoch 287
Loss of epoch 287 = 4.248107280927835
process: 50 / 291. Epoch 288
process: 100 / 291. Epoch 288
process: 150 / 291. Epoch 288
process: 200 / 291. Epoch 288
process: 250 / 291. Epoch 288
process: 291 / 291. Epoch 288
Loss of epoch 288 = 4.156776034954897
process: 50 / 291. Epoch 289
process: 100 / 291. Epoch 289
process: 150 / 291. Epoch 289
process: 200 / 291. Epoch 289
process: 250 / 291. Epoch 289
process: 291 / 291. Epoch 289
Loss of epoch 289 = 4.129430187526847
process: 50 / 291. Epoch 290
process: 100 / 291. Epoch 290
process: 150 / 291. Epoch 290
process: 200 / 291. Epoch 290
process: 250 / 291. Epoch 290
process: 291 / 291. Epoch 290
Loss of epoch 290 = 4.398009624677835
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-290. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.798822
     epoch  training_loss
285    286       4.272451
286    287       4.248107
287    288       4.156776
288    289       4.129430
289    290       4.398010
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
24        250  0.014276  0.119984      0.300835   0.300806
25        260  0.014256  0.119473      0.302099   0.302078
26        270  0.014302  0.116999      0.303358   0.303364
27        280  0.014547  0.112656      0.305048   0.305105
28        290  0.014518  0.114389      0.305988   0.306046
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
24      250.0  0.971129  0.977820  ...  0.959765  0.954634  0.940463
25      260.0  0.970427  0.977715  ...  0.960336  0.954716  0.941766
26      270.0  0.970802  0.977695  ...  0.959358  0.954064  0.942743
27      280.0  0.972078  0.978656  ...  0.960091  0.953738  0.934354
28      290.0  0.970695  0.977713  ...  0.959277  0.954634  0.942580

[5 rows x 13 columns]
process: 50 / 291. Epoch 291
process: 100 / 291. Epoch 291
process: 150 / 291. Epoch 291
process: 200 / 291. Epoch 291
process: 250 / 291. Epoch 291
process: 291 / 291. Epoch 291
Loss of epoch 291 = 4.315632718535223
process: 50 / 291. Epoch 292
process: 100 / 291. Epoch 292
process: 150 / 291. Epoch 292
process: 200 / 291. Epoch 292
process: 250 / 291. Epoch 292
process: 291 / 291. Epoch 292
Loss of epoch 292 = 4.1906264262510735
process: 50 / 291. Epoch 293
process: 100 / 291. Epoch 293
process: 150 / 291. Epoch 293
process: 200 / 291. Epoch 293
process: 250 / 291. Epoch 293
process: 291 / 291. Epoch 293
Loss of epoch 293 = 4.092927808204467
process: 50 / 291. Epoch 294
process: 100 / 291. Epoch 294
process: 150 / 291. Epoch 294
process: 200 / 291. Epoch 294
process: 250 / 291. Epoch 294
process: 291 / 291. Epoch 294
Loss of epoch 294 = 4.101247466306916
process: 50 / 291. Epoch 295
process: 100 / 291. Epoch 295
process: 150 / 291. Epoch 295
process: 200 / 291. Epoch 295
process: 250 / 291. Epoch 295
process: 291 / 291. Epoch 295
Loss of epoch 295 = 4.152665075977234
process: 50 / 291. Epoch 296
process: 100 / 291. Epoch 296
process: 150 / 291. Epoch 296
process: 200 / 291. Epoch 296
process: 250 / 291. Epoch 296
process: 291 / 291. Epoch 296
Loss of epoch 296 = 4.222076101401417
process: 50 / 291. Epoch 297
process: 100 / 291. Epoch 297
process: 150 / 291. Epoch 297
process: 200 / 291. Epoch 297
process: 250 / 291. Epoch 297
process: 291 / 291. Epoch 297
Loss of epoch 297 = 4.151918391591495
process: 50 / 291. Epoch 298
process: 100 / 291. Epoch 298
process: 150 / 291. Epoch 298
process: 200 / 291. Epoch 298
process: 250 / 291. Epoch 298
process: 291 / 291. Epoch 298
Loss of epoch 298 = 4.175510681781573
process: 50 / 291. Epoch 299
process: 100 / 291. Epoch 299
process: 150 / 291. Epoch 299
process: 200 / 291. Epoch 299
process: 250 / 291. Epoch 299
process: 291 / 291. Epoch 299
Loss of epoch 299 = 4.176720897766323
process: 50 / 291. Epoch 300
process: 100 / 291. Epoch 300
process: 150 / 291. Epoch 300
process: 200 / 291. Epoch 300
process: 250 / 291. Epoch 300
process: 291 / 291. Epoch 300
Loss of epoch 300 = 4.114697433419244
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-300. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.796080
     epoch  training_loss
295    296       4.222076
296    297       4.151918
297    298       4.175511
298    299       4.176721
299    300       4.114697
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
25        260  0.014256  0.119473      0.302099   0.302078
26        270  0.014302  0.116999      0.303358   0.303364
27        280  0.014547  0.112656      0.305048   0.305105
28        290  0.014518  0.114389      0.305988   0.306046
29        300  0.014417  0.113201      0.308279   0.308366
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
25      260.0  0.970427  0.977715  ...  0.960336  0.954716  0.941766
26      270.0  0.970802  0.977695  ...  0.959358  0.954064  0.942743
27      280.0  0.972078  0.978656  ...  0.960091  0.953738  0.934354
28      290.0  0.970695  0.977713  ...  0.959277  0.954634  0.942580
29      300.0  0.970916  0.978026  ...  0.959603  0.954309  0.942092

[5 rows x 13 columns]
process: 50 / 291. Epoch 301
process: 100 / 291. Epoch 301
process: 150 / 291. Epoch 301
process: 200 / 291. Epoch 301
process: 250 / 291. Epoch 301
process: 291 / 291. Epoch 301
Loss of epoch 301 = 4.150650706078179
process: 50 / 291. Epoch 302
process: 100 / 291. Epoch 302
process: 150 / 291. Epoch 302
process: 200 / 291. Epoch 302
process: 250 / 291. Epoch 302
process: 291 / 291. Epoch 302
Loss of epoch 302 = 4.063923314674613
process: 50 / 291. Epoch 303
process: 100 / 291. Epoch 303
process: 150 / 291. Epoch 303
process: 200 / 291. Epoch 303
process: 250 / 291. Epoch 303
process: 291 / 291. Epoch 303
Loss of epoch 303 = 4.264457152061856
process: 50 / 291. Epoch 304
process: 100 / 291. Epoch 304
process: 150 / 291. Epoch 304
process: 200 / 291. Epoch 304
process: 250 / 291. Epoch 304
process: 291 / 291. Epoch 304
Loss of epoch 304 = 4.314212340259879
process: 50 / 291. Epoch 305
process: 100 / 291. Epoch 305
process: 150 / 291. Epoch 305
process: 200 / 291. Epoch 305
process: 250 / 291. Epoch 305
process: 291 / 291. Epoch 305
Loss of epoch 305 = 4.222090783397766
process: 50 / 291. Epoch 306
process: 100 / 291. Epoch 306
process: 150 / 291. Epoch 306
process: 200 / 291. Epoch 306
process: 250 / 291. Epoch 306
process: 291 / 291. Epoch 306
Loss of epoch 306 = 4.0646150464454465
process: 50 / 291. Epoch 307
process: 100 / 291. Epoch 307
process: 150 / 291. Epoch 307
process: 200 / 291. Epoch 307
process: 250 / 291. Epoch 307
process: 291 / 291. Epoch 307
Loss of epoch 307 = 3.9828552036350944
process: 50 / 291. Epoch 308
process: 100 / 291. Epoch 308
process: 150 / 291. Epoch 308
process: 200 / 291. Epoch 308
process: 250 / 291. Epoch 308
process: 291 / 291. Epoch 308
Loss of epoch 308 = 4.055166552566581
process: 50 / 291. Epoch 309
process: 100 / 291. Epoch 309
process: 150 / 291. Epoch 309
process: 200 / 291. Epoch 309
process: 250 / 291. Epoch 309
process: 291 / 291. Epoch 309
Loss of epoch 309 = 4.135229995570232
process: 50 / 291. Epoch 310
process: 100 / 291. Epoch 310
process: 150 / 291. Epoch 310
process: 200 / 291. Epoch 310
process: 250 / 291. Epoch 310
process: 291 / 291. Epoch 310
Loss of epoch 310 = 4.146799408693084
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-310. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.787607
     epoch  training_loss
305    306       4.064615
306    307       3.982855
307    308       4.055167
308    309       4.135230
309    310       4.146799
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
26        270  0.014302  0.116999      0.303358   0.303364
27        280  0.014547  0.112656      0.305048   0.305105
28        290  0.014518  0.114389      0.305988   0.306046
29        300  0.014417  0.113201      0.308279   0.308366
30        310  0.014583  0.109941      0.309315   0.309423
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
26      270.0  0.970802  0.977695  ...  0.959358  0.954064  0.942743
27      280.0  0.972078  0.978656  ...  0.960091  0.953738  0.934354
28      290.0  0.970695  0.977713  ...  0.959277  0.954634  0.942580
29      300.0  0.970916  0.978026  ...  0.959603  0.954309  0.942092
30      310.0  0.972501  0.978550  ...  0.960254  0.953820  0.936309

[5 rows x 13 columns]
process: 50 / 291. Epoch 311
process: 100 / 291. Epoch 311
process: 150 / 291. Epoch 311
process: 200 / 291. Epoch 311
process: 250 / 291. Epoch 311
process: 291 / 291. Epoch 311
Loss of epoch 311 = 4.247208742751289
process: 50 / 291. Epoch 312
process: 100 / 291. Epoch 312
process: 150 / 291. Epoch 312
process: 200 / 291. Epoch 312
process: 250 / 291. Epoch 312
process: 291 / 291. Epoch 312
Loss of epoch 312 = 4.113791344501718
process: 50 / 291. Epoch 313
process: 100 / 291. Epoch 313
process: 150 / 291. Epoch 313
process: 200 / 291. Epoch 313
process: 250 / 291. Epoch 313
process: 291 / 291. Epoch 313
Loss of epoch 313 = 4.096861744254725
process: 50 / 291. Epoch 314
process: 100 / 291. Epoch 314
process: 150 / 291. Epoch 314
process: 200 / 291. Epoch 314
process: 250 / 291. Epoch 314
process: 291 / 291. Epoch 314
Loss of epoch 314 = 4.012631970172895
process: 50 / 291. Epoch 315
process: 100 / 291. Epoch 315
process: 150 / 291. Epoch 315
process: 200 / 291. Epoch 315
process: 250 / 291. Epoch 315
process: 291 / 291. Epoch 315
Loss of epoch 315 = 4.075843417767397
process: 50 / 291. Epoch 316
process: 100 / 291. Epoch 316
process: 150 / 291. Epoch 316
process: 200 / 291. Epoch 316
process: 250 / 291. Epoch 316
process: 291 / 291. Epoch 316
Loss of epoch 316 = 4.046163132919888
process: 50 / 291. Epoch 317
process: 100 / 291. Epoch 317
process: 150 / 291. Epoch 317
process: 200 / 291. Epoch 317
process: 250 / 291. Epoch 317
process: 291 / 291. Epoch 317
Loss of epoch 317 = 4.080664985368342
process: 50 / 291. Epoch 318
process: 100 / 291. Epoch 318
process: 150 / 291. Epoch 318
process: 200 / 291. Epoch 318
process: 250 / 291. Epoch 318
process: 291 / 291. Epoch 318
Loss of epoch 318 = 4.105358005798969
process: 50 / 291. Epoch 319
process: 100 / 291. Epoch 319
process: 150 / 291. Epoch 319
process: 200 / 291. Epoch 319
process: 250 / 291. Epoch 319
process: 291 / 291. Epoch 319
Loss of epoch 319 = 3.9870588689325603
process: 50 / 291. Epoch 320
process: 100 / 291. Epoch 320
process: 150 / 291. Epoch 320
process: 200 / 291. Epoch 320
process: 250 / 291. Epoch 320
process: 291 / 291. Epoch 320
Loss of epoch 320 = 4.071179996241409
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-320. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.797312
     epoch  training_loss
315    316       4.046163
316    317       4.080665
317    318       4.105358
318    319       3.987059
319    320       4.071180
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
27        280  0.014547  0.112656      0.305048   0.305105
28        290  0.014518  0.114389      0.305988   0.306046
29        300  0.014417  0.113201      0.308279   0.308366
30        310  0.014583  0.109941      0.309315   0.309423
31        320  0.014416  0.111398      0.311549   0.311722
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
27      280.0  0.972078  0.978656  ...  0.960091  0.953738  0.934354
28      290.0  0.970695  0.977713  ...  0.959277  0.954634  0.942580
29      300.0  0.970916  0.978026  ...  0.959603  0.954309  0.942092
30      310.0  0.972501  0.978550  ...  0.960254  0.953820  0.936309
31      320.0  0.971145  0.978459  ...  0.960173  0.954390  0.942906

[5 rows x 13 columns]
process: 50 / 291. Epoch 321
process: 100 / 291. Epoch 321
process: 150 / 291. Epoch 321
process: 200 / 291. Epoch 321
process: 250 / 291. Epoch 321
process: 291 / 291. Epoch 321
Loss of epoch 321 = 4.279894222508591
process: 50 / 291. Epoch 322
process: 100 / 291. Epoch 322
process: 150 / 291. Epoch 322
process: 200 / 291. Epoch 322
process: 250 / 291. Epoch 322
process: 291 / 291. Epoch 322
Loss of epoch 322 = 4.074201551089992
process: 50 / 291. Epoch 323
process: 100 / 291. Epoch 323
process: 150 / 291. Epoch 323
process: 200 / 291. Epoch 323
process: 250 / 291. Epoch 323
process: 291 / 291. Epoch 323
Loss of epoch 323 = 3.930029800257732
process: 50 / 291. Epoch 324
process: 100 / 291. Epoch 324
process: 150 / 291. Epoch 324
process: 200 / 291. Epoch 324
process: 250 / 291. Epoch 324
process: 291 / 291. Epoch 324
Loss of epoch 324 = 4.037402175955756
process: 50 / 291. Epoch 325
process: 100 / 291. Epoch 325
process: 150 / 291. Epoch 325
process: 200 / 291. Epoch 325
process: 250 / 291. Epoch 325
process: 291 / 291. Epoch 325
Loss of epoch 325 = 4.089342884181701
process: 50 / 291. Epoch 326
process: 100 / 291. Epoch 326
process: 150 / 291. Epoch 326
process: 200 / 291. Epoch 326
process: 250 / 291. Epoch 326
process: 291 / 291. Epoch 326
Loss of epoch 326 = 4.1181921680358675
process: 50 / 291. Epoch 327
process: 100 / 291. Epoch 327
process: 150 / 291. Epoch 327
process: 200 / 291. Epoch 327
process: 250 / 291. Epoch 327
process: 291 / 291. Epoch 327
Loss of epoch 327 = 4.03527873979811
process: 50 / 291. Epoch 328
process: 100 / 291. Epoch 328
process: 150 / 291. Epoch 328
process: 200 / 291. Epoch 328
process: 250 / 291. Epoch 328
process: 291 / 291. Epoch 328
Loss of epoch 328 = 4.0204176230938575
process: 50 / 291. Epoch 329
process: 100 / 291. Epoch 329
process: 150 / 291. Epoch 329
process: 200 / 291. Epoch 329
process: 250 / 291. Epoch 329
process: 291 / 291. Epoch 329
Loss of epoch 329 = 4.031808754832475
process: 50 / 291. Epoch 330
process: 100 / 291. Epoch 330
process: 150 / 291. Epoch 330
process: 200 / 291. Epoch 330
process: 250 / 291. Epoch 330
process: 291 / 291. Epoch 330
Loss of epoch 330 = 4.050954497556916
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-330. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.789435
     epoch  training_loss
325    326       4.118192
326    327       4.035279
327    328       4.020418
328    329       4.031809
329    330       4.050954
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
28        290  0.014518  0.114389      0.305988   0.306046
29        300  0.014417  0.113201      0.308279   0.308366
30        310  0.014583  0.109941      0.309315   0.309423
31        320  0.014416  0.111398      0.311549   0.311722
32        330  0.014549  0.108047      0.310401   0.310547
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
28      290.0  0.970695  0.977713  ...  0.959277  0.954634  0.942580
29      300.0  0.970916  0.978026  ...  0.959603  0.954309  0.942092
30      310.0  0.972501  0.978550  ...  0.960254  0.953820  0.936309
31      320.0  0.971145  0.978459  ...  0.960173  0.954390  0.942906
32      330.0  0.971861  0.978872  ...  0.959847  0.953738  0.937123

[5 rows x 13 columns]
process: 50 / 291. Epoch 331
process: 100 / 291. Epoch 331
process: 150 / 291. Epoch 331
process: 200 / 291. Epoch 331
process: 250 / 291. Epoch 331
process: 291 / 291. Epoch 331
Loss of epoch 331 = 3.95568805707689
process: 50 / 291. Epoch 332
process: 100 / 291. Epoch 332
process: 150 / 291. Epoch 332
process: 200 / 291. Epoch 332
process: 250 / 291. Epoch 332
process: 291 / 291. Epoch 332
Loss of epoch 332 = 3.981883255476804
process: 50 / 291. Epoch 333
process: 100 / 291. Epoch 333
process: 150 / 291. Epoch 333
process: 200 / 291. Epoch 333
process: 250 / 291. Epoch 333
process: 291 / 291. Epoch 333
Loss of epoch 333 = 3.954909491784794
process: 50 / 291. Epoch 334
process: 100 / 291. Epoch 334
process: 150 / 291. Epoch 334
process: 200 / 291. Epoch 334
process: 250 / 291. Epoch 334
process: 291 / 291. Epoch 334
Loss of epoch 334 = 3.8906275169136597
process: 50 / 291. Epoch 335
process: 100 / 291. Epoch 335
process: 150 / 291. Epoch 335
process: 200 / 291. Epoch 335
process: 250 / 291. Epoch 335
process: 291 / 291. Epoch 335
Loss of epoch 335 = 4.028166780766752
process: 50 / 291. Epoch 336
process: 100 / 291. Epoch 336
process: 150 / 291. Epoch 336
process: 200 / 291. Epoch 336
process: 250 / 291. Epoch 336
process: 291 / 291. Epoch 336
Loss of epoch 336 = 4.077924905364046
process: 50 / 291. Epoch 337
process: 100 / 291. Epoch 337
process: 150 / 291. Epoch 337
process: 200 / 291. Epoch 337
process: 250 / 291. Epoch 337
process: 291 / 291. Epoch 337
Loss of epoch 337 = 4.065346209863617
process: 50 / 291. Epoch 338
process: 100 / 291. Epoch 338
process: 150 / 291. Epoch 338
process: 200 / 291. Epoch 338
process: 250 / 291. Epoch 338
process: 291 / 291. Epoch 338
Loss of epoch 338 = 4.045608992429123
process: 50 / 291. Epoch 339
process: 100 / 291. Epoch 339
process: 150 / 291. Epoch 339
process: 200 / 291. Epoch 339
process: 250 / 291. Epoch 339
process: 291 / 291. Epoch 339
Loss of epoch 339 = 4.072711957689004
process: 50 / 291. Epoch 340
process: 100 / 291. Epoch 340
process: 150 / 291. Epoch 340
process: 200 / 291. Epoch 340
process: 250 / 291. Epoch 340
process: 291 / 291. Epoch 340
Loss of epoch 340 = 4.030647618664089
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-340. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.790672
     epoch  training_loss
335    336       4.077925
336    337       4.065346
337    338       4.045609
338    339       4.072712
339    340       4.030648
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
29        300  0.014417  0.113201      0.308279   0.308366
30        310  0.014583  0.109941      0.309315   0.309423
31        320  0.014416  0.111398      0.311549   0.311722
32        330  0.014549  0.108047      0.310401   0.310547
33        340  0.014590  0.107432      0.313208   0.313415
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
29      300.0  0.970916  0.978026  ...  0.959603  0.954309  0.942092
30      310.0  0.972501  0.978550  ...  0.960254  0.953820  0.936309
31      320.0  0.971145  0.978459  ...  0.960173  0.954390  0.942906
32      330.0  0.971861  0.978872  ...  0.959847  0.953738  0.937123
33      340.0  0.972391  0.978997  ...  0.960091  0.954309  0.938997

[5 rows x 13 columns]
process: 50 / 291. Epoch 341
process: 100 / 291. Epoch 341
process: 150 / 291. Epoch 341
process: 200 / 291. Epoch 341
process: 250 / 291. Epoch 341
process: 291 / 291. Epoch 341
Loss of epoch 341 = 3.8983095568889605
process: 50 / 291. Epoch 342
process: 100 / 291. Epoch 342
process: 150 / 291. Epoch 342
process: 200 / 291. Epoch 342
process: 250 / 291. Epoch 342
process: 291 / 291. Epoch 342
Loss of epoch 342 = 3.8320752959890463
process: 50 / 291. Epoch 343
process: 100 / 291. Epoch 343
process: 150 / 291. Epoch 343
process: 200 / 291. Epoch 343
process: 250 / 291. Epoch 343
process: 291 / 291. Epoch 343
Loss of epoch 343 = 3.8338576903457904
process: 50 / 291. Epoch 344
process: 100 / 291. Epoch 344
process: 150 / 291. Epoch 344
process: 200 / 291. Epoch 344
process: 250 / 291. Epoch 344
process: 291 / 291. Epoch 344
Loss of epoch 344 = 3.982215488079897
process: 50 / 291. Epoch 345
process: 100 / 291. Epoch 345
process: 150 / 291. Epoch 345
process: 200 / 291. Epoch 345
process: 250 / 291. Epoch 345
process: 291 / 291. Epoch 345
Loss of epoch 345 = 4.126479945231959
process: 50 / 291. Epoch 346
process: 100 / 291. Epoch 346
process: 150 / 291. Epoch 346
process: 200 / 291. Epoch 346
process: 250 / 291. Epoch 346
process: 291 / 291. Epoch 346
Loss of epoch 346 = 3.896768366757947
process: 50 / 291. Epoch 347
process: 100 / 291. Epoch 347
process: 150 / 291. Epoch 347
process: 200 / 291. Epoch 347
process: 250 / 291. Epoch 347
process: 291 / 291. Epoch 347
Loss of epoch 347 = 3.9475529726428267
process: 50 / 291. Epoch 348
process: 100 / 291. Epoch 348
process: 150 / 291. Epoch 348
process: 200 / 291. Epoch 348
process: 250 / 291. Epoch 348
process: 291 / 291. Epoch 348
Loss of epoch 348 = 3.9609811265034365
process: 50 / 291. Epoch 349
process: 100 / 291. Epoch 349
process: 150 / 291. Epoch 349
process: 200 / 291. Epoch 349
process: 250 / 291. Epoch 349
process: 291 / 291. Epoch 349
Loss of epoch 349 = 3.918346706534579
process: 50 / 291. Epoch 350
process: 100 / 291. Epoch 350
process: 150 / 291. Epoch 350
process: 200 / 291. Epoch 350
process: 250 / 291. Epoch 350
process: 291 / 291. Epoch 350
Loss of epoch 350 = 3.9108211346917954
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-350. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.791485
     epoch  training_loss
345    346       3.896768
346    347       3.947553
347    348       3.960981
348    349       3.918347
349    350       3.910821
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
30        310  0.014583  0.109941      0.309315   0.309423
31        320  0.014416  0.111398      0.311549   0.311722
32        330  0.014549  0.108047      0.310401   0.310547
33        340  0.014590  0.107432      0.313208   0.313415
34        350  0.014577  0.106160      0.313429   0.313603
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
30      310.0  0.972501  0.978550  ...  0.960254  0.953820  0.936309
31      320.0  0.971145  0.978459  ...  0.960173  0.954390  0.942906
32      330.0  0.971861  0.978872  ...  0.959847  0.953738  0.937123
33      340.0  0.972391  0.978997  ...  0.960091  0.954309  0.938997
34      350.0  0.971630  0.978767  ...  0.959277  0.953820  0.941521

[5 rows x 13 columns]
process: 50 / 291. Epoch 351
process: 100 / 291. Epoch 351
process: 150 / 291. Epoch 351
process: 200 / 291. Epoch 351
process: 250 / 291. Epoch 351
process: 291 / 291. Epoch 351
Loss of epoch 351 = 3.9825762457044673
process: 50 / 291. Epoch 352
process: 100 / 291. Epoch 352
process: 150 / 291. Epoch 352
process: 200 / 291. Epoch 352
process: 250 / 291. Epoch 352
process: 291 / 291. Epoch 352
Loss of epoch 352 = 3.8649944292311
process: 50 / 291. Epoch 353
process: 100 / 291. Epoch 353
process: 150 / 291. Epoch 353
process: 200 / 291. Epoch 353
process: 250 / 291. Epoch 353
process: 291 / 291. Epoch 353
Loss of epoch 353 = 3.8542262336232818
process: 50 / 291. Epoch 354
process: 100 / 291. Epoch 354
process: 150 / 291. Epoch 354
process: 200 / 291. Epoch 354
process: 250 / 291. Epoch 354
process: 291 / 291. Epoch 354
Loss of epoch 354 = 3.8899928351857818
process: 50 / 291. Epoch 355
process: 100 / 291. Epoch 355
process: 150 / 291. Epoch 355
process: 200 / 291. Epoch 355
process: 250 / 291. Epoch 355
process: 291 / 291. Epoch 355
Loss of epoch 355 = 4.051604700252363
process: 50 / 291. Epoch 356
process: 100 / 291. Epoch 356
process: 150 / 291. Epoch 356
process: 200 / 291. Epoch 356
process: 250 / 291. Epoch 356
process: 291 / 291. Epoch 356
Loss of epoch 356 = 4.069768427163875
process: 50 / 291. Epoch 357
process: 100 / 291. Epoch 357
process: 150 / 291. Epoch 357
process: 200 / 291. Epoch 357
process: 250 / 291. Epoch 357
process: 291 / 291. Epoch 357
Loss of epoch 357 = 4.017891900236254
process: 50 / 291. Epoch 358
process: 100 / 291. Epoch 358
process: 150 / 291. Epoch 358
process: 200 / 291. Epoch 358
process: 250 / 291. Epoch 358
process: 291 / 291. Epoch 358
Loss of epoch 358 = 3.839658337360395
process: 50 / 291. Epoch 359
process: 100 / 291. Epoch 359
process: 150 / 291. Epoch 359
process: 200 / 291. Epoch 359
process: 250 / 291. Epoch 359
process: 291 / 291. Epoch 359
Loss of epoch 359 = 3.756309483059493
process: 50 / 291. Epoch 360
process: 100 / 291. Epoch 360
process: 150 / 291. Epoch 360
process: 200 / 291. Epoch 360
process: 250 / 291. Epoch 360
process: 291 / 291. Epoch 360
Loss of epoch 360 = 3.8695282297036084
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-360. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.787965
     epoch  training_loss
355    356       4.069768
356    357       4.017892
357    358       3.839658
358    359       3.756309
359    360       3.869528
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
31        320  0.014416  0.111398      0.311549   0.311722
32        330  0.014549  0.108047      0.310401   0.310547
33        340  0.014590  0.107432      0.313208   0.313415
34        350  0.014577  0.106160      0.313429   0.313603
35        360  0.014615  0.105134      0.314602   0.314824
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
31      320.0  0.971145  0.978459  ...  0.960173  0.954390  0.942906
32      330.0  0.971861  0.978872  ...  0.959847  0.953738  0.937123
33      340.0  0.972391  0.978997  ...  0.960091  0.954309  0.938997
34      350.0  0.971630  0.978767  ...  0.959277  0.953820  0.941521
35      360.0  0.971318  0.979098  ...  0.959277  0.954064  0.937531

[5 rows x 13 columns]
process: 50 / 291. Epoch 361
process: 100 / 291. Epoch 361
process: 150 / 291. Epoch 361
process: 200 / 291. Epoch 361
process: 250 / 291. Epoch 361
process: 291 / 291. Epoch 361
Loss of epoch 361 = 3.9503824030820445
process: 50 / 291. Epoch 362
process: 100 / 291. Epoch 362
process: 150 / 291. Epoch 362
process: 200 / 291. Epoch 362
process: 250 / 291. Epoch 362
process: 291 / 291. Epoch 362
Loss of epoch 362 = 3.9631616127040377
process: 50 / 291. Epoch 363
process: 100 / 291. Epoch 363
process: 150 / 291. Epoch 363
process: 200 / 291. Epoch 363
process: 250 / 291. Epoch 363
process: 291 / 291. Epoch 363
Loss of epoch 363 = 3.8573547573024056
process: 50 / 291. Epoch 364
process: 100 / 291. Epoch 364
process: 150 / 291. Epoch 364
process: 200 / 291. Epoch 364
process: 250 / 291. Epoch 364
process: 291 / 291. Epoch 364
Loss of epoch 364 = 3.871386550955756
process: 50 / 291. Epoch 365
process: 100 / 291. Epoch 365
process: 150 / 291. Epoch 365
process: 200 / 291. Epoch 365
process: 250 / 291. Epoch 365
process: 291 / 291. Epoch 365
Loss of epoch 365 = 3.9093223126073884
process: 50 / 291. Epoch 366
process: 100 / 291. Epoch 366
process: 150 / 291. Epoch 366
process: 200 / 291. Epoch 366
process: 250 / 291. Epoch 366
process: 291 / 291. Epoch 366
Loss of epoch 366 = 3.9883722783773625
process: 50 / 291. Epoch 367
process: 100 / 291. Epoch 367
process: 150 / 291. Epoch 367
process: 200 / 291. Epoch 367
process: 250 / 291. Epoch 367
process: 291 / 291. Epoch 367
Loss of epoch 367 = 3.9577208843427836
process: 50 / 291. Epoch 368
process: 100 / 291. Epoch 368
process: 150 / 291. Epoch 368
process: 200 / 291. Epoch 368
process: 250 / 291. Epoch 368
process: 291 / 291. Epoch 368
Loss of epoch 368 = 3.7467603126342355
process: 50 / 291. Epoch 369
process: 100 / 291. Epoch 369
process: 150 / 291. Epoch 369
process: 200 / 291. Epoch 369
process: 250 / 291. Epoch 369
process: 291 / 291. Epoch 369
Loss of epoch 369 = 3.7397888812822164
process: 50 / 291. Epoch 370
process: 100 / 291. Epoch 370
process: 150 / 291. Epoch 370
process: 200 / 291. Epoch 370
process: 250 / 291. Epoch 370
process: 291 / 291. Epoch 370
Loss of epoch 370 = 3.881824191902921
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-370. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.789154
     epoch  training_loss
365    366       3.988372
366    367       3.957721
367    368       3.746760
368    369       3.739789
369    370       3.881824
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
32        330  0.014549  0.108047      0.310401   0.310547
33        340  0.014590  0.107432      0.313208   0.313415
34        350  0.014577  0.106160      0.313429   0.313603
35        360  0.014615  0.105134      0.314602   0.314824
36        370  0.014680  0.103551      0.316017   0.316267
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
32      330.0  0.971861  0.978872  ...  0.959847  0.953738  0.937123
33      340.0  0.972391  0.978997  ...  0.960091  0.954309  0.938997
34      350.0  0.971630  0.978767  ...  0.959277  0.953820  0.941521
35      360.0  0.971318  0.979098  ...  0.959277  0.954064  0.937531
36      370.0  0.971934  0.979292  ...  0.959032  0.953250  0.938915

[5 rows x 13 columns]
process: 50 / 291. Epoch 371
process: 100 / 291. Epoch 371
process: 150 / 291. Epoch 371
process: 200 / 291. Epoch 371
process: 250 / 291. Epoch 371
process: 291 / 291. Epoch 371
Loss of epoch 371 = 3.886622687795318
process: 50 / 291. Epoch 372
process: 100 / 291. Epoch 372
process: 150 / 291. Epoch 372
process: 200 / 291. Epoch 372
process: 250 / 291. Epoch 372
process: 291 / 291. Epoch 372
Loss of epoch 372 = 3.9025702722293816
process: 50 / 291. Epoch 373
process: 100 / 291. Epoch 373
process: 150 / 291. Epoch 373
process: 200 / 291. Epoch 373
process: 250 / 291. Epoch 373
process: 291 / 291. Epoch 373
Loss of epoch 373 = 3.944277209514605
process: 50 / 291. Epoch 374
process: 100 / 291. Epoch 374
process: 150 / 291. Epoch 374
process: 200 / 291. Epoch 374
process: 250 / 291. Epoch 374
process: 291 / 291. Epoch 374
Loss of epoch 374 = 3.957946987086555
process: 50 / 291. Epoch 375
process: 100 / 291. Epoch 375
process: 150 / 291. Epoch 375
process: 200 / 291. Epoch 375
process: 250 / 291. Epoch 375
process: 291 / 291. Epoch 375
Loss of epoch 375 = 3.879798915378007
process: 50 / 291. Epoch 376
process: 100 / 291. Epoch 376
process: 150 / 291. Epoch 376
process: 200 / 291. Epoch 376
process: 250 / 291. Epoch 376
process: 291 / 291. Epoch 376
Loss of epoch 376 = 3.9248030095575603
process: 50 / 291. Epoch 377
process: 100 / 291. Epoch 377
process: 150 / 291. Epoch 377
process: 200 / 291. Epoch 377
process: 250 / 291. Epoch 377
process: 291 / 291. Epoch 377
Loss of epoch 377 = 3.905895115173969
process: 50 / 291. Epoch 378
process: 100 / 291. Epoch 378
process: 150 / 291. Epoch 378
process: 200 / 291. Epoch 378
process: 250 / 291. Epoch 378
process: 291 / 291. Epoch 378
Loss of epoch 378 = 3.7219317983515894
process: 50 / 291. Epoch 379
process: 100 / 291. Epoch 379
process: 150 / 291. Epoch 379
process: 200 / 291. Epoch 379
process: 250 / 291. Epoch 379
process: 291 / 291. Epoch 379
Loss of epoch 379 = 3.8208418908397768
process: 50 / 291. Epoch 380
process: 100 / 291. Epoch 380
process: 150 / 291. Epoch 380
process: 200 / 291. Epoch 380
process: 250 / 291. Epoch 380
process: 291 / 291. Epoch 380
Loss of epoch 380 = 3.7314881000322164
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-380. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.792191
     epoch  training_loss
375    376       3.924803
376    377       3.905895
377    378       3.721932
378    379       3.820842
379    380       3.731488
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
33        340  0.014590  0.107432      0.313208   0.313415
34        350  0.014577  0.106160      0.313429   0.313603
35        360  0.014615  0.105134      0.314602   0.314824
36        370  0.014680  0.103551      0.316017   0.316267
37        380  0.014637  0.103347      0.317194   0.317476
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
33      340.0  0.972391  0.978997  ...  0.960091  0.954309  0.938997
34      350.0  0.971630  0.978767  ...  0.959277  0.953820  0.941521
35      360.0  0.971318  0.979098  ...  0.959277  0.954064  0.937531
36      370.0  0.971934  0.979292  ...  0.959032  0.953250  0.938915
37      380.0  0.971315  0.978884  ...  0.959195  0.954146  0.939648

[5 rows x 13 columns]
process: 50 / 291. Epoch 381
process: 100 / 291. Epoch 381
process: 150 / 291. Epoch 381
process: 200 / 291. Epoch 381
process: 250 / 291. Epoch 381
process: 291 / 291. Epoch 381
Loss of epoch 381 = 3.8458205809707904
process: 50 / 291. Epoch 382
process: 100 / 291. Epoch 382
process: 150 / 291. Epoch 382
process: 200 / 291. Epoch 382
process: 250 / 291. Epoch 382
process: 291 / 291. Epoch 382
Loss of epoch 382 = 3.826577937070447
process: 50 / 291. Epoch 383
process: 100 / 291. Epoch 383
process: 150 / 291. Epoch 383
process: 200 / 291. Epoch 383
process: 250 / 291. Epoch 383
process: 291 / 291. Epoch 383
Loss of epoch 383 = 3.862108787720146
process: 50 / 291. Epoch 384
process: 100 / 291. Epoch 384
process: 150 / 291. Epoch 384
process: 200 / 291. Epoch 384
process: 250 / 291. Epoch 384
process: 291 / 291. Epoch 384
Loss of epoch 384 = 3.9455297935459623
process: 50 / 291. Epoch 385
process: 100 / 291. Epoch 385
process: 150 / 291. Epoch 385
process: 200 / 291. Epoch 385
process: 250 / 291. Epoch 385
process: 291 / 291. Epoch 385
Loss of epoch 385 = 3.8057827769276202
process: 50 / 291. Epoch 386
process: 100 / 291. Epoch 386
process: 150 / 291. Epoch 386
process: 200 / 291. Epoch 386
process: 250 / 291. Epoch 386
process: 291 / 291. Epoch 386
Loss of epoch 386 = 3.7534385235448884
process: 50 / 291. Epoch 387
process: 100 / 291. Epoch 387
process: 150 / 291. Epoch 387
process: 200 / 291. Epoch 387
process: 250 / 291. Epoch 387
process: 291 / 291. Epoch 387
Loss of epoch 387 = 3.771397121993127
process: 50 / 291. Epoch 388
process: 100 / 291. Epoch 388
process: 150 / 291. Epoch 388
process: 200 / 291. Epoch 388
process: 250 / 291. Epoch 388
process: 291 / 291. Epoch 388
Loss of epoch 388 = 3.7844422854918385
process: 50 / 291. Epoch 389
process: 100 / 291. Epoch 389
process: 150 / 291. Epoch 389
process: 200 / 291. Epoch 389
process: 250 / 291. Epoch 389
process: 291 / 291. Epoch 389
Loss of epoch 389 = 3.750562949688574
process: 50 / 291. Epoch 390
process: 100 / 291. Epoch 390
process: 150 / 291. Epoch 390
process: 200 / 291. Epoch 390
process: 250 / 291. Epoch 390
process: 291 / 291. Epoch 390
Loss of epoch 390 = 3.83202831360073
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-390. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.792193
     epoch  training_loss
385    386       3.753439
386    387       3.771397
387    388       3.784442
388    389       3.750563
389    390       3.832028
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
34        350  0.014577  0.106160      0.313429   0.313603
35        360  0.014615  0.105134      0.314602   0.314824
36        370  0.014680  0.103551      0.316017   0.316267
37        380  0.014637  0.103347      0.317194   0.317476
38        390  0.014679  0.102739      0.318486   0.318773
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
34      350.0  0.971630  0.978767  ...  0.959277  0.953820  0.941521
35      360.0  0.971318  0.979098  ...  0.959277  0.954064  0.937531
36      370.0  0.971934  0.979292  ...  0.959032  0.953250  0.938915
37      380.0  0.971315  0.978884  ...  0.959195  0.954146  0.939648
38      390.0  0.971722  0.978656  ...  0.958951  0.953738  0.939811

[5 rows x 13 columns]
process: 50 / 291. Epoch 391
process: 100 / 291. Epoch 391
process: 150 / 291. Epoch 391
process: 200 / 291. Epoch 391
process: 250 / 291. Epoch 391
process: 291 / 291. Epoch 391
Loss of epoch 391 = 3.930872546848153
process: 50 / 291. Epoch 392
process: 100 / 291. Epoch 392
process: 150 / 291. Epoch 392
process: 200 / 291. Epoch 392
process: 250 / 291. Epoch 392
process: 291 / 291. Epoch 392
Loss of epoch 392 = 3.8215491435781788
process: 50 / 291. Epoch 393
process: 100 / 291. Epoch 393
process: 150 / 291. Epoch 393
process: 200 / 291. Epoch 393
process: 250 / 291. Epoch 393
process: 291 / 291. Epoch 393
Loss of epoch 393 = 3.766812144276203
process: 50 / 291. Epoch 394
process: 100 / 291. Epoch 394
process: 150 / 291. Epoch 394
process: 200 / 291. Epoch 394
process: 250 / 291. Epoch 394
process: 291 / 291. Epoch 394
Loss of epoch 394 = 3.7898259638101375
process: 50 / 291. Epoch 395
process: 100 / 291. Epoch 395
process: 150 / 291. Epoch 395
process: 200 / 291. Epoch 395
process: 250 / 291. Epoch 395
process: 291 / 291. Epoch 395
Loss of epoch 395 = 3.781335575064433
process: 50 / 291. Epoch 396
process: 100 / 291. Epoch 396
process: 150 / 291. Epoch 396
process: 200 / 291. Epoch 396
process: 250 / 291. Epoch 396
process: 291 / 291. Epoch 396
Loss of epoch 396 = 3.876670391698883
process: 50 / 291. Epoch 397
process: 100 / 291. Epoch 397
process: 150 / 291. Epoch 397
process: 200 / 291. Epoch 397
process: 250 / 291. Epoch 397
process: 291 / 291. Epoch 397
Loss of epoch 397 = 3.7275247999892613
process: 50 / 291. Epoch 398
process: 100 / 291. Epoch 398
process: 150 / 291. Epoch 398
process: 200 / 291. Epoch 398
process: 250 / 291. Epoch 398
process: 291 / 291. Epoch 398
Loss of epoch 398 = 3.6454264322916665
process: 50 / 291. Epoch 399
process: 100 / 291. Epoch 399
process: 150 / 291. Epoch 399
process: 200 / 291. Epoch 399
process: 250 / 291. Epoch 399
process: 291 / 291. Epoch 399
Loss of epoch 399 = 3.7525940990120277
process: 50 / 291. Epoch 400
process: 100 / 291. Epoch 400
process: 150 / 291. Epoch 400
process: 200 / 291. Epoch 400
process: 250 / 291. Epoch 400
process: 291 / 291. Epoch 400
Loss of epoch 400 = 3.762484730723797
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-400. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.787723
     epoch  training_loss
395    396       3.876670
396    397       3.727525
397    398       3.645426
398    399       3.752594
399    400       3.762485
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
35        360  0.014615  0.105134      0.314602   0.314824
36        370  0.014680  0.103551      0.316017   0.316267
37        380  0.014637  0.103347      0.317194   0.317476
38        390  0.014679  0.102739      0.318486   0.318773
39        400  0.014752  0.100889      0.319898   0.320306
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
35      360.0  0.971318  0.979098  ...  0.959277  0.954064  0.937531
36      370.0  0.971934  0.979292  ...  0.959032  0.953250  0.938915
37      380.0  0.971315  0.978884  ...  0.959195  0.954146  0.939648
38      390.0  0.971722  0.978656  ...  0.958951  0.953738  0.939811
39      400.0  0.971599  0.979308  ...  0.958462  0.953820  0.937612

[5 rows x 13 columns]
process: 50 / 291. Epoch 401
process: 100 / 291. Epoch 401
process: 150 / 291. Epoch 401
process: 200 / 291. Epoch 401
process: 250 / 291. Epoch 401
process: 291 / 291. Epoch 401
Loss of epoch 401 = 3.8181211071735395
process: 50 / 291. Epoch 402
process: 100 / 291. Epoch 402
process: 150 / 291. Epoch 402
process: 200 / 291. Epoch 402
process: 250 / 291. Epoch 402
process: 291 / 291. Epoch 402
Loss of epoch 402 = 3.752731690292096
process: 50 / 291. Epoch 403
process: 100 / 291. Epoch 403
process: 150 / 291. Epoch 403
process: 200 / 291. Epoch 403
process: 250 / 291. Epoch 403
process: 291 / 291. Epoch 403
Loss of epoch 403 = 3.7325007382946733
process: 50 / 291. Epoch 404
process: 100 / 291. Epoch 404
process: 150 / 291. Epoch 404
process: 200 / 291. Epoch 404
process: 250 / 291. Epoch 404
process: 291 / 291. Epoch 404
Loss of epoch 404 = 3.7826951279263317
process: 50 / 291. Epoch 405
process: 100 / 291. Epoch 405
process: 150 / 291. Epoch 405
process: 200 / 291. Epoch 405
process: 250 / 291. Epoch 405
process: 291 / 291. Epoch 405
Loss of epoch 405 = 3.9181113751073884
process: 50 / 291. Epoch 406
process: 100 / 291. Epoch 406
process: 150 / 291. Epoch 406
process: 200 / 291. Epoch 406
process: 250 / 291. Epoch 406
process: 291 / 291. Epoch 406
Loss of epoch 406 = 3.7921390074634878
process: 50 / 291. Epoch 407
process: 100 / 291. Epoch 407
process: 150 / 291. Epoch 407
process: 200 / 291. Epoch 407
process: 250 / 291. Epoch 407
process: 291 / 291. Epoch 407
Loss of epoch 407 = 3.6971485885148194
process: 50 / 291. Epoch 408
process: 100 / 291. Epoch 408
process: 150 / 291. Epoch 408
process: 200 / 291. Epoch 408
process: 250 / 291. Epoch 408
process: 291 / 291. Epoch 408
Loss of epoch 408 = 3.637062728200172
process: 50 / 291. Epoch 409
process: 100 / 291. Epoch 409
process: 150 / 291. Epoch 409
process: 200 / 291. Epoch 409
process: 250 / 291. Epoch 409
process: 291 / 291. Epoch 409
Loss of epoch 409 = 3.775488784632732
process: 50 / 291. Epoch 410
process: 100 / 291. Epoch 410
process: 150 / 291. Epoch 410
process: 200 / 291. Epoch 410
process: 250 / 291. Epoch 410
process: 291 / 291. Epoch 410
Loss of epoch 410 = 3.9904223045532645
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-410. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.789697
     epoch  training_loss
405    406       3.792139
406    407       3.697149
407    408       3.637063
408    409       3.775489
409    410       3.990422
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
36        370  0.014680  0.103551      0.316017   0.316267
37        380  0.014637  0.103347      0.317194   0.317476
38        390  0.014679  0.102739      0.318486   0.318773
39        400  0.014752  0.100889      0.319898   0.320306
40        410  0.014631  0.100686      0.319472   0.319790
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
36      370.0  0.971934  0.979292  ...  0.959032  0.953250  0.938915
37      380.0  0.971315  0.978884  ...  0.959195  0.954146  0.939648
38      390.0  0.971722  0.978656  ...  0.958951  0.953738  0.939811
39      400.0  0.971599  0.979308  ...  0.958462  0.953820  0.937612
40      410.0  0.971731  0.978978  ...  0.959195  0.953657  0.939322

[5 rows x 13 columns]
process: 50 / 291. Epoch 411
process: 100 / 291. Epoch 411
process: 150 / 291. Epoch 411
process: 200 / 291. Epoch 411
process: 250 / 291. Epoch 411
process: 291 / 291. Epoch 411
Loss of epoch 411 = 3.713450638289304
process: 50 / 291. Epoch 412
process: 100 / 291. Epoch 412
process: 150 / 291. Epoch 412
process: 200 / 291. Epoch 412
process: 250 / 291. Epoch 412
process: 291 / 291. Epoch 412
Loss of epoch 412 = 3.602365395457474
process: 50 / 291. Epoch 413
process: 100 / 291. Epoch 413
process: 150 / 291. Epoch 413
process: 200 / 291. Epoch 413
process: 250 / 291. Epoch 413
process: 291 / 291. Epoch 413
Loss of epoch 413 = 3.6660814842407645
process: 50 / 291. Epoch 414
process: 100 / 291. Epoch 414
process: 150 / 291. Epoch 414
process: 200 / 291. Epoch 414
process: 250 / 291. Epoch 414
process: 291 / 291. Epoch 414
Loss of epoch 414 = 3.86462612086555
process: 50 / 291. Epoch 415
process: 100 / 291. Epoch 415
process: 150 / 291. Epoch 415
process: 200 / 291. Epoch 415
process: 250 / 291. Epoch 415
process: 291 / 291. Epoch 415
Loss of epoch 415 = 3.8236901981314433
process: 50 / 291. Epoch 416
process: 100 / 291. Epoch 416
process: 150 / 291. Epoch 416
process: 200 / 291. Epoch 416
process: 250 / 291. Epoch 416
process: 291 / 291. Epoch 416
Loss of epoch 416 = 3.6795352267235826
process: 50 / 291. Epoch 417
process: 100 / 291. Epoch 417
process: 150 / 291. Epoch 417
process: 200 / 291. Epoch 417
process: 250 / 291. Epoch 417
process: 291 / 291. Epoch 417
Loss of epoch 417 = 3.6551920572916665
process: 50 / 291. Epoch 418
process: 100 / 291. Epoch 418
process: 150 / 291. Epoch 418
process: 200 / 291. Epoch 418
process: 250 / 291. Epoch 418
process: 291 / 291. Epoch 418
Loss of epoch 418 = 3.6910996060191152
process: 50 / 291. Epoch 419
process: 100 / 291. Epoch 419
process: 150 / 291. Epoch 419
process: 200 / 291. Epoch 419
process: 250 / 291. Epoch 419
process: 291 / 291. Epoch 419
Loss of epoch 419 = 3.612771994469502
process: 50 / 291. Epoch 420
process: 100 / 291. Epoch 420
process: 150 / 291. Epoch 420
process: 200 / 291. Epoch 420
process: 250 / 291. Epoch 420
process: 291 / 291. Epoch 420
Loss of epoch 420 = 3.7031023477770617
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-420. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.785231
     epoch  training_loss
415    416       3.679535
416    417       3.655192
417    418       3.691100
418    419       3.612772
419    420       3.703102
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
37        380  0.014637  0.103347      0.317194   0.317476
38        390  0.014679  0.102739      0.318486   0.318773
39        400  0.014752  0.100889      0.319898   0.320306
40        410  0.014631  0.100686      0.319472   0.319790
41        420  0.014784  0.098580      0.322088   0.322513
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
37      380.0  0.971315  0.978884  ...  0.959195  0.954146  0.939648
38      390.0  0.971722  0.978656  ...  0.958951  0.953738  0.939811
39      400.0  0.971599  0.979308  ...  0.958462  0.953820  0.937612
40      410.0  0.971731  0.978978  ...  0.959195  0.953657  0.939322
41      420.0  0.971710  0.979072  ...  0.958625  0.953168  0.936879

[5 rows x 13 columns]
process: 50 / 291. Epoch 421
process: 100 / 291. Epoch 421
process: 150 / 291. Epoch 421
process: 200 / 291. Epoch 421
process: 250 / 291. Epoch 421
process: 291 / 291. Epoch 421
Loss of epoch 421 = 3.7955401967890894
process: 50 / 291. Epoch 422
process: 100 / 291. Epoch 422
process: 150 / 291. Epoch 422
process: 200 / 291. Epoch 422
process: 250 / 291. Epoch 422
process: 291 / 291. Epoch 422
Loss of epoch 422 = 3.6842712192600944
process: 50 / 291. Epoch 423
process: 100 / 291. Epoch 423
process: 150 / 291. Epoch 423
process: 200 / 291. Epoch 423
process: 250 / 291. Epoch 423
process: 291 / 291. Epoch 423
Loss of epoch 423 = 3.6729383960212627
process: 50 / 291. Epoch 424
process: 100 / 291. Epoch 424
process: 150 / 291. Epoch 424
process: 200 / 291. Epoch 424
process: 250 / 291. Epoch 424
process: 291 / 291. Epoch 424
Loss of epoch 424 = 3.7014923620060136
process: 50 / 291. Epoch 425
process: 100 / 291. Epoch 425
process: 150 / 291. Epoch 425
process: 200 / 291. Epoch 425
process: 250 / 291. Epoch 425
process: 291 / 291. Epoch 425
Loss of epoch 425 = 3.818528847186426
process: 50 / 291. Epoch 426
process: 100 / 291. Epoch 426
process: 150 / 291. Epoch 426
process: 200 / 291. Epoch 426
process: 250 / 291. Epoch 426
process: 291 / 291. Epoch 426
Loss of epoch 426 = 3.7571522296499142
process: 50 / 291. Epoch 427
process: 100 / 291. Epoch 427
process: 150 / 291. Epoch 427
process: 200 / 291. Epoch 427
process: 250 / 291. Epoch 427
process: 291 / 291. Epoch 427
Loss of epoch 427 = 3.708728488777921
process: 50 / 291. Epoch 428
process: 100 / 291. Epoch 428
process: 150 / 291. Epoch 428
process: 200 / 291. Epoch 428
process: 250 / 291. Epoch 428
process: 291 / 291. Epoch 428
Loss of epoch 428 = 3.6291352891430413
process: 50 / 291. Epoch 429
process: 100 / 291. Epoch 429
process: 150 / 291. Epoch 429
process: 200 / 291. Epoch 429
process: 250 / 291. Epoch 429
process: 291 / 291. Epoch 429
Loss of epoch 429 = 3.616760463649055
process: 50 / 291. Epoch 430
process: 100 / 291. Epoch 430
process: 150 / 291. Epoch 430
process: 200 / 291. Epoch 430
process: 250 / 291. Epoch 430
process: 291 / 291. Epoch 430
Loss of epoch 430 = 3.5997738133591066
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-430. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.792392
     epoch  training_loss
425    426       3.757152
426    427       3.708728
427    428       3.629135
428    429       3.616760
429    430       3.599774
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
38        390  0.014679  0.102739      0.318486   0.318773
39        400  0.014752  0.100889      0.319898   0.320306
40        410  0.014631  0.100686      0.319472   0.319790
41        420  0.014784  0.098580      0.322088   0.322513
42        430  0.014709  0.099808      0.322034   0.322419
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
38      390.0  0.971722  0.978656  ...  0.958951  0.953738  0.939811
39      400.0  0.971599  0.979308  ...  0.958462  0.953820  0.937612
40      410.0  0.971731  0.978978  ...  0.959195  0.953657  0.939322
41      420.0  0.971710  0.979072  ...  0.958625  0.953168  0.936879
42      430.0  0.971814  0.978983  ...  0.958625  0.953820  0.941196

[5 rows x 13 columns]
process: 50 / 291. Epoch 431
process: 100 / 291. Epoch 431
process: 150 / 291. Epoch 431
process: 200 / 291. Epoch 431
process: 250 / 291. Epoch 431
process: 291 / 291. Epoch 431
Loss of epoch 431 = 3.710482777598797
process: 50 / 291. Epoch 432
process: 100 / 291. Epoch 432
process: 150 / 291. Epoch 432
process: 200 / 291. Epoch 432
process: 250 / 291. Epoch 432
process: 291 / 291. Epoch 432
Loss of epoch 432 = 3.692825789304124
process: 50 / 291. Epoch 433
process: 100 / 291. Epoch 433
process: 150 / 291. Epoch 433
process: 200 / 291. Epoch 433
process: 250 / 291. Epoch 433
process: 291 / 291. Epoch 433
Loss of epoch 433 = 3.758627141054553
process: 50 / 291. Epoch 434
process: 100 / 291. Epoch 434
process: 150 / 291. Epoch 434
process: 200 / 291. Epoch 434
process: 250 / 291. Epoch 434
process: 291 / 291. Epoch 434
Loss of epoch 434 = 3.688865006174828
process: 50 / 291. Epoch 435
process: 100 / 291. Epoch 435
process: 150 / 291. Epoch 435
process: 200 / 291. Epoch 435
process: 250 / 291. Epoch 435
process: 291 / 291. Epoch 435
Loss of epoch 435 = 3.6748952963917527
process: 50 / 291. Epoch 436
process: 100 / 291. Epoch 436
process: 150 / 291. Epoch 436
process: 200 / 291. Epoch 436
process: 250 / 291. Epoch 436
process: 291 / 291. Epoch 436
Loss of epoch 436 = 3.7722851730294242
process: 50 / 291. Epoch 437
process: 100 / 291. Epoch 437
process: 150 / 291. Epoch 437
process: 200 / 291. Epoch 437
process: 250 / 291. Epoch 437
process: 291 / 291. Epoch 437
Loss of epoch 437 = 3.7107571211877146
process: 50 / 291. Epoch 438
process: 100 / 291. Epoch 438
process: 150 / 291. Epoch 438
process: 200 / 291. Epoch 438
process: 250 / 291. Epoch 438
process: 291 / 291. Epoch 438
Loss of epoch 438 = 3.592967239851804
process: 50 / 291. Epoch 439
process: 100 / 291. Epoch 439
process: 150 / 291. Epoch 439
process: 200 / 291. Epoch 439
process: 250 / 291. Epoch 439
process: 291 / 291. Epoch 439
Loss of epoch 439 = 3.6153035901256443
process: 50 / 291. Epoch 440
process: 100 / 291. Epoch 440
process: 150 / 291. Epoch 440
process: 200 / 291. Epoch 440
process: 250 / 291. Epoch 440
process: 291 / 291. Epoch 440
Loss of epoch 440 = 3.775281558741409
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-440. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.792370
     epoch  training_loss
435    436       3.772285
436    437       3.710757
437    438       3.592967
438    439       3.615304
439    440       3.775282
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
39        400  0.014752  0.100889      0.319898   0.320306
40        410  0.014631  0.100686      0.319472   0.319790
41        420  0.014784  0.098580      0.322088   0.322513
42        430  0.014709  0.099808      0.322034   0.322419
43        440  0.014684  0.099323      0.323099   0.323502
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
39      400.0  0.971599  0.979308  ...  0.958462  0.953820  0.937612
40      410.0  0.971731  0.978978  ...  0.959195  0.953657  0.939322
41      420.0  0.971710  0.979072  ...  0.958625  0.953168  0.936879
42      430.0  0.971814  0.978983  ...  0.958625  0.953820  0.941196
43      440.0  0.971501  0.978774  ...  0.958625  0.954064  0.940951

[5 rows x 13 columns]
process: 50 / 291. Epoch 441
process: 100 / 291. Epoch 441
process: 150 / 291. Epoch 441
process: 200 / 291. Epoch 441
process: 250 / 291. Epoch 441
process: 291 / 291. Epoch 441
Loss of epoch 441 = 3.679979042498926
process: 50 / 291. Epoch 442
process: 100 / 291. Epoch 442
process: 150 / 291. Epoch 442
process: 200 / 291. Epoch 442
process: 250 / 291. Epoch 442
process: 291 / 291. Epoch 442
Loss of epoch 442 = 3.59143108354811
process: 50 / 291. Epoch 443
process: 100 / 291. Epoch 443
process: 150 / 291. Epoch 443
process: 200 / 291. Epoch 443
process: 250 / 291. Epoch 443
process: 291 / 291. Epoch 443
Loss of epoch 443 = 3.658126359133376
process: 50 / 291. Epoch 444
process: 100 / 291. Epoch 444
process: 150 / 291. Epoch 444
process: 200 / 291. Epoch 444
process: 250 / 291. Epoch 444
process: 291 / 291. Epoch 444
Loss of epoch 444 = 3.6069121999838916
process: 50 / 291. Epoch 445
process: 100 / 291. Epoch 445
process: 150 / 291. Epoch 445
process: 200 / 291. Epoch 445
process: 250 / 291. Epoch 445
process: 291 / 291. Epoch 445
Loss of epoch 445 = 3.5742867066688144
process: 50 / 291. Epoch 446
process: 100 / 291. Epoch 446
process: 150 / 291. Epoch 446
process: 200 / 291. Epoch 446
process: 250 / 291. Epoch 446
process: 291 / 291. Epoch 446
Loss of epoch 446 = 3.6239084984428693
process: 50 / 291. Epoch 447
process: 100 / 291. Epoch 447
process: 150 / 291. Epoch 447
process: 200 / 291. Epoch 447
process: 250 / 291. Epoch 447
process: 291 / 291. Epoch 447
Loss of epoch 447 = 3.6062468958064864
process: 50 / 291. Epoch 448
process: 100 / 291. Epoch 448
process: 150 / 291. Epoch 448
process: 200 / 291. Epoch 448
process: 250 / 291. Epoch 448
process: 291 / 291. Epoch 448
Loss of epoch 448 = 3.7375647685781788
process: 50 / 291. Epoch 449
process: 100 / 291. Epoch 449
process: 150 / 291. Epoch 449
process: 200 / 291. Epoch 449
process: 250 / 291. Epoch 449
process: 291 / 291. Epoch 449
Loss of epoch 449 = 3.632434123979811
process: 50 / 291. Epoch 450
process: 100 / 291. Epoch 450
process: 150 / 291. Epoch 450
process: 200 / 291. Epoch 450
process: 250 / 291. Epoch 450
process: 291 / 291. Epoch 450
Loss of epoch 450 = 3.6177655511705327
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-450. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.789754
     epoch  training_loss
445    446       3.623908
446    447       3.606247
447    448       3.737565
448    449       3.632434
449    450       3.617766
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
40        410  0.014631  0.100686      0.319472   0.319790
41        420  0.014784  0.098580      0.322088   0.322513
42        430  0.014709  0.099808      0.322034   0.322419
43        440  0.014684  0.099323      0.323099   0.323502
44        450  0.014717  0.097557      0.326004   0.326510
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
40      410.0  0.971731  0.978978  ...  0.959195  0.953657  0.939322
41      420.0  0.971710  0.979072  ...  0.958625  0.953168  0.936879
42      430.0  0.971814  0.978983  ...  0.958625  0.953820  0.941196
43      440.0  0.971501  0.978774  ...  0.958625  0.954064  0.940951
44      450.0  0.971719  0.978851  ...  0.958870  0.953005  0.939159

[5 rows x 13 columns]
process: 50 / 291. Epoch 451
process: 100 / 291. Epoch 451
process: 150 / 291. Epoch 451
process: 200 / 291. Epoch 451
process: 250 / 291. Epoch 451
process: 291 / 291. Epoch 451
Loss of epoch 451 = 3.662315342434493
process: 50 / 291. Epoch 452
process: 100 / 291. Epoch 452
process: 150 / 291. Epoch 452
process: 200 / 291. Epoch 452
process: 250 / 291. Epoch 452
process: 291 / 291. Epoch 452
Loss of epoch 452 = 3.6203307056754723
process: 50 / 291. Epoch 453
process: 100 / 291. Epoch 453
process: 150 / 291. Epoch 453
process: 200 / 291. Epoch 453
process: 250 / 291. Epoch 453
process: 291 / 291. Epoch 453
Loss of epoch 453 = 3.5539391376718212
process: 50 / 291. Epoch 454
process: 100 / 291. Epoch 454
process: 150 / 291. Epoch 454
process: 200 / 291. Epoch 454
process: 250 / 291. Epoch 454
process: 291 / 291. Epoch 454
Loss of epoch 454 = 3.576510819372852
process: 50 / 291. Epoch 455
process: 100 / 291. Epoch 455
process: 150 / 291. Epoch 455
process: 200 / 291. Epoch 455
process: 250 / 291. Epoch 455
process: 291 / 291. Epoch 455
Loss of epoch 455 = 3.7293646638745703
process: 50 / 291. Epoch 456
process: 100 / 291. Epoch 456
process: 150 / 291. Epoch 456
process: 200 / 291. Epoch 456
process: 250 / 291. Epoch 456
process: 291 / 291. Epoch 456
Loss of epoch 456 = 3.736558842085481
process: 50 / 291. Epoch 457
process: 100 / 291. Epoch 457
process: 150 / 291. Epoch 457
process: 200 / 291. Epoch 457
process: 250 / 291. Epoch 457
process: 291 / 291. Epoch 457
Loss of epoch 457 = 3.5346235032753435
process: 50 / 291. Epoch 458
process: 100 / 291. Epoch 458
process: 150 / 291. Epoch 458
process: 200 / 291. Epoch 458
process: 250 / 291. Epoch 458
process: 291 / 291. Epoch 458
Loss of epoch 458 = 3.54003948198561
process: 50 / 291. Epoch 459
process: 100 / 291. Epoch 459
process: 150 / 291. Epoch 459
process: 200 / 291. Epoch 459
process: 250 / 291. Epoch 459
process: 291 / 291. Epoch 459
Loss of epoch 459 = 3.521424388557775
process: 50 / 291. Epoch 460
process: 100 / 291. Epoch 460
process: 150 / 291. Epoch 460
process: 200 / 291. Epoch 460
process: 250 / 291. Epoch 460
process: 291 / 291. Epoch 460
Loss of epoch 460 = 3.5694294827910222
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-460. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.785676
     epoch  training_loss
455    456       3.736559
456    457       3.534624
457    458       3.540039
458    459       3.521424
459    460       3.569429
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
41        420  0.014784  0.098580      0.322088   0.322513
42        430  0.014709  0.099808      0.322034   0.322419
43        440  0.014684  0.099323      0.323099   0.323502
44        450  0.014717  0.097557      0.326004   0.326510
45        460  0.014879  0.095702      0.325891   0.326335
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
41      420.0  0.971710  0.979072  ...  0.958625  0.953168  0.936879
42      430.0  0.971814  0.978983  ...  0.958625  0.953820  0.941196
43      440.0  0.971501  0.978774  ...  0.958625  0.954064  0.940951
44      450.0  0.971719  0.978851  ...  0.958870  0.953005  0.939159
45      460.0  0.972142  0.978841  ...  0.959032  0.952680  0.934436

[5 rows x 13 columns]
process: 50 / 291. Epoch 461
process: 100 / 291. Epoch 461
process: 150 / 291. Epoch 461
process: 200 / 291. Epoch 461
process: 250 / 291. Epoch 461
process: 291 / 291. Epoch 461
Loss of epoch 461 = 3.5784484234052836
process: 50 / 291. Epoch 462
process: 100 / 291. Epoch 462
process: 150 / 291. Epoch 462
process: 200 / 291. Epoch 462
process: 250 / 291. Epoch 462
process: 291 / 291. Epoch 462
Loss of epoch 462 = 3.609543633215206
process: 50 / 291. Epoch 463
process: 100 / 291. Epoch 463
process: 150 / 291. Epoch 463
process: 200 / 291. Epoch 463
process: 250 / 291. Epoch 463
process: 291 / 291. Epoch 463
Loss of epoch 463 = 3.5519457420532645
process: 50 / 291. Epoch 464
process: 100 / 291. Epoch 464
process: 150 / 291. Epoch 464
process: 200 / 291. Epoch 464
process: 250 / 291. Epoch 464
process: 291 / 291. Epoch 464
Loss of epoch 464 = 3.5930360354918385
process: 50 / 291. Epoch 465
process: 100 / 291. Epoch 465
process: 150 / 291. Epoch 465
process: 200 / 291. Epoch 465
process: 250 / 291. Epoch 465
process: 291 / 291. Epoch 465
Loss of epoch 465 = 3.733408085669029
process: 50 / 291. Epoch 466
process: 100 / 291. Epoch 466
process: 150 / 291. Epoch 466
process: 200 / 291. Epoch 466
process: 250 / 291. Epoch 466
process: 291 / 291. Epoch 466
Loss of epoch 466 = 3.6511893256013748
process: 50 / 291. Epoch 467
process: 100 / 291. Epoch 467
process: 150 / 291. Epoch 467
process: 200 / 291. Epoch 467
process: 250 / 291. Epoch 467
process: 291 / 291. Epoch 467
Loss of epoch 467 = 3.56445396397122
process: 50 / 291. Epoch 468
process: 100 / 291. Epoch 468
process: 150 / 291. Epoch 468
process: 200 / 291. Epoch 468
process: 250 / 291. Epoch 468
process: 291 / 291. Epoch 468
Loss of epoch 468 = 3.530672368315077
process: 50 / 291. Epoch 469
process: 100 / 291. Epoch 469
process: 150 / 291. Epoch 469
process: 200 / 291. Epoch 469
process: 250 / 291. Epoch 469
process: 291 / 291. Epoch 469
Loss of epoch 469 = 3.5743928365281357
process: 50 / 291. Epoch 470
process: 100 / 291. Epoch 470
process: 150 / 291. Epoch 470
process: 200 / 291. Epoch 470
process: 250 / 291. Epoch 470
process: 291 / 291. Epoch 470
Loss of epoch 470 = 3.5501482462145617
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-470. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.792704
     epoch  training_loss
465    466       3.651189
466    467       3.564454
467    468       3.530672
468    469       3.574393
469    470       3.550148
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
42        430  0.014709  0.099808      0.322034   0.322419
43        440  0.014684  0.099323      0.323099   0.323502
44        450  0.014717  0.097557      0.326004   0.326510
45        460  0.014879  0.095702      0.325891   0.326335
46        470  0.014683  0.097522      0.326787   0.327283
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
42      430.0  0.971814  0.978983  ...  0.958625  0.953820  0.941196
43      440.0  0.971501  0.978774  ...  0.958625  0.954064  0.940951
44      450.0  0.971719  0.978851  ...  0.958870  0.953005  0.939159
45      460.0  0.972142  0.978841  ...  0.959032  0.952680  0.934436
46      470.0  0.971615  0.979197  ...  0.958870  0.953738  0.942010

[5 rows x 13 columns]
process: 50 / 291. Epoch 471
process: 100 / 291. Epoch 471
process: 150 / 291. Epoch 471
process: 200 / 291. Epoch 471
process: 250 / 291. Epoch 471
process: 291 / 291. Epoch 471
Loss of epoch 471 = 3.598062312070447
process: 50 / 291. Epoch 472
process: 100 / 291. Epoch 472
process: 150 / 291. Epoch 472
process: 200 / 291. Epoch 472
process: 250 / 291. Epoch 472
process: 291 / 291. Epoch 472
Loss of epoch 472 = 3.547231562768471
process: 50 / 291. Epoch 473
process: 100 / 291. Epoch 473
process: 150 / 291. Epoch 473
process: 200 / 291. Epoch 473
process: 250 / 291. Epoch 473
process: 291 / 291. Epoch 473
Loss of epoch 473 = 3.5697692661350944
process: 50 / 291. Epoch 474
process: 100 / 291. Epoch 474
process: 150 / 291. Epoch 474
process: 200 / 291. Epoch 474
process: 250 / 291. Epoch 474
process: 291 / 291. Epoch 474
Loss of epoch 474 = 3.6049246771638748
process: 50 / 291. Epoch 475
process: 100 / 291. Epoch 475
process: 150 / 291. Epoch 475
process: 200 / 291. Epoch 475
process: 250 / 291. Epoch 475
process: 291 / 291. Epoch 475
Loss of epoch 475 = 3.602991687473153
process: 50 / 291. Epoch 476
process: 100 / 291. Epoch 476
process: 150 / 291. Epoch 476
process: 200 / 291. Epoch 476
process: 250 / 291. Epoch 476
process: 291 / 291. Epoch 476
Loss of epoch 476 = 3.592749107334622
process: 50 / 291. Epoch 477
process: 100 / 291. Epoch 477
process: 150 / 291. Epoch 477
process: 200 / 291. Epoch 477
process: 250 / 291. Epoch 477
process: 291 / 291. Epoch 477
Loss of epoch 477 = 3.5593689594072164
process: 50 / 291. Epoch 478
process: 100 / 291. Epoch 478
process: 150 / 291. Epoch 478
process: 200 / 291. Epoch 478
process: 250 / 291. Epoch 478
process: 291 / 291. Epoch 478
Loss of epoch 478 = 3.6000024330165377
process: 50 / 291. Epoch 479
process: 100 / 291. Epoch 479
process: 150 / 291. Epoch 479
process: 200 / 291. Epoch 479
process: 250 / 291. Epoch 479
process: 291 / 291. Epoch 479
Loss of epoch 479 = 3.663180741247852
process: 50 / 291. Epoch 480
process: 100 / 291. Epoch 480
process: 150 / 291. Epoch 480
process: 200 / 291. Epoch 480
process: 250 / 291. Epoch 480
process: 291 / 291. Epoch 480
Loss of epoch 480 = 3.4659612596649483
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-480. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.799483
     epoch  training_loss
475    476       3.592749
476    477       3.559369
477    478       3.600002
478    479       3.663181
479    480       3.465961
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
43        440  0.014684  0.099323      0.323099   0.323502
44        450  0.014717  0.097557      0.326004   0.326510
45        460  0.014879  0.095702      0.325891   0.326335
46        470  0.014683  0.097522      0.326787   0.327283
47        480  0.014756  0.097132      0.326664   0.327100
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
43      440.0  0.971501  0.978774  ...  0.958625  0.954064  0.940951
44      450.0  0.971719  0.978851  ...  0.958870  0.953005  0.939159
45      460.0  0.972142  0.978841  ...  0.959032  0.952680  0.934436
46      470.0  0.971615  0.979197  ...  0.958870  0.953738  0.942010
47      480.0  0.970997  0.979105  ...  0.959032  0.954309  0.945349

[5 rows x 13 columns]
process: 50 / 291. Epoch 481
process: 100 / 291. Epoch 481
process: 150 / 291. Epoch 481
process: 200 / 291. Epoch 481
process: 250 / 291. Epoch 481
process: 291 / 291. Epoch 481
Loss of epoch 481 = 3.487157028565292
process: 50 / 291. Epoch 482
process: 100 / 291. Epoch 482
process: 150 / 291. Epoch 482
process: 200 / 291. Epoch 482
process: 250 / 291. Epoch 482
process: 291 / 291. Epoch 482
Loss of epoch 482 = 3.504844849052298
process: 50 / 291. Epoch 483
process: 100 / 291. Epoch 483
process: 150 / 291. Epoch 483
process: 200 / 291. Epoch 483
process: 250 / 291. Epoch 483
process: 291 / 291. Epoch 483
Loss of epoch 483 = 3.526951111469072
process: 50 / 291. Epoch 484
process: 100 / 291. Epoch 484
process: 150 / 291. Epoch 484
process: 200 / 291. Epoch 484
process: 250 / 291. Epoch 484
process: 291 / 291. Epoch 484
Loss of epoch 484 = 3.4724387467112328
process: 50 / 291. Epoch 485
process: 100 / 291. Epoch 485
process: 150 / 291. Epoch 485
process: 200 / 291. Epoch 485
process: 250 / 291. Epoch 485
process: 291 / 291. Epoch 485
Loss of epoch 485 = 3.5322164948453607
process: 50 / 291. Epoch 486
process: 100 / 291. Epoch 486
process: 150 / 291. Epoch 486
process: 200 / 291. Epoch 486
process: 250 / 291. Epoch 486
process: 291 / 291. Epoch 486
Loss of epoch 486 = 3.625307063466495
process: 50 / 291. Epoch 487
process: 100 / 291. Epoch 487
process: 150 / 291. Epoch 487
process: 200 / 291. Epoch 487
process: 250 / 291. Epoch 487
process: 291 / 291. Epoch 487
Loss of epoch 487 = 3.5914839387349655
process: 50 / 291. Epoch 488
process: 100 / 291. Epoch 488
process: 150 / 291. Epoch 488
process: 200 / 291. Epoch 488
process: 250 / 291. Epoch 488
process: 291 / 291. Epoch 488
Loss of epoch 488 = 3.631174828178694
process: 50 / 291. Epoch 489
process: 100 / 291. Epoch 489
process: 150 / 291. Epoch 489
process: 200 / 291. Epoch 489
process: 250 / 291. Epoch 489
process: 291 / 291. Epoch 489
Loss of epoch 489 = 3.530286861039519
process: 50 / 291. Epoch 490
process: 100 / 291. Epoch 490
process: 150 / 291. Epoch 490
process: 200 / 291. Epoch 490
process: 250 / 291. Epoch 490
process: 291 / 291. Epoch 490
Loss of epoch 490 = 3.51079902780015
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-490. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.784356
     epoch  training_loss
485    486       3.625307
486    487       3.591484
487    488       3.631175
488    489       3.530287
489    490       3.510799
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
44        450  0.014717  0.097557      0.326004   0.326510
45        460  0.014879  0.095702      0.325891   0.326335
46        470  0.014683  0.097522      0.326787   0.327283
47        480  0.014756  0.097132      0.326664   0.327100
48        490  0.014830  0.094452      0.329208   0.329792
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
44      450.0  0.971719  0.978851  ...  0.958870  0.953005  0.939159
45      460.0  0.972142  0.978841  ...  0.959032  0.952680  0.934436
46      470.0  0.971615  0.979197  ...  0.958870  0.953738  0.942010
47      480.0  0.970997  0.979105  ...  0.959032  0.954309  0.945349
48      490.0  0.971268  0.979278  ...  0.957974  0.952761  0.935983

[5 rows x 13 columns]
process: 50 / 291. Epoch 491
process: 100 / 291. Epoch 491
process: 150 / 291. Epoch 491
process: 200 / 291. Epoch 491
process: 250 / 291. Epoch 491
process: 291 / 291. Epoch 491
Loss of epoch 491 = 3.501257827601482
process: 50 / 291. Epoch 492
process: 100 / 291. Epoch 492
process: 150 / 291. Epoch 492
process: 200 / 291. Epoch 492
process: 250 / 291. Epoch 492
process: 291 / 291. Epoch 492
Loss of epoch 492 = 3.5095504288820876
process: 50 / 291. Epoch 493
process: 100 / 291. Epoch 493
process: 150 / 291. Epoch 493
process: 200 / 291. Epoch 493
process: 250 / 291. Epoch 493
process: 291 / 291. Epoch 493
Loss of epoch 493 = 3.481406719823883
process: 50 / 291. Epoch 494
process: 100 / 291. Epoch 494
process: 150 / 291. Epoch 494
process: 200 / 291. Epoch 494
process: 250 / 291. Epoch 494
process: 291 / 291. Epoch 494
Loss of epoch 494 = 3.5107591766672037
process: 50 / 291. Epoch 495
process: 100 / 291. Epoch 495
process: 150 / 291. Epoch 495
process: 200 / 291. Epoch 495
process: 250 / 291. Epoch 495
process: 291 / 291. Epoch 495
Loss of epoch 495 = 3.6021334199151633
process: 50 / 291. Epoch 496
process: 100 / 291. Epoch 496
process: 150 / 291. Epoch 496
process: 200 / 291. Epoch 496
process: 250 / 291. Epoch 496
process: 291 / 291. Epoch 496
Loss of epoch 496 = 3.519736378463273
process: 50 / 291. Epoch 497
process: 100 / 291. Epoch 497
process: 150 / 291. Epoch 497
process: 200 / 291. Epoch 497
process: 250 / 291. Epoch 497
process: 291 / 291. Epoch 497
Loss of epoch 497 = 3.442124199621456
process: 50 / 291. Epoch 498
process: 100 / 291. Epoch 498
process: 150 / 291. Epoch 498
process: 200 / 291. Epoch 498
process: 250 / 291. Epoch 498
process: 291 / 291. Epoch 498
Loss of epoch 498 = 3.611862969152706
process: 50 / 291. Epoch 499
process: 100 / 291. Epoch 499
process: 150 / 291. Epoch 499
process: 200 / 291. Epoch 499
process: 250 / 291. Epoch 499
process: 291 / 291. Epoch 499
Loss of epoch 499 = 3.570884258886383
process: 50 / 291. Epoch 500
process: 100 / 291. Epoch 500
process: 150 / 291. Epoch 500
process: 200 / 291. Epoch 500
process: 250 / 291. Epoch 500
process: 291 / 291. Epoch 500
Loss of epoch 500 = 3.483350406397659
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-500. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.796028
     epoch  training_loss
495    496       3.519736
496    497       3.442124
497    498       3.611863
498    499       3.570884
499    500       3.483350
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
45        460  0.014879  0.095702      0.325891   0.326335
46        470  0.014683  0.097522      0.326787   0.327283
47        480  0.014756  0.097132      0.326664   0.327100
48        490  0.014830  0.094452      0.329208   0.329792
49        500  0.014724  0.096250      0.329958   0.330554
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
45      460.0  0.972142  0.978841  ...  0.959032  0.952680  0.934436
46      470.0  0.971615  0.979197  ...  0.958870  0.953738  0.942010
47      480.0  0.970997  0.979105  ...  0.959032  0.954309  0.945349
48      490.0  0.971268  0.979278  ...  0.957974  0.952761  0.935983
49      500.0  0.971198  0.978969  ...  0.958870  0.953331  0.943558

[5 rows x 13 columns]
process: 50 / 291. Epoch 501
process: 100 / 291. Epoch 501
process: 150 / 291. Epoch 501
process: 200 / 291. Epoch 501
process: 250 / 291. Epoch 501
process: 291 / 291. Epoch 501
Loss of epoch 501 = 3.532114979327749
process: 50 / 291. Epoch 502
process: 100 / 291. Epoch 502
process: 150 / 291. Epoch 502
process: 200 / 291. Epoch 502
process: 250 / 291. Epoch 502
process: 291 / 291. Epoch 502
Loss of epoch 502 = 3.491260646544781
process: 50 / 291. Epoch 503
process: 100 / 291. Epoch 503
process: 150 / 291. Epoch 503
process: 200 / 291. Epoch 503
process: 250 / 291. Epoch 503
process: 291 / 291. Epoch 503
Loss of epoch 503 = 3.4281630892933848
process: 50 / 291. Epoch 504
process: 100 / 291. Epoch 504
process: 150 / 291. Epoch 504
process: 200 / 291. Epoch 504
process: 250 / 291. Epoch 504
process: 291 / 291. Epoch 504
Loss of epoch 504 = 3.4696464407484964
process: 50 / 291. Epoch 505
process: 100 / 291. Epoch 505
process: 150 / 291. Epoch 505
process: 200 / 291. Epoch 505
process: 250 / 291. Epoch 505
process: 291 / 291. Epoch 505
Loss of epoch 505 = 3.48968589756497
process: 50 / 291. Epoch 506
process: 100 / 291. Epoch 506
process: 150 / 291. Epoch 506
process: 200 / 291. Epoch 506
process: 250 / 291. Epoch 506
process: 291 / 291. Epoch 506
Loss of epoch 506 = 3.564953990818299
process: 50 / 291. Epoch 507
process: 100 / 291. Epoch 507
process: 150 / 291. Epoch 507
process: 200 / 291. Epoch 507
process: 250 / 291. Epoch 507
process: 291 / 291. Epoch 507
Loss of epoch 507 = 3.4923060046848153
process: 50 / 291. Epoch 508
process: 100 / 291. Epoch 508
process: 150 / 291. Epoch 508
process: 200 / 291. Epoch 508
process: 250 / 291. Epoch 508
process: 291 / 291. Epoch 508
Loss of epoch 508 = 3.5227839414196733
process: 50 / 291. Epoch 509
process: 100 / 291. Epoch 509
process: 150 / 291. Epoch 509
process: 200 / 291. Epoch 509
process: 250 / 291. Epoch 509
process: 291 / 291. Epoch 509
Loss of epoch 509 = 3.48730594595683
process: 50 / 291. Epoch 510
process: 100 / 291. Epoch 510
process: 150 / 291. Epoch 510
process: 200 / 291. Epoch 510
process: 250 / 291. Epoch 510
process: 291 / 291. Epoch 510
Loss of epoch 510 = 3.4301722156223153
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-510. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.791350
     epoch  training_loss
505    506       3.564954
506    507       3.492306
507    508       3.522784
508    509       3.487306
509    510       3.430172
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
46        470  0.014683  0.097522      0.326787   0.327283
47        480  0.014756  0.097132      0.326664   0.327100
48        490  0.014830  0.094452      0.329208   0.329792
49        500  0.014724  0.096250      0.329958   0.330554
50        510  0.014830  0.093950      0.329951   0.330517
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
46      470.0  0.971615  0.979197  ...  0.958870  0.953738  0.942010
47      480.0  0.970997  0.979105  ...  0.959032  0.954309  0.945349
48      490.0  0.971268  0.979278  ...  0.957974  0.952761  0.935983
49      500.0  0.971198  0.978969  ...  0.958870  0.953331  0.943558
50      510.0  0.971160  0.979065  ...  0.957892  0.952924  0.941766

[5 rows x 13 columns]
process: 50 / 291. Epoch 511
process: 100 / 291. Epoch 511
process: 150 / 291. Epoch 511
process: 200 / 291. Epoch 511
process: 250 / 291. Epoch 511
process: 291 / 291. Epoch 511
Loss of epoch 511 = 3.451404270027921
process: 50 / 291. Epoch 512
process: 100 / 291. Epoch 512
process: 150 / 291. Epoch 512
process: 200 / 291. Epoch 512
process: 250 / 291. Epoch 512
process: 291 / 291. Epoch 512
Loss of epoch 512 = 3.5132626667874787
process: 50 / 291. Epoch 513
process: 100 / 291. Epoch 513
process: 150 / 291. Epoch 513
process: 200 / 291. Epoch 513
process: 250 / 291. Epoch 513
process: 291 / 291. Epoch 513
Loss of epoch 513 = 3.4390699248952963
process: 50 / 291. Epoch 514
process: 100 / 291. Epoch 514
process: 150 / 291. Epoch 514
process: 200 / 291. Epoch 514
process: 250 / 291. Epoch 514
process: 291 / 291. Epoch 514
Loss of epoch 514 = 3.446116234428694
process: 50 / 291. Epoch 515
process: 100 / 291. Epoch 515
process: 150 / 291. Epoch 515
process: 200 / 291. Epoch 515
process: 250 / 291. Epoch 515
process: 291 / 291. Epoch 515
Loss of epoch 515 = 3.679283115871993
process: 50 / 291. Epoch 516
process: 100 / 291. Epoch 516
process: 150 / 291. Epoch 516
process: 200 / 291. Epoch 516
process: 250 / 291. Epoch 516
process: 291 / 291. Epoch 516
Loss of epoch 516 = 3.5312206360073026
process: 50 / 291. Epoch 517
process: 100 / 291. Epoch 517
process: 150 / 291. Epoch 517
process: 200 / 291. Epoch 517
process: 250 / 291. Epoch 517
process: 291 / 291. Epoch 517
Loss of epoch 517 = 3.3738610965689433
process: 50 / 291. Epoch 518
process: 100 / 291. Epoch 518
process: 150 / 291. Epoch 518
process: 200 / 291. Epoch 518
process: 250 / 291. Epoch 518
process: 291 / 291. Epoch 518
Loss of epoch 518 = 3.459229144853415
process: 50 / 291. Epoch 519
process: 100 / 291. Epoch 519
process: 150 / 291. Epoch 519
process: 200 / 291. Epoch 519
process: 250 / 291. Epoch 519
process: 291 / 291. Epoch 519
Loss of epoch 519 = 3.5094461867080113
process: 50 / 291. Epoch 520
process: 100 / 291. Epoch 520
process: 150 / 291. Epoch 520
process: 200 / 291. Epoch 520
process: 250 / 291. Epoch 520
process: 291 / 291. Epoch 520
Loss of epoch 520 = 3.4576963444346007
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-520. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.785517
     epoch  training_loss
515    516       3.531221
516    517       3.373861
517    518       3.459229
518    519       3.509446
519    520       3.457696
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
47        480  0.014756  0.097132      0.326664   0.327100
48        490  0.014830  0.094452      0.329208   0.329792
49        500  0.014724  0.096250      0.329958   0.330554
50        510  0.014830  0.093950      0.329951   0.330517
51        520  0.014914  0.092291      0.331047   0.331601
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
47      480.0  0.970997  0.979105  ...  0.959032  0.954309  0.945349
48      490.0  0.971268  0.979278  ...  0.957974  0.952761  0.935983
49      500.0  0.971198  0.978969  ...  0.958870  0.953331  0.943558
50      510.0  0.971160  0.979065  ...  0.957892  0.952924  0.941766
51      520.0  0.971795  0.978947  ...  0.958137  0.952598  0.937368

[5 rows x 13 columns]
process: 50 / 291. Epoch 521
process: 100 / 291. Epoch 521
process: 150 / 291. Epoch 521
process: 200 / 291. Epoch 521
process: 250 / 291. Epoch 521
process: 291 / 291. Epoch 521
Loss of epoch 521 = 3.439048111643578
process: 50 / 291. Epoch 522
process: 100 / 291. Epoch 522
process: 150 / 291. Epoch 522
process: 200 / 291. Epoch 522
process: 250 / 291. Epoch 522
process: 291 / 291. Epoch 522
Loss of epoch 522 = 3.4052264551116838
process: 50 / 291. Epoch 523
process: 100 / 291. Epoch 523
process: 150 / 291. Epoch 523
process: 200 / 291. Epoch 523
process: 250 / 291. Epoch 523
process: 291 / 291. Epoch 523
Loss of epoch 523 = 3.397142128436426
process: 50 / 291. Epoch 524
process: 100 / 291. Epoch 524
process: 150 / 291. Epoch 524
process: 200 / 291. Epoch 524
process: 250 / 291. Epoch 524
process: 291 / 291. Epoch 524
Loss of epoch 524 = 3.475759394799721
process: 50 / 291. Epoch 525
process: 100 / 291. Epoch 525
process: 150 / 291. Epoch 525
process: 200 / 291. Epoch 525
process: 250 / 291. Epoch 525
process: 291 / 291. Epoch 525
Loss of epoch 525 = 3.4753376020189
process: 50 / 291. Epoch 526
process: 100 / 291. Epoch 526
process: 150 / 291. Epoch 526
process: 200 / 291. Epoch 526
process: 250 / 291. Epoch 526
process: 291 / 291. Epoch 526
Loss of epoch 526 = 3.513465907565507
process: 50 / 291. Epoch 527
process: 100 / 291. Epoch 527
process: 150 / 291. Epoch 527
process: 200 / 291. Epoch 527
process: 250 / 291. Epoch 527
process: 291 / 291. Epoch 527
Loss of epoch 527 = 3.4565792542552622
process: 50 / 291. Epoch 528
process: 100 / 291. Epoch 528
process: 150 / 291. Epoch 528
process: 200 / 291. Epoch 528
process: 250 / 291. Epoch 528
process: 291 / 291. Epoch 528
Loss of epoch 528 = 3.421682456105026
process: 50 / 291. Epoch 529
process: 100 / 291. Epoch 529
process: 150 / 291. Epoch 529
process: 200 / 291. Epoch 529
process: 250 / 291. Epoch 529
process: 291 / 291. Epoch 529
Loss of epoch 529 = 3.4709279692869415
process: 50 / 291. Epoch 530
process: 100 / 291. Epoch 530
process: 150 / 291. Epoch 530
process: 200 / 291. Epoch 530
process: 250 / 291. Epoch 530
process: 291 / 291. Epoch 530
Loss of epoch 530 = 3.3845061731502364
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-530. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.791170
     epoch  training_loss
525    526       3.513466
526    527       3.456579
527    528       3.421682
528    529       3.470928
529    530       3.384506
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
48        490  0.014830  0.094452      0.329208   0.329792
49        500  0.014724  0.096250      0.329958   0.330554
50        510  0.014830  0.093950      0.329951   0.330517
51        520  0.014914  0.092291      0.331047   0.331601
52        530  0.014889  0.093470      0.332922   0.333537
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
48      490.0  0.971268  0.979278  ...  0.957974  0.952761  0.935983
49      500.0  0.971198  0.978969  ...  0.958870  0.953331  0.943558
50      510.0  0.971160  0.979065  ...  0.957892  0.952924  0.941766
51      520.0  0.971795  0.978947  ...  0.958137  0.952598  0.937368
52      530.0  0.971406  0.979280  ...  0.958870  0.952842  0.941359

[5 rows x 13 columns]
process: 50 / 291. Epoch 531
process: 100 / 291. Epoch 531
process: 150 / 291. Epoch 531
process: 200 / 291. Epoch 531
process: 250 / 291. Epoch 531
process: 291 / 291. Epoch 531
Loss of epoch 531 = 3.4239430640571307
process: 50 / 291. Epoch 532
process: 100 / 291. Epoch 532
process: 150 / 291. Epoch 532
process: 200 / 291. Epoch 532
process: 250 / 291. Epoch 532
process: 291 / 291. Epoch 532
Loss of epoch 532 = 3.4746402071923326
process: 50 / 291. Epoch 533
process: 100 / 291. Epoch 533
process: 150 / 291. Epoch 533
process: 200 / 291. Epoch 533
process: 250 / 291. Epoch 533
process: 291 / 291. Epoch 533
Loss of epoch 533 = 3.567248577104811
process: 50 / 291. Epoch 534
process: 100 / 291. Epoch 534
process: 150 / 291. Epoch 534
process: 200 / 291. Epoch 534
process: 250 / 291. Epoch 534
process: 291 / 291. Epoch 534
Loss of epoch 534 = 3.449479670049399
process: 50 / 291. Epoch 535
process: 100 / 291. Epoch 535
process: 150 / 291. Epoch 535
process: 200 / 291. Epoch 535
process: 250 / 291. Epoch 535
process: 291 / 291. Epoch 535
Loss of epoch 535 = 3.3227358683687713
process: 50 / 291. Epoch 536
process: 100 / 291. Epoch 536
process: 150 / 291. Epoch 536
process: 200 / 291. Epoch 536
process: 250 / 291. Epoch 536
process: 291 / 291. Epoch 536
Loss of epoch 536 = 3.4033714897444156
process: 50 / 291. Epoch 537
process: 100 / 291. Epoch 537
process: 150 / 291. Epoch 537
process: 200 / 291. Epoch 537
process: 250 / 291. Epoch 537
process: 291 / 291. Epoch 537
Loss of epoch 537 = 3.3635811822111252
process: 50 / 291. Epoch 538
process: 100 / 291. Epoch 538
process: 150 / 291. Epoch 538
process: 200 / 291. Epoch 538
process: 250 / 291. Epoch 538
process: 291 / 291. Epoch 538
Loss of epoch 538 = 3.427346980039197
process: 50 / 291. Epoch 539
process: 100 / 291. Epoch 539
process: 150 / 291. Epoch 539
process: 200 / 291. Epoch 539
process: 250 / 291. Epoch 539
process: 291 / 291. Epoch 539
Loss of epoch 539 = 3.4642971602502146
process: 50 / 291. Epoch 540
process: 100 / 291. Epoch 540
process: 150 / 291. Epoch 540
process: 200 / 291. Epoch 540
process: 250 / 291. Epoch 540
process: 291 / 291. Epoch 540
Loss of epoch 540 = 3.3849288049022768
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-540. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.788730
     epoch  training_loss
535    536       3.403371
536    537       3.363581
537    538       3.427347
538    539       3.464297
539    540       3.384929
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
49        500  0.014724  0.096250      0.329958   0.330554
50        510  0.014830  0.093950      0.329951   0.330517
51        520  0.014914  0.092291      0.331047   0.331601
52        530  0.014889  0.093470      0.332922   0.333537
53        540  0.014926  0.090904      0.333400   0.334011
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
49      500.0  0.971198  0.978969  ...  0.958870  0.953331  0.943558
50      510.0  0.971160  0.979065  ...  0.957892  0.952924  0.941766
51      520.0  0.971795  0.978947  ...  0.958137  0.952598  0.937368
52      530.0  0.971406  0.979280  ...  0.958870  0.952842  0.941359
53      540.0  0.971590  0.979280  ...  0.958218  0.952842  0.938915

[5 rows x 13 columns]
process: 50 / 291. Epoch 541
process: 100 / 291. Epoch 541
process: 150 / 291. Epoch 541
process: 200 / 291. Epoch 541
process: 250 / 291. Epoch 541
process: 291 / 291. Epoch 541
Loss of epoch 541 = 3.5412899685889174
process: 50 / 291. Epoch 542
process: 100 / 291. Epoch 542
process: 150 / 291. Epoch 542
process: 200 / 291. Epoch 542
process: 250 / 291. Epoch 542
process: 291 / 291. Epoch 542
Loss of epoch 542 = 3.4528273749597296
process: 50 / 291. Epoch 543
process: 100 / 291. Epoch 543
process: 150 / 291. Epoch 543
process: 200 / 291. Epoch 543
process: 250 / 291. Epoch 543
process: 291 / 291. Epoch 543
Loss of epoch 543 = 3.414585598555627
process: 50 / 291. Epoch 544
process: 100 / 291. Epoch 544
process: 150 / 291. Epoch 544
process: 200 / 291. Epoch 544
process: 250 / 291. Epoch 544
process: 291 / 291. Epoch 544
Loss of epoch 544 = 3.365882480267397
process: 50 / 291. Epoch 545
process: 100 / 291. Epoch 545
process: 150 / 291. Epoch 545
process: 200 / 291. Epoch 545
process: 250 / 291. Epoch 545
process: 291 / 291. Epoch 545
Loss of epoch 545 = 3.4203516380074097
process: 50 / 291. Epoch 546
process: 100 / 291. Epoch 546
process: 150 / 291. Epoch 546
process: 200 / 291. Epoch 546
process: 250 / 291. Epoch 546
process: 291 / 291. Epoch 546
Loss of epoch 546 = 3.474818069090958
process: 50 / 291. Epoch 547
process: 100 / 291. Epoch 547
process: 150 / 291. Epoch 547
process: 200 / 291. Epoch 547
process: 250 / 291. Epoch 547
process: 291 / 291. Epoch 547
Loss of epoch 547 = 3.440954883483677
process: 50 / 291. Epoch 548
process: 100 / 291. Epoch 548
process: 150 / 291. Epoch 548
process: 200 / 291. Epoch 548
process: 250 / 291. Epoch 548
process: 291 / 291. Epoch 548
Loss of epoch 548 = 3.421544445339347
process: 50 / 291. Epoch 549
process: 100 / 291. Epoch 549
process: 150 / 291. Epoch 549
process: 200 / 291. Epoch 549
process: 250 / 291. Epoch 549
process: 291 / 291. Epoch 549
Loss of epoch 549 = 3.419739818245275
process: 50 / 291. Epoch 550
process: 100 / 291. Epoch 550
process: 150 / 291. Epoch 550
process: 200 / 291. Epoch 550
process: 250 / 291. Epoch 550
process: 291 / 291. Epoch 550
Loss of epoch 550 = 3.4360890601508807
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-550. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.790391
     epoch  training_loss
545    546       3.474818
546    547       3.440955
547    548       3.421544
548    549       3.419740
549    550       3.436089
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
50        510  0.014830  0.093950      0.329951   0.330517
51        520  0.014914  0.092291      0.331047   0.331601
52        530  0.014889  0.093470      0.332922   0.333537
53        540  0.014926  0.090904      0.333400   0.334011
54        550  0.014860  0.091944      0.334132   0.334762
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
50      510.0  0.971160  0.979065  ...  0.957892  0.952924  0.941766
51      520.0  0.971795  0.978947  ...  0.958137  0.952598  0.937368
52      530.0  0.971406  0.979280  ...  0.958870  0.952842  0.941359
53      540.0  0.971590  0.979280  ...  0.958218  0.952842  0.938915
54      550.0  0.971722  0.979046  ...  0.958951  0.952272  0.941114

[5 rows x 13 columns]
process: 50 / 291. Epoch 551
process: 100 / 291. Epoch 551
process: 150 / 291. Epoch 551
process: 200 / 291. Epoch 551
process: 250 / 291. Epoch 551
process: 291 / 291. Epoch 551
Loss of epoch 551 = 3.3356027504832473
process: 50 / 291. Epoch 552
process: 100 / 291. Epoch 552
process: 150 / 291. Epoch 552
process: 200 / 291. Epoch 552
process: 250 / 291. Epoch 552
process: 291 / 291. Epoch 552
Loss of epoch 552 = 3.381457561479811
process: 50 / 291. Epoch 553
process: 100 / 291. Epoch 553
process: 150 / 291. Epoch 553
process: 200 / 291. Epoch 553
process: 250 / 291. Epoch 553
process: 291 / 291. Epoch 553
Loss of epoch 553 = 3.3261047573024056
process: 50 / 291. Epoch 554
process: 100 / 291. Epoch 554
process: 150 / 291. Epoch 554
process: 200 / 291. Epoch 554
process: 250 / 291. Epoch 554
process: 291 / 291. Epoch 554
Loss of epoch 554 = 3.39111412022122
process: 50 / 291. Epoch 555
process: 100 / 291. Epoch 555
process: 150 / 291. Epoch 555
process: 200 / 291. Epoch 555
process: 250 / 291. Epoch 555
process: 291 / 291. Epoch 555
Loss of epoch 555 = 3.461832892034472
process: 50 / 291. Epoch 556
process: 100 / 291. Epoch 556
process: 150 / 291. Epoch 556
process: 200 / 291. Epoch 556
process: 250 / 291. Epoch 556
process: 291 / 291. Epoch 556
Loss of epoch 556 = 3.4782138051036298
process: 50 / 291. Epoch 557
process: 100 / 291. Epoch 557
process: 150 / 291. Epoch 557
process: 200 / 291. Epoch 557
process: 250 / 291. Epoch 557
process: 291 / 291. Epoch 557
Loss of epoch 557 = 3.3930678744496348
process: 50 / 291. Epoch 558
process: 100 / 291. Epoch 558
process: 150 / 291. Epoch 558
process: 200 / 291. Epoch 558
process: 250 / 291. Epoch 558
process: 291 / 291. Epoch 558
Loss of epoch 558 = 3.3894705756013748
process: 50 / 291. Epoch 559
process: 100 / 291. Epoch 559
process: 150 / 291. Epoch 559
process: 200 / 291. Epoch 559
process: 250 / 291. Epoch 559
process: 291 / 291. Epoch 559
Loss of epoch 559 = 3.3887129845897768
process: 50 / 291. Epoch 560
process: 100 / 291. Epoch 560
process: 150 / 291. Epoch 560
process: 200 / 291. Epoch 560
process: 250 / 291. Epoch 560
process: 291 / 291. Epoch 560
Loss of epoch 560 = 3.387929804955971
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-560. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.800299
     epoch  training_loss
555    556       3.478214
556    557       3.393068
557    558       3.389471
558    559       3.388713
559    560       3.387930
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
51        520  0.014914  0.092291      0.331047   0.331601
52        530  0.014889  0.093470      0.332922   0.333537
53        540  0.014926  0.090904      0.333400   0.334011
54        550  0.014860  0.091944      0.334132   0.334762
55        560  0.014937  0.093489      0.333521   0.334092
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
51      520.0  0.971795  0.978947  ...  0.958137  0.952598  0.937368
52      530.0  0.971406  0.979280  ...  0.958870  0.952842  0.941359
53      540.0  0.971590  0.979280  ...  0.958218  0.952842  0.938915
54      550.0  0.971722  0.979046  ...  0.958951  0.952272  0.941114
55      560.0  0.970238  0.978767  ...  0.958218  0.953820  0.945512

[5 rows x 13 columns]
process: 50 / 291. Epoch 561
process: 100 / 291. Epoch 561
process: 150 / 291. Epoch 561
process: 200 / 291. Epoch 561
process: 250 / 291. Epoch 561
process: 291 / 291. Epoch 561
Loss of epoch 561 = 3.321788040633054
process: 50 / 291. Epoch 562
process: 100 / 291. Epoch 562
process: 150 / 291. Epoch 562
process: 200 / 291. Epoch 562
process: 250 / 291. Epoch 562
process: 291 / 291. Epoch 562
Loss of epoch 562 = 3.291453358233999
process: 50 / 291. Epoch 563
process: 100 / 291. Epoch 563
process: 150 / 291. Epoch 563
process: 200 / 291. Epoch 563
process: 250 / 291. Epoch 563
process: 291 / 291. Epoch 563
Loss of epoch 563 = 3.423816169660116
process: 50 / 291. Epoch 564
process: 100 / 291. Epoch 564
process: 150 / 291. Epoch 564
process: 200 / 291. Epoch 564
process: 250 / 291. Epoch 564
process: 291 / 291. Epoch 564
Loss of epoch 564 = 3.3765642618395617
process: 50 / 291. Epoch 565
process: 100 / 291. Epoch 565
process: 150 / 291. Epoch 565
process: 200 / 291. Epoch 565
process: 250 / 291. Epoch 565
process: 291 / 291. Epoch 565
Loss of epoch 565 = 3.344956860099871
process: 50 / 291. Epoch 566
process: 100 / 291. Epoch 566
process: 150 / 291. Epoch 566
process: 200 / 291. Epoch 566
process: 250 / 291. Epoch 566
process: 291 / 291. Epoch 566
Loss of epoch 566 = 3.3979779535142827
process: 50 / 291. Epoch 567
process: 100 / 291. Epoch 567
process: 150 / 291. Epoch 567
process: 200 / 291. Epoch 567
process: 250 / 291. Epoch 567
process: 291 / 291. Epoch 567
Loss of epoch 567 = 3.4143129329091493
process: 50 / 291. Epoch 568
process: 100 / 291. Epoch 568
process: 150 / 291. Epoch 568
process: 200 / 291. Epoch 568
process: 250 / 291. Epoch 568
process: 291 / 291. Epoch 568
Loss of epoch 568 = 3.428897189110825
process: 50 / 291. Epoch 569
process: 100 / 291. Epoch 569
process: 150 / 291. Epoch 569
process: 200 / 291. Epoch 569
process: 250 / 291. Epoch 569
process: 291 / 291. Epoch 569
Loss of epoch 569 = 3.3974433191043816
process: 50 / 291. Epoch 570
process: 100 / 291. Epoch 570
process: 150 / 291. Epoch 570
process: 200 / 291. Epoch 570
process: 250 / 291. Epoch 570
process: 291 / 291. Epoch 570
Loss of epoch 570 = 3.3706428029692868
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-570. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.788201
     epoch  training_loss
565    566       3.397978
566    567       3.414313
567    568       3.428897
568    569       3.397443
569    570       3.370643
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
52        530  0.014889  0.093470      0.332922   0.333537
53        540  0.014926  0.090904      0.333400   0.334011
54        550  0.014860  0.091944      0.334132   0.334762
55        560  0.014937  0.093489      0.333521   0.334092
56        570  0.014905  0.090622      0.335250   0.335917
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
52      530.0  0.971406  0.979280  ...  0.958870  0.952842  0.941359
53      540.0  0.971590  0.979280  ...  0.958218  0.952842  0.938915
54      550.0  0.971722  0.979046  ...  0.958951  0.952272  0.941114
55      560.0  0.970238  0.978767  ...  0.958218  0.953820  0.945512
56      570.0  0.972029  0.978499  ...  0.958788  0.952109  0.938752

[5 rows x 13 columns]
process: 50 / 291. Epoch 571
process: 100 / 291. Epoch 571
process: 150 / 291. Epoch 571
process: 200 / 291. Epoch 571
process: 250 / 291. Epoch 571
process: 291 / 291. Epoch 571
Loss of epoch 571 = 3.3346492596917954
process: 50 / 291. Epoch 572
process: 100 / 291. Epoch 572
process: 150 / 291. Epoch 572
process: 200 / 291. Epoch 572
process: 250 / 291. Epoch 572
process: 291 / 291. Epoch 572
Loss of epoch 572 = 3.4001072624704682
process: 50 / 291. Epoch 573
process: 100 / 291. Epoch 573
process: 150 / 291. Epoch 573
process: 200 / 291. Epoch 573
process: 250 / 291. Epoch 573
process: 291 / 291. Epoch 573
Loss of epoch 573 = 3.3449262376503435
process: 50 / 291. Epoch 574
process: 100 / 291. Epoch 574
process: 150 / 291. Epoch 574
process: 200 / 291. Epoch 574
process: 250 / 291. Epoch 574
process: 291 / 291. Epoch 574
Loss of epoch 574 = 3.372387863106744
process: 50 / 291. Epoch 575
process: 100 / 291. Epoch 575
process: 150 / 291. Epoch 575
process: 200 / 291. Epoch 575
process: 250 / 291. Epoch 575
process: 291 / 291. Epoch 575
Loss of epoch 575 = 3.3660089551788017
process: 50 / 291. Epoch 576
process: 100 / 291. Epoch 576
process: 150 / 291. Epoch 576
process: 200 / 291. Epoch 576
process: 250 / 291. Epoch 576
process: 291 / 291. Epoch 576
Loss of epoch 576 = 3.3916944785626075
process: 50 / 291. Epoch 577
process: 100 / 291. Epoch 577
process: 150 / 291. Epoch 577
process: 200 / 291. Epoch 577
process: 250 / 291. Epoch 577
process: 291 / 291. Epoch 577
Loss of epoch 577 = 3.368238940681379
process: 50 / 291. Epoch 578
process: 100 / 291. Epoch 578
process: 150 / 291. Epoch 578
process: 200 / 291. Epoch 578
process: 250 / 291. Epoch 578
process: 291 / 291. Epoch 578
Loss of epoch 578 = 3.2926965038391325
process: 50 / 291. Epoch 579
process: 100 / 291. Epoch 579
process: 150 / 291. Epoch 579
process: 200 / 291. Epoch 579
process: 250 / 291. Epoch 579
process: 291 / 291. Epoch 579
Loss of epoch 579 = 3.299952765920318
process: 50 / 291. Epoch 580
process: 100 / 291. Epoch 580
process: 150 / 291. Epoch 580
process: 200 / 291. Epoch 580
process: 250 / 291. Epoch 580
process: 291 / 291. Epoch 580
Loss of epoch 580 = 3.3568912257033934
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-580. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.794616
     epoch  training_loss
575    576       3.391694
576    577       3.368239
577    578       3.292697
578    579       3.299953
579    580       3.356891
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
53        540  0.014926  0.090904      0.333400   0.334011
54        550  0.014860  0.091944      0.334132   0.334762
55        560  0.014937  0.093489      0.333521   0.334092
56        570  0.014905  0.090622      0.335250   0.335917
57        580  0.014922  0.090912      0.334399   0.334975
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
53      540.0  0.971590  0.979280  ...  0.958218  0.952842  0.938915
54      550.0  0.971722  0.979046  ...  0.958951  0.952272  0.941114
55      560.0  0.970238  0.978767  ...  0.958218  0.953820  0.945512
56      570.0  0.972029  0.978499  ...  0.958788  0.952109  0.938752
57      580.0  0.971183  0.979053  ...  0.958462  0.952517  0.943313

[5 rows x 13 columns]
process: 50 / 291. Epoch 581
process: 100 / 291. Epoch 581
process: 150 / 291. Epoch 581
process: 200 / 291. Epoch 581
process: 250 / 291. Epoch 581
process: 291 / 291. Epoch 581
Loss of epoch 581 = 3.37304729448561
process: 50 / 291. Epoch 582
process: 100 / 291. Epoch 582
process: 150 / 291. Epoch 582
process: 200 / 291. Epoch 582
process: 250 / 291. Epoch 582
process: 291 / 291. Epoch 582
Loss of epoch 582 = 3.396228279035116
process: 50 / 291. Epoch 583
process: 100 / 291. Epoch 583
process: 150 / 291. Epoch 583
process: 200 / 291. Epoch 583
process: 250 / 291. Epoch 583
process: 291 / 291. Epoch 583
Loss of epoch 583 = 3.4286081635255585
process: 50 / 291. Epoch 584
process: 100 / 291. Epoch 584
process: 150 / 291. Epoch 584
process: 200 / 291. Epoch 584
process: 250 / 291. Epoch 584
process: 291 / 291. Epoch 584
Loss of epoch 584 = 3.3520075742321733
process: 50 / 291. Epoch 585
process: 100 / 291. Epoch 585
process: 150 / 291. Epoch 585
process: 200 / 291. Epoch 585
process: 250 / 291. Epoch 585
process: 291 / 291. Epoch 585
Loss of epoch 585 = 3.3097194396343426
process: 50 / 291. Epoch 586
process: 100 / 291. Epoch 586
process: 150 / 291. Epoch 586
process: 200 / 291. Epoch 586
process: 250 / 291. Epoch 586
process: 291 / 291. Epoch 586
Loss of epoch 586 = 3.227577025947702
process: 50 / 291. Epoch 587
process: 100 / 291. Epoch 587
process: 150 / 291. Epoch 587
process: 200 / 291. Epoch 587
process: 250 / 291. Epoch 587
process: 291 / 291. Epoch 587
Loss of epoch 587 = 3.308260258940077
process: 50 / 291. Epoch 588
process: 100 / 291. Epoch 588
process: 150 / 291. Epoch 588
process: 200 / 291. Epoch 588
process: 250 / 291. Epoch 588
process: 291 / 291. Epoch 588
Loss of epoch 588 = 3.3277319419834623
process: 50 / 291. Epoch 589
process: 100 / 291. Epoch 589
process: 150 / 291. Epoch 589
process: 200 / 291. Epoch 589
process: 250 / 291. Epoch 589
process: 291 / 291. Epoch 589
Loss of epoch 589 = 3.3548277759879723
process: 50 / 291. Epoch 590
process: 100 / 291. Epoch 590
process: 150 / 291. Epoch 590
process: 200 / 291. Epoch 590
process: 250 / 291. Epoch 590
process: 291 / 291. Epoch 590
Loss of epoch 590 = 3.4253124748308634
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-590. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.784010
     epoch  training_loss
585    586       3.227577
586    587       3.308260
587    588       3.327732
588    589       3.354828
589    590       3.425312
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
54        550  0.014860  0.091944      0.334132   0.334762
55        560  0.014937  0.093489      0.333521   0.334092
56        570  0.014905  0.090622      0.335250   0.335917
57        580  0.014922  0.090912      0.334399   0.334975
58        590  0.015093  0.088637      0.336951   0.337645
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
54      550.0  0.971722  0.979046  ...  0.958951  0.952272  0.941114
55      560.0  0.970238  0.978767  ...  0.958218  0.953820  0.945512
56      570.0  0.972029  0.978499  ...  0.958788  0.952109  0.938752
57      580.0  0.971183  0.979053  ...  0.958462  0.952517  0.943313
58      590.0  0.971378  0.979462  ...  0.958137  0.951621  0.935657

[5 rows x 13 columns]
process: 50 / 291. Epoch 591
process: 100 / 291. Epoch 591
process: 150 / 291. Epoch 591
process: 200 / 291. Epoch 591
process: 250 / 291. Epoch 591
process: 291 / 291. Epoch 591
Loss of epoch 591 = 3.3942529212977877
process: 50 / 291. Epoch 592
process: 100 / 291. Epoch 592
process: 150 / 291. Epoch 592
process: 200 / 291. Epoch 592
process: 250 / 291. Epoch 592
process: 291 / 291. Epoch 592
Loss of epoch 592 = 3.3258081809761597
process: 50 / 291. Epoch 593
process: 100 / 291. Epoch 593
process: 150 / 291. Epoch 593
process: 200 / 291. Epoch 593
process: 250 / 291. Epoch 593
process: 291 / 291. Epoch 593
Loss of epoch 593 = 3.299813077212199
process: 50 / 291. Epoch 594
process: 100 / 291. Epoch 594
process: 150 / 291. Epoch 594
process: 200 / 291. Epoch 594
process: 250 / 291. Epoch 594
process: 291 / 291. Epoch 594
Loss of epoch 594 = 3.281554966038445
process: 50 / 291. Epoch 595
process: 100 / 291. Epoch 595
process: 150 / 291. Epoch 595
process: 200 / 291. Epoch 595
process: 250 / 291. Epoch 595
process: 291 / 291. Epoch 595
Loss of epoch 595 = 3.3336846525316797
process: 50 / 291. Epoch 596
process: 100 / 291. Epoch 596
process: 150 / 291. Epoch 596
process: 200 / 291. Epoch 596
process: 250 / 291. Epoch 596
process: 291 / 291. Epoch 596
Loss of epoch 596 = 3.303796302821628
process: 50 / 291. Epoch 597
process: 100 / 291. Epoch 597
process: 150 / 291. Epoch 597
process: 200 / 291. Epoch 597
process: 250 / 291. Epoch 597
process: 291 / 291. Epoch 597
Loss of epoch 597 = 3.2823295462172464
process: 50 / 291. Epoch 598
process: 100 / 291. Epoch 598
process: 150 / 291. Epoch 598
process: 200 / 291. Epoch 598
process: 250 / 291. Epoch 598
process: 291 / 291. Epoch 598
Loss of epoch 598 = 3.3226484056190935
process: 50 / 291. Epoch 599
process: 100 / 291. Epoch 599
process: 150 / 291. Epoch 599
process: 200 / 291. Epoch 599
process: 250 / 291. Epoch 599
process: 291 / 291. Epoch 599
Loss of epoch 599 = 3.3269730925150345
process: 50 / 291. Epoch 600
process: 100 / 291. Epoch 600
process: 150 / 291. Epoch 600
process: 200 / 291. Epoch 600
process: 250 / 291. Epoch 600
process: 291 / 291. Epoch 600
Loss of epoch 600 = 3.3735181670827963
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-600. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.792518
     epoch  training_loss
595    596       3.303796
596    597       3.282330
597    598       3.322648
598    599       3.326973
599    600       3.373518
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
55        560  0.014937  0.093489      0.333521   0.334092
56        570  0.014905  0.090622      0.335250   0.335917
57        580  0.014922  0.090912      0.334399   0.334975
58        590  0.015093  0.088637      0.336951   0.337645
59        600  0.014934  0.089969      0.337678   0.338370
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
55      560.0  0.970238  0.978767  ...  0.958218  0.953820  0.945512
56      570.0  0.972029  0.978499  ...  0.958788  0.952109  0.938752
57      580.0  0.971183  0.979053  ...  0.958462  0.952517  0.943313
58      590.0  0.971378  0.979462  ...  0.958137  0.951621  0.935657
59      600.0  0.970858  0.978931  ...  0.958137  0.952028  0.941440

[5 rows x 13 columns]
process: 50 / 291. Epoch 601
process: 100 / 291. Epoch 601
process: 150 / 291. Epoch 601
process: 200 / 291. Epoch 601
process: 250 / 291. Epoch 601
process: 291 / 291. Epoch 601
Loss of epoch 601 = 3.402162951702105
process: 50 / 291. Epoch 602
process: 100 / 291. Epoch 602
process: 150 / 291. Epoch 602
process: 200 / 291. Epoch 602
process: 250 / 291. Epoch 602
process: 291 / 291. Epoch 602
Loss of epoch 602 = 3.3428004943218426
process: 50 / 291. Epoch 603
process: 100 / 291. Epoch 603
process: 150 / 291. Epoch 603
process: 200 / 291. Epoch 603
process: 250 / 291. Epoch 603
process: 291 / 291. Epoch 603
Loss of epoch 603 = 3.2651404941204896
process: 50 / 291. Epoch 604
process: 100 / 291. Epoch 604
process: 150 / 291. Epoch 604
process: 200 / 291. Epoch 604
process: 250 / 291. Epoch 604
process: 291 / 291. Epoch 604
Loss of epoch 604 = 3.2658875979918385
process: 50 / 291. Epoch 605
process: 100 / 291. Epoch 605
process: 150 / 291. Epoch 605
process: 200 / 291. Epoch 605
process: 250 / 291. Epoch 605
process: 291 / 291. Epoch 605
Loss of epoch 605 = 3.374110690506873
process: 50 / 291. Epoch 606
process: 100 / 291. Epoch 606
process: 150 / 291. Epoch 606
process: 200 / 291. Epoch 606
process: 250 / 291. Epoch 606
process: 291 / 291. Epoch 606
Loss of epoch 606 = 3.388145840045103
process: 50 / 291. Epoch 607
process: 100 / 291. Epoch 607
process: 150 / 291. Epoch 607
process: 200 / 291. Epoch 607
process: 250 / 291. Epoch 607
process: 291 / 291. Epoch 607
Loss of epoch 607 = 3.338365482710481
process: 50 / 291. Epoch 608
process: 100 / 291. Epoch 608
process: 150 / 291. Epoch 608
process: 200 / 291. Epoch 608
process: 250 / 291. Epoch 608
process: 291 / 291. Epoch 608
Loss of epoch 608 = 3.2287203339776633
process: 50 / 291. Epoch 609
process: 100 / 291. Epoch 609
process: 150 / 291. Epoch 609
process: 200 / 291. Epoch 609
process: 250 / 291. Epoch 609
process: 291 / 291. Epoch 609
Loss of epoch 609 = 3.2513587138906788
process: 50 / 291. Epoch 610
process: 100 / 291. Epoch 610
process: 150 / 291. Epoch 610
process: 200 / 291. Epoch 610
process: 250 / 291. Epoch 610
process: 291 / 291. Epoch 610
Loss of epoch 610 = 3.3237822752228308
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-610. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.790421
     epoch  training_loss
605    606       3.388146
606    607       3.338365
607    608       3.228720
608    609       3.251359
609    610       3.323782
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
56        570  0.014905  0.090622      0.335250   0.335917
57        580  0.014922  0.090912      0.334399   0.334975
58        590  0.015093  0.088637      0.336951   0.337645
59        600  0.014934  0.089969      0.337678   0.338370
60        610  0.014975  0.088207      0.337492   0.338109
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
56      570.0  0.972029  0.978499  ...  0.958788  0.952109  0.938752
57      580.0  0.971183  0.979053  ...  0.958462  0.952517  0.943313
58      590.0  0.971378  0.979462  ...  0.958137  0.951621  0.935657
59      600.0  0.970858  0.978931  ...  0.958137  0.952028  0.941440
60      610.0  0.971063  0.979499  ...  0.958055  0.952924  0.939648

[5 rows x 13 columns]
process: 50 / 291. Epoch 611
process: 100 / 291. Epoch 611
process: 150 / 291. Epoch 611
process: 200 / 291. Epoch 611
process: 250 / 291. Epoch 611
process: 291 / 291. Epoch 611
Loss of epoch 611 = 3.3132542351267182
process: 50 / 291. Epoch 612
process: 100 / 291. Epoch 612
process: 150 / 291. Epoch 612
process: 200 / 291. Epoch 612
process: 250 / 291. Epoch 612
process: 291 / 291. Epoch 612
Loss of epoch 612 = 3.304847324017397
process: 50 / 291. Epoch 613
process: 100 / 291. Epoch 613
process: 150 / 291. Epoch 613
process: 200 / 291. Epoch 613
process: 250 / 291. Epoch 613
process: 291 / 291. Epoch 613
Loss of epoch 613 = 3.3413910226723584
process: 50 / 291. Epoch 614
process: 100 / 291. Epoch 614
process: 150 / 291. Epoch 614
process: 200 / 291. Epoch 614
process: 250 / 291. Epoch 614
process: 291 / 291. Epoch 614
Loss of epoch 614 = 3.2662905139202105
process: 50 / 291. Epoch 615
process: 100 / 291. Epoch 615
process: 150 / 291. Epoch 615
process: 200 / 291. Epoch 615
process: 250 / 291. Epoch 615
process: 291 / 291. Epoch 615
Loss of epoch 615 = 3.2280470595736683
process: 50 / 291. Epoch 616
process: 100 / 291. Epoch 616
process: 150 / 291. Epoch 616
process: 200 / 291. Epoch 616
process: 250 / 291. Epoch 616
process: 291 / 291. Epoch 616
Loss of epoch 616 = 3.21991008745436
process: 50 / 291. Epoch 617
process: 100 / 291. Epoch 617
process: 150 / 291. Epoch 617
process: 200 / 291. Epoch 617
process: 250 / 291. Epoch 617
process: 291 / 291. Epoch 617
Loss of epoch 617 = 3.2778867741221007
process: 50 / 291. Epoch 618
process: 100 / 291. Epoch 618
process: 150 / 291. Epoch 618
process: 200 / 291. Epoch 618
process: 250 / 291. Epoch 618
process: 291 / 291. Epoch 618
Loss of epoch 618 = 3.2163291485448884
process: 50 / 291. Epoch 619
process: 100 / 291. Epoch 619
process: 150 / 291. Epoch 619
process: 200 / 291. Epoch 619
process: 250 / 291. Epoch 619
process: 291 / 291. Epoch 619
Loss of epoch 619 = 3.347917170049399
process: 50 / 291. Epoch 620
process: 100 / 291. Epoch 620
process: 150 / 291. Epoch 620
process: 200 / 291. Epoch 620
process: 250 / 291. Epoch 620
process: 291 / 291. Epoch 620
Loss of epoch 620 = 3.3609554120355454
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-620. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.788035
     epoch  training_loss
615    616       3.219910
616    617       3.277887
617    618       3.216329
618    619       3.347917
619    620       3.360955
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
57        580  0.014922  0.090912      0.334399   0.334975
58        590  0.015093  0.088637      0.336951   0.337645
59        600  0.014934  0.089969      0.337678   0.338370
60        610  0.014975  0.088207      0.337492   0.338109
61        620  0.015036  0.088305      0.338914   0.339585
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
57      580.0  0.971183  0.979053  ...  0.958462  0.952517  0.943313
58      590.0  0.971378  0.979462  ...  0.958137  0.951621  0.935657
59      600.0  0.970858  0.978931  ...  0.958137  0.952028  0.941440
60      610.0  0.971063  0.979499  ...  0.958055  0.952924  0.939648
61      620.0  0.971444  0.979160  ...  0.957159  0.952435  0.939322

[5 rows x 13 columns]
process: 50 / 291. Epoch 621
process: 100 / 291. Epoch 621
process: 150 / 291. Epoch 621
process: 200 / 291. Epoch 621
process: 250 / 291. Epoch 621
process: 291 / 291. Epoch 621
Loss of epoch 621 = 3.3107998248228094
process: 50 / 291. Epoch 622
process: 100 / 291. Epoch 622
process: 150 / 291. Epoch 622
process: 200 / 291. Epoch 622
process: 250 / 291. Epoch 622
process: 291 / 291. Epoch 622
Loss of epoch 622 = 3.2190258117885526
process: 50 / 291. Epoch 623
process: 100 / 291. Epoch 623
process: 150 / 291. Epoch 623
process: 200 / 291. Epoch 623
process: 250 / 291. Epoch 623
process: 291 / 291. Epoch 623
Loss of epoch 623 = 3.2554050720844074
process: 50 / 291. Epoch 624
process: 100 / 291. Epoch 624
process: 150 / 291. Epoch 624
process: 200 / 291. Epoch 624
process: 250 / 291. Epoch 624
process: 291 / 291. Epoch 624
Loss of epoch 624 = 3.3212718635899914
process: 50 / 291. Epoch 625
process: 100 / 291. Epoch 625
process: 150 / 291. Epoch 625
process: 200 / 291. Epoch 625
process: 250 / 291. Epoch 625
process: 291 / 291. Epoch 625
Loss of epoch 625 = 3.3702862402008162
process: 50 / 291. Epoch 626
process: 100 / 291. Epoch 626
process: 150 / 291. Epoch 626
process: 200 / 291. Epoch 626
process: 250 / 291. Epoch 626
process: 291 / 291. Epoch 626
Loss of epoch 626 = 3.231040299143578
process: 50 / 291. Epoch 627
process: 100 / 291. Epoch 627
process: 150 / 291. Epoch 627
process: 200 / 291. Epoch 627
process: 250 / 291. Epoch 627
process: 291 / 291. Epoch 627
Loss of epoch 627 = 3.2863333266215635
process: 50 / 291. Epoch 628
process: 100 / 291. Epoch 628
process: 150 / 291. Epoch 628
process: 200 / 291. Epoch 628
process: 250 / 291. Epoch 628
process: 291 / 291. Epoch 628
Loss of epoch 628 = 3.2268748070366193
process: 50 / 291. Epoch 629
process: 100 / 291. Epoch 629
process: 150 / 291. Epoch 629
process: 200 / 291. Epoch 629
process: 250 / 291. Epoch 629
process: 291 / 291. Epoch 629
Loss of epoch 629 = 3.2484091008242055
process: 50 / 291. Epoch 630
process: 100 / 291. Epoch 630
process: 150 / 291. Epoch 630
process: 200 / 291. Epoch 630
process: 250 / 291. Epoch 630
process: 291 / 291. Epoch 630
Loss of epoch 630 = 3.311264614878651
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-630. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.796812
     epoch  training_loss
625    626       3.231040
626    627       3.286333
627    628       3.226875
628    629       3.248409
629    630       3.311265
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
58        590  0.015093  0.088637      0.336951   0.337645
59        600  0.014934  0.089969      0.337678   0.338370
60        610  0.014975  0.088207      0.337492   0.338109
61        620  0.015036  0.088305      0.338914   0.339585
62        630  0.014940  0.089199      0.338920   0.339564
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
58      590.0  0.971378  0.979462  ...  0.958137  0.951621  0.935657
59      600.0  0.970858  0.978931  ...  0.958137  0.952028  0.941440
60      610.0  0.971063  0.979499  ...  0.958055  0.952924  0.939648
61      620.0  0.971444  0.979160  ...  0.957159  0.952435  0.939322
62      630.0  0.971075  0.978723  ...  0.958381  0.952354  0.944453

[5 rows x 13 columns]
process: 50 / 291. Epoch 631
process: 100 / 291. Epoch 631
process: 150 / 291. Epoch 631
process: 200 / 291. Epoch 631
process: 250 / 291. Epoch 631
process: 291 / 291. Epoch 631
Loss of epoch 631 = 3.2322075178533076
process: 50 / 291. Epoch 632
process: 100 / 291. Epoch 632
process: 150 / 291. Epoch 632
process: 200 / 291. Epoch 632
process: 250 / 291. Epoch 632
process: 291 / 291. Epoch 632
Loss of epoch 632 = 3.3026666280739905
process: 50 / 291. Epoch 633
process: 100 / 291. Epoch 633
process: 150 / 291. Epoch 633
process: 200 / 291. Epoch 633
process: 250 / 291. Epoch 633
process: 291 / 291. Epoch 633
Loss of epoch 633 = 3.298500926224227
process: 50 / 291. Epoch 634
process: 100 / 291. Epoch 634
process: 150 / 291. Epoch 634
process: 200 / 291. Epoch 634
process: 250 / 291. Epoch 634
process: 291 / 291. Epoch 634
Loss of epoch 634 = 3.2643866784793816
process: 50 / 291. Epoch 635
process: 100 / 291. Epoch 635
process: 150 / 291. Epoch 635
process: 200 / 291. Epoch 635
process: 250 / 291. Epoch 635
process: 291 / 291. Epoch 635
Loss of epoch 635 = 3.253866398867053
process: 50 / 291. Epoch 636
process: 100 / 291. Epoch 636
process: 150 / 291. Epoch 636
process: 200 / 291. Epoch 636
process: 250 / 291. Epoch 636
process: 291 / 291. Epoch 636
Loss of epoch 636 = 3.2188305412371134
process: 50 / 291. Epoch 637
process: 100 / 291. Epoch 637
process: 150 / 291. Epoch 637
process: 200 / 291. Epoch 637
process: 250 / 291. Epoch 637
process: 291 / 291. Epoch 637
Loss of epoch 637 = 3.3202596448131443
process: 50 / 291. Epoch 638
process: 100 / 291. Epoch 638
process: 150 / 291. Epoch 638
process: 200 / 291. Epoch 638
process: 250 / 291. Epoch 638
process: 291 / 291. Epoch 638
Loss of epoch 638 = 3.4007639671928693
process: 50 / 291. Epoch 639
process: 100 / 291. Epoch 639
process: 150 / 291. Epoch 639
process: 200 / 291. Epoch 639
process: 250 / 291. Epoch 639
process: 291 / 291. Epoch 639
Loss of epoch 639 = 3.2370418797653566
process: 50 / 291. Epoch 640
process: 100 / 291. Epoch 640
process: 150 / 291. Epoch 640
process: 200 / 291. Epoch 640
process: 250 / 291. Epoch 640
process: 291 / 291. Epoch 640
Loss of epoch 640 = 3.251611873456293
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-640. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.798843
     epoch  training_loss
635    636       3.218831
636    637       3.320260
637    638       3.400764
638    639       3.237042
639    640       3.251612
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
59        600  0.014934  0.089969      0.337678   0.338370
60        610  0.014975  0.088207      0.337492   0.338109
61        620  0.015036  0.088305      0.338914   0.339585
62        630  0.014940  0.089199      0.338920   0.339564
63        640  0.014981  0.089133      0.340452   0.341189
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
59      600.0  0.970858  0.978931  ...  0.958137  0.952028  0.941440
60      610.0  0.971063  0.979499  ...  0.958055  0.952924  0.939648
61      620.0  0.971444  0.979160  ...  0.957159  0.952435  0.939322
62      630.0  0.971075  0.978723  ...  0.958381  0.952354  0.944453
63      640.0  0.970971  0.978851  ...  0.958381  0.953005  0.944209

[5 rows x 13 columns]
process: 50 / 291. Epoch 641
process: 100 / 291. Epoch 641
process: 150 / 291. Epoch 641
process: 200 / 291. Epoch 641
process: 250 / 291. Epoch 641
process: 291 / 291. Epoch 641
Loss of epoch 641 = 3.1783887725515463
process: 50 / 291. Epoch 642
process: 100 / 291. Epoch 642
process: 150 / 291. Epoch 642
process: 200 / 291. Epoch 642
process: 250 / 291. Epoch 642
process: 291 / 291. Epoch 642
Loss of epoch 642 = 3.225097865992805
process: 50 / 291. Epoch 643
process: 100 / 291. Epoch 643
process: 150 / 291. Epoch 643
process: 200 / 291. Epoch 643
process: 250 / 291. Epoch 643
process: 291 / 291. Epoch 643
Loss of epoch 643 = 3.2803233562875858
process: 50 / 291. Epoch 644
process: 100 / 291. Epoch 644
process: 150 / 291. Epoch 644
process: 200 / 291. Epoch 644
process: 250 / 291. Epoch 644
process: 291 / 291. Epoch 644
Loss of epoch 644 = 3.2530454655283507
process: 50 / 291. Epoch 645
process: 100 / 291. Epoch 645
process: 150 / 291. Epoch 645
process: 200 / 291. Epoch 645
process: 250 / 291. Epoch 645
process: 291 / 291. Epoch 645
Loss of epoch 645 = 3.2290471132678267
process: 50 / 291. Epoch 646
process: 100 / 291. Epoch 646
process: 150 / 291. Epoch 646
process: 200 / 291. Epoch 646
process: 250 / 291. Epoch 646
process: 291 / 291. Epoch 646
Loss of epoch 646 = 3.2627855019061425
process: 50 / 291. Epoch 647
process: 100 / 291. Epoch 647
process: 150 / 291. Epoch 647
process: 200 / 291. Epoch 647
process: 250 / 291. Epoch 647
process: 291 / 291. Epoch 647
Loss of epoch 647 = 3.2464742234482387
process: 50 / 291. Epoch 648
process: 100 / 291. Epoch 648
process: 150 / 291. Epoch 648
process: 200 / 291. Epoch 648
process: 250 / 291. Epoch 648
process: 291 / 291. Epoch 648
Loss of epoch 648 = 3.2685047687124142
process: 50 / 291. Epoch 649
process: 100 / 291. Epoch 649
process: 150 / 291. Epoch 649
process: 200 / 291. Epoch 649
process: 250 / 291. Epoch 649
process: 291 / 291. Epoch 649
Loss of epoch 649 = 3.2222757765517613
process: 50 / 291. Epoch 650
process: 100 / 291. Epoch 650
process: 150 / 291. Epoch 650
process: 200 / 291. Epoch 650
process: 250 / 291. Epoch 650
process: 291 / 291. Epoch 650
Loss of epoch 650 = 3.2446272283075603
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-650. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.786749
     epoch  training_loss
645    646       3.262786
646    647       3.246474
647    648       3.268505
648    649       3.222276
649    650       3.244627
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
60        610  0.014975  0.088207      0.337492   0.338109
61        620  0.015036  0.088305      0.338914   0.339585
62        630  0.014940  0.089199      0.338920   0.339564
63        640  0.014981  0.089133      0.340452   0.341189
64        650  0.014984  0.086009      0.339907   0.340619
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
60      610.0  0.971063  0.979499  ...  0.958055  0.952924  0.939648
61      620.0  0.971444  0.979160  ...  0.957159  0.952435  0.939322
62      630.0  0.971075  0.978723  ...  0.958381  0.952354  0.944453
63      640.0  0.970971  0.978851  ...  0.958381  0.953005  0.944209
64      650.0  0.971492  0.979261  ...  0.958381  0.952191  0.938345

[5 rows x 13 columns]
process: 50 / 291. Epoch 651
process: 100 / 291. Epoch 651
process: 150 / 291. Epoch 651
process: 200 / 291. Epoch 651
process: 250 / 291. Epoch 651
process: 291 / 291. Epoch 651
Loss of epoch 651 = 3.2445722756926547
process: 50 / 291. Epoch 652
process: 100 / 291. Epoch 652
process: 150 / 291. Epoch 652
process: 200 / 291. Epoch 652
process: 250 / 291. Epoch 652
process: 291 / 291. Epoch 652
Loss of epoch 652 = 3.2910311459675685
process: 50 / 291. Epoch 653
process: 100 / 291. Epoch 653
process: 150 / 291. Epoch 653
process: 200 / 291. Epoch 653
process: 250 / 291. Epoch 653
process: 291 / 291. Epoch 653
Loss of epoch 653 = 3.2207371033344074
process: 50 / 291. Epoch 654
process: 100 / 291. Epoch 654
process: 150 / 291. Epoch 654
process: 200 / 291. Epoch 654
process: 250 / 291. Epoch 654
process: 291 / 291. Epoch 654
Loss of epoch 654 = 3.2473205356663444
process: 50 / 291. Epoch 655
process: 100 / 291. Epoch 655
process: 150 / 291. Epoch 655
process: 200 / 291. Epoch 655
process: 250 / 291. Epoch 655
process: 291 / 291. Epoch 655
Loss of epoch 655 = 3.2130777155820445
process: 50 / 291. Epoch 656
process: 100 / 291. Epoch 656
process: 150 / 291. Epoch 656
process: 200 / 291. Epoch 656
process: 250 / 291. Epoch 656
process: 291 / 291. Epoch 656
Loss of epoch 656 = 3.2057534968320445
process: 50 / 291. Epoch 657
process: 100 / 291. Epoch 657
process: 150 / 291. Epoch 657
process: 200 / 291. Epoch 657
process: 250 / 291. Epoch 657
process: 291 / 291. Epoch 657
Loss of epoch 657 = 3.2320162324151633
process: 50 / 291. Epoch 658
process: 100 / 291. Epoch 658
process: 150 / 291. Epoch 658
process: 200 / 291. Epoch 658
process: 250 / 291. Epoch 658
process: 291 / 291. Epoch 658
Loss of epoch 658 = 3.344471095763531
process: 50 / 291. Epoch 659
process: 100 / 291. Epoch 659
process: 150 / 291. Epoch 659
process: 200 / 291. Epoch 659
process: 250 / 291. Epoch 659
process: 291 / 291. Epoch 659
Loss of epoch 659 = 3.3021420613187287
process: 50 / 291. Epoch 660
process: 100 / 291. Epoch 660
process: 150 / 291. Epoch 660
process: 200 / 291. Epoch 660
process: 250 / 291. Epoch 660
process: 291 / 291. Epoch 660
Loss of epoch 660 = 3.1620409988455758
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-660. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.790344
     epoch  training_loss
655    656       3.205753
656    657       3.232016
657    658       3.344471
658    659       3.302142
659    660       3.162041
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
61        620  0.015036  0.088305      0.338914   0.339585
62        630  0.014940  0.089199      0.338920   0.339564
63        640  0.014981  0.089133      0.340452   0.341189
64        650  0.014984  0.086009      0.339907   0.340619
65        660  0.014997  0.087292      0.339281   0.339957
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
61      620.0  0.971444  0.979160  ...  0.957159  0.952435  0.939322
62      630.0  0.971075  0.978723  ...  0.958381  0.952354  0.944453
63      640.0  0.970971  0.978851  ...  0.958381  0.953005  0.944209
64      650.0  0.971492  0.979261  ...  0.958381  0.952191  0.938345
65      660.0  0.971050  0.979268  ...  0.957729  0.952435  0.939648

[5 rows x 13 columns]
process: 50 / 291. Epoch 661
process: 100 / 291. Epoch 661
process: 150 / 291. Epoch 661
process: 200 / 291. Epoch 661
process: 250 / 291. Epoch 661
process: 291 / 291. Epoch 661
Loss of epoch 661 = 3.1747616902249787
process: 50 / 291. Epoch 662
process: 100 / 291. Epoch 662
process: 150 / 291. Epoch 662
process: 200 / 291. Epoch 662
process: 250 / 291. Epoch 662
process: 291 / 291. Epoch 662
Loss of epoch 662 = 3.2108699628167954
process: 50 / 291. Epoch 663
process: 100 / 291. Epoch 663
process: 150 / 291. Epoch 663
process: 200 / 291. Epoch 663
process: 250 / 291. Epoch 663
process: 291 / 291. Epoch 663
Loss of epoch 663 = 3.249753971689755
process: 50 / 291. Epoch 664
process: 100 / 291. Epoch 664
process: 150 / 291. Epoch 664
process: 200 / 291. Epoch 664
process: 250 / 291. Epoch 664
process: 291 / 291. Epoch 664
Loss of epoch 664 = 3.2969544925230885
process: 50 / 291. Epoch 665
process: 100 / 291. Epoch 665
process: 150 / 291. Epoch 665
process: 200 / 291. Epoch 665
process: 250 / 291. Epoch 665
process: 291 / 291. Epoch 665
Loss of epoch 665 = 3.2824283350783934
process: 50 / 291. Epoch 666
process: 100 / 291. Epoch 666
process: 150 / 291. Epoch 666
process: 200 / 291. Epoch 666
process: 250 / 291. Epoch 666
process: 291 / 291. Epoch 666
Loss of epoch 666 = 3.1917659589105454
process: 50 / 291. Epoch 667
process: 100 / 291. Epoch 667
process: 150 / 291. Epoch 667
process: 200 / 291. Epoch 667
process: 250 / 291. Epoch 667
process: 291 / 291. Epoch 667
Loss of epoch 667 = 3.1472560187795318
process: 50 / 291. Epoch 668
process: 100 / 291. Epoch 668
process: 150 / 291. Epoch 668
process: 200 / 291. Epoch 668
process: 250 / 291. Epoch 668
process: 291 / 291. Epoch 668
Loss of epoch 668 = 3.228113338300043
process: 50 / 291. Epoch 669
process: 100 / 291. Epoch 669
process: 150 / 291. Epoch 669
process: 200 / 291. Epoch 669
process: 250 / 291. Epoch 669
process: 291 / 291. Epoch 669
Loss of epoch 669 = 3.2623760839508162
process: 50 / 291. Epoch 670
process: 100 / 291. Epoch 670
process: 150 / 291. Epoch 670
process: 200 / 291. Epoch 670
process: 250 / 291. Epoch 670
process: 291 / 291. Epoch 670
Loss of epoch 670 = 3.299719531921177
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-670. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.789489
     epoch  training_loss
665    666       3.191766
666    667       3.147256
667    668       3.228113
668    669       3.262376
669    670       3.299720
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
62        630  0.014940  0.089199      0.338920   0.339564
63        640  0.014981  0.089133      0.340452   0.341189
64        650  0.014984  0.086009      0.339907   0.340619
65        660  0.014997  0.087292      0.339281   0.339957
66        670  0.015066  0.086886      0.341782   0.342489
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
62      630.0  0.971075  0.978723  ...  0.958381  0.952354  0.944453
63      640.0  0.970971  0.978851  ...  0.958381  0.953005  0.944209
64      650.0  0.971492  0.979261  ...  0.958381  0.952191  0.938345
65      660.0  0.971050  0.979268  ...  0.957729  0.952435  0.939648
66      670.0  0.971040  0.979148  ...  0.957485  0.952028  0.940300

[5 rows x 13 columns]
process: 50 / 291. Epoch 671
process: 100 / 291. Epoch 671
process: 150 / 291. Epoch 671
process: 200 / 291. Epoch 671
process: 250 / 291. Epoch 671
process: 291 / 291. Epoch 671
Loss of epoch 671 = 3.1674980871456184
process: 50 / 291. Epoch 672
process: 100 / 291. Epoch 672
process: 150 / 291. Epoch 672
process: 200 / 291. Epoch 672
process: 250 / 291. Epoch 672
process: 291 / 291. Epoch 672
Loss of epoch 672 = 3.1367518893631874
process: 50 / 291. Epoch 673
process: 100 / 291. Epoch 673
process: 150 / 291. Epoch 673
process: 200 / 291. Epoch 673
process: 250 / 291. Epoch 673
process: 291 / 291. Epoch 673
Loss of epoch 673 = 3.2918151645725944
process: 50 / 291. Epoch 674
process: 100 / 291. Epoch 674
process: 150 / 291. Epoch 674
process: 200 / 291. Epoch 674
process: 250 / 291. Epoch 674
process: 291 / 291. Epoch 674
Loss of epoch 674 = 3.2182539582662155
process: 50 / 291. Epoch 675
process: 100 / 291. Epoch 675
process: 150 / 291. Epoch 675
process: 200 / 291. Epoch 675
process: 250 / 291. Epoch 675
process: 291 / 291. Epoch 675
Loss of epoch 675 = 3.12738037109375
process: 50 / 291. Epoch 676
process: 100 / 291. Epoch 676
process: 150 / 291. Epoch 676
process: 200 / 291. Epoch 676
process: 250 / 291. Epoch 676
process: 291 / 291. Epoch 676
Loss of epoch 676 = 3.151878959944158
process: 50 / 291. Epoch 677
process: 100 / 291. Epoch 677
process: 150 / 291. Epoch 677
process: 200 / 291. Epoch 677
process: 250 / 291. Epoch 677
process: 291 / 291. Epoch 677
Loss of epoch 677 = 3.2469432083601806
process: 50 / 291. Epoch 678
process: 100 / 291. Epoch 678
process: 150 / 291. Epoch 678
process: 200 / 291. Epoch 678
process: 250 / 291. Epoch 678
process: 291 / 291. Epoch 678
Loss of epoch 678 = 3.265868930882195
process: 50 / 291. Epoch 679
process: 100 / 291. Epoch 679
process: 150 / 291. Epoch 679
process: 200 / 291. Epoch 679
process: 250 / 291. Epoch 679
process: 291 / 291. Epoch 679
Loss of epoch 679 = 3.2020171385040808
process: 50 / 291. Epoch 680
process: 100 / 291. Epoch 680
process: 150 / 291. Epoch 680
process: 200 / 291. Epoch 680
process: 250 / 291. Epoch 680
process: 291 / 291. Epoch 680
Loss of epoch 680 = 3.1857629100891325
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-680. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.792603
     epoch  training_loss
675    676       3.151879
676    677       3.246943
677    678       3.265869
678    679       3.202017
679    680       3.185763
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
63        640  0.014981  0.089133      0.340452   0.341189
64        650  0.014984  0.086009      0.339907   0.340619
65        660  0.014997  0.087292      0.339281   0.339957
66        670  0.015066  0.086886      0.341782   0.342489
67        680  0.015011  0.086562      0.343686   0.344461
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
63      640.0  0.970971  0.978851  ...  0.958381  0.953005  0.944209
64      650.0  0.971492  0.979261  ...  0.958381  0.952191  0.938345
65      660.0  0.971050  0.979268  ...  0.957729  0.952435  0.939648
66      670.0  0.971040  0.979148  ...  0.957485  0.952028  0.940300
67      680.0  0.971350  0.978827  ...  0.957403  0.952191  0.942580

[5 rows x 13 columns]
process: 50 / 291. Epoch 681
process: 100 / 291. Epoch 681
process: 150 / 291. Epoch 681
process: 200 / 291. Epoch 681
process: 250 / 291. Epoch 681
process: 291 / 291. Epoch 681
Loss of epoch 681 = 3.2029276320205113
process: 50 / 291. Epoch 682
process: 100 / 291. Epoch 682
process: 150 / 291. Epoch 682
process: 200 / 291. Epoch 682
process: 250 / 291. Epoch 682
process: 291 / 291. Epoch 682
Loss of epoch 682 = 3.1901209460910653
process: 50 / 291. Epoch 683
process: 100 / 291. Epoch 683
process: 150 / 291. Epoch 683
process: 200 / 291. Epoch 683
process: 250 / 291. Epoch 683
process: 291 / 291. Epoch 683
Loss of epoch 683 = 3.1337091504913017
process: 50 / 291. Epoch 684
process: 100 / 291. Epoch 684
process: 150 / 291. Epoch 684
process: 200 / 291. Epoch 684
process: 250 / 291. Epoch 684
process: 291 / 291. Epoch 684
Loss of epoch 684 = 3.1704810493180844
process: 50 / 291. Epoch 685
process: 100 / 291. Epoch 685
process: 150 / 291. Epoch 685
process: 200 / 291. Epoch 685
process: 250 / 291. Epoch 685
process: 291 / 291. Epoch 685
Loss of epoch 685 = 3.223009037397981
process: 50 / 291. Epoch 686
process: 100 / 291. Epoch 686
process: 150 / 291. Epoch 686
process: 200 / 291. Epoch 686
process: 250 / 291. Epoch 686
process: 291 / 291. Epoch 686
Loss of epoch 686 = 3.2461245821923326
process: 50 / 291. Epoch 687
process: 100 / 291. Epoch 687
process: 150 / 291. Epoch 687
process: 200 / 291. Epoch 687
process: 250 / 291. Epoch 687
process: 291 / 291. Epoch 687
Loss of epoch 687 = 3.2183749798646906
process: 50 / 291. Epoch 688
process: 100 / 291. Epoch 688
process: 150 / 291. Epoch 688
process: 200 / 291. Epoch 688
process: 250 / 291. Epoch 688
process: 291 / 291. Epoch 688
Loss of epoch 688 = 3.2183550542982173
process: 50 / 291. Epoch 689
process: 100 / 291. Epoch 689
process: 150 / 291. Epoch 689
process: 200 / 291. Epoch 689
process: 250 / 291. Epoch 689
process: 291 / 291. Epoch 689
Loss of epoch 689 = 3.1636212011383162
process: 50 / 291. Epoch 690
process: 100 / 291. Epoch 690
process: 150 / 291. Epoch 690
process: 200 / 291. Epoch 690
process: 250 / 291. Epoch 690
process: 291 / 291. Epoch 690
Loss of epoch 690 = 3.176575336259665
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-690. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.792320
     epoch  training_loss
685    686       3.246125
686    687       3.218375
687    688       3.218355
688    689       3.163621
689    690       3.176575
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
64        650  0.014984  0.086009      0.339907   0.340619
65        660  0.014997  0.087292      0.339281   0.339957
66        670  0.015066  0.086886      0.341782   0.342489
67        680  0.015011  0.086562      0.343686   0.344461
68        690  0.014980  0.086397      0.341303   0.341999
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
64      650.0  0.971492  0.979261  ...  0.958381  0.952191  0.938345
65      660.0  0.971050  0.979268  ...  0.957729  0.952435  0.939648
66      670.0  0.971040  0.979148  ...  0.957485  0.952028  0.940300
67      680.0  0.971350  0.978827  ...  0.957403  0.952191  0.942580
68      690.0  0.971147  0.979053  ...  0.957566  0.952517  0.941521

[5 rows x 13 columns]
process: 50 / 291. Epoch 691
process: 100 / 291. Epoch 691
process: 150 / 291. Epoch 691
process: 200 / 291. Epoch 691
process: 250 / 291. Epoch 691
process: 291 / 291. Epoch 691
Loss of epoch 691 = 3.195223149565077
process: 50 / 291. Epoch 692
process: 100 / 291. Epoch 692
process: 150 / 291. Epoch 692
process: 200 / 291. Epoch 692
process: 250 / 291. Epoch 692
process: 291 / 291. Epoch 692
Loss of epoch 692 = 3.22009319292311
process: 50 / 291. Epoch 693
process: 100 / 291. Epoch 693
process: 150 / 291. Epoch 693
process: 200 / 291. Epoch 693
process: 250 / 291. Epoch 693
process: 291 / 291. Epoch 693
Loss of epoch 693 = 3.1576573742214347
process: 50 / 291. Epoch 694
process: 100 / 291. Epoch 694
process: 150 / 291. Epoch 694
process: 200 / 291. Epoch 694
process: 250 / 291. Epoch 694
process: 291 / 291. Epoch 694
Loss of epoch 694 = 3.111766906948024
process: 50 / 291. Epoch 695
process: 100 / 291. Epoch 695
process: 150 / 291. Epoch 695
process: 200 / 291. Epoch 695
process: 250 / 291. Epoch 695
process: 291 / 291. Epoch 695
Loss of epoch 695 = 3.1914733676975944
process: 50 / 291. Epoch 696
process: 100 / 291. Epoch 696
process: 150 / 291. Epoch 696
process: 200 / 291. Epoch 696
process: 250 / 291. Epoch 696
process: 291 / 291. Epoch 696
Loss of epoch 696 = 3.208531120798432
process: 50 / 291. Epoch 697
process: 100 / 291. Epoch 697
process: 150 / 291. Epoch 697
process: 200 / 291. Epoch 697
process: 250 / 291. Epoch 697
process: 291 / 291. Epoch 697
Loss of epoch 697 = 3.134471775330219
process: 50 / 291. Epoch 698
process: 100 / 291. Epoch 698
process: 150 / 291. Epoch 698
process: 200 / 291. Epoch 698
process: 250 / 291. Epoch 698
process: 291 / 291. Epoch 698
Loss of epoch 698 = 3.2829682130584192
process: 50 / 291. Epoch 699
process: 100 / 291. Epoch 699
process: 150 / 291. Epoch 699
process: 200 / 291. Epoch 699
process: 250 / 291. Epoch 699
process: 291 / 291. Epoch 699
Loss of epoch 699 = 3.212096958225945
process: 50 / 291. Epoch 700
process: 100 / 291. Epoch 700
process: 150 / 291. Epoch 700
process: 200 / 291. Epoch 700
process: 250 / 291. Epoch 700
process: 291 / 291. Epoch 700
Loss of epoch 700 = 3.178623684493127
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-700. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.787539
     epoch  training_loss
695    696       3.208531
696    697       3.134472
697    698       3.282968
698    699       3.212097
699    700       3.178624
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
65        660  0.014997  0.087292      0.339281   0.339957
66        670  0.015066  0.086886      0.341782   0.342489
67        680  0.015011  0.086562      0.343686   0.344461
68        690  0.014980  0.086397      0.341303   0.341999
69        700  0.015120  0.084721      0.343178   0.343937
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
65      660.0  0.971050  0.979268  ...  0.957729  0.952435  0.939648
66      670.0  0.971040  0.979148  ...  0.957485  0.952028  0.940300
67      680.0  0.971350  0.978827  ...  0.957403  0.952191  0.942580
68      690.0  0.971147  0.979053  ...  0.957566  0.952517  0.941521
69      700.0  0.971912  0.979592  ...  0.958462  0.952354  0.938752

[5 rows x 13 columns]
process: 50 / 291. Epoch 701
process: 100 / 291. Epoch 701
process: 150 / 291. Epoch 701
process: 200 / 291. Epoch 701
process: 250 / 291. Epoch 701
process: 291 / 291. Epoch 701
Loss of epoch 701 = 3.144383591065292
process: 50 / 291. Epoch 702
process: 100 / 291. Epoch 702
process: 150 / 291. Epoch 702
process: 200 / 291. Epoch 702
process: 250 / 291. Epoch 702
process: 291 / 291. Epoch 702
Loss of epoch 702 = 3.1668757802432346
process: 50 / 291. Epoch 703
process: 100 / 291. Epoch 703
process: 150 / 291. Epoch 703
process: 200 / 291. Epoch 703
process: 250 / 291. Epoch 703
process: 291 / 291. Epoch 703
Loss of epoch 703 = 3.119912898007947
process: 50 / 291. Epoch 704
process: 100 / 291. Epoch 704
process: 150 / 291. Epoch 704
process: 200 / 291. Epoch 704
process: 250 / 291. Epoch 704
process: 291 / 291. Epoch 704
Loss of epoch 704 = 3.2174814755154637
process: 50 / 291. Epoch 705
process: 100 / 291. Epoch 705
process: 150 / 291. Epoch 705
process: 200 / 291. Epoch 705
process: 250 / 291. Epoch 705
process: 291 / 291. Epoch 705
Loss of epoch 705 = 3.2310350555734537
process: 50 / 291. Epoch 706
process: 100 / 291. Epoch 706
process: 150 / 291. Epoch 706
process: 200 / 291. Epoch 706
process: 250 / 291. Epoch 706
process: 291 / 291. Epoch 706
Loss of epoch 706 = 3.1836533169566152
process: 50 / 291. Epoch 707
process: 100 / 291. Epoch 707
process: 150 / 291. Epoch 707
process: 200 / 291. Epoch 707
process: 250 / 291. Epoch 707
process: 291 / 291. Epoch 707
Loss of epoch 707 = 3.1969199688573884
process: 50 / 291. Epoch 708
process: 100 / 291. Epoch 708
process: 150 / 291. Epoch 708
process: 200 / 291. Epoch 708
process: 250 / 291. Epoch 708
process: 291 / 291. Epoch 708
Loss of epoch 708 = 3.158741744523196
process: 50 / 291. Epoch 709
process: 100 / 291. Epoch 709
process: 150 / 291. Epoch 709
process: 200 / 291. Epoch 709
process: 250 / 291. Epoch 709
process: 291 / 291. Epoch 709
Loss of epoch 709 = 3.1483456326514174
process: 50 / 291. Epoch 710
process: 100 / 291. Epoch 710
process: 150 / 291. Epoch 710
process: 200 / 291. Epoch 710
process: 250 / 291. Epoch 710
process: 291 / 291. Epoch 710
Loss of epoch 710 = 3.179431194292311
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-710. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.784256
     epoch  training_loss
705    706       3.183653
706    707       3.196920
707    708       3.158742
708    709       3.148346
709    710       3.179431
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
66        670  0.015066  0.086886      0.341782   0.342489
67        680  0.015011  0.086562      0.343686   0.344461
68        690  0.014980  0.086397      0.341303   0.341999
69        700  0.015120  0.084721      0.343178   0.343937
70        710  0.015141  0.084328      0.343093   0.343857
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
66      670.0  0.971040  0.979148  ...  0.957485  0.952028  0.940300
67      680.0  0.971350  0.978827  ...  0.957403  0.952191  0.942580
68      690.0  0.971147  0.979053  ...  0.957566  0.952517  0.941521
69      700.0  0.971912  0.979592  ...  0.958462  0.952354  0.938752
70      710.0  0.971773  0.979358  ...  0.957566  0.951784  0.936553

[5 rows x 13 columns]
process: 50 / 291. Epoch 711
process: 100 / 291. Epoch 711
process: 150 / 291. Epoch 711
process: 200 / 291. Epoch 711
process: 250 / 291. Epoch 711
process: 291 / 291. Epoch 711
Loss of epoch 711 = 3.2233437869147337
process: 50 / 291. Epoch 712
process: 100 / 291. Epoch 712
process: 150 / 291. Epoch 712
process: 200 / 291. Epoch 712
process: 250 / 291. Epoch 712
process: 291 / 291. Epoch 712
Loss of epoch 712 = 3.1935040975354383
process: 50 / 291. Epoch 713
process: 100 / 291. Epoch 713
process: 150 / 291. Epoch 713
process: 200 / 291. Epoch 713
process: 250 / 291. Epoch 713
process: 291 / 291. Epoch 713
Loss of epoch 713 = 3.0845796250805413
process: 50 / 291. Epoch 714
process: 100 / 291. Epoch 714
process: 150 / 291. Epoch 714
process: 200 / 291. Epoch 714
process: 250 / 291. Epoch 714
process: 291 / 291. Epoch 714
Loss of epoch 714 = 3.111326237314755
process: 50 / 291. Epoch 715
process: 100 / 291. Epoch 715
process: 150 / 291. Epoch 715
process: 200 / 291. Epoch 715
process: 250 / 291. Epoch 715
process: 291 / 291. Epoch 715
Loss of epoch 715 = 3.1292428872019973
process: 50 / 291. Epoch 716
process: 100 / 291. Epoch 716
process: 150 / 291. Epoch 716
process: 200 / 291. Epoch 716
process: 250 / 291. Epoch 716
process: 291 / 291. Epoch 716
Loss of epoch 716 = 3.139273627107496
process: 50 / 291. Epoch 717
process: 100 / 291. Epoch 717
process: 150 / 291. Epoch 717
process: 200 / 291. Epoch 717
process: 250 / 291. Epoch 717
process: 291 / 291. Epoch 717
Loss of epoch 717 = 3.2443767953984106
process: 50 / 291. Epoch 718
process: 100 / 291. Epoch 718
process: 150 / 291. Epoch 718
process: 200 / 291. Epoch 718
process: 250 / 291. Epoch 718
process: 291 / 291. Epoch 718
Loss of epoch 718 = 3.1842227686721434
process: 50 / 291. Epoch 719
process: 100 / 291. Epoch 719
process: 150 / 291. Epoch 719
process: 200 / 291. Epoch 719
process: 250 / 291. Epoch 719
process: 291 / 291. Epoch 719
Loss of epoch 719 = 3.179544245664197
process: 50 / 291. Epoch 720
process: 100 / 291. Epoch 720
process: 150 / 291. Epoch 720
process: 200 / 291. Epoch 720
process: 250 / 291. Epoch 720
process: 291 / 291. Epoch 720
Loss of epoch 720 = 3.2334061979837845
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-720. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.791138
     epoch  training_loss
715    716       3.139274
716    717       3.244377
717    718       3.184223
718    719       3.179544
719    720       3.233406
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
67        680  0.015011  0.086562      0.343686   0.344461
68        690  0.014980  0.086397      0.341303   0.341999
69        700  0.015120  0.084721      0.343178   0.343937
70        710  0.015141  0.084328      0.343093   0.343857
71        720  0.014978  0.085015      0.344204   0.344969
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
67      680.0  0.971350  0.978827  ...  0.957403  0.952191  0.942580
68      690.0  0.971147  0.979053  ...  0.957566  0.952517  0.941521
69      700.0  0.971912  0.979592  ...  0.958462  0.952354  0.938752
70      710.0  0.971773  0.979358  ...  0.957566  0.951784  0.936553
71      720.0  0.972019  0.978952  ...  0.958544  0.952761  0.941521

[5 rows x 13 columns]
process: 50 / 291. Epoch 721
process: 100 / 291. Epoch 721
process: 150 / 291. Epoch 721
process: 200 / 291. Epoch 721
process: 250 / 291. Epoch 721
process: 291 / 291. Epoch 721
Loss of epoch 721 = 3.1118082262806057
process: 50 / 291. Epoch 722
process: 100 / 291. Epoch 722
process: 150 / 291. Epoch 722
process: 200 / 291. Epoch 722
process: 250 / 291. Epoch 722
process: 291 / 291. Epoch 722
Loss of epoch 722 = 3.157483707178909
process: 50 / 291. Epoch 723
process: 100 / 291. Epoch 723
process: 150 / 291. Epoch 723
process: 200 / 291. Epoch 723
process: 250 / 291. Epoch 723
process: 291 / 291. Epoch 723
Loss of epoch 723 = 3.1111620086984537
process: 50 / 291. Epoch 724
process: 100 / 291. Epoch 724
process: 150 / 291. Epoch 724
process: 200 / 291. Epoch 724
process: 250 / 291. Epoch 724
process: 291 / 291. Epoch 724
Loss of epoch 724 = 3.098913448373067
process: 50 / 291. Epoch 725
process: 100 / 291. Epoch 725
process: 150 / 291. Epoch 725
process: 200 / 291. Epoch 725
process: 250 / 291. Epoch 725
process: 291 / 291. Epoch 725
Loss of epoch 725 = 3.213109596488402
process: 50 / 291. Epoch 726
process: 100 / 291. Epoch 726
process: 150 / 291. Epoch 726
process: 200 / 291. Epoch 726
process: 250 / 291. Epoch 726
process: 291 / 291. Epoch 726
Loss of epoch 726 = 3.1079202239046393
process: 50 / 291. Epoch 727
process: 100 / 291. Epoch 727
process: 150 / 291. Epoch 727
process: 200 / 291. Epoch 727
process: 250 / 291. Epoch 727
process: 291 / 291. Epoch 727
Loss of epoch 727 = 3.0860201386651633
process: 50 / 291. Epoch 728
process: 100 / 291. Epoch 728
process: 150 / 291. Epoch 728
process: 200 / 291. Epoch 728
process: 250 / 291. Epoch 728
process: 291 / 291. Epoch 728
Loss of epoch 728 = 3.099816600891323
process: 50 / 291. Epoch 729
process: 100 / 291. Epoch 729
process: 150 / 291. Epoch 729
process: 200 / 291. Epoch 729
process: 250 / 291. Epoch 729
process: 291 / 291. Epoch 729
Loss of epoch 729 = 3.114759097803909
process: 50 / 291. Epoch 730
process: 100 / 291. Epoch 730
process: 150 / 291. Epoch 730
process: 200 / 291. Epoch 730
process: 250 / 291. Epoch 730
process: 291 / 291. Epoch 730
Loss of epoch 730 = 3.144909206534579
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-730. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.791584
     epoch  training_loss
725    726       3.107920
726    727       3.086020
727    728       3.099817
728    729       3.114759
729    730       3.144909
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
68        690  0.014980  0.086397      0.341303   0.341999
69        700  0.015120  0.084721      0.343178   0.343937
70        710  0.015141  0.084328      0.343093   0.343857
71        720  0.014978  0.085015      0.344204   0.344969
72        730  0.015065  0.084349      0.346118   0.346931
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
68      690.0  0.971147  0.979053  ...  0.957566  0.952517  0.941521
69      700.0  0.971912  0.979592  ...  0.958462  0.952354  0.938752
70      710.0  0.971773  0.979358  ...  0.957566  0.951784  0.936553
71      720.0  0.972019  0.978952  ...  0.958544  0.952761  0.941521
72      730.0  0.971915  0.979145  ...  0.958544  0.951947  0.942499

[5 rows x 13 columns]
process: 50 / 291. Epoch 731
process: 100 / 291. Epoch 731
process: 150 / 291. Epoch 731
process: 200 / 291. Epoch 731
process: 250 / 291. Epoch 731
process: 291 / 291. Epoch 731
Loss of epoch 731 = 3.1689415371295104
process: 50 / 291. Epoch 732
process: 100 / 291. Epoch 732
process: 150 / 291. Epoch 732
process: 200 / 291. Epoch 732
process: 250 / 291. Epoch 732
process: 291 / 291. Epoch 732
Loss of epoch 732 = 3.208165539089347
process: 50 / 291. Epoch 733
process: 100 / 291. Epoch 733
process: 150 / 291. Epoch 733
process: 200 / 291. Epoch 733
process: 250 / 291. Epoch 733
process: 291 / 291. Epoch 733
Loss of epoch 733 = 3.1976024719448026
process: 50 / 291. Epoch 734
process: 100 / 291. Epoch 734
process: 150 / 291. Epoch 734
process: 200 / 291. Epoch 734
process: 250 / 291. Epoch 734
process: 291 / 291. Epoch 734
Loss of epoch 734 = 3.0905008742080113
process: 50 / 291. Epoch 735
process: 100 / 291. Epoch 735
process: 150 / 291. Epoch 735
process: 200 / 291. Epoch 735
process: 250 / 291. Epoch 735
process: 291 / 291. Epoch 735
Loss of epoch 735 = 3.1184505711716066
process: 50 / 291. Epoch 736
process: 100 / 291. Epoch 736
process: 150 / 291. Epoch 736
process: 200 / 291. Epoch 736
process: 250 / 291. Epoch 736
process: 291 / 291. Epoch 736
Loss of epoch 736 = 3.124037909753544
process: 50 / 291. Epoch 737
process: 100 / 291. Epoch 737
process: 150 / 291. Epoch 737
process: 200 / 291. Epoch 737
process: 250 / 291. Epoch 737
process: 291 / 291. Epoch 737
Loss of epoch 737 = 3.1605879006926547
process: 50 / 291. Epoch 738
process: 100 / 291. Epoch 738
process: 150 / 291. Epoch 738
process: 200 / 291. Epoch 738
process: 250 / 291. Epoch 738
process: 291 / 291. Epoch 738
Loss of epoch 738 = 3.097390086380477
process: 50 / 291. Epoch 739
process: 100 / 291. Epoch 739
process: 150 / 291. Epoch 739
process: 200 / 291. Epoch 739
process: 250 / 291. Epoch 739
process: 291 / 291. Epoch 739
Loss of epoch 739 = 3.1839698188493344
process: 50 / 291. Epoch 740
process: 100 / 291. Epoch 740
process: 150 / 291. Epoch 740
process: 200 / 291. Epoch 740
process: 250 / 291. Epoch 740
process: 291 / 291. Epoch 740
Loss of epoch 740 = 3.172105717085481
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-740. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.787926
     epoch  training_loss
735    736       3.124038
736    737       3.160588
737    738       3.097390
738    739       3.183970
739    740       3.172106
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
69        700  0.015120  0.084721      0.343178   0.343937
70        710  0.015141  0.084328      0.343093   0.343857
71        720  0.014978  0.085015      0.344204   0.344969
72        730  0.015065  0.084349      0.346118   0.346931
73        740  0.015102  0.083706      0.345844   0.346605
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
69      700.0  0.971912  0.979592  ...  0.958462  0.952354  0.938752
70      710.0  0.971773  0.979358  ...  0.957566  0.951784  0.936553
71      720.0  0.972019  0.978952  ...  0.958544  0.952761  0.941521
72      730.0  0.971915  0.979145  ...  0.958544  0.951947  0.942499
73      740.0  0.971132  0.979372  ...  0.957159  0.952272  0.940788

[5 rows x 13 columns]
process: 50 / 291. Epoch 741
process: 100 / 291. Epoch 741
process: 150 / 291. Epoch 741
process: 200 / 291. Epoch 741
process: 250 / 291. Epoch 741
process: 291 / 291. Epoch 741
Loss of epoch 741 = 3.1818650498013317
process: 50 / 291. Epoch 742
process: 100 / 291. Epoch 742
process: 150 / 291. Epoch 742
process: 200 / 291. Epoch 742
process: 250 / 291. Epoch 742
process: 291 / 291. Epoch 742
Loss of epoch 742 = 3.038734881738617
process: 50 / 291. Epoch 743
process: 100 / 291. Epoch 743
process: 150 / 291. Epoch 743
process: 200 / 291. Epoch 743
process: 250 / 291. Epoch 743
process: 291 / 291. Epoch 743
Loss of epoch 743 = 3.040902154142504
process: 50 / 291. Epoch 744
process: 100 / 291. Epoch 744
process: 150 / 291. Epoch 744
process: 200 / 291. Epoch 744
process: 250 / 291. Epoch 744
process: 291 / 291. Epoch 744
Loss of epoch 744 = 3.1187068768792954
process: 50 / 291. Epoch 745
process: 100 / 291. Epoch 745
process: 150 / 291. Epoch 745
process: 200 / 291. Epoch 745
process: 250 / 291. Epoch 745
process: 291 / 291. Epoch 745
Loss of epoch 745 = 3.118603263933634
process: 50 / 291. Epoch 746
process: 100 / 291. Epoch 746
process: 150 / 291. Epoch 746
process: 200 / 291. Epoch 746
process: 250 / 291. Epoch 746
process: 291 / 291. Epoch 746
Loss of epoch 746 = 3.1104163730267396
process: 50 / 291. Epoch 747
process: 100 / 291. Epoch 747
process: 150 / 291. Epoch 747
process: 200 / 291. Epoch 747
process: 250 / 291. Epoch 747
process: 291 / 291. Epoch 747
Loss of epoch 747 = 3.1135054650585268
process: 50 / 291. Epoch 748
process: 100 / 291. Epoch 748
process: 150 / 291. Epoch 748
process: 200 / 291. Epoch 748
process: 250 / 291. Epoch 748
process: 291 / 291. Epoch 748
Loss of epoch 748 = 3.2134319711796606
process: 50 / 291. Epoch 749
process: 100 / 291. Epoch 749
process: 150 / 291. Epoch 749
process: 200 / 291. Epoch 749
process: 250 / 291. Epoch 749
process: 291 / 291. Epoch 749
Loss of epoch 749 = 3.1259012648330113
process: 50 / 291. Epoch 750
process: 100 / 291. Epoch 750
process: 150 / 291. Epoch 750
process: 200 / 291. Epoch 750
process: 250 / 291. Epoch 750
process: 291 / 291. Epoch 750
Loss of epoch 750 = 3.128650363777921
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-750. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.786724
     epoch  training_loss
745    746       3.110416
746    747       3.113505
747    748       3.213432
748    749       3.125901
749    750       3.128650
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
70        710  0.015141  0.084328      0.343093   0.343857
71        720  0.014978  0.085015      0.344204   0.344969
72        730  0.015065  0.084349      0.346118   0.346931
73        740  0.015102  0.083706      0.345844   0.346605
74        750  0.015072  0.082453      0.347517   0.348355
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
70      710.0  0.971773  0.979358  ...  0.957566  0.951784  0.936553
71      720.0  0.972019  0.978952  ...  0.958544  0.952761  0.941521
72      730.0  0.971915  0.979145  ...  0.958544  0.951947  0.942499
73      740.0  0.971132  0.979372  ...  0.957159  0.952272  0.940788
74      750.0  0.971362  0.979261  ...  0.957729  0.952191  0.940137

[5 rows x 13 columns]
process: 50 / 291. Epoch 751
process: 100 / 291. Epoch 751
process: 150 / 291. Epoch 751
process: 200 / 291. Epoch 751
process: 250 / 291. Epoch 751
process: 291 / 291. Epoch 751
Loss of epoch 751 = 3.069299022766323
process: 50 / 291. Epoch 752
process: 100 / 291. Epoch 752
process: 150 / 291. Epoch 752
process: 200 / 291. Epoch 752
process: 250 / 291. Epoch 752
process: 291 / 291. Epoch 752
Loss of epoch 752 = 3.1171721887752364
process: 50 / 291. Epoch 753
process: 100 / 291. Epoch 753
process: 150 / 291. Epoch 753
process: 200 / 291. Epoch 753
process: 250 / 291. Epoch 753
process: 291 / 291. Epoch 753
Loss of epoch 753 = 3.1257357777598798
process: 50 / 291. Epoch 754
process: 100 / 291. Epoch 754
process: 150 / 291. Epoch 754
process: 200 / 291. Epoch 754
process: 250 / 291. Epoch 754
process: 291 / 291. Epoch 754
Loss of epoch 754 = 3.1181984603200172
process: 50 / 291. Epoch 755
process: 100 / 291. Epoch 755
process: 150 / 291. Epoch 755
process: 200 / 291. Epoch 755
process: 250 / 291. Epoch 755
process: 291 / 291. Epoch 755
Loss of epoch 755 = 3.0996341246509878
process: 50 / 291. Epoch 756
process: 100 / 291. Epoch 756
process: 150 / 291. Epoch 756
process: 200 / 291. Epoch 756
process: 250 / 291. Epoch 756
process: 291 / 291. Epoch 756
Loss of epoch 756 = 3.1121626916210268
process: 50 / 291. Epoch 757
process: 100 / 291. Epoch 757
process: 150 / 291. Epoch 757
process: 200 / 291. Epoch 757
process: 250 / 291. Epoch 757
process: 291 / 291. Epoch 757
Loss of epoch 757 = 3.0568453339776633
process: 50 / 291. Epoch 758
process: 100 / 291. Epoch 758
process: 150 / 291. Epoch 758
process: 200 / 291. Epoch 758
process: 250 / 291. Epoch 758
process: 291 / 291. Epoch 758
Loss of epoch 758 = 3.091249865764605
process: 50 / 291. Epoch 759
process: 100 / 291. Epoch 759
process: 150 / 291. Epoch 759
process: 200 / 291. Epoch 759
process: 250 / 291. Epoch 759
process: 291 / 291. Epoch 759
Loss of epoch 759 = 3.1958517487516107
process: 50 / 291. Epoch 760
process: 100 / 291. Epoch 760
process: 150 / 291. Epoch 760
process: 200 / 291. Epoch 760
process: 250 / 291. Epoch 760
process: 291 / 291. Epoch 760
Loss of epoch 760 = 3.1038021336716066
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-760. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.793702
     epoch  training_loss
755    756       3.112163
756    757       3.056845
757    758       3.091250
758    759       3.195852
759    760       3.103802
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
71        720  0.014978  0.085015      0.344204   0.344969
72        730  0.015065  0.084349      0.346118   0.346931
73        740  0.015102  0.083706      0.345844   0.346605
74        750  0.015072  0.082453      0.347517   0.348355
75        760  0.015008  0.083608      0.347243   0.348053
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
71      720.0  0.972019  0.978952  ...  0.958544  0.952761  0.941521
72      730.0  0.971915  0.979145  ...  0.958544  0.951947  0.942499
73      740.0  0.971132  0.979372  ...  0.957159  0.952272  0.940788
74      750.0  0.971362  0.979261  ...  0.957729  0.952191  0.940137
75      760.0  0.971460  0.979388  ...  0.957566  0.952842  0.942906

[5 rows x 13 columns]
process: 50 / 291. Epoch 761
process: 100 / 291. Epoch 761
process: 150 / 291. Epoch 761
process: 200 / 291. Epoch 761
process: 250 / 291. Epoch 761
process: 291 / 291. Epoch 761
Loss of epoch 761 = 3.0398632980294242
process: 50 / 291. Epoch 762
process: 100 / 291. Epoch 762
process: 150 / 291. Epoch 762
process: 200 / 291. Epoch 762
process: 250 / 291. Epoch 762
process: 291 / 291. Epoch 762
Loss of epoch 762 = 3.125228409914626
process: 50 / 291. Epoch 763
process: 100 / 291. Epoch 763
process: 150 / 291. Epoch 763
process: 200 / 291. Epoch 763
process: 250 / 291. Epoch 763
process: 291 / 291. Epoch 763
Loss of epoch 763 = 3.1289813379241838
process: 50 / 291. Epoch 764
process: 100 / 291. Epoch 764
process: 150 / 291. Epoch 764
process: 200 / 291. Epoch 764
process: 250 / 291. Epoch 764
process: 291 / 291. Epoch 764
Loss of epoch 764 = 3.0806912032189646
process: 50 / 291. Epoch 765
process: 100 / 291. Epoch 765
process: 150 / 291. Epoch 765
process: 200 / 291. Epoch 765
process: 250 / 291. Epoch 765
process: 291 / 291. Epoch 765
Loss of epoch 765 = 3.083753238428909
process: 50 / 291. Epoch 766
process: 100 / 291. Epoch 766
process: 150 / 291. Epoch 766
process: 200 / 291. Epoch 766
process: 250 / 291. Epoch 766
process: 291 / 291. Epoch 766
Loss of epoch 766 = 3.0903051841709623
process: 50 / 291. Epoch 767
process: 100 / 291. Epoch 767
process: 150 / 291. Epoch 767
process: 200 / 291. Epoch 767
process: 250 / 291. Epoch 767
process: 291 / 291. Epoch 767
Loss of epoch 767 = 3.0689030283505154
process: 50 / 291. Epoch 768
process: 100 / 291. Epoch 768
process: 150 / 291. Epoch 768
process: 200 / 291. Epoch 768
process: 250 / 291. Epoch 768
process: 291 / 291. Epoch 768
Loss of epoch 768 = 3.1461982858140036
process: 50 / 291. Epoch 769
process: 100 / 291. Epoch 769
process: 150 / 291. Epoch 769
process: 200 / 291. Epoch 769
process: 250 / 291. Epoch 769
process: 291 / 291. Epoch 769
Loss of epoch 769 = 3.107578552875322
process: 50 / 291. Epoch 770
process: 100 / 291. Epoch 770
process: 150 / 291. Epoch 770
process: 200 / 291. Epoch 770
process: 250 / 291. Epoch 770
process: 291 / 291. Epoch 770
Loss of epoch 770 = 3.0912681133886384
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-770. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.783400
     epoch  training_loss
765    766       3.090305
766    767       3.068903
767    768       3.146198
768    769       3.107579
769    770       3.091268
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
72        730  0.015065  0.084349      0.346118   0.346931
73        740  0.015102  0.083706      0.345844   0.346605
74        750  0.015072  0.082453      0.347517   0.348355
75        760  0.015008  0.083608      0.347243   0.348053
76        770  0.015252  0.081343      0.348457   0.349307
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
72      730.0  0.971915  0.979145  ...  0.958544  0.951947  0.942499
73      740.0  0.971132  0.979372  ...  0.957159  0.952272  0.940788
74      750.0  0.971362  0.979261  ...  0.957729  0.952191  0.940137
75      760.0  0.971460  0.979388  ...  0.957566  0.952842  0.942906
76      770.0  0.971546  0.979798  ...  0.957078  0.951947  0.935902

[5 rows x 13 columns]
process: 50 / 291. Epoch 771
process: 100 / 291. Epoch 771
process: 150 / 291. Epoch 771
process: 200 / 291. Epoch 771
process: 250 / 291. Epoch 771
process: 291 / 291. Epoch 771
Loss of epoch 771 = 3.108261685191151
process: 50 / 291. Epoch 772
process: 100 / 291. Epoch 772
process: 150 / 291. Epoch 772
process: 200 / 291. Epoch 772
process: 250 / 291. Epoch 772
process: 291 / 291. Epoch 772
Loss of epoch 772 = 3.1687934587091924
process: 50 / 291. Epoch 773
process: 100 / 291. Epoch 773
process: 150 / 291. Epoch 773
process: 200 / 291. Epoch 773
process: 250 / 291. Epoch 773
process: 291 / 291. Epoch 773
Loss of epoch 773 = 3.103941822379725
process: 50 / 291. Epoch 774
process: 100 / 291. Epoch 774
process: 150 / 291. Epoch 774
process: 200 / 291. Epoch 774
process: 250 / 291. Epoch 774
process: 291 / 291. Epoch 774
Loss of epoch 774 = 3.060984398491194
process: 50 / 291. Epoch 775
process: 100 / 291. Epoch 775
process: 150 / 291. Epoch 775
process: 200 / 291. Epoch 775
process: 250 / 291. Epoch 775
process: 291 / 291. Epoch 775
Loss of epoch 775 = 3.058238026202749
process: 50 / 291. Epoch 776
process: 100 / 291. Epoch 776
process: 150 / 291. Epoch 776
process: 200 / 291. Epoch 776
process: 250 / 291. Epoch 776
process: 291 / 291. Epoch 776
Loss of epoch 776 = 3.0813781109052836
process: 50 / 291. Epoch 777
process: 100 / 291. Epoch 777
process: 150 / 291. Epoch 777
process: 200 / 291. Epoch 777
process: 250 / 291. Epoch 777
process: 291 / 291. Epoch 777
Loss of epoch 777 = 3.1102101958494415
process: 50 / 291. Epoch 778
process: 100 / 291. Epoch 778
process: 150 / 291. Epoch 778
process: 200 / 291. Epoch 778
process: 250 / 291. Epoch 778
process: 291 / 291. Epoch 778
Loss of epoch 778 = 3.143930546606529
process: 50 / 291. Epoch 779
process: 100 / 291. Epoch 779
process: 150 / 291. Epoch 779
process: 200 / 291. Epoch 779
process: 250 / 291. Epoch 779
process: 291 / 291. Epoch 779
Loss of epoch 779 = 3.1481287585910653
process: 50 / 291. Epoch 780
process: 100 / 291. Epoch 780
process: 150 / 291. Epoch 780
process: 200 / 291. Epoch 780
process: 250 / 291. Epoch 780
process: 291 / 291. Epoch 780
Loss of epoch 780 = 3.0636019886973798
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-780. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.784457
     epoch  training_loss
775    776       3.081378
776    777       3.110210
777    778       3.143931
778    779       3.148129
779    780       3.063602
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
73        740  0.015102  0.083706      0.345844   0.346605
74        750  0.015072  0.082453      0.347517   0.348355
75        760  0.015008  0.083608      0.347243   0.348053
76        770  0.015252  0.081343      0.348457   0.349307
77        780  0.015133  0.081517      0.347534   0.348374
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
73      740.0  0.971132  0.979372  ...  0.957159  0.952272  0.940788
74      750.0  0.971362  0.979261  ...  0.957729  0.952191  0.940137
75      760.0  0.971460  0.979388  ...  0.957566  0.952842  0.942906
76      770.0  0.971546  0.979798  ...  0.957078  0.951947  0.935902
77      780.0  0.972001  0.979363  ...  0.958055  0.951947  0.938508

[5 rows x 13 columns]
process: 50 / 291. Epoch 781
process: 100 / 291. Epoch 781
process: 150 / 291. Epoch 781
process: 200 / 291. Epoch 781
process: 250 / 291. Epoch 781
process: 291 / 291. Epoch 781
Loss of epoch 781 = 3.0386021145430626
process: 50 / 291. Epoch 782
process: 100 / 291. Epoch 782
process: 150 / 291. Epoch 782
process: 200 / 291. Epoch 782
process: 250 / 291. Epoch 782
process: 291 / 291. Epoch 782
Loss of epoch 782 = 3.0245902464561856
process: 50 / 291. Epoch 783
process: 100 / 291. Epoch 783
process: 150 / 291. Epoch 783
process: 200 / 291. Epoch 783
process: 250 / 291. Epoch 783
process: 291 / 291. Epoch 783
Loss of epoch 783 = 3.0752393584890463
process: 50 / 291. Epoch 784
process: 100 / 291. Epoch 784
process: 150 / 291. Epoch 784
process: 200 / 291. Epoch 784
process: 250 / 291. Epoch 784
process: 291 / 291. Epoch 784
Loss of epoch 784 = 3.0347214531652704
process: 50 / 291. Epoch 785
process: 100 / 291. Epoch 785
process: 150 / 291. Epoch 785
process: 200 / 291. Epoch 785
process: 250 / 291. Epoch 785
process: 291 / 291. Epoch 785
Loss of epoch 785 = 3.0016695527276633
process: 50 / 291. Epoch 786
process: 100 / 291. Epoch 786
process: 150 / 291. Epoch 786
process: 200 / 291. Epoch 786
process: 250 / 291. Epoch 786
process: 291 / 291. Epoch 786
Loss of epoch 786 = 3.0307768202319587
process: 50 / 291. Epoch 787
process: 100 / 291. Epoch 787
process: 150 / 291. Epoch 787
process: 200 / 291. Epoch 787
process: 250 / 291. Epoch 787
process: 291 / 291. Epoch 787
Loss of epoch 787 = 3.052211066701568
process: 50 / 291. Epoch 788
process: 100 / 291. Epoch 788
process: 150 / 291. Epoch 788
process: 200 / 291. Epoch 788
process: 250 / 291. Epoch 788
process: 291 / 291. Epoch 788
Loss of epoch 788 = 3.1520954145189
process: 50 / 291. Epoch 789
process: 100 / 291. Epoch 789
process: 150 / 291. Epoch 789
process: 200 / 291. Epoch 789
process: 250 / 291. Epoch 789
process: 291 / 291. Epoch 789
Loss of epoch 789 = 3.106849277142397
process: 50 / 291. Epoch 790
process: 100 / 291. Epoch 790
process: 150 / 291. Epoch 790
process: 200 / 291. Epoch 790
process: 250 / 291. Epoch 790
process: 291 / 291. Epoch 790
Loss of epoch 790 = 3.0502766088112114
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-790. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.788943
     epoch  training_loss
785    786       3.030777
786    787       3.052211
787    788       3.152095
788    789       3.106849
789    790       3.050277
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
74        750  0.015072  0.082453      0.347517   0.348355
75        760  0.015008  0.083608      0.347243   0.348053
76        770  0.015252  0.081343      0.348457   0.349307
77        780  0.015133  0.081517      0.347534   0.348374
78        790  0.015071  0.082353      0.349295   0.350129
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
74      750.0  0.971362  0.979261  ...  0.957729  0.952191  0.940137
75      760.0  0.971460  0.979388  ...  0.957566  0.952842  0.942906
76      770.0  0.971546  0.979798  ...  0.957078  0.951947  0.935902
77      780.0  0.972001  0.979363  ...  0.958055  0.951947  0.938508
78      790.0  0.971982  0.979039  ...  0.957566  0.952028  0.941196

[5 rows x 13 columns]
process: 50 / 291. Epoch 791
process: 100 / 291. Epoch 791
process: 150 / 291. Epoch 791
process: 200 / 291. Epoch 791
process: 250 / 291. Epoch 791
process: 291 / 291. Epoch 791
Loss of epoch 791 = 3.0466050610099873
process: 50 / 291. Epoch 792
process: 100 / 291. Epoch 792
process: 150 / 291. Epoch 792
process: 200 / 291. Epoch 792
process: 250 / 291. Epoch 792
process: 291 / 291. Epoch 792
Loss of epoch 792 = 3.086715226320876
process: 50 / 291. Epoch 793
process: 100 / 291. Epoch 793
process: 150 / 291. Epoch 793
process: 200 / 291. Epoch 793
process: 250 / 291. Epoch 793
process: 291 / 291. Epoch 793
Loss of epoch 793 = 3.167385874744953
process: 50 / 291. Epoch 794
process: 100 / 291. Epoch 794
process: 150 / 291. Epoch 794
process: 200 / 291. Epoch 794
process: 250 / 291. Epoch 794
process: 291 / 291. Epoch 794
Loss of epoch 794 = 3.069679705957367
process: 50 / 291. Epoch 795
process: 100 / 291. Epoch 795
process: 150 / 291. Epoch 795
process: 200 / 291. Epoch 795
process: 250 / 291. Epoch 795
process: 291 / 291. Epoch 795
Loss of epoch 795 = 3.112650763128222
process: 50 / 291. Epoch 796
process: 100 / 291. Epoch 796
process: 150 / 291. Epoch 796
process: 200 / 291. Epoch 796
process: 250 / 291. Epoch 796
process: 291 / 291. Epoch 796
Loss of epoch 796 = 3.1137162565775345
process: 50 / 291. Epoch 797
process: 100 / 291. Epoch 797
process: 150 / 291. Epoch 797
process: 200 / 291. Epoch 797
process: 250 / 291. Epoch 797
process: 291 / 291. Epoch 797
Loss of epoch 797 = 3.0326261225434923
process: 50 / 291. Epoch 798
process: 100 / 291. Epoch 798
process: 150 / 291. Epoch 798
process: 200 / 291. Epoch 798
process: 250 / 291. Epoch 798
process: 291 / 291. Epoch 798
Loss of epoch 798 = 3.033363787988617
process: 50 / 291. Epoch 799
process: 100 / 291. Epoch 799
process: 150 / 291. Epoch 799
process: 200 / 291. Epoch 799
process: 250 / 291. Epoch 799
process: 291 / 291. Epoch 799
Loss of epoch 799 = 3.1213819366140463
process: 50 / 291. Epoch 800
process: 100 / 291. Epoch 800
process: 150 / 291. Epoch 800
process: 200 / 291. Epoch 800
process: 250 / 291. Epoch 800
process: 291 / 291. Epoch 800
Loss of epoch 800 = 3.0784813530256656
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-800. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.788364
     epoch  training_loss
795    796       3.113716
796    797       3.032626
797    798       3.033364
798    799       3.121382
799    800       3.078481
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
75        760  0.015008  0.083608      0.347243   0.348053
76        770  0.015252  0.081343      0.348457   0.349307
77        780  0.015133  0.081517      0.347534   0.348374
78        790  0.015071  0.082353      0.349295   0.350129
79        800  0.015057  0.082006      0.349020   0.349855
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
75      760.0  0.971460  0.979388  ...  0.957566  0.952842  0.942906
76      770.0  0.971546  0.979798  ...  0.957078  0.951947  0.935902
77      780.0  0.972001  0.979363  ...  0.958055  0.951947  0.938508
78      790.0  0.971982  0.979039  ...  0.957566  0.952028  0.941196
79      800.0  0.971242  0.979356  ...  0.957322  0.951702  0.941847

[5 rows x 13 columns]
process: 50 / 291. Epoch 801
process: 100 / 291. Epoch 801
process: 150 / 291. Epoch 801
process: 200 / 291. Epoch 801
process: 250 / 291. Epoch 801
process: 291 / 291. Epoch 801
Loss of epoch 801 = 2.97552070748765
process: 50 / 291. Epoch 802
process: 100 / 291. Epoch 802
process: 150 / 291. Epoch 802
process: 200 / 291. Epoch 802
process: 250 / 291. Epoch 802
process: 291 / 291. Epoch 802
Loss of epoch 802 = 2.9862339504805626
process: 50 / 291. Epoch 803
process: 100 / 291. Epoch 803
process: 150 / 291. Epoch 803
process: 200 / 291. Epoch 803
process: 250 / 291. Epoch 803
process: 291 / 291. Epoch 803
Loss of epoch 803 = 3.077699641591495
process: 50 / 291. Epoch 804
process: 100 / 291. Epoch 804
process: 150 / 291. Epoch 804
process: 200 / 291. Epoch 804
process: 250 / 291. Epoch 804
process: 291 / 291. Epoch 804
Loss of epoch 804 = 3.1273738690667954
process: 50 / 291. Epoch 805
process: 100 / 291. Epoch 805
process: 150 / 291. Epoch 805
process: 200 / 291. Epoch 805
process: 250 / 291. Epoch 805
process: 291 / 291. Epoch 805
Loss of epoch 805 = 3.0899140138396692
process: 50 / 291. Epoch 806
process: 100 / 291. Epoch 806
process: 150 / 291. Epoch 806
process: 200 / 291. Epoch 806
process: 250 / 291. Epoch 806
process: 291 / 291. Epoch 806
Loss of epoch 806 = 3.077994539975301
process: 50 / 291. Epoch 807
process: 100 / 291. Epoch 807
process: 150 / 291. Epoch 807
process: 200 / 291. Epoch 807
process: 250 / 291. Epoch 807
process: 291 / 291. Epoch 807
Loss of epoch 807 = 3.0401412072460268
process: 50 / 291. Epoch 808
process: 100 / 291. Epoch 808
process: 150 / 291. Epoch 808
process: 200 / 291. Epoch 808
process: 250 / 291. Epoch 808
process: 291 / 291. Epoch 808
Loss of epoch 808 = 2.9639254959997854
process: 50 / 291. Epoch 809
process: 100 / 291. Epoch 809
process: 150 / 291. Epoch 809
process: 200 / 291. Epoch 809
process: 250 / 291. Epoch 809
process: 291 / 291. Epoch 809
Loss of epoch 809 = 3.0309181868825172
process: 50 / 291. Epoch 810
process: 100 / 291. Epoch 810
process: 150 / 291. Epoch 810
process: 200 / 291. Epoch 810
process: 250 / 291. Epoch 810
process: 291 / 291. Epoch 810
Loss of epoch 810 = 3.0722102528994846
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-810. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.789191
     epoch  training_loss
805    806       3.077995
806    807       3.040141
807    808       2.963925
808    809       3.030918
809    810       3.072210
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
76        770  0.015252  0.081343      0.348457   0.349307
77        780  0.015133  0.081517      0.347534   0.348374
78        790  0.015071  0.082353      0.349295   0.350129
79        800  0.015057  0.082006      0.349020   0.349855
80        810  0.015093  0.081459      0.348586   0.349385
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
76      770.0  0.971546  0.979798  ...  0.957078  0.951947  0.935902
77      780.0  0.972001  0.979363  ...  0.958055  0.951947  0.938508
78      790.0  0.971982  0.979039  ...  0.957566  0.952028  0.941196
79      800.0  0.971242  0.979356  ...  0.957322  0.951702  0.941847
80      810.0  0.971568  0.979046  ...  0.957648  0.952272  0.941114

[5 rows x 13 columns]
process: 50 / 291. Epoch 811
process: 100 / 291. Epoch 811
process: 150 / 291. Epoch 811
process: 200 / 291. Epoch 811
process: 250 / 291. Epoch 811
process: 291 / 291. Epoch 811
Loss of epoch 811 = 3.029492774779854
process: 50 / 291. Epoch 812
process: 100 / 291. Epoch 812
process: 150 / 291. Epoch 812
process: 200 / 291. Epoch 812
process: 250 / 291. Epoch 812
process: 291 / 291. Epoch 812
Loss of epoch 812 = 3.0803272994523194
process: 50 / 291. Epoch 813
process: 100 / 291. Epoch 813
process: 150 / 291. Epoch 813
process: 200 / 291. Epoch 813
process: 250 / 291. Epoch 813
process: 291 / 291. Epoch 813
Loss of epoch 813 = 3.075852856193621
process: 50 / 291. Epoch 814
process: 100 / 291. Epoch 814
process: 150 / 291. Epoch 814
process: 200 / 291. Epoch 814
process: 250 / 291. Epoch 814
process: 291 / 291. Epoch 814
Loss of epoch 814 = 3.070567547250859
process: 50 / 291. Epoch 815
process: 100 / 291. Epoch 815
process: 150 / 291. Epoch 815
process: 200 / 291. Epoch 815
process: 250 / 291. Epoch 815
process: 291 / 291. Epoch 815
Loss of epoch 815 = 3.0417677626986683
process: 50 / 291. Epoch 816
process: 100 / 291. Epoch 816
process: 150 / 291. Epoch 816
process: 200 / 291. Epoch 816
process: 250 / 291. Epoch 816
process: 291 / 291. Epoch 816
Loss of epoch 816 = 3.039562946332689
process: 50 / 291. Epoch 817
process: 100 / 291. Epoch 817
process: 150 / 291. Epoch 817
process: 200 / 291. Epoch 817
process: 250 / 291. Epoch 817
process: 291 / 291. Epoch 817
Loss of epoch 817 = 3.1167084474334192
process: 50 / 291. Epoch 818
process: 100 / 291. Epoch 818
process: 150 / 291. Epoch 818
process: 200 / 291. Epoch 818
process: 250 / 291. Epoch 818
process: 291 / 291. Epoch 818
Loss of epoch 818 = 3.050427833373604
process: 50 / 291. Epoch 819
process: 100 / 291. Epoch 819
process: 150 / 291. Epoch 819
process: 200 / 291. Epoch 819
process: 250 / 291. Epoch 819
process: 291 / 291. Epoch 819
Loss of epoch 819 = 2.952012524162371
process: 50 / 291. Epoch 820
process: 100 / 291. Epoch 820
process: 150 / 291. Epoch 820
process: 200 / 291. Epoch 820
process: 250 / 291. Epoch 820
process: 291 / 291. Epoch 820
Loss of epoch 820 = 3.0441970038659796
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-820. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.788053
     epoch  training_loss
815    816       3.039563
816    817       3.116708
817    818       3.050428
818    819       2.952013
819    820       3.044197
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
77        780  0.015133  0.081517      0.347534   0.348374
78        790  0.015071  0.082353      0.349295   0.350129
79        800  0.015057  0.082006      0.349020   0.349855
80        810  0.015093  0.081459      0.348586   0.349385
81        820  0.015095  0.080906      0.350667   0.351550
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
77      780.0  0.972001  0.979363  ...  0.958055  0.951947  0.938508
78      790.0  0.971982  0.979039  ...  0.957566  0.952028  0.941196
79      800.0  0.971242  0.979356  ...  0.957322  0.951702  0.941847
80      810.0  0.971568  0.979046  ...  0.957648  0.952272  0.941114
81      820.0  0.972099  0.979268  ...  0.957892  0.952435  0.940137

[5 rows x 13 columns]
process: 50 / 291. Epoch 821
process: 100 / 291. Epoch 821
process: 150 / 291. Epoch 821
process: 200 / 291. Epoch 821
process: 250 / 291. Epoch 821
process: 291 / 291. Epoch 821
Loss of epoch 821 = 3.1591473871080327
process: 50 / 291. Epoch 822
process: 100 / 291. Epoch 822
process: 150 / 291. Epoch 822
process: 200 / 291. Epoch 822
process: 250 / 291. Epoch 822
process: 291 / 291. Epoch 822
Loss of epoch 822 = 3.0244694346005154
process: 50 / 291. Epoch 823
process: 100 / 291. Epoch 823
process: 150 / 291. Epoch 823
process: 200 / 291. Epoch 823
process: 250 / 291. Epoch 823
process: 291 / 291. Epoch 823
Loss of epoch 823 = 3.022059070285653
process: 50 / 291. Epoch 824
process: 100 / 291. Epoch 824
process: 150 / 291. Epoch 824
process: 200 / 291. Epoch 824
process: 250 / 291. Epoch 824
process: 291 / 291. Epoch 824
Loss of epoch 824 = 3.0407614167203607
process: 50 / 291. Epoch 825
process: 100 / 291. Epoch 825
process: 150 / 291. Epoch 825
process: 200 / 291. Epoch 825
process: 250 / 291. Epoch 825
process: 291 / 291. Epoch 825
Loss of epoch 825 = 3.082155207997745
process: 50 / 291. Epoch 826
process: 100 / 291. Epoch 826
process: 150 / 291. Epoch 826
process: 200 / 291. Epoch 826
process: 250 / 291. Epoch 826
process: 291 / 291. Epoch 826
Loss of epoch 826 = 2.9978052512886597
process: 50 / 291. Epoch 827
process: 100 / 291. Epoch 827
process: 150 / 291. Epoch 827
process: 200 / 291. Epoch 827
process: 250 / 291. Epoch 827
process: 291 / 291. Epoch 827
Loss of epoch 827 = 2.9723944909793816
process: 50 / 291. Epoch 828
process: 100 / 291. Epoch 828
process: 150 / 291. Epoch 828
process: 200 / 291. Epoch 828
process: 250 / 291. Epoch 828
process: 291 / 291. Epoch 828
Loss of epoch 828 = 3.0549341575386597
process: 50 / 291. Epoch 829
process: 100 / 291. Epoch 829
process: 150 / 291. Epoch 829
process: 200 / 291. Epoch 829
process: 250 / 291. Epoch 829
process: 291 / 291. Epoch 829
Loss of epoch 829 = 3.1187064573936856
process: 50 / 291. Epoch 830
process: 100 / 291. Epoch 830
process: 150 / 291. Epoch 830
process: 200 / 291. Epoch 830
process: 250 / 291. Epoch 830
process: 291 / 291. Epoch 830
Loss of epoch 830 = 3.0641034837440935
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-830. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.788100
     epoch  training_loss
825    826       2.997805
826    827       2.972394
827    828       3.054934
828    829       3.118706
829    830       3.064103
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
78        790  0.015071  0.082353      0.349295   0.350129
79        800  0.015057  0.082006      0.349020   0.349855
80        810  0.015093  0.081459      0.348586   0.349385
81        820  0.015095  0.080906      0.350667   0.351550
82        830  0.015154  0.080514      0.349916   0.350790
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
78      790.0  0.971982  0.979039  ...  0.957566  0.952028  0.941196
79      800.0  0.971242  0.979356  ...  0.957322  0.951702  0.941847
80      810.0  0.971568  0.979046  ...  0.957648  0.952272  0.941114
81      820.0  0.972099  0.979268  ...  0.957892  0.952435  0.940137
82      830.0  0.971343  0.978921  ...  0.957241  0.951702  0.940788

[5 rows x 13 columns]
process: 50 / 291. Epoch 831
process: 100 / 291. Epoch 831
process: 150 / 291. Epoch 831
process: 200 / 291. Epoch 831
process: 250 / 291. Epoch 831
process: 291 / 291. Epoch 831
Loss of epoch 831 = 2.9424549640249142
process: 50 / 291. Epoch 832
process: 100 / 291. Epoch 832
process: 150 / 291. Epoch 832
process: 200 / 291. Epoch 832
process: 250 / 291. Epoch 832
process: 291 / 291. Epoch 832
Loss of epoch 832 = 3.010668987261061
process: 50 / 291. Epoch 833
process: 100 / 291. Epoch 833
process: 150 / 291. Epoch 833
process: 200 / 291. Epoch 833
process: 250 / 291. Epoch 833
process: 291 / 291. Epoch 833
Loss of epoch 833 = 3.047058315211555
process: 50 / 291. Epoch 834
process: 100 / 291. Epoch 834
process: 150 / 291. Epoch 834
process: 200 / 291. Epoch 834
process: 250 / 291. Epoch 834
process: 291 / 291. Epoch 834
Loss of epoch 834 = 3.042735306258054
process: 50 / 291. Epoch 835
process: 100 / 291. Epoch 835
process: 150 / 291. Epoch 835
process: 200 / 291. Epoch 835
process: 250 / 291. Epoch 835
process: 291 / 291. Epoch 835
Loss of epoch 835 = 3.0095906995006443
process: 50 / 291. Epoch 836
process: 100 / 291. Epoch 836
process: 150 / 291. Epoch 836
process: 200 / 291. Epoch 836
process: 250 / 291. Epoch 836
process: 291 / 291. Epoch 836
Loss of epoch 836 = 3.0548389343051974
process: 50 / 291. Epoch 837
process: 100 / 291. Epoch 837
process: 150 / 291. Epoch 837
process: 200 / 291. Epoch 837
process: 250 / 291. Epoch 837
process: 291 / 291. Epoch 837
Loss of epoch 837 = 3.0876177496107173
process: 50 / 291. Epoch 838
process: 100 / 291. Epoch 838
process: 150 / 291. Epoch 838
process: 200 / 291. Epoch 838
process: 250 / 291. Epoch 838
process: 291 / 291. Epoch 838
Loss of epoch 838 = 2.9951828369979596
process: 50 / 291. Epoch 839
process: 100 / 291. Epoch 839
process: 150 / 291. Epoch 839
process: 200 / 291. Epoch 839
process: 250 / 291. Epoch 839
process: 291 / 291. Epoch 839
Loss of epoch 839 = 3.0433764900128866
process: 50 / 291. Epoch 840
process: 100 / 291. Epoch 840
process: 150 / 291. Epoch 840
process: 200 / 291. Epoch 840
process: 250 / 291. Epoch 840
process: 291 / 291. Epoch 840
Loss of epoch 840 = 3.0134839454467355
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-840. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.781318
     epoch  training_loss
835    836       3.054839
836    837       3.087618
837    838       2.995183
838    839       3.043376
839    840       3.013484
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
79        800  0.015057  0.082006      0.349020   0.349855
80        810  0.015093  0.081459      0.348586   0.349385
81        820  0.015095  0.080906      0.350667   0.351550
82        830  0.015154  0.080514      0.349916   0.350790
83        840  0.015280  0.079252      0.350963   0.351848
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
79      800.0  0.971242  0.979356  ...  0.957322  0.951702  0.941847
80      810.0  0.971568  0.979046  ...  0.957648  0.952272  0.941114
81      820.0  0.972099  0.979268  ...  0.957892  0.952435  0.940137
82      830.0  0.971343  0.978921  ...  0.957241  0.951702  0.940788
83      840.0  0.972071  0.979803  ...  0.957159  0.952109  0.935087

[5 rows x 13 columns]
process: 50 / 291. Epoch 841
process: 100 / 291. Epoch 841
process: 150 / 291. Epoch 841
process: 200 / 291. Epoch 841
process: 250 / 291. Epoch 841
process: 291 / 291. Epoch 841
Loss of epoch 841 = 2.936025508080971
process: 50 / 291. Epoch 842
process: 100 / 291. Epoch 842
process: 150 / 291. Epoch 842
process: 200 / 291. Epoch 842
process: 250 / 291. Epoch 842
process: 291 / 291. Epoch 842
Loss of epoch 842 = 3.049949829521048
process: 50 / 291. Epoch 843
process: 100 / 291. Epoch 843
process: 150 / 291. Epoch 843
process: 200 / 291. Epoch 843
process: 250 / 291. Epoch 843
process: 291 / 291. Epoch 843
Loss of epoch 843 = 3.0187434560244846
process: 50 / 291. Epoch 844
process: 100 / 291. Epoch 844
process: 150 / 291. Epoch 844
process: 200 / 291. Epoch 844
process: 250 / 291. Epoch 844
process: 291 / 291. Epoch 844
Loss of epoch 844 = 2.9681702708870277
process: 50 / 291. Epoch 845
process: 100 / 291. Epoch 845
process: 150 / 291. Epoch 845
process: 200 / 291. Epoch 845
process: 250 / 291. Epoch 845
process: 291 / 291. Epoch 845
Loss of epoch 845 = 2.9805453061238185
process: 50 / 291. Epoch 846
process: 100 / 291. Epoch 846
process: 150 / 291. Epoch 846
process: 200 / 291. Epoch 846
process: 250 / 291. Epoch 846
process: 291 / 291. Epoch 846
Loss of epoch 846 = 3.0297549532860826
process: 50 / 291. Epoch 847
process: 100 / 291. Epoch 847
process: 150 / 291. Epoch 847
process: 200 / 291. Epoch 847
process: 250 / 291. Epoch 847
process: 291 / 291. Epoch 847
Loss of epoch 847 = 3.015207192332474
process: 50 / 291. Epoch 848
process: 100 / 291. Epoch 848
process: 150 / 291. Epoch 848
process: 200 / 291. Epoch 848
process: 250 / 291. Epoch 848
process: 291 / 291. Epoch 848
Loss of epoch 848 = 3.0103594068809065
process: 50 / 291. Epoch 849
process: 100 / 291. Epoch 849
process: 150 / 291. Epoch 849
process: 200 / 291. Epoch 849
process: 250 / 291. Epoch 849
process: 291 / 291. Epoch 849
Loss of epoch 849 = 3.0642396068245277
process: 50 / 291. Epoch 850
process: 100 / 291. Epoch 850
process: 150 / 291. Epoch 850
process: 200 / 291. Epoch 850
process: 250 / 291. Epoch 850
process: 291 / 291. Epoch 850
Loss of epoch 850 = 3.056566795532646
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-850. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.789524
     epoch  training_loss
845    846       3.029755
846    847       3.015207
847    848       3.010359
848    849       3.064240
849    850       3.056567
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
80        810  0.015093  0.081459      0.348586   0.349385
81        820  0.015095  0.080906      0.350667   0.351550
82        830  0.015154  0.080514      0.349916   0.350790
83        840  0.015280  0.079252      0.350963   0.351848
84        850  0.015079  0.081129      0.351284   0.352129
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
80      810.0  0.971568  0.979046  ...  0.957648  0.952272  0.941114
81      820.0  0.972099  0.979268  ...  0.957892  0.952435  0.940137
82      830.0  0.971343  0.978921  ...  0.957241  0.951702  0.940788
83      840.0  0.972071  0.979803  ...  0.957159  0.952109  0.935087
84      850.0  0.971565  0.979608  ...  0.957566  0.952924  0.941196

[5 rows x 13 columns]
process: 50 / 291. Epoch 851
process: 100 / 291. Epoch 851
process: 150 / 291. Epoch 851
process: 200 / 291. Epoch 851
process: 250 / 291. Epoch 851
process: 291 / 291. Epoch 851
Loss of epoch 851 = 3.0180945117858675
process: 50 / 291. Epoch 852
process: 100 / 291. Epoch 852
process: 150 / 291. Epoch 852
process: 200 / 291. Epoch 852
process: 250 / 291. Epoch 852
process: 291 / 291. Epoch 852
Loss of epoch 852 = 3.0245394886973798
process: 50 / 291. Epoch 853
process: 100 / 291. Epoch 853
process: 150 / 291. Epoch 853
process: 200 / 291. Epoch 853
process: 250 / 291. Epoch 853
process: 291 / 291. Epoch 853
Loss of epoch 853 = 3.0202091387457046
process: 50 / 291. Epoch 854
process: 100 / 291. Epoch 854
process: 150 / 291. Epoch 854
process: 200 / 291. Epoch 854
process: 250 / 291. Epoch 854
process: 291 / 291. Epoch 854
Loss of epoch 854 = 3.041916680090206
process: 50 / 291. Epoch 855
process: 100 / 291. Epoch 855
process: 150 / 291. Epoch 855
process: 200 / 291. Epoch 855
process: 250 / 291. Epoch 855
process: 291 / 291. Epoch 855
Loss of epoch 855 = 2.981213966186104
process: 50 / 291. Epoch 856
process: 100 / 291. Epoch 856
process: 150 / 291. Epoch 856
process: 200 / 291. Epoch 856
process: 250 / 291. Epoch 856
process: 291 / 291. Epoch 856
Loss of epoch 856 = 3.00586147242805
process: 50 / 291. Epoch 857
process: 100 / 291. Epoch 857
process: 150 / 291. Epoch 857
process: 200 / 291. Epoch 857
process: 250 / 291. Epoch 857
process: 291 / 291. Epoch 857
Loss of epoch 857 = 3.0244660787156357
process: 50 / 291. Epoch 858
process: 100 / 291. Epoch 858
process: 150 / 291. Epoch 858
process: 200 / 291. Epoch 858
process: 250 / 291. Epoch 858
process: 291 / 291. Epoch 858
Loss of epoch 858 = 2.934373573748926
process: 50 / 291. Epoch 859
process: 100 / 291. Epoch 859
process: 150 / 291. Epoch 859
process: 200 / 291. Epoch 859
process: 250 / 291. Epoch 859
process: 291 / 291. Epoch 859
Loss of epoch 859 = 3.036914733676976
process: 50 / 291. Epoch 860
process: 100 / 291. Epoch 860
process: 150 / 291. Epoch 860
process: 200 / 291. Epoch 860
process: 250 / 291. Epoch 860
process: 291 / 291. Epoch 860
Loss of epoch 860 = 3.0129096696466924
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-860. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.790546
     epoch  training_loss
855    856       3.005861
856    857       3.024466
857    858       2.934374
858    859       3.036915
859    860       3.012910
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
81        820  0.015095  0.080906      0.350667   0.351550
82        830  0.015154  0.080514      0.349916   0.350790
83        840  0.015280  0.079252      0.350963   0.351848
84        850  0.015079  0.081129      0.351284   0.352129
85        860  0.015178  0.080407      0.352688   0.353599
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
81      820.0  0.972099  0.979268  ...  0.957892  0.952435  0.940137
82      830.0  0.971343  0.978921  ...  0.957241  0.951702  0.940788
83      840.0  0.972071  0.979803  ...  0.957159  0.952109  0.935087
84      850.0  0.971565  0.979608  ...  0.957566  0.952924  0.941196
85      860.0  0.971669  0.979490  ...  0.957566  0.952598  0.941603

[5 rows x 13 columns]
process: 50 / 291. Epoch 861
process: 100 / 291. Epoch 861
process: 150 / 291. Epoch 861
process: 200 / 291. Epoch 861
process: 250 / 291. Epoch 861
process: 291 / 291. Epoch 861
Loss of epoch 861 = 3.021701249060352
process: 50 / 291. Epoch 862
process: 100 / 291. Epoch 862
process: 150 / 291. Epoch 862
process: 200 / 291. Epoch 862
process: 250 / 291. Epoch 862
process: 291 / 291. Epoch 862
Loss of epoch 862 = 3.0109313755100944
process: 50 / 291. Epoch 863
process: 100 / 291. Epoch 863
process: 150 / 291. Epoch 863
process: 200 / 291. Epoch 863
process: 250 / 291. Epoch 863
process: 291 / 291. Epoch 863
Loss of epoch 863 = 2.919639141698883
process: 50 / 291. Epoch 864
process: 100 / 291. Epoch 864
process: 150 / 291. Epoch 864
process: 200 / 291. Epoch 864
process: 250 / 291. Epoch 864
process: 291 / 291. Epoch 864
Loss of epoch 864 = 2.999179066661297
process: 50 / 291. Epoch 865
process: 100 / 291. Epoch 865
process: 150 / 291. Epoch 865
process: 200 / 291. Epoch 865
process: 250 / 291. Epoch 865
process: 291 / 291. Epoch 865
Loss of epoch 865 = 3.0218163978602877
process: 50 / 291. Epoch 866
process: 100 / 291. Epoch 866
process: 150 / 291. Epoch 866
process: 200 / 291. Epoch 866
process: 250 / 291. Epoch 866
process: 291 / 291. Epoch 866
Loss of epoch 866 = 2.985620243033183
process: 50 / 291. Epoch 867
process: 100 / 291. Epoch 867
process: 150 / 291. Epoch 867
process: 200 / 291. Epoch 867
process: 250 / 291. Epoch 867
process: 291 / 291. Epoch 867
Loss of epoch 867 = 3.0138438641000858
process: 50 / 291. Epoch 868
process: 100 / 291. Epoch 868
process: 150 / 291. Epoch 868
process: 200 / 291. Epoch 868
process: 250 / 291. Epoch 868
process: 291 / 291. Epoch 868
Loss of epoch 868 = 2.9946322621348798
process: 50 / 291. Epoch 869
process: 100 / 291. Epoch 869
process: 150 / 291. Epoch 869
process: 200 / 291. Epoch 869
process: 250 / 291. Epoch 869
process: 291 / 291. Epoch 869
Loss of epoch 869 = 2.9901571896477663
process: 50 / 291. Epoch 870
process: 100 / 291. Epoch 870
process: 150 / 291. Epoch 870
process: 200 / 291. Epoch 870
process: 250 / 291. Epoch 870
process: 291 / 291. Epoch 870
Loss of epoch 870 = 3.030081942319051
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-870. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.786192
     epoch  training_loss
865    866       2.985620
866    867       3.013844
867    868       2.994632
868    869       2.990157
869    870       3.030082
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
82        830  0.015154  0.080514      0.349916   0.350790
83        840  0.015280  0.079252      0.350963   0.351848
84        850  0.015079  0.081129      0.351284   0.352129
85        860  0.015178  0.080407      0.352688   0.353599
86        870  0.015266  0.079516      0.352427   0.353317
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
82      830.0  0.971343  0.978921  ...  0.957241  0.951702  0.940788
83      840.0  0.972071  0.979803  ...  0.957159  0.952109  0.935087
84      850.0  0.971565  0.979608  ...  0.957566  0.952924  0.941196
85      860.0  0.971669  0.979490  ...  0.957566  0.952598  0.941603
86      870.0  0.971751  0.979596  ...  0.956996  0.952517  0.938589

[5 rows x 13 columns]
process: 50 / 291. Epoch 871
process: 100 / 291. Epoch 871
process: 150 / 291. Epoch 871
process: 200 / 291. Epoch 871
process: 250 / 291. Epoch 871
process: 291 / 291. Epoch 871
Loss of epoch 871 = 3.0512250657753435
process: 50 / 291. Epoch 872
process: 100 / 291. Epoch 872
process: 150 / 291. Epoch 872
process: 200 / 291. Epoch 872
process: 250 / 291. Epoch 872
process: 291 / 291. Epoch 872
Loss of epoch 872 = 2.9751305858703825
process: 50 / 291. Epoch 873
process: 100 / 291. Epoch 873
process: 150 / 291. Epoch 873
process: 200 / 291. Epoch 873
process: 250 / 291. Epoch 873
process: 291 / 291. Epoch 873
Loss of epoch 873 = 3.0195041931781574
process: 50 / 291. Epoch 874
process: 100 / 291. Epoch 874
process: 150 / 291. Epoch 874
process: 200 / 291. Epoch 874
process: 250 / 291. Epoch 874
process: 291 / 291. Epoch 874
Loss of epoch 874 = 2.984678288096005
process: 50 / 291. Epoch 875
process: 100 / 291. Epoch 875
process: 150 / 291. Epoch 875
process: 200 / 291. Epoch 875
process: 250 / 291. Epoch 875
process: 291 / 291. Epoch 875
Loss of epoch 875 = 3.0103963216145835
process: 50 / 291. Epoch 876
process: 100 / 291. Epoch 876
process: 150 / 291. Epoch 876
process: 200 / 291. Epoch 876
process: 250 / 291. Epoch 876
process: 291 / 291. Epoch 876
Loss of epoch 876 = 3.065421088044996
process: 50 / 291. Epoch 877
process: 100 / 291. Epoch 877
process: 150 / 291. Epoch 877
process: 200 / 291. Epoch 877
process: 250 / 291. Epoch 877
process: 291 / 291. Epoch 877
Loss of epoch 877 = 2.96581989301439
process: 50 / 291. Epoch 878
process: 100 / 291. Epoch 878
process: 150 / 291. Epoch 878
process: 200 / 291. Epoch 878
process: 250 / 291. Epoch 878
process: 291 / 291. Epoch 878
Loss of epoch 878 = 2.9538297358247423
process: 50 / 291. Epoch 879
process: 100 / 291. Epoch 879
process: 150 / 291. Epoch 879
process: 200 / 291. Epoch 879
process: 250 / 291. Epoch 879
process: 291 / 291. Epoch 879
Loss of epoch 879 = 3.0207821560889174
process: 50 / 291. Epoch 880
process: 100 / 291. Epoch 880
process: 150 / 291. Epoch 880
process: 200 / 291. Epoch 880
process: 250 / 291. Epoch 880
process: 291 / 291. Epoch 880
Loss of epoch 880 = 2.9560488147014605
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-880. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.789071
     epoch  training_loss
875    876       3.065421
876    877       2.965820
877    878       2.953830
878    879       3.020782
879    880       2.956049
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
83        840  0.015280  0.079252      0.350963   0.351848
84        850  0.015079  0.081129      0.351284   0.352129
85        860  0.015178  0.080407      0.352688   0.353599
86        870  0.015266  0.079516      0.352427   0.353317
87        880  0.015178  0.080132      0.352982   0.353876
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
83      840.0  0.972071  0.979803  ...  0.957159  0.952109  0.935087
84      850.0  0.971565  0.979608  ...  0.957566  0.952924  0.941196
85      860.0  0.971669  0.979490  ...  0.957566  0.952598  0.941603
86      870.0  0.971751  0.979596  ...  0.956996  0.952517  0.938589
87      880.0  0.971964  0.979485  ...  0.957078  0.952435  0.940463

[5 rows x 13 columns]
process: 50 / 291. Epoch 881
process: 100 / 291. Epoch 881
process: 150 / 291. Epoch 881
process: 200 / 291. Epoch 881
process: 250 / 291. Epoch 881
process: 291 / 291. Epoch 881
Loss of epoch 881 = 2.987843307023196
process: 50 / 291. Epoch 882
process: 100 / 291. Epoch 882
process: 150 / 291. Epoch 882
process: 200 / 291. Epoch 882
process: 250 / 291. Epoch 882
process: 291 / 291. Epoch 882
Loss of epoch 882 = 2.9435808634020617
process: 50 / 291. Epoch 883
process: 100 / 291. Epoch 883
process: 150 / 291. Epoch 883
process: 200 / 291. Epoch 883
process: 250 / 291. Epoch 883
process: 291 / 291. Epoch 883
Loss of epoch 883 = 3.0474656357388317
process: 50 / 291. Epoch 884
process: 100 / 291. Epoch 884
process: 150 / 291. Epoch 884
process: 200 / 291. Epoch 884
process: 250 / 291. Epoch 884
process: 291 / 291. Epoch 884
Loss of epoch 884 = 2.9656281880906357
process: 50 / 291. Epoch 885
process: 100 / 291. Epoch 885
process: 150 / 291. Epoch 885
process: 200 / 291. Epoch 885
process: 250 / 291. Epoch 885
process: 291 / 291. Epoch 885
Loss of epoch 885 = 3.0461853656572164
process: 50 / 291. Epoch 886
process: 100 / 291. Epoch 886
process: 150 / 291. Epoch 886
process: 200 / 291. Epoch 886
process: 250 / 291. Epoch 886
process: 291 / 291. Epoch 886
Loss of epoch 886 = 2.989025417472079
process: 50 / 291. Epoch 887
process: 100 / 291. Epoch 887
process: 150 / 291. Epoch 887
process: 200 / 291. Epoch 887
process: 250 / 291. Epoch 887
process: 291 / 291. Epoch 887
Loss of epoch 887 = 2.984436664384665
process: 50 / 291. Epoch 888
process: 100 / 291. Epoch 888
process: 150 / 291. Epoch 888
process: 200 / 291. Epoch 888
process: 250 / 291. Epoch 888
process: 291 / 291. Epoch 888
Loss of epoch 888 = 2.9715261557667527
process: 50 / 291. Epoch 889
process: 100 / 291. Epoch 889
process: 150 / 291. Epoch 889
process: 200 / 291. Epoch 889
process: 250 / 291. Epoch 889
process: 291 / 291. Epoch 889
Loss of epoch 889 = 2.9645710843535222
process: 50 / 291. Epoch 890
process: 100 / 291. Epoch 890
process: 150 / 291. Epoch 890
process: 200 / 291. Epoch 890
process: 250 / 291. Epoch 890
process: 291 / 291. Epoch 890
Loss of epoch 890 = 2.9583083739395404
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-890. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.790689
     epoch  training_loss
885    886       2.989025
886    887       2.984437
887    888       2.971526
888    889       2.964571
889    890       2.958308
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
84        850  0.015079  0.081129      0.351284   0.352129
85        860  0.015178  0.080407      0.352688   0.353599
86        870  0.015266  0.079516      0.352427   0.353317
87        880  0.015178  0.080132      0.352982   0.353876
88        890  0.015044  0.079835      0.353223   0.354122
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
84      850.0  0.971565  0.979608  ...  0.957566  0.952924  0.941196
85      860.0  0.971669  0.979490  ...  0.957566  0.952598  0.941603
86      870.0  0.971751  0.979596  ...  0.956996  0.952517  0.938589
87      880.0  0.971964  0.979485  ...  0.957078  0.952435  0.940463
88      890.0  0.971574  0.979703  ...  0.957811  0.952435  0.943150

[5 rows x 13 columns]
process: 50 / 291. Epoch 891
process: 100 / 291. Epoch 891
process: 150 / 291. Epoch 891
process: 200 / 291. Epoch 891
process: 250 / 291. Epoch 891
process: 291 / 291. Epoch 891
Loss of epoch 891 = 2.8919660954950603
process: 50 / 291. Epoch 892
process: 100 / 291. Epoch 892
process: 150 / 291. Epoch 892
process: 200 / 291. Epoch 892
process: 250 / 291. Epoch 892
process: 291 / 291. Epoch 892
Loss of epoch 892 = 2.9643401575252364
process: 50 / 291. Epoch 893
process: 100 / 291. Epoch 893
process: 150 / 291. Epoch 893
process: 200 / 291. Epoch 893
process: 250 / 291. Epoch 893
process: 291 / 291. Epoch 893
Loss of epoch 893 = 3.022839523262994
process: 50 / 291. Epoch 894
process: 100 / 291. Epoch 894
process: 150 / 291. Epoch 894
process: 200 / 291. Epoch 894
process: 250 / 291. Epoch 894
process: 291 / 291. Epoch 894
Loss of epoch 894 = 3.0132616180734537
process: 50 / 291. Epoch 895
process: 100 / 291. Epoch 895
process: 150 / 291. Epoch 895
process: 200 / 291. Epoch 895
process: 250 / 291. Epoch 895
process: 291 / 291. Epoch 895
Loss of epoch 895 = 2.964430137188574
process: 50 / 291. Epoch 896
process: 100 / 291. Epoch 896
process: 150 / 291. Epoch 896
process: 200 / 291. Epoch 896
process: 250 / 291. Epoch 896
process: 291 / 291. Epoch 896
Loss of epoch 896 = 2.9806073899940935
process: 50 / 291. Epoch 897
process: 100 / 291. Epoch 897
process: 150 / 291. Epoch 897
process: 200 / 291. Epoch 897
process: 250 / 291. Epoch 897
process: 291 / 291. Epoch 897
Loss of epoch 897 = 2.9866735713998067
process: 50 / 291. Epoch 898
process: 100 / 291. Epoch 898
process: 150 / 291. Epoch 898
process: 200 / 291. Epoch 898
process: 250 / 291. Epoch 898
process: 291 / 291. Epoch 898
Loss of epoch 898 = 2.8712319705084837
process: 50 / 291. Epoch 899
process: 100 / 291. Epoch 899
process: 150 / 291. Epoch 899
process: 200 / 291. Epoch 899
process: 250 / 291. Epoch 899
process: 291 / 291. Epoch 899
Loss of epoch 899 = 2.922462070111147
process: 50 / 291. Epoch 900
process: 100 / 291. Epoch 900
process: 150 / 291. Epoch 900
process: 200 / 291. Epoch 900
process: 250 / 291. Epoch 900
process: 291 / 291. Epoch 900
Loss of epoch 900 = 2.9589306808419242
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-900. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.791905
     epoch  training_loss
895    896       2.980607
896    897       2.986674
897    898       2.871232
898    899       2.922462
899    900       2.958931
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
85        860  0.015178  0.080407      0.352688   0.353599
86        870  0.015266  0.079516      0.352427   0.353317
87        880  0.015178  0.080132      0.352982   0.353876
88        890  0.015044  0.079835      0.353223   0.354122
89        900  0.015139  0.079295      0.354306   0.355278
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
85      860.0  0.971669  0.979490  ...  0.957566  0.952598  0.941603
86      870.0  0.971751  0.979596  ...  0.956996  0.952517  0.938589
87      880.0  0.971964  0.979485  ...  0.957078  0.952435  0.940463
88      890.0  0.971574  0.979703  ...  0.957811  0.952435  0.943150
89      900.0  0.971890  0.979594  ...  0.957892  0.952435  0.943639

[5 rows x 13 columns]
process: 50 / 291. Epoch 901
process: 100 / 291. Epoch 901
process: 150 / 291. Epoch 901
process: 200 / 291. Epoch 901
process: 250 / 291. Epoch 901
process: 291 / 291. Epoch 901
Loss of epoch 901 = 3.0152776659149483
process: 50 / 291. Epoch 902
process: 100 / 291. Epoch 902
process: 150 / 291. Epoch 902
process: 200 / 291. Epoch 902
process: 250 / 291. Epoch 902
process: 291 / 291. Epoch 902
Loss of epoch 902 = 3.028818241919029
process: 50 / 291. Epoch 903
process: 100 / 291. Epoch 903
process: 150 / 291. Epoch 903
process: 200 / 291. Epoch 903
process: 250 / 291. Epoch 903
process: 291 / 291. Epoch 903
Loss of epoch 903 = 2.956922183741409
process: 50 / 291. Epoch 904
process: 100 / 291. Epoch 904
process: 150 / 291. Epoch 904
process: 200 / 291. Epoch 904
process: 250 / 291. Epoch 904
process: 291 / 291. Epoch 904
Loss of epoch 904 = 2.9836371248120703
process: 50 / 291. Epoch 905
process: 100 / 291. Epoch 905
process: 150 / 291. Epoch 905
process: 200 / 291. Epoch 905
process: 250 / 291. Epoch 905
process: 291 / 291. Epoch 905
Loss of epoch 905 = 2.905751231609751
process: 50 / 291. Epoch 906
process: 100 / 291. Epoch 906
process: 150 / 291. Epoch 906
process: 200 / 291. Epoch 906
process: 250 / 291. Epoch 906
process: 291 / 291. Epoch 906
Loss of epoch 906 = 2.9874817104274056
process: 50 / 291. Epoch 907
process: 100 / 291. Epoch 907
process: 150 / 291. Epoch 907
process: 200 / 291. Epoch 907
process: 250 / 291. Epoch 907
process: 291 / 291. Epoch 907
Loss of epoch 907 = 2.9492349001959837
process: 50 / 291. Epoch 908
process: 100 / 291. Epoch 908
process: 150 / 291. Epoch 908
process: 200 / 291. Epoch 908
process: 250 / 291. Epoch 908
process: 291 / 291. Epoch 908
Loss of epoch 908 = 2.988893908733355
process: 50 / 291. Epoch 909
process: 100 / 291. Epoch 909
process: 150 / 291. Epoch 909
process: 200 / 291. Epoch 909
process: 250 / 291. Epoch 909
process: 291 / 291. Epoch 909
Loss of epoch 909 = 2.941458685701246
process: 50 / 291. Epoch 910
process: 100 / 291. Epoch 910
process: 150 / 291. Epoch 910
process: 200 / 291. Epoch 910
process: 250 / 291. Epoch 910
process: 291 / 291. Epoch 910
Loss of epoch 910 = 2.9565341595521906
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-910. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.796244
     epoch  training_loss
905    906       2.987482
906    907       2.949235
907    908       2.988894
908    909       2.941459
909    910       2.956534
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
86        870  0.015266  0.079516      0.352427   0.353317
87        880  0.015178  0.080132      0.352982   0.353876
88        890  0.015044  0.079835      0.353223   0.354122
89        900  0.015139  0.079295      0.354306   0.355278
90        910  0.015059  0.080067      0.353868   0.354820
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
86      870.0  0.971751  0.979596  ...  0.956996  0.952517  0.938589
87      880.0  0.971964  0.979485  ...  0.957078  0.952435  0.940463
88      890.0  0.971574  0.979703  ...  0.957811  0.952435  0.943150
89      900.0  0.971890  0.979594  ...  0.957892  0.952435  0.943639
90      910.0  0.971353  0.979164  ...  0.957485  0.952598  0.944535

[5 rows x 13 columns]
process: 50 / 291. Epoch 911
process: 100 / 291. Epoch 911
process: 150 / 291. Epoch 911
process: 200 / 291. Epoch 911
process: 250 / 291. Epoch 911
process: 291 / 291. Epoch 911
Loss of epoch 911 = 2.994125943003651
process: 50 / 291. Epoch 912
process: 100 / 291. Epoch 912
process: 150 / 291. Epoch 912
process: 200 / 291. Epoch 912
process: 250 / 291. Epoch 912
process: 291 / 291. Epoch 912
Loss of epoch 912 = 2.950269980938574
process: 50 / 291. Epoch 913
process: 100 / 291. Epoch 913
process: 150 / 291. Epoch 913
process: 200 / 291. Epoch 913
process: 250 / 291. Epoch 913
process: 291 / 291. Epoch 913
Loss of epoch 913 = 3.017552955863402
process: 50 / 291. Epoch 914
process: 100 / 291. Epoch 914
process: 150 / 291. Epoch 914
process: 200 / 291. Epoch 914
process: 250 / 291. Epoch 914
process: 291 / 291. Epoch 914
Loss of epoch 914 = 2.912866966011598
process: 50 / 291. Epoch 915
process: 100 / 291. Epoch 915
process: 150 / 291. Epoch 915
process: 200 / 291. Epoch 915
process: 250 / 291. Epoch 915
process: 291 / 291. Epoch 915
Loss of epoch 915 = 2.9029962598663017
process: 50 / 291. Epoch 916
process: 100 / 291. Epoch 916
process: 150 / 291. Epoch 916
process: 200 / 291. Epoch 916
process: 250 / 291. Epoch 916
process: 291 / 291. Epoch 916
Loss of epoch 916 = 2.9725853569319156
process: 50 / 291. Epoch 917
process: 100 / 291. Epoch 917
process: 150 / 291. Epoch 917
process: 200 / 291. Epoch 917
process: 250 / 291. Epoch 917
process: 291 / 291. Epoch 917
Loss of epoch 917 = 2.9277140299479165
process: 50 / 291. Epoch 918
process: 100 / 291. Epoch 918
process: 150 / 291. Epoch 918
process: 200 / 291. Epoch 918
process: 250 / 291. Epoch 918
process: 291 / 291. Epoch 918
Loss of epoch 918 = 2.9811971867617055
process: 50 / 291. Epoch 919
process: 100 / 291. Epoch 919
process: 150 / 291. Epoch 919
process: 200 / 291. Epoch 919
process: 250 / 291. Epoch 919
process: 291 / 291. Epoch 919
Loss of epoch 919 = 2.9995024900665808
process: 50 / 291. Epoch 920
process: 100 / 291. Epoch 920
process: 150 / 291. Epoch 920
process: 200 / 291. Epoch 920
process: 250 / 291. Epoch 920
process: 291 / 291. Epoch 920
Loss of epoch 920 = 2.9363816513638317
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-920. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.794567
     epoch  training_loss
915    916       2.972585
916    917       2.927714
917    918       2.981197
918    919       2.999502
919    920       2.936382
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
87        880  0.015178  0.080132      0.352982   0.353876
88        890  0.015044  0.079835      0.353223   0.354122
89        900  0.015139  0.079295      0.354306   0.355278
90        910  0.015059  0.080067      0.353868   0.354820
91        920  0.015093  0.079027      0.355382   0.356382
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
87      880.0  0.971964  0.979485  ...  0.957078  0.952435  0.940463
88      890.0  0.971574  0.979703  ...  0.957811  0.952435  0.943150
89      900.0  0.971890  0.979594  ...  0.957892  0.952435  0.943639
90      910.0  0.971353  0.979164  ...  0.957485  0.952598  0.944535
91      920.0  0.971574  0.979405  ...  0.957811  0.953413  0.942743

[5 rows x 13 columns]
process: 50 / 291. Epoch 921
process: 100 / 291. Epoch 921
process: 150 / 291. Epoch 921
process: 200 / 291. Epoch 921
process: 250 / 291. Epoch 921
process: 291 / 291. Epoch 921
Loss of epoch 921 = 2.9596396115227663
process: 50 / 291. Epoch 922
process: 100 / 291. Epoch 922
process: 150 / 291. Epoch 922
process: 200 / 291. Epoch 922
process: 250 / 291. Epoch 922
process: 291 / 291. Epoch 922
Loss of epoch 922 = 2.938745243033183
process: 50 / 291. Epoch 923
process: 100 / 291. Epoch 923
process: 150 / 291. Epoch 923
process: 200 / 291. Epoch 923
process: 250 / 291. Epoch 923
process: 291 / 291. Epoch 923
Loss of epoch 923 = 2.9316729253919673
process: 50 / 291. Epoch 924
process: 100 / 291. Epoch 924
process: 150 / 291. Epoch 924
process: 200 / 291. Epoch 924
process: 250 / 291. Epoch 924
process: 291 / 291. Epoch 924
Loss of epoch 924 = 2.891015750845683
process: 50 / 291. Epoch 925
process: 100 / 291. Epoch 925
process: 150 / 291. Epoch 925
process: 200 / 291. Epoch 925
process: 250 / 291. Epoch 925
process: 291 / 291. Epoch 925
Loss of epoch 925 = 2.9029893383537373
process: 50 / 291. Epoch 926
process: 100 / 291. Epoch 926
process: 150 / 291. Epoch 926
process: 200 / 291. Epoch 926
process: 250 / 291. Epoch 926
process: 291 / 291. Epoch 926
Loss of epoch 926 = 3.0347954923754297
process: 50 / 291. Epoch 927
process: 100 / 291. Epoch 927
process: 150 / 291. Epoch 927
process: 200 / 291. Epoch 927
process: 250 / 291. Epoch 927
process: 291 / 291. Epoch 927
Loss of epoch 927 = 3.0145687352341066
process: 50 / 291. Epoch 928
process: 100 / 291. Epoch 928
process: 150 / 291. Epoch 928
process: 200 / 291. Epoch 928
process: 250 / 291. Epoch 928
process: 291 / 291. Epoch 928
Loss of epoch 928 = 2.889880832527921
process: 50 / 291. Epoch 929
process: 100 / 291. Epoch 929
process: 150 / 291. Epoch 929
process: 200 / 291. Epoch 929
process: 250 / 291. Epoch 929
process: 291 / 291. Epoch 929
Loss of epoch 929 = 2.937571312553694
process: 50 / 291. Epoch 930
process: 100 / 291. Epoch 930
process: 150 / 291. Epoch 930
process: 200 / 291. Epoch 930
process: 250 / 291. Epoch 930
process: 291 / 291. Epoch 930
Loss of epoch 930 = 2.9774711058311856
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-930. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.785446
     epoch  training_loss
925    926       3.034795
926    927       3.014569
927    928       2.889881
928    929       2.937571
929    930       2.977471
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
88        890  0.015044  0.079835      0.353223   0.354122
89        900  0.015139  0.079295      0.354306   0.355278
90        910  0.015059  0.080067      0.353868   0.354820
91        920  0.015093  0.079027      0.355382   0.356382
92        930  0.015247  0.076917      0.355147   0.356122
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
88      890.0  0.971574  0.979703  ...  0.957811  0.952435  0.943150
89      900.0  0.971890  0.979594  ...  0.957892  0.952435  0.943639
90      910.0  0.971353  0.979164  ...  0.957485  0.952598  0.944535
91      920.0  0.971574  0.979405  ...  0.957811  0.953413  0.942743
92      930.0  0.972188  0.979698  ...  0.957485  0.952272  0.936472

[5 rows x 13 columns]
process: 50 / 291. Epoch 931
process: 100 / 291. Epoch 931
process: 150 / 291. Epoch 931
process: 200 / 291. Epoch 931
process: 250 / 291. Epoch 931
process: 291 / 291. Epoch 931
Loss of epoch 931 = 2.992342290190077
process: 50 / 291. Epoch 932
process: 100 / 291. Epoch 932
process: 150 / 291. Epoch 932
process: 200 / 291. Epoch 932
process: 250 / 291. Epoch 932
process: 291 / 291. Epoch 932
Loss of epoch 932 = 2.9649121261544242
process: 50 / 291. Epoch 933
process: 100 / 291. Epoch 933
process: 150 / 291. Epoch 933
process: 200 / 291. Epoch 933
process: 250 / 291. Epoch 933
process: 291 / 291. Epoch 933
Loss of epoch 933 = 2.893843083856851
process: 50 / 291. Epoch 934
process: 100 / 291. Epoch 934
process: 150 / 291. Epoch 934
process: 200 / 291. Epoch 934
process: 250 / 291. Epoch 934
process: 291 / 291. Epoch 934
Loss of epoch 934 = 2.905078586434171
process: 50 / 291. Epoch 935
process: 100 / 291. Epoch 935
process: 150 / 291. Epoch 935
process: 200 / 291. Epoch 935
process: 250 / 291. Epoch 935
process: 291 / 291. Epoch 935
Loss of epoch 935 = 2.9177065714937713
process: 50 / 291. Epoch 936
process: 100 / 291. Epoch 936
process: 150 / 291. Epoch 936
process: 200 / 291. Epoch 936
process: 250 / 291. Epoch 936
process: 291 / 291. Epoch 936
Loss of epoch 936 = 2.942313177888746
process: 50 / 291. Epoch 937
process: 100 / 291. Epoch 937
process: 150 / 291. Epoch 937
process: 200 / 291. Epoch 937
process: 250 / 291. Epoch 937
process: 291 / 291. Epoch 937
Loss of epoch 937 = 2.8766771034686425
process: 50 / 291. Epoch 938
process: 100 / 291. Epoch 938
process: 150 / 291. Epoch 938
process: 200 / 291. Epoch 938
process: 250 / 291. Epoch 938
process: 291 / 291. Epoch 938
Loss of epoch 938 = 2.8830495093696307
process: 50 / 291. Epoch 939
process: 100 / 291. Epoch 939
process: 150 / 291. Epoch 939
process: 200 / 291. Epoch 939
process: 250 / 291. Epoch 939
process: 291 / 291. Epoch 939
Loss of epoch 939 = 2.9447426287988616
process: 50 / 291. Epoch 940
process: 100 / 291. Epoch 940
process: 150 / 291. Epoch 940
process: 200 / 291. Epoch 940
process: 250 / 291. Epoch 940
process: 291 / 291. Epoch 940
Loss of epoch 940 = 2.9102112026149056
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-940. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.790803
     epoch  training_loss
935    936       2.942313
936    937       2.876677
937    938       2.883050
938    939       2.944743
939    940       2.910211
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
89        900  0.015139  0.079295      0.354306   0.355278
90        910  0.015059  0.080067      0.353868   0.354820
91        920  0.015093  0.079027      0.355382   0.356382
92        930  0.015247  0.076917      0.355147   0.356122
93        940  0.015130  0.078055      0.355680   0.356648
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
89      900.0  0.971890  0.979594  ...  0.957892  0.952435  0.943639
90      910.0  0.971353  0.979164  ...  0.957485  0.952598  0.944535
91      920.0  0.971574  0.979405  ...  0.957811  0.953413  0.942743
92      930.0  0.972188  0.979698  ...  0.957485  0.952272  0.936472
93      940.0  0.972632  0.979952  ...  0.958137  0.953576  0.941847

[5 rows x 13 columns]
process: 50 / 291. Epoch 941
process: 100 / 291. Epoch 941
process: 150 / 291. Epoch 941
process: 200 / 291. Epoch 941
process: 250 / 291. Epoch 941
process: 291 / 291. Epoch 941
Loss of epoch 941 = 2.978700618153995
process: 50 / 291. Epoch 942
process: 100 / 291. Epoch 942
process: 150 / 291. Epoch 942
process: 200 / 291. Epoch 942
process: 250 / 291. Epoch 942
process: 291 / 291. Epoch 942
Loss of epoch 942 = 2.90002357509128
process: 50 / 291. Epoch 943
process: 100 / 291. Epoch 943
process: 150 / 291. Epoch 943
process: 200 / 291. Epoch 943
process: 250 / 291. Epoch 943
process: 291 / 291. Epoch 943
Loss of epoch 943 = 3.0248582977609537
process: 50 / 291. Epoch 944
process: 100 / 291. Epoch 944
process: 150 / 291. Epoch 944
process: 200 / 291. Epoch 944
process: 250 / 291. Epoch 944
process: 291 / 291. Epoch 944
Loss of epoch 944 = 2.917529968051976
process: 50 / 291. Epoch 945
process: 100 / 291. Epoch 945
process: 150 / 291. Epoch 945
process: 200 / 291. Epoch 945
process: 250 / 291. Epoch 945
process: 291 / 291. Epoch 945
Loss of epoch 945 = 2.9071044921875
process: 50 / 291. Epoch 946
process: 100 / 291. Epoch 946
process: 150 / 291. Epoch 946
process: 200 / 291. Epoch 946
process: 250 / 291. Epoch 946
process: 291 / 291. Epoch 946
Loss of epoch 946 = 2.8928776377255154
process: 50 / 291. Epoch 947
process: 100 / 291. Epoch 947
process: 150 / 291. Epoch 947
process: 200 / 291. Epoch 947
process: 250 / 291. Epoch 947
process: 291 / 291. Epoch 947
Loss of epoch 947 = 2.8770577866596865
process: 50 / 291. Epoch 948
process: 100 / 291. Epoch 948
process: 150 / 291. Epoch 948
process: 200 / 291. Epoch 948
process: 250 / 291. Epoch 948
process: 291 / 291. Epoch 948
Loss of epoch 948 = 3.015782726589347
process: 50 / 291. Epoch 949
process: 100 / 291. Epoch 949
process: 150 / 291. Epoch 949
process: 200 / 291. Epoch 949
process: 250 / 291. Epoch 949
process: 291 / 291. Epoch 949
Loss of epoch 949 = 2.9998561164357818
process: 50 / 291. Epoch 950
process: 100 / 291. Epoch 950
process: 150 / 291. Epoch 950
process: 200 / 291. Epoch 950
process: 250 / 291. Epoch 950
process: 291 / 291. Epoch 950
Loss of epoch 950 = 2.8964688540324315
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-950. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.787542
     epoch  training_loss
945    946       2.892878
946    947       2.877058
947    948       3.015783
948    949       2.999856
949    950       2.896469
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
90        910  0.015059  0.080067      0.353868   0.354820
91        920  0.015093  0.079027      0.355382   0.356382
92        930  0.015247  0.076917      0.355147   0.356122
93        940  0.015130  0.078055      0.355680   0.356648
94        950  0.015238  0.077759      0.356377   0.357395
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
90      910.0  0.971353  0.979164  ...  0.957485  0.952598  0.944535
91      920.0  0.971574  0.979405  ...  0.957811  0.953413  0.942743
92      930.0  0.972188  0.979698  ...  0.957485  0.952272  0.936472
93      940.0  0.972632  0.979952  ...  0.958137  0.953576  0.941847
94      950.0  0.971973  0.979930  ...  0.957322  0.952761  0.941196

[5 rows x 13 columns]
process: 50 / 291. Epoch 951
process: 100 / 291. Epoch 951
process: 150 / 291. Epoch 951
process: 200 / 291. Epoch 951
process: 250 / 291. Epoch 951
process: 291 / 291. Epoch 951
Loss of epoch 951 = 2.8941132325896692
process: 50 / 291. Epoch 952
process: 100 / 291. Epoch 952
process: 150 / 291. Epoch 952
process: 200 / 291. Epoch 952
process: 250 / 291. Epoch 952
process: 291 / 291. Epoch 952
Loss of epoch 952 = 2.9180060842192868
process: 50 / 291. Epoch 953
process: 100 / 291. Epoch 953
process: 150 / 291. Epoch 953
process: 200 / 291. Epoch 953
process: 250 / 291. Epoch 953
process: 291 / 291. Epoch 953
Loss of epoch 953 = 2.924305080138531
process: 50 / 291. Epoch 954
process: 100 / 291. Epoch 954
process: 150 / 291. Epoch 954
process: 200 / 291. Epoch 954
process: 250 / 291. Epoch 954
process: 291 / 291. Epoch 954
Loss of epoch 954 = 2.923303767987543
process: 50 / 291. Epoch 955
process: 100 / 291. Epoch 955
process: 150 / 291. Epoch 955
process: 200 / 291. Epoch 955
process: 250 / 291. Epoch 955
process: 291 / 291. Epoch 955
Loss of epoch 955 = 3.014990318272122
process: 50 / 291. Epoch 956
process: 100 / 291. Epoch 956
process: 150 / 291. Epoch 956
process: 200 / 291. Epoch 956
process: 250 / 291. Epoch 956
process: 291 / 291. Epoch 956
Loss of epoch 956 = 2.918104243852019
process: 50 / 291. Epoch 957
process: 100 / 291. Epoch 957
process: 150 / 291. Epoch 957
process: 200 / 291. Epoch 957
process: 250 / 291. Epoch 957
process: 291 / 291. Epoch 957
Loss of epoch 957 = 2.8487735499221434
process: 50 / 291. Epoch 958
process: 100 / 291. Epoch 958
process: 150 / 291. Epoch 958
process: 200 / 291. Epoch 958
process: 250 / 291. Epoch 958
process: 291 / 291. Epoch 958
Loss of epoch 958 = 2.8695118697648194
process: 50 / 291. Epoch 959
process: 100 / 291. Epoch 959
process: 150 / 291. Epoch 959
process: 200 / 291. Epoch 959
process: 250 / 291. Epoch 959
process: 291 / 291. Epoch 959
Loss of epoch 959 = 2.9222670093025127
process: 50 / 291. Epoch 960
process: 100 / 291. Epoch 960
process: 150 / 291. Epoch 960
process: 200 / 291. Epoch 960
process: 250 / 291. Epoch 960
process: 291 / 291. Epoch 960
Loss of epoch 960 = 3.0202187869147337
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-960. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.791954
     epoch  training_loss
955    956       2.918104
956    957       2.848774
957    958       2.869512
958    959       2.922267
959    960       3.020219
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
91        920  0.015093  0.079027      0.355382   0.356382
92        930  0.015247  0.076917      0.355147   0.356122
93        940  0.015130  0.078055      0.355680   0.356648
94        950  0.015238  0.077759      0.356377   0.357395
95        960  0.015125  0.077866      0.356710   0.357697
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
91      920.0  0.971574  0.979405  ...  0.957811  0.953413  0.942743
92      930.0  0.972188  0.979698  ...  0.957485  0.952272  0.936472
93      940.0  0.972632  0.979952  ...  0.958137  0.953576  0.941847
94      950.0  0.971973  0.979930  ...  0.957322  0.952761  0.941196
95      960.0  0.971568  0.979832  ...  0.957648  0.953168  0.942743

[5 rows x 13 columns]
process: 50 / 291. Epoch 961
process: 100 / 291. Epoch 961
process: 150 / 291. Epoch 961
process: 200 / 291. Epoch 961
process: 250 / 291. Epoch 961
process: 291 / 291. Epoch 961
Loss of epoch 961 = 2.9378876047036084
process: 50 / 291. Epoch 962
process: 100 / 291. Epoch 962
process: 150 / 291. Epoch 962
process: 200 / 291. Epoch 962
process: 250 / 291. Epoch 962
process: 291 / 291. Epoch 962
Loss of epoch 962 = 2.8714914223582473
process: 50 / 291. Epoch 963
process: 100 / 291. Epoch 963
process: 150 / 291. Epoch 963
process: 200 / 291. Epoch 963
process: 250 / 291. Epoch 963
process: 291 / 291. Epoch 963
Loss of epoch 963 = 2.877480418411727
process: 50 / 291. Epoch 964
process: 100 / 291. Epoch 964
process: 150 / 291. Epoch 964
process: 200 / 291. Epoch 964
process: 250 / 291. Epoch 964
process: 291 / 291. Epoch 964
Loss of epoch 964 = 2.9242106958762886
process: 50 / 291. Epoch 965
process: 100 / 291. Epoch 965
process: 150 / 291. Epoch 965
process: 200 / 291. Epoch 965
process: 250 / 291. Epoch 965
process: 291 / 291. Epoch 965
Loss of epoch 965 = 2.917284568970146
process: 50 / 291. Epoch 966
process: 100 / 291. Epoch 966
process: 150 / 291. Epoch 966
process: 200 / 291. Epoch 966
process: 250 / 291. Epoch 966
process: 291 / 291. Epoch 966
Loss of epoch 966 = 2.9201102240388748
process: 50 / 291. Epoch 967
process: 100 / 291. Epoch 967
process: 150 / 291. Epoch 967
process: 200 / 291. Epoch 967
process: 250 / 291. Epoch 967
process: 291 / 291. Epoch 967
Loss of epoch 967 = 2.962331031196306
process: 50 / 291. Epoch 968
process: 100 / 291. Epoch 968
process: 150 / 291. Epoch 968
process: 200 / 291. Epoch 968
process: 250 / 291. Epoch 968
process: 291 / 291. Epoch 968
Loss of epoch 968 = 2.917739291371349
process: 50 / 291. Epoch 969
process: 100 / 291. Epoch 969
process: 150 / 291. Epoch 969
process: 200 / 291. Epoch 969
process: 250 / 291. Epoch 969
process: 291 / 291. Epoch 969
Loss of epoch 969 = 2.905418999006658
process: 50 / 291. Epoch 970
process: 100 / 291. Epoch 970
process: 150 / 291. Epoch 970
process: 200 / 291. Epoch 970
process: 250 / 291. Epoch 970
process: 291 / 291. Epoch 970
Loss of epoch 970 = 2.9487013145001075
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-970. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.794254
     epoch  training_loss
965    966       2.920110
966    967       2.962331
967    968       2.917739
968    969       2.905419
969    970       2.948701
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
92        930  0.015247  0.076917      0.355147   0.356122
93        940  0.015130  0.078055      0.355680   0.356648
94        950  0.015238  0.077759      0.356377   0.357395
95        960  0.015125  0.077866      0.356710   0.357697
96        970  0.015149  0.078550      0.356824   0.357821
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
92      930.0  0.972188  0.979698  ...  0.957485  0.952272  0.936472
93      940.0  0.972632  0.979952  ...  0.958137  0.953576  0.941847
94      950.0  0.971973  0.979930  ...  0.957322  0.952761  0.941196
95      960.0  0.971568  0.979832  ...  0.957648  0.953168  0.942743
96      970.0  0.971170  0.979728  ...  0.958137  0.953331  0.942987

[5 rows x 13 columns]
process: 50 / 291. Epoch 971
process: 100 / 291. Epoch 971
process: 150 / 291. Epoch 971
process: 200 / 291. Epoch 971
process: 250 / 291. Epoch 971
process: 291 / 291. Epoch 971
Loss of epoch 971 = 2.920937030176117
process: 50 / 291. Epoch 972
process: 100 / 291. Epoch 972
process: 150 / 291. Epoch 972
process: 200 / 291. Epoch 972
process: 250 / 291. Epoch 972
process: 291 / 291. Epoch 972
Loss of epoch 972 = 2.979086125429553
process: 50 / 291. Epoch 973
process: 100 / 291. Epoch 973
process: 150 / 291. Epoch 973
process: 200 / 291. Epoch 973
process: 250 / 291. Epoch 973
process: 291 / 291. Epoch 973
Loss of epoch 973 = 2.895801662169781
process: 50 / 291. Epoch 974
process: 100 / 291. Epoch 974
process: 150 / 291. Epoch 974
process: 200 / 291. Epoch 974
process: 250 / 291. Epoch 974
process: 291 / 291. Epoch 974
Loss of epoch 974 = 2.85992851126235
process: 50 / 291. Epoch 975
process: 100 / 291. Epoch 975
process: 150 / 291. Epoch 975
process: 200 / 291. Epoch 975
process: 250 / 291. Epoch 975
process: 291 / 291. Epoch 975
Loss of epoch 975 = 2.856095880986899
process: 50 / 291. Epoch 976
process: 100 / 291. Epoch 976
process: 150 / 291. Epoch 976
process: 200 / 291. Epoch 976
process: 250 / 291. Epoch 976
process: 291 / 291. Epoch 976
Loss of epoch 976 = 2.8666918777518258
process: 50 / 291. Epoch 977
process: 100 / 291. Epoch 977
process: 150 / 291. Epoch 977
process: 200 / 291. Epoch 977
process: 250 / 291. Epoch 977
process: 291 / 291. Epoch 977
Loss of epoch 977 = 2.962145408813896
process: 50 / 291. Epoch 978
process: 100 / 291. Epoch 978
process: 150 / 291. Epoch 978
process: 200 / 291. Epoch 978
process: 250 / 291. Epoch 978
process: 291 / 291. Epoch 978
Loss of epoch 978 = 2.940223720065507
process: 50 / 291. Epoch 979
process: 100 / 291. Epoch 979
process: 150 / 291. Epoch 979
process: 200 / 291. Epoch 979
process: 250 / 291. Epoch 979
process: 291 / 291. Epoch 979
Loss of epoch 979 = 2.8710671126637672
process: 50 / 291. Epoch 980
process: 100 / 291. Epoch 980
process: 150 / 291. Epoch 980
process: 200 / 291. Epoch 980
process: 250 / 291. Epoch 980
process: 291 / 291. Epoch 980
Loss of epoch 980 = 2.8739177271262886
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-980. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.792186
     epoch  training_loss
975    976       2.866692
976    977       2.962145
977    978       2.940224
978    979       2.871067
979    980       2.873918
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
93        940  0.015130  0.078055      0.355680   0.356648
94        950  0.015238  0.077759      0.356377   0.357395
95        960  0.015125  0.077866      0.356710   0.357697
96        970  0.015149  0.078550      0.356824   0.357821
97        980  0.015134  0.077375      0.357359   0.358349
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
93      940.0  0.972632  0.979952  ...  0.958137  0.953576  0.941847
94      950.0  0.971973  0.979930  ...  0.957322  0.952761  0.941196
95      960.0  0.971568  0.979832  ...  0.957648  0.953168  0.942743
96      970.0  0.971170  0.979728  ...  0.958137  0.953331  0.942987
97      980.0  0.971555  0.979853  ...  0.957322  0.953901  0.944453

[5 rows x 13 columns]
process: 50 / 291. Epoch 981
process: 100 / 291. Epoch 981
process: 150 / 291. Epoch 981
process: 200 / 291. Epoch 981
process: 250 / 291. Epoch 981
process: 291 / 291. Epoch 981
Loss of epoch 981 = 2.906911948292526
process: 50 / 291. Epoch 982
process: 100 / 291. Epoch 982
process: 150 / 291. Epoch 982
process: 200 / 291. Epoch 982
process: 250 / 291. Epoch 982
process: 291 / 291. Epoch 982
Loss of epoch 982 = 2.9559844236603308
process: 50 / 291. Epoch 983
process: 100 / 291. Epoch 983
process: 150 / 291. Epoch 983
process: 200 / 291. Epoch 983
process: 250 / 291. Epoch 983
process: 291 / 291. Epoch 983
Loss of epoch 983 = 2.944039361173754
process: 50 / 291. Epoch 984
process: 100 / 291. Epoch 984
process: 150 / 291. Epoch 984
process: 200 / 291. Epoch 984
process: 250 / 291. Epoch 984
process: 291 / 291. Epoch 984
Loss of epoch 984 = 2.898513007409794
process: 50 / 291. Epoch 985
process: 100 / 291. Epoch 985
process: 150 / 291. Epoch 985
process: 200 / 291. Epoch 985
process: 250 / 291. Epoch 985
process: 291 / 291. Epoch 985
Loss of epoch 985 = 2.9045351428264605
process: 50 / 291. Epoch 986
process: 100 / 291. Epoch 986
process: 150 / 291. Epoch 986
process: 200 / 291. Epoch 986
process: 250 / 291. Epoch 986
process: 291 / 291. Epoch 986
Loss of epoch 986 = 2.8358368234536084
process: 50 / 291. Epoch 987
process: 100 / 291. Epoch 987
process: 150 / 291. Epoch 987
process: 200 / 291. Epoch 987
process: 250 / 291. Epoch 987
process: 291 / 291. Epoch 987
Loss of epoch 987 = 2.8776089907511815
process: 50 / 291. Epoch 988
process: 100 / 291. Epoch 988
process: 150 / 291. Epoch 988
process: 200 / 291. Epoch 988
process: 250 / 291. Epoch 988
process: 291 / 291. Epoch 988
Loss of epoch 988 = 2.934902754845898
process: 50 / 291. Epoch 989
process: 100 / 291. Epoch 989
process: 150 / 291. Epoch 989
process: 200 / 291. Epoch 989
process: 250 / 291. Epoch 989
process: 291 / 291. Epoch 989
Loss of epoch 989 = 2.892294972213273
process: 50 / 291. Epoch 990
process: 100 / 291. Epoch 990
process: 150 / 291. Epoch 990
process: 200 / 291. Epoch 990
process: 250 / 291. Epoch 990
process: 291 / 291. Epoch 990
Loss of epoch 990 = 2.925671344770189
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-990. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.793959
     epoch  training_loss
985    986       2.835837
986    987       2.877609
987    988       2.934903
988    989       2.892295
989    990       2.925671
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
94        950  0.015238  0.077759      0.356377   0.357395
95        960  0.015125  0.077866      0.356710   0.357697
96        970  0.015149  0.078550      0.356824   0.357821
97        980  0.015134  0.077375      0.357359   0.358349
98        990  0.015197  0.077234      0.357579   0.358585
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
94      950.0  0.971973  0.979930  ...  0.957322  0.952761  0.941196
95      960.0  0.971568  0.979832  ...  0.957648  0.953168  0.942743
96      970.0  0.971170  0.979728  ...  0.958137  0.953331  0.942987
97      980.0  0.971555  0.979853  ...  0.957322  0.953901  0.944453
98      990.0  0.972321  0.979957  ...  0.958218  0.953738  0.942662

[5 rows x 13 columns]
process: 50 / 291. Epoch 991
process: 100 / 291. Epoch 991
process: 150 / 291. Epoch 991
process: 200 / 291. Epoch 991
process: 250 / 291. Epoch 991
process: 291 / 291. Epoch 991
Loss of epoch 991 = 2.899012824514068
process: 50 / 291. Epoch 992
process: 100 / 291. Epoch 992
process: 150 / 291. Epoch 992
process: 200 / 291. Epoch 992
process: 250 / 291. Epoch 992
process: 291 / 291. Epoch 992
Loss of epoch 992 = 2.883082229247208
process: 50 / 291. Epoch 993
process: 100 / 291. Epoch 993
process: 150 / 291. Epoch 993
process: 200 / 291. Epoch 993
process: 250 / 291. Epoch 993
process: 291 / 291. Epoch 993
Loss of epoch 993 = 2.950281726535653
process: 50 / 291. Epoch 994
process: 100 / 291. Epoch 994
process: 150 / 291. Epoch 994
process: 200 / 291. Epoch 994
process: 250 / 291. Epoch 994
process: 291 / 291. Epoch 994
Loss of epoch 994 = 2.900198081105026
process: 50 / 291. Epoch 995
process: 100 / 291. Epoch 995
process: 150 / 291. Epoch 995
process: 200 / 291. Epoch 995
process: 250 / 291. Epoch 995
process: 291 / 291. Epoch 995
Loss of epoch 995 = 2.8489434415941797
process: 50 / 291. Epoch 996
process: 100 / 291. Epoch 996
process: 150 / 291. Epoch 996
process: 200 / 291. Epoch 996
process: 250 / 291. Epoch 996
process: 291 / 291. Epoch 996
Loss of epoch 996 = 2.8511295908505154
process: 50 / 291. Epoch 997
process: 100 / 291. Epoch 997
process: 150 / 291. Epoch 997
process: 200 / 291. Epoch 997
process: 250 / 291. Epoch 997
process: 291 / 291. Epoch 997
Loss of epoch 997 = 2.8311564127604165
process: 50 / 291. Epoch 998
process: 100 / 291. Epoch 998
process: 150 / 291. Epoch 998
process: 200 / 291. Epoch 998
process: 250 / 291. Epoch 998
process: 291 / 291. Epoch 998
Loss of epoch 998 = 2.8947789562526847
process: 50 / 291. Epoch 999
process: 100 / 291. Epoch 999
process: 150 / 291. Epoch 999
process: 200 / 291. Epoch 999
process: 250 / 291. Epoch 999
process: 291 / 291. Epoch 999
Loss of epoch 999 = 2.8662375748362328
process: 50 / 291. Epoch 1000
process: 100 / 291. Epoch 1000
process: 150 / 291. Epoch 1000
process: 200 / 291. Epoch 1000
process: 250 / 291. Epoch 1000
process: 291 / 291. Epoch 1000
Loss of epoch 1000 = 2.911083103455219
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1000. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.787705
     epoch  training_loss
995    996       2.851130
996    997       2.831156
997    998       2.894779
998    999       2.866238
999   1000       2.911083
    val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
95        960  0.015125  0.077866      0.356710   0.357697
96        970  0.015149  0.078550      0.356824   0.357821
97        980  0.015134  0.077375      0.357359   0.358349
98        990  0.015197  0.077234      0.357579   0.358585
99       1000  0.015203  0.076209      0.358021   0.359032
    val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
95      960.0  0.971568  0.979832  ...  0.957648  0.953168  0.942743
96      970.0  0.971170  0.979728  ...  0.958137  0.953331  0.942987
97      980.0  0.971555  0.979853  ...  0.957322  0.953901  0.944453
98      990.0  0.972321  0.979957  ...  0.958218  0.953738  0.942662
99     1000.0  0.971558  0.979927  ...  0.957403  0.952680  0.938915

[5 rows x 13 columns]
process: 50 / 291. Epoch 1001
process: 100 / 291. Epoch 1001
process: 150 / 291. Epoch 1001
process: 200 / 291. Epoch 1001
process: 250 / 291. Epoch 1001
process: 291 / 291. Epoch 1001
Loss of epoch 1001 = 2.888661387859751
process: 50 / 291. Epoch 1002
process: 100 / 291. Epoch 1002
process: 150 / 291. Epoch 1002
process: 200 / 291. Epoch 1002
process: 250 / 291. Epoch 1002
process: 291 / 291. Epoch 1002
Loss of epoch 1002 = 2.8537404692869415
process: 50 / 291. Epoch 1003
process: 100 / 291. Epoch 1003
process: 150 / 291. Epoch 1003
process: 200 / 291. Epoch 1003
process: 250 / 291. Epoch 1003
process: 291 / 291. Epoch 1003
Loss of epoch 1003 = 3.0059294290968643
process: 50 / 291. Epoch 1004
process: 100 / 291. Epoch 1004
process: 150 / 291. Epoch 1004
process: 200 / 291. Epoch 1004
process: 250 / 291. Epoch 1004
process: 291 / 291. Epoch 1004
Loss of epoch 1004 = 2.8980895366865336
process: 50 / 291. Epoch 1005
process: 100 / 291. Epoch 1005
process: 150 / 291. Epoch 1005
process: 200 / 291. Epoch 1005
process: 250 / 291. Epoch 1005
process: 291 / 291. Epoch 1005
Loss of epoch 1005 = 2.8532909904558634
process: 50 / 291. Epoch 1006
process: 100 / 291. Epoch 1006
process: 150 / 291. Epoch 1006
process: 200 / 291. Epoch 1006
process: 250 / 291. Epoch 1006
process: 291 / 291. Epoch 1006
Loss of epoch 1006 = 2.893875593991624
process: 50 / 291. Epoch 1007
process: 100 / 291. Epoch 1007
process: 150 / 291. Epoch 1007
process: 200 / 291. Epoch 1007
process: 250 / 291. Epoch 1007
process: 291 / 291. Epoch 1007
Loss of epoch 1007 = 2.8437600676546393
process: 50 / 291. Epoch 1008
process: 100 / 291. Epoch 1008
process: 150 / 291. Epoch 1008
process: 200 / 291. Epoch 1008
process: 250 / 291. Epoch 1008
process: 291 / 291. Epoch 1008
Loss of epoch 1008 = 2.8342079608301116
process: 50 / 291. Epoch 1009
process: 100 / 291. Epoch 1009
process: 150 / 291. Epoch 1009
process: 200 / 291. Epoch 1009
process: 250 / 291. Epoch 1009
process: 291 / 291. Epoch 1009
Loss of epoch 1009 = 2.8984792388181915
process: 50 / 291. Epoch 1010
process: 100 / 291. Epoch 1010
process: 150 / 291. Epoch 1010
process: 200 / 291. Epoch 1010
process: 250 / 291. Epoch 1010
process: 291 / 291. Epoch 1010
Loss of epoch 1010 = 2.851552012859751
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1010. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.791977
      epoch  training_loss
1005   1006       2.893876
1006   1007       2.843760
1007   1008       2.834208
1008   1009       2.898479
1009   1010       2.851552
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
96         970  0.015149  0.078550      0.356824   0.357821
97         980  0.015134  0.077375      0.357359   0.358349
98         990  0.015197  0.077234      0.357579   0.358585
99        1000  0.015203  0.076209      0.358021   0.359032
100       1010  0.015128  0.076718      0.357697   0.358692
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
96       970.0  0.971170  0.979728  ...  0.958137  0.953331  0.942987
97       980.0  0.971555  0.979853  ...  0.957322  0.953901  0.944453
98       990.0  0.972321  0.979957  ...  0.958218  0.953738  0.942662
99      1000.0  0.971558  0.979927  ...  0.957403  0.952680  0.938915
100     1010.0  0.971552  0.980059  ...  0.957241  0.953494  0.942987

[5 rows x 13 columns]
process: 50 / 291. Epoch 1011
process: 100 / 291. Epoch 1011
process: 150 / 291. Epoch 1011
process: 200 / 291. Epoch 1011
process: 250 / 291. Epoch 1011
process: 291 / 291. Epoch 1011
Loss of epoch 1011 = 2.818896736066366
process: 50 / 291. Epoch 1012
process: 100 / 291. Epoch 1012
process: 150 / 291. Epoch 1012
process: 200 / 291. Epoch 1012
process: 250 / 291. Epoch 1012
process: 291 / 291. Epoch 1012
Loss of epoch 1012 = 2.861657421203823
process: 50 / 291. Epoch 1013
process: 100 / 291. Epoch 1013
process: 150 / 291. Epoch 1013
process: 200 / 291. Epoch 1013
process: 250 / 291. Epoch 1013
process: 291 / 291. Epoch 1013
Loss of epoch 1013 = 2.9579488747718
process: 50 / 291. Epoch 1014
process: 100 / 291. Epoch 1014
process: 150 / 291. Epoch 1014
process: 200 / 291. Epoch 1014
process: 250 / 291. Epoch 1014
process: 291 / 291. Epoch 1014
Loss of epoch 1014 = 2.899902972978415
process: 50 / 291. Epoch 1015
process: 100 / 291. Epoch 1015
process: 150 / 291. Epoch 1015
process: 200 / 291. Epoch 1015
process: 250 / 291. Epoch 1015
process: 291 / 291. Epoch 1015
Loss of epoch 1015 = 2.9334072886463702
process: 50 / 291. Epoch 1016
process: 100 / 291. Epoch 1016
process: 150 / 291. Epoch 1016
process: 200 / 291. Epoch 1016
process: 250 / 291. Epoch 1016
process: 291 / 291. Epoch 1016
Loss of epoch 1016 = 2.9963813073856316
process: 50 / 291. Epoch 1017
process: 100 / 291. Epoch 1017
process: 150 / 291. Epoch 1017
process: 200 / 291. Epoch 1017
process: 250 / 291. Epoch 1017
process: 291 / 291. Epoch 1017
Loss of epoch 1017 = 2.869911220065507
process: 50 / 291. Epoch 1018
process: 100 / 291. Epoch 1018
process: 150 / 291. Epoch 1018
process: 200 / 291. Epoch 1018
process: 250 / 291. Epoch 1018
process: 291 / 291. Epoch 1018
Loss of epoch 1018 = 2.7879701594716493
process: 50 / 291. Epoch 1019
process: 100 / 291. Epoch 1019
process: 150 / 291. Epoch 1019
process: 200 / 291. Epoch 1019
process: 250 / 291. Epoch 1019
process: 291 / 291. Epoch 1019
Loss of epoch 1019 = 2.8706130194909796
process: 50 / 291. Epoch 1020
process: 100 / 291. Epoch 1020
process: 150 / 291. Epoch 1020
process: 200 / 291. Epoch 1020
process: 250 / 291. Epoch 1020
process: 291 / 291. Epoch 1020
Loss of epoch 1020 = 2.890600879577427
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1020. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.786214
      epoch  training_loss
1015   1016       2.996381
1016   1017       2.869911
1017   1018       2.787970
1018   1019       2.870613
1019   1020       2.890601
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
97         980  0.015134  0.077375      0.357359   0.358349
98         990  0.015197  0.077234      0.357579   0.358585
99        1000  0.015203  0.076209      0.358021   0.359032
100       1010  0.015128  0.076718      0.357697   0.358692
101       1020  0.015229  0.075286      0.358368   0.359459
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
97       980.0  0.971555  0.979853  ...  0.957322  0.953901  0.944453
98       990.0  0.972321  0.979957  ...  0.958218  0.953738  0.942662
99      1000.0  0.971558  0.979927  ...  0.957403  0.952680  0.938915
100     1010.0  0.971552  0.980059  ...  0.957241  0.953494  0.942987
101     1020.0  0.971751  0.980050  ...  0.956996  0.953168  0.940544

[5 rows x 13 columns]
process: 50 / 291. Epoch 1021
process: 100 / 291. Epoch 1021
process: 150 / 291. Epoch 1021
process: 200 / 291. Epoch 1021
process: 250 / 291. Epoch 1021
process: 291 / 291. Epoch 1021
Loss of epoch 1021 = 2.855140292767397
process: 50 / 291. Epoch 1022
process: 100 / 291. Epoch 1022
process: 150 / 291. Epoch 1022
process: 200 / 291. Epoch 1022
process: 250 / 291. Epoch 1022
process: 291 / 291. Epoch 1022
Loss of epoch 1022 = 2.8292555137188575
process: 50 / 291. Epoch 1023
process: 100 / 291. Epoch 1023
process: 150 / 291. Epoch 1023
process: 200 / 291. Epoch 1023
process: 250 / 291. Epoch 1023
process: 291 / 291. Epoch 1023
Loss of epoch 1023 = 2.8563387631550685
process: 50 / 291. Epoch 1024
process: 100 / 291. Epoch 1024
process: 150 / 291. Epoch 1024
process: 200 / 291. Epoch 1024
process: 250 / 291. Epoch 1024
process: 291 / 291. Epoch 1024
Loss of epoch 1024 = 2.887805637215421
process: 50 / 291. Epoch 1025
process: 100 / 291. Epoch 1025
process: 150 / 291. Epoch 1025
process: 200 / 291. Epoch 1025
process: 250 / 291. Epoch 1025
process: 291 / 291. Epoch 1025
Loss of epoch 1025 = 2.8319276370543385
process: 50 / 291. Epoch 1026
process: 100 / 291. Epoch 1026
process: 150 / 291. Epoch 1026
process: 200 / 291. Epoch 1026
process: 250 / 291. Epoch 1026
process: 291 / 291. Epoch 1026
Loss of epoch 1026 = 2.914173244201031
process: 50 / 291. Epoch 1027
process: 100 / 291. Epoch 1027
process: 150 / 291. Epoch 1027
process: 200 / 291. Epoch 1027
process: 250 / 291. Epoch 1027
process: 291 / 291. Epoch 1027
Loss of epoch 1027 = 2.8546473971756874
process: 50 / 291. Epoch 1028
process: 100 / 291. Epoch 1028
process: 150 / 291. Epoch 1028
process: 200 / 291. Epoch 1028
process: 250 / 291. Epoch 1028
process: 291 / 291. Epoch 1028
Loss of epoch 1028 = 2.840612037894652
process: 50 / 291. Epoch 1029
process: 100 / 291. Epoch 1029
process: 150 / 291. Epoch 1029
process: 200 / 291. Epoch 1029
process: 250 / 291. Epoch 1029
process: 291 / 291. Epoch 1029
Loss of epoch 1029 = 2.911645004429768
process: 50 / 291. Epoch 1030
process: 100 / 291. Epoch 1030
process: 150 / 291. Epoch 1030
process: 200 / 291. Epoch 1030
process: 250 / 291. Epoch 1030
process: 291 / 291. Epoch 1030
Loss of epoch 1030 = 2.9083488962494632
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1030. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.794050
      epoch  training_loss
1025   1026       2.914173
1026   1027       2.854647
1027   1028       2.840612
1028   1029       2.911645
1029   1030       2.908349
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
98         990  0.015197  0.077234      0.357579   0.358585
99        1000  0.015203  0.076209      0.358021   0.359032
100       1010  0.015128  0.076718      0.357697   0.358692
101       1020  0.015229  0.075286      0.358368   0.359459
102       1030  0.015135  0.077104      0.359966   0.361090
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
98       990.0  0.972321  0.979957  ...  0.958218  0.953738  0.942662
99      1000.0  0.971558  0.979927  ...  0.957403  0.952680  0.938915
100     1010.0  0.971552  0.980059  ...  0.957241  0.953494  0.942987
101     1020.0  0.971751  0.980050  ...  0.956996  0.953168  0.940544
102     1030.0  0.971037  0.979835  ...  0.957403  0.953250  0.943639

[5 rows x 13 columns]
process: 50 / 291. Epoch 1031
process: 100 / 291. Epoch 1031
process: 150 / 291. Epoch 1031
process: 200 / 291. Epoch 1031
process: 250 / 291. Epoch 1031
process: 291 / 291. Epoch 1031
Loss of epoch 1031 = 2.904561989905498
process: 50 / 291. Epoch 1032
process: 100 / 291. Epoch 1032
process: 150 / 291. Epoch 1032
process: 200 / 291. Epoch 1032
process: 250 / 291. Epoch 1032
process: 291 / 291. Epoch 1032
Loss of epoch 1032 = 2.8126531122476375
process: 50 / 291. Epoch 1033
process: 100 / 291. Epoch 1033
process: 150 / 291. Epoch 1033
process: 200 / 291. Epoch 1033
process: 250 / 291. Epoch 1033
process: 291 / 291. Epoch 1033
Loss of epoch 1033 = 2.8035313976589347
process: 50 / 291. Epoch 1034
process: 100 / 291. Epoch 1034
process: 150 / 291. Epoch 1034
process: 200 / 291. Epoch 1034
process: 250 / 291. Epoch 1034
process: 291 / 291. Epoch 1034
Loss of epoch 1034 = 2.8730754000214778
process: 50 / 291. Epoch 1035
process: 100 / 291. Epoch 1035
process: 150 / 291. Epoch 1035
process: 200 / 291. Epoch 1035
process: 250 / 291. Epoch 1035
process: 291 / 291. Epoch 1035
Loss of epoch 1035 = 2.855775813466495
process: 50 / 291. Epoch 1036
process: 100 / 291. Epoch 1036
process: 150 / 291. Epoch 1036
process: 200 / 291. Epoch 1036
process: 250 / 291. Epoch 1036
process: 291 / 291. Epoch 1036
Loss of epoch 1036 = 2.8511136503973367
process: 50 / 291. Epoch 1037
process: 100 / 291. Epoch 1037
process: 150 / 291. Epoch 1037
process: 200 / 291. Epoch 1037
process: 250 / 291. Epoch 1037
process: 291 / 291. Epoch 1037
Loss of epoch 1037 = 2.8968258362865122
process: 50 / 291. Epoch 1038
process: 100 / 291. Epoch 1038
process: 150 / 291. Epoch 1038
process: 200 / 291. Epoch 1038
process: 250 / 291. Epoch 1038
process: 291 / 291. Epoch 1038
Loss of epoch 1038 = 2.8590024967783507
process: 50 / 291. Epoch 1039
process: 100 / 291. Epoch 1039
process: 150 / 291. Epoch 1039
process: 200 / 291. Epoch 1039
process: 250 / 291. Epoch 1039
process: 291 / 291. Epoch 1039
Loss of epoch 1039 = 2.887622951232281
process: 50 / 291. Epoch 1040
process: 100 / 291. Epoch 1040
process: 150 / 291. Epoch 1040
process: 200 / 291. Epoch 1040
process: 250 / 291. Epoch 1040
process: 291 / 291. Epoch 1040
Loss of epoch 1040 = 2.915053744496349
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1040. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.789893
      epoch  training_loss
1035   1036       2.851114
1036   1037       2.896826
1037   1038       2.859002
1038   1039       2.887623
1039   1040       2.915054
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
99        1000  0.015203  0.076209      0.358021   0.359032
100       1010  0.015128  0.076718      0.357697   0.358692
101       1020  0.015229  0.075286      0.358368   0.359459
102       1030  0.015135  0.077104      0.359966   0.361090
103       1040  0.015292  0.075312      0.358608   0.359708
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
99      1000.0  0.971558  0.979927  ...  0.957403  0.952680  0.938915
100     1010.0  0.971552  0.980059  ...  0.957241  0.953494  0.942987
101     1020.0  0.971751  0.980050  ...  0.956996  0.953168  0.940544
102     1030.0  0.971037  0.979835  ...  0.957403  0.953250  0.943639
103     1040.0  0.971881  0.979835  ...  0.957648  0.953250  0.942010

[5 rows x 13 columns]
process: 50 / 291. Epoch 1041
process: 100 / 291. Epoch 1041
process: 150 / 291. Epoch 1041
process: 200 / 291. Epoch 1041
process: 250 / 291. Epoch 1041
process: 291 / 291. Epoch 1041
Loss of epoch 1041 = 2.807117370395726
process: 50 / 291. Epoch 1042
process: 100 / 291. Epoch 1042
process: 150 / 291. Epoch 1042
process: 200 / 291. Epoch 1042
process: 250 / 291. Epoch 1042
process: 291 / 291. Epoch 1042
Loss of epoch 1042 = 2.7872874466414306
process: 50 / 291. Epoch 1043
process: 100 / 291. Epoch 1043
process: 150 / 291. Epoch 1043
process: 200 / 291. Epoch 1043
process: 250 / 291. Epoch 1043
process: 291 / 291. Epoch 1043
Loss of epoch 1043 = 2.8667229196869632
process: 50 / 291. Epoch 1044
process: 100 / 291. Epoch 1044
process: 150 / 291. Epoch 1044
process: 200 / 291. Epoch 1044
process: 250 / 291. Epoch 1044
process: 291 / 291. Epoch 1044
Loss of epoch 1044 = 2.9131077507517182
process: 50 / 291. Epoch 1045
process: 100 / 291. Epoch 1045
process: 150 / 291. Epoch 1045
process: 200 / 291. Epoch 1045
process: 250 / 291. Epoch 1045
process: 291 / 291. Epoch 1045
Loss of epoch 1045 = 2.822863182251396
process: 50 / 291. Epoch 1046
process: 100 / 291. Epoch 1046
process: 150 / 291. Epoch 1046
process: 200 / 291. Epoch 1046
process: 250 / 291. Epoch 1046
process: 291 / 291. Epoch 1046
Loss of epoch 1046 = 2.808217890893471
process: 50 / 291. Epoch 1047
process: 100 / 291. Epoch 1047
process: 150 / 291. Epoch 1047
process: 200 / 291. Epoch 1047
process: 250 / 291. Epoch 1047
process: 291 / 291. Epoch 1047
Loss of epoch 1047 = 2.803199165055842
process: 50 / 291. Epoch 1048
process: 100 / 291. Epoch 1048
process: 150 / 291. Epoch 1048
process: 200 / 291. Epoch 1048
process: 250 / 291. Epoch 1048
process: 291 / 291. Epoch 1048
Loss of epoch 1048 = 2.831312251664519
process: 50 / 291. Epoch 1049
process: 100 / 291. Epoch 1049
process: 150 / 291. Epoch 1049
process: 200 / 291. Epoch 1049
process: 250 / 291. Epoch 1049
process: 291 / 291. Epoch 1049
Loss of epoch 1049 = 2.909850444990335
process: 50 / 291. Epoch 1050
process: 100 / 291. Epoch 1050
process: 150 / 291. Epoch 1050
process: 200 / 291. Epoch 1050
process: 250 / 291. Epoch 1050
process: 291 / 291. Epoch 1050
Loss of epoch 1050 = 2.8631692473421393
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1050. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.790537
      epoch  training_loss
1045   1046       2.808218
1046   1047       2.803199
1047   1048       2.831312
1048   1049       2.909850
1049   1050       2.863169
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
100       1010  0.015128  0.076718      0.357697   0.358692
101       1020  0.015229  0.075286      0.358368   0.359459
102       1030  0.015135  0.077104      0.359966   0.361090
103       1040  0.015292  0.075312      0.358608   0.359708
104       1050  0.015199  0.075437      0.360336   0.361426
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
100     1010.0  0.971552  0.980059  ...  0.957241  0.953494  0.942987
101     1020.0  0.971751  0.980050  ...  0.956996  0.953168  0.940544
102     1030.0  0.971037  0.979835  ...  0.957403  0.953250  0.943639
103     1040.0  0.971881  0.979835  ...  0.957648  0.953250  0.942010
104     1050.0  0.971666  0.980054  ...  0.957485  0.953331  0.942092

[5 rows x 13 columns]
process: 50 / 291. Epoch 1051
process: 100 / 291. Epoch 1051
process: 150 / 291. Epoch 1051
process: 200 / 291. Epoch 1051
process: 250 / 291. Epoch 1051
process: 291 / 291. Epoch 1051
Loss of epoch 1051 = 2.8519350032216493
process: 50 / 291. Epoch 1052
process: 100 / 291. Epoch 1052
process: 150 / 291. Epoch 1052
process: 200 / 291. Epoch 1052
process: 250 / 291. Epoch 1052
process: 291 / 291. Epoch 1052
Loss of epoch 1052 = 2.81811733180305
process: 50 / 291. Epoch 1053
process: 100 / 291. Epoch 1053
process: 150 / 291. Epoch 1053
process: 200 / 291. Epoch 1053
process: 250 / 291. Epoch 1053
process: 291 / 291. Epoch 1053
Loss of epoch 1053 = 2.855247471340743
process: 50 / 291. Epoch 1054
process: 100 / 291. Epoch 1054
process: 150 / 291. Epoch 1054
process: 200 / 291. Epoch 1054
process: 250 / 291. Epoch 1054
process: 291 / 291. Epoch 1054
Loss of epoch 1054 = 2.8538497452883376
process: 50 / 291. Epoch 1055
process: 100 / 291. Epoch 1055
process: 150 / 291. Epoch 1055
process: 200 / 291. Epoch 1055
process: 250 / 291. Epoch 1055
process: 291 / 291. Epoch 1055
Loss of epoch 1055 = 2.9625189607495703
process: 50 / 291. Epoch 1056
process: 100 / 291. Epoch 1056
process: 150 / 291. Epoch 1056
process: 200 / 291. Epoch 1056
process: 250 / 291. Epoch 1056
process: 291 / 291. Epoch 1056
Loss of epoch 1056 = 2.820602784042096
process: 50 / 291. Epoch 1057
process: 100 / 291. Epoch 1057
process: 150 / 291. Epoch 1057
process: 200 / 291. Epoch 1057
process: 250 / 291. Epoch 1057
process: 291 / 291. Epoch 1057
Loss of epoch 1057 = 2.8719931271477663
process: 50 / 291. Epoch 1058
process: 100 / 291. Epoch 1058
process: 150 / 291. Epoch 1058
process: 200 / 291. Epoch 1058
process: 250 / 291. Epoch 1058
process: 291 / 291. Epoch 1058
Loss of epoch 1058 = 2.892100750375859
process: 50 / 291. Epoch 1059
process: 100 / 291. Epoch 1059
process: 150 / 291. Epoch 1059
process: 200 / 291. Epoch 1059
process: 250 / 291. Epoch 1059
process: 291 / 291. Epoch 1059
Loss of epoch 1059 = 2.79223716709622
process: 50 / 291. Epoch 1060
process: 100 / 291. Epoch 1060
process: 150 / 291. Epoch 1060
process: 200 / 291. Epoch 1060
process: 250 / 291. Epoch 1060
process: 291 / 291. Epoch 1060
Loss of epoch 1060 = 2.8148126241677405
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1060. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.789323
      epoch  training_loss
1055   1056       2.820603
1056   1057       2.871993
1057   1058       2.892101
1058   1059       2.792237
1059   1060       2.814813
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
101       1020  0.015229  0.075286      0.358368   0.359459
102       1030  0.015135  0.077104      0.359966   0.361090
103       1040  0.015292  0.075312      0.358608   0.359708
104       1050  0.015199  0.075437      0.360336   0.361426
105       1060  0.015302  0.074991      0.359619   0.360712
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
101     1020.0  0.971751  0.980050  ...  0.956996  0.953168  0.940544
102     1030.0  0.971037  0.979835  ...  0.957403  0.953250  0.943639
103     1040.0  0.971881  0.979835  ...  0.957648  0.953250  0.942010
104     1050.0  0.971666  0.980054  ...  0.957485  0.953331  0.942092
105     1060.0  0.971644  0.979601  ...  0.956915  0.952680  0.940300

[5 rows x 13 columns]
process: 50 / 291. Epoch 1061
process: 100 / 291. Epoch 1061
process: 150 / 291. Epoch 1061
process: 200 / 291. Epoch 1061
process: 250 / 291. Epoch 1061
process: 291 / 291. Epoch 1061
Loss of epoch 1061 = 2.8209918569453394
process: 50 / 291. Epoch 1062
process: 100 / 291. Epoch 1062
process: 150 / 291. Epoch 1062
process: 200 / 291. Epoch 1062
process: 250 / 291. Epoch 1062
process: 291 / 291. Epoch 1062
Loss of epoch 1062 = 2.8067968833897123
process: 50 / 291. Epoch 1063
process: 100 / 291. Epoch 1063
process: 150 / 291. Epoch 1063
process: 200 / 291. Epoch 1063
process: 250 / 291. Epoch 1063
process: 291 / 291. Epoch 1063
Loss of epoch 1063 = 2.8642307556781574
process: 50 / 291. Epoch 1064
process: 100 / 291. Epoch 1064
process: 150 / 291. Epoch 1064
process: 200 / 291. Epoch 1064
process: 250 / 291. Epoch 1064
process: 291 / 291. Epoch 1064
Loss of epoch 1064 = 2.908297928747852
process: 50 / 291. Epoch 1065
process: 100 / 291. Epoch 1065
process: 150 / 291. Epoch 1065
process: 200 / 291. Epoch 1065
process: 250 / 291. Epoch 1065
process: 291 / 291. Epoch 1065
Loss of epoch 1065 = 2.808116794861469
process: 50 / 291. Epoch 1066
process: 100 / 291. Epoch 1066
process: 150 / 291. Epoch 1066
process: 200 / 291. Epoch 1066
process: 250 / 291. Epoch 1066
process: 291 / 291. Epoch 1066
Loss of epoch 1066 = 2.877001995073561
process: 50 / 291. Epoch 1067
process: 100 / 291. Epoch 1067
process: 150 / 291. Epoch 1067
process: 200 / 291. Epoch 1067
process: 250 / 291. Epoch 1067
process: 291 / 291. Epoch 1067
Loss of epoch 1067 = 2.9608846448131443
process: 50 / 291. Epoch 1068
process: 100 / 291. Epoch 1068
process: 150 / 291. Epoch 1068
process: 200 / 291. Epoch 1068
process: 250 / 291. Epoch 1068
process: 291 / 291. Epoch 1068
Loss of epoch 1068 = 2.8144747285089133
process: 50 / 291. Epoch 1069
process: 100 / 291. Epoch 1069
process: 150 / 291. Epoch 1069
process: 200 / 291. Epoch 1069
process: 250 / 291. Epoch 1069
process: 291 / 291. Epoch 1069
Loss of epoch 1069 = 2.8117757580943943
process: 50 / 291. Epoch 1070
process: 100 / 291. Epoch 1070
process: 150 / 291. Epoch 1070
process: 200 / 291. Epoch 1070
process: 250 / 291. Epoch 1070
process: 291 / 291. Epoch 1070
Loss of epoch 1070 = 2.845309437755047
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1070. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.784965
      epoch  training_loss
1065   1066       2.877002
1066   1067       2.960885
1067   1068       2.814475
1068   1069       2.811776
1069   1070       2.845309
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
102       1030  0.015135  0.077104      0.359966   0.361090
103       1040  0.015292  0.075312      0.358608   0.359708
104       1050  0.015199  0.075437      0.360336   0.361426
105       1060  0.015302  0.074991      0.359619   0.360712
106       1070  0.015323  0.074168      0.360538   0.361653
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
102     1030.0  0.971037  0.979835  ...  0.957403  0.953250  0.943639
103     1040.0  0.971881  0.979835  ...  0.957648  0.953250  0.942010
104     1050.0  0.971666  0.980054  ...  0.957485  0.953331  0.942092
105     1060.0  0.971644  0.979601  ...  0.956915  0.952680  0.940300
106     1070.0  0.972299  0.979930  ...  0.957648  0.952761  0.937286

[5 rows x 13 columns]
process: 50 / 291. Epoch 1071
process: 100 / 291. Epoch 1071
process: 150 / 291. Epoch 1071
process: 200 / 291. Epoch 1071
process: 250 / 291. Epoch 1071
process: 291 / 291. Epoch 1071
Loss of epoch 1071 = 2.8288995801788017
process: 50 / 291. Epoch 1072
process: 100 / 291. Epoch 1072
process: 150 / 291. Epoch 1072
process: 200 / 291. Epoch 1072
process: 250 / 291. Epoch 1072
process: 291 / 291. Epoch 1072
Loss of epoch 1072 = 2.8118449732200386
process: 50 / 291. Epoch 1073
process: 100 / 291. Epoch 1073
process: 150 / 291. Epoch 1073
process: 200 / 291. Epoch 1073
process: 250 / 291. Epoch 1073
process: 291 / 291. Epoch 1073
Loss of epoch 1073 = 2.847740147121993
process: 50 / 291. Epoch 1074
process: 100 / 291. Epoch 1074
process: 150 / 291. Epoch 1074
process: 200 / 291. Epoch 1074
process: 250 / 291. Epoch 1074
process: 291 / 291. Epoch 1074
Loss of epoch 1074 = 2.8471629349226806
process: 50 / 291. Epoch 1075
process: 100 / 291. Epoch 1075
process: 150 / 291. Epoch 1075
process: 200 / 291. Epoch 1075
process: 250 / 291. Epoch 1075
process: 291 / 291. Epoch 1075
Loss of epoch 1075 = 2.830869694346005
process: 50 / 291. Epoch 1076
process: 100 / 291. Epoch 1076
process: 150 / 291. Epoch 1076
process: 200 / 291. Epoch 1076
process: 250 / 291. Epoch 1076
process: 291 / 291. Epoch 1076
Loss of epoch 1076 = 2.8269120573587845
process: 50 / 291. Epoch 1077
process: 100 / 291. Epoch 1077
process: 150 / 291. Epoch 1077
process: 200 / 291. Epoch 1077
process: 250 / 291. Epoch 1077
process: 291 / 291. Epoch 1077
Loss of epoch 1077 = 2.874707408787049
process: 50 / 291. Epoch 1078
process: 100 / 291. Epoch 1078
process: 150 / 291. Epoch 1078
process: 200 / 291. Epoch 1078
process: 250 / 291. Epoch 1078
process: 291 / 291. Epoch 1078
Loss of epoch 1078 = 2.8312585575064433
process: 50 / 291. Epoch 1079
process: 100 / 291. Epoch 1079
process: 150 / 291. Epoch 1079
process: 200 / 291. Epoch 1079
process: 250 / 291. Epoch 1079
process: 291 / 291. Epoch 1079
Loss of epoch 1079 = 2.8062341434439433
process: 50 / 291. Epoch 1080
process: 100 / 291. Epoch 1080
process: 150 / 291. Epoch 1080
process: 200 / 291. Epoch 1080
process: 250 / 291. Epoch 1080
process: 291 / 291. Epoch 1080
Loss of epoch 1080 = 2.807397377040378
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1080. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.787224
      epoch  training_loss
1075   1076       2.826912
1076   1077       2.874707
1077   1078       2.831259
1078   1079       2.806234
1079   1080       2.807397
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
103       1040  0.015292  0.075312      0.358608   0.359708
104       1050  0.015199  0.075437      0.360336   0.361426
105       1060  0.015302  0.074991      0.359619   0.360712
106       1070  0.015323  0.074168      0.360538   0.361653
107       1080  0.015288  0.074852      0.362767   0.363941
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
103     1040.0  0.971881  0.979835  ...  0.957648  0.953250  0.942010
104     1050.0  0.971666  0.980054  ...  0.957485  0.953331  0.942092
105     1060.0  0.971644  0.979601  ...  0.956915  0.952680  0.940300
106     1070.0  0.972299  0.979930  ...  0.957648  0.952761  0.937286
107     1080.0  0.972293  0.980490  ...  0.957485  0.953331  0.940218

[5 rows x 13 columns]
process: 50 / 291. Epoch 1081
process: 100 / 291. Epoch 1081
process: 150 / 291. Epoch 1081
process: 200 / 291. Epoch 1081
process: 250 / 291. Epoch 1081
process: 291 / 291. Epoch 1081
Loss of epoch 1081 = 2.8913905612381874
process: 50 / 291. Epoch 1082
process: 100 / 291. Epoch 1082
process: 150 / 291. Epoch 1082
process: 200 / 291. Epoch 1082
process: 250 / 291. Epoch 1082
process: 291 / 291. Epoch 1082
Loss of epoch 1082 = 2.8453964810191152
process: 50 / 291. Epoch 1083
process: 100 / 291. Epoch 1083
process: 150 / 291. Epoch 1083
process: 200 / 291. Epoch 1083
process: 250 / 291. Epoch 1083
process: 291 / 291. Epoch 1083
Loss of epoch 1083 = 2.8377966602233675
process: 50 / 291. Epoch 1084
process: 100 / 291. Epoch 1084
process: 150 / 291. Epoch 1084
process: 200 / 291. Epoch 1084
process: 250 / 291. Epoch 1084
process: 291 / 291. Epoch 1084
Loss of epoch 1084 = 2.7926123969743344
process: 50 / 291. Epoch 1085
process: 100 / 291. Epoch 1085
process: 150 / 291. Epoch 1085
process: 200 / 291. Epoch 1085
process: 250 / 291. Epoch 1085
process: 291 / 291. Epoch 1085
Loss of epoch 1085 = 2.764722896195769
process: 50 / 291. Epoch 1086
process: 100 / 291. Epoch 1086
process: 150 / 291. Epoch 1086
process: 200 / 291. Epoch 1086
process: 250 / 291. Epoch 1086
process: 291 / 291. Epoch 1086
Loss of epoch 1086 = 2.82885951930305
process: 50 / 291. Epoch 1087
process: 100 / 291. Epoch 1087
process: 150 / 291. Epoch 1087
process: 200 / 291. Epoch 1087
process: 250 / 291. Epoch 1087
process: 291 / 291. Epoch 1087
Loss of epoch 1087 = 2.8844082232603094
process: 50 / 291. Epoch 1088
process: 100 / 291. Epoch 1088
process: 150 / 291. Epoch 1088
process: 200 / 291. Epoch 1088
process: 250 / 291. Epoch 1088
process: 291 / 291. Epoch 1088
Loss of epoch 1088 = 2.9691621446117913
process: 50 / 291. Epoch 1089
process: 100 / 291. Epoch 1089
process: 150 / 291. Epoch 1089
process: 200 / 291. Epoch 1089
process: 250 / 291. Epoch 1089
process: 291 / 291. Epoch 1089
Loss of epoch 1089 = 2.8125142625107387
process: 50 / 291. Epoch 1090
process: 100 / 291. Epoch 1090
process: 150 / 291. Epoch 1090
process: 200 / 291. Epoch 1090
process: 250 / 291. Epoch 1090
process: 291 / 291. Epoch 1090
Loss of epoch 1090 = 2.6996273289841066
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1090. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.792698
      epoch  training_loss
1085   1086       2.828860
1086   1087       2.884408
1087   1088       2.969162
1088   1089       2.812514
1089   1090       2.699627
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
104       1050  0.015199  0.075437      0.360336   0.361426
105       1060  0.015302  0.074991      0.359619   0.360712
106       1070  0.015323  0.074168      0.360538   0.361653
107       1080  0.015288  0.074852      0.362767   0.363941
108       1090  0.015207  0.075420      0.361762   0.362861
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
104     1050.0  0.971666  0.980054  ...  0.957485  0.953331  0.942092
105     1060.0  0.971644  0.979601  ...  0.956915  0.952680  0.940300
106     1070.0  0.972299  0.979930  ...  0.957648  0.952761  0.937286
107     1080.0  0.972293  0.980490  ...  0.957485  0.953331  0.940218
108     1090.0  0.971656  0.980156  ...  0.957241  0.953087  0.943720

[5 rows x 13 columns]
process: 50 / 291. Epoch 1091
process: 100 / 291. Epoch 1091
process: 150 / 291. Epoch 1091
process: 200 / 291. Epoch 1091
process: 250 / 291. Epoch 1091
process: 291 / 291. Epoch 1091
Loss of epoch 1091 = 2.7786680660706615
process: 50 / 291. Epoch 1092
process: 100 / 291. Epoch 1092
process: 150 / 291. Epoch 1092
process: 200 / 291. Epoch 1092
process: 250 / 291. Epoch 1092
process: 291 / 291. Epoch 1092
Loss of epoch 1092 = 2.8265976528941152
process: 50 / 291. Epoch 1093
process: 100 / 291. Epoch 1093
process: 150 / 291. Epoch 1093
process: 200 / 291. Epoch 1093
process: 250 / 291. Epoch 1093
process: 291 / 291. Epoch 1093
Loss of epoch 1093 = 2.859437922841495
process: 50 / 291. Epoch 1094
process: 100 / 291. Epoch 1094
process: 150 / 291. Epoch 1094
process: 200 / 291. Epoch 1094
process: 250 / 291. Epoch 1094
process: 291 / 291. Epoch 1094
Loss of epoch 1094 = 2.7938935060271692
process: 50 / 291. Epoch 1095
process: 100 / 291. Epoch 1095
process: 150 / 291. Epoch 1095
process: 200 / 291. Epoch 1095
process: 250 / 291. Epoch 1095
process: 291 / 291. Epoch 1095
Loss of epoch 1095 = 2.830920032619201
process: 50 / 291. Epoch 1096
process: 100 / 291. Epoch 1096
process: 150 / 291. Epoch 1096
process: 200 / 291. Epoch 1096
process: 250 / 291. Epoch 1096
process: 291 / 291. Epoch 1096
Loss of epoch 1096 = 2.863217068701675
process: 50 / 291. Epoch 1097
process: 100 / 291. Epoch 1097
process: 150 / 291. Epoch 1097
process: 200 / 291. Epoch 1097
process: 250 / 291. Epoch 1097
process: 291 / 291. Epoch 1097
Loss of epoch 1097 = 2.9148846917955327
process: 50 / 291. Epoch 1098
process: 100 / 291. Epoch 1098
process: 150 / 291. Epoch 1098
process: 200 / 291. Epoch 1098
process: 250 / 291. Epoch 1098
process: 291 / 291. Epoch 1098
Loss of epoch 1098 = 2.778797267638531
process: 50 / 291. Epoch 1099
process: 100 / 291. Epoch 1099
process: 150 / 291. Epoch 1099
process: 200 / 291. Epoch 1099
process: 250 / 291. Epoch 1099
process: 291 / 291. Epoch 1099
Loss of epoch 1099 = 2.776537498657646
process: 50 / 291. Epoch 1100
process: 100 / 291. Epoch 1100
process: 150 / 291. Epoch 1100
process: 200 / 291. Epoch 1100
process: 250 / 291. Epoch 1100
process: 291 / 291. Epoch 1100
Loss of epoch 1100 = 2.7655182409122636
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1100. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.789850
      epoch  training_loss
1095   1096       2.863217
1096   1097       2.914885
1097   1098       2.778797
1098   1099       2.776537
1099   1100       2.765518
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
105       1060  0.015302  0.074991      0.359619   0.360712
106       1070  0.015323  0.074168      0.360538   0.361653
107       1080  0.015288  0.074852      0.362767   0.363941
108       1090  0.015207  0.075420      0.361762   0.362861
109       1100  0.015239  0.074216      0.361518   0.362580
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
105     1060.0  0.971644  0.979601  ...  0.956915  0.952680  0.940300
106     1070.0  0.972299  0.979930  ...  0.957648  0.952761  0.937286
107     1080.0  0.972293  0.980490  ...  0.957485  0.953331  0.940218
108     1090.0  0.971656  0.980156  ...  0.957241  0.953087  0.943720
109     1100.0  0.971761  0.979726  ...  0.957241  0.953250  0.941684

[5 rows x 13 columns]
process: 50 / 291. Epoch 1101
process: 100 / 291. Epoch 1101
process: 150 / 291. Epoch 1101
process: 200 / 291. Epoch 1101
process: 250 / 291. Epoch 1101
process: 291 / 291. Epoch 1101
Loss of epoch 1101 = 2.7965016578071307
process: 50 / 291. Epoch 1102
process: 100 / 291. Epoch 1102
process: 150 / 291. Epoch 1102
process: 200 / 291. Epoch 1102
process: 250 / 291. Epoch 1102
process: 291 / 291. Epoch 1102
Loss of epoch 1102 = 2.86242591884128
process: 50 / 291. Epoch 1103
process: 100 / 291. Epoch 1103
process: 150 / 291. Epoch 1103
process: 200 / 291. Epoch 1103
process: 250 / 291. Epoch 1103
process: 291 / 291. Epoch 1103
Loss of epoch 1103 = 2.8410357183607173
process: 50 / 291. Epoch 1104
process: 100 / 291. Epoch 1104
process: 150 / 291. Epoch 1104
process: 200 / 291. Epoch 1104
process: 250 / 291. Epoch 1104
process: 291 / 291. Epoch 1104
Loss of epoch 1104 = 2.829723659659579
process: 50 / 291. Epoch 1105
process: 100 / 291. Epoch 1105
process: 150 / 291. Epoch 1105
process: 200 / 291. Epoch 1105
process: 250 / 291. Epoch 1105
process: 291 / 291. Epoch 1105
Loss of epoch 1105 = 2.8331586175767827
process: 50 / 291. Epoch 1106
process: 100 / 291. Epoch 1106
process: 150 / 291. Epoch 1106
process: 200 / 291. Epoch 1106
process: 250 / 291. Epoch 1106
process: 291 / 291. Epoch 1106
Loss of epoch 1106 = 2.805617919082904
process: 50 / 291. Epoch 1107
process: 100 / 291. Epoch 1107
process: 150 / 291. Epoch 1107
process: 200 / 291. Epoch 1107
process: 250 / 291. Epoch 1107
process: 291 / 291. Epoch 1107
Loss of epoch 1107 = 2.8164003772014605
process: 50 / 291. Epoch 1108
process: 100 / 291. Epoch 1108
process: 150 / 291. Epoch 1108
process: 200 / 291. Epoch 1108
process: 250 / 291. Epoch 1108
process: 291 / 291. Epoch 1108
Loss of epoch 1108 = 2.777981577869953
process: 50 / 291. Epoch 1109
process: 100 / 291. Epoch 1109
process: 150 / 291. Epoch 1109
process: 200 / 291. Epoch 1109
process: 250 / 291. Epoch 1109
process: 291 / 291. Epoch 1109
Loss of epoch 1109 = 2.8302723468374142
process: 50 / 291. Epoch 1110
process: 100 / 291. Epoch 1110
process: 150 / 291. Epoch 1110
process: 200 / 291. Epoch 1110
process: 250 / 291. Epoch 1110
process: 291 / 291. Epoch 1110
Loss of epoch 1110 = 2.7952255825816152
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1110. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.790353
      epoch  training_loss
1105   1106       2.805618
1106   1107       2.816400
1107   1108       2.777982
1108   1109       2.830272
1109   1110       2.795226
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
106       1070  0.015323  0.074168      0.360538   0.361653
107       1080  0.015288  0.074852      0.362767   0.363941
108       1090  0.015207  0.075420      0.361762   0.362861
109       1100  0.015239  0.074216      0.361518   0.362580
110       1110  0.015286  0.074919      0.363373   0.364580
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
106     1070.0  0.972299  0.979930  ...  0.957648  0.952761  0.937286
107     1080.0  0.972293  0.980490  ...  0.957485  0.953331  0.940218
108     1090.0  0.971656  0.980156  ...  0.957241  0.953087  0.943720
109     1100.0  0.971761  0.979726  ...  0.957241  0.953250  0.941684
110     1110.0  0.972195  0.980048  ...  0.957648  0.953087  0.942173

[5 rows x 13 columns]
process: 50 / 291. Epoch 1111
process: 100 / 291. Epoch 1111
process: 150 / 291. Epoch 1111
process: 200 / 291. Epoch 1111
process: 250 / 291. Epoch 1111
process: 291 / 291. Epoch 1111
Loss of epoch 1111 = 2.85949623134128
process: 50 / 291. Epoch 1112
process: 100 / 291. Epoch 1112
process: 150 / 291. Epoch 1112
process: 200 / 291. Epoch 1112
process: 250 / 291. Epoch 1112
process: 291 / 291. Epoch 1112
Loss of epoch 1112 = 2.847068760403243
process: 50 / 291. Epoch 1113
process: 100 / 291. Epoch 1113
process: 150 / 291. Epoch 1113
process: 200 / 291. Epoch 1113
process: 250 / 291. Epoch 1113
process: 291 / 291. Epoch 1113
Loss of epoch 1113 = 2.8677928177351806
process: 50 / 291. Epoch 1114
process: 100 / 291. Epoch 1114
process: 150 / 291. Epoch 1114
process: 200 / 291. Epoch 1114
process: 250 / 291. Epoch 1114
process: 291 / 291. Epoch 1114
Loss of epoch 1114 = 2.78845172895189
process: 50 / 291. Epoch 1115
process: 100 / 291. Epoch 1115
process: 150 / 291. Epoch 1115
process: 200 / 291. Epoch 1115
process: 250 / 291. Epoch 1115
process: 291 / 291. Epoch 1115
Loss of epoch 1115 = 2.71386634852878
process: 50 / 291. Epoch 1116
process: 100 / 291. Epoch 1116
process: 150 / 291. Epoch 1116
process: 200 / 291. Epoch 1116
process: 250 / 291. Epoch 1116
process: 291 / 291. Epoch 1116
Loss of epoch 1116 = 2.7587072628060567
process: 50 / 291. Epoch 1117
process: 100 / 291. Epoch 1117
process: 150 / 291. Epoch 1117
process: 200 / 291. Epoch 1117
process: 250 / 291. Epoch 1117
process: 291 / 291. Epoch 1117
Loss of epoch 1117 = 2.8261055962736252
process: 50 / 291. Epoch 1118
process: 100 / 291. Epoch 1118
process: 150 / 291. Epoch 1118
process: 200 / 291. Epoch 1118
process: 250 / 291. Epoch 1118
process: 291 / 291. Epoch 1118
Loss of epoch 1118 = 2.911046188721542
process: 50 / 291. Epoch 1119
process: 100 / 291. Epoch 1119
process: 150 / 291. Epoch 1119
process: 200 / 291. Epoch 1119
process: 250 / 291. Epoch 1119
process: 291 / 291. Epoch 1119
Loss of epoch 1119 = 2.7982358113187287
process: 50 / 291. Epoch 1120
process: 100 / 291. Epoch 1120
process: 150 / 291. Epoch 1120
process: 200 / 291. Epoch 1120
process: 250 / 291. Epoch 1120
process: 291 / 291. Epoch 1120
Loss of epoch 1120 = 2.749244086930842
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1120. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.785370
      epoch  training_loss
1115   1116       2.758707
1116   1117       2.826106
1117   1118       2.911046
1118   1119       2.798236
1119   1120       2.749244
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
107       1080  0.015288  0.074852      0.362767   0.363941
108       1090  0.015207  0.075420      0.361762   0.362861
109       1100  0.015239  0.074216      0.361518   0.362580
110       1110  0.015286  0.074919      0.363373   0.364580
111       1120  0.015324  0.073233      0.364096   0.365313
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
107     1080.0  0.972293  0.980490  ...  0.957485  0.953331  0.940218
108     1090.0  0.971656  0.980156  ...  0.957241  0.953087  0.943720
109     1100.0  0.971761  0.979726  ...  0.957241  0.953250  0.941684
110     1110.0  0.972195  0.980048  ...  0.957648  0.953087  0.942173
111     1120.0  0.972395  0.980052  ...  0.957403  0.953250  0.940463

[5 rows x 13 columns]
process: 50 / 291. Epoch 1121
process: 100 / 291. Epoch 1121
process: 150 / 291. Epoch 1121
process: 200 / 291. Epoch 1121
process: 250 / 291. Epoch 1121
process: 291 / 291. Epoch 1121
Loss of epoch 1121 = 2.7566454910330758
process: 50 / 291. Epoch 1122
process: 100 / 291. Epoch 1122
process: 150 / 291. Epoch 1122
process: 200 / 291. Epoch 1122
process: 250 / 291. Epoch 1122
process: 291 / 291. Epoch 1122
Loss of epoch 1122 = 2.886757342676117
process: 50 / 291. Epoch 1123
process: 100 / 291. Epoch 1123
process: 150 / 291. Epoch 1123
process: 200 / 291. Epoch 1123
process: 250 / 291. Epoch 1123
process: 291 / 291. Epoch 1123
Loss of epoch 1123 = 2.7977735381765463
process: 50 / 291. Epoch 1124
process: 100 / 291. Epoch 1124
process: 150 / 291. Epoch 1124
process: 200 / 291. Epoch 1124
process: 250 / 291. Epoch 1124
process: 291 / 291. Epoch 1124
Loss of epoch 1124 = 2.806482898410653
process: 50 / 291. Epoch 1125
process: 100 / 291. Epoch 1125
process: 150 / 291. Epoch 1125
process: 200 / 291. Epoch 1125
process: 250 / 291. Epoch 1125
process: 291 / 291. Epoch 1125
Loss of epoch 1125 = 2.8524985821386384
process: 50 / 291. Epoch 1126
process: 100 / 291. Epoch 1126
process: 150 / 291. Epoch 1126
process: 200 / 291. Epoch 1126
process: 250 / 291. Epoch 1126
process: 291 / 291. Epoch 1126
Loss of epoch 1126 = 2.7854654108945445
process: 50 / 291. Epoch 1127
process: 100 / 291. Epoch 1127
process: 150 / 291. Epoch 1127
process: 200 / 291. Epoch 1127
process: 250 / 291. Epoch 1127
process: 291 / 291. Epoch 1127
Loss of epoch 1127 = 2.7696747140786084
process: 50 / 291. Epoch 1128
process: 100 / 291. Epoch 1128
process: 150 / 291. Epoch 1128
process: 200 / 291. Epoch 1128
process: 250 / 291. Epoch 1128
process: 291 / 291. Epoch 1128
Loss of epoch 1128 = 2.822927363549721
process: 50 / 291. Epoch 1129
process: 100 / 291. Epoch 1129
process: 150 / 291. Epoch 1129
process: 200 / 291. Epoch 1129
process: 250 / 291. Epoch 1129
process: 291 / 291. Epoch 1129
Loss of epoch 1129 = 2.921681617133806
process: 50 / 291. Epoch 1130
process: 100 / 291. Epoch 1130
process: 150 / 291. Epoch 1130
process: 200 / 291. Epoch 1130
process: 250 / 291. Epoch 1130
process: 291 / 291. Epoch 1130
Loss of epoch 1130 = 2.7489194050687287
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1130. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.789498
      epoch  training_loss
1125   1126       2.785465
1126   1127       2.769675
1127   1128       2.822927
1128   1129       2.921682
1129   1130       2.748919
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
108       1090  0.015207  0.075420      0.361762   0.362861
109       1100  0.015239  0.074216      0.361518   0.362580
110       1110  0.015286  0.074919      0.363373   0.364580
111       1120  0.015324  0.073233      0.364096   0.365313
112       1130  0.015320  0.073345      0.364798   0.366037
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
108     1090.0  0.971656  0.980156  ...  0.957241  0.953087  0.943720
109     1100.0  0.971761  0.979726  ...  0.957241  0.953250  0.941684
110     1110.0  0.972195  0.980048  ...  0.957648  0.953087  0.942173
111     1120.0  0.972395  0.980052  ...  0.957403  0.953250  0.940463
112     1130.0  0.972499  0.980159  ...  0.957403  0.953168  0.941847

[5 rows x 13 columns]
process: 50 / 291. Epoch 1131
process: 100 / 291. Epoch 1131
process: 150 / 291. Epoch 1131
process: 200 / 291. Epoch 1131
process: 250 / 291. Epoch 1131
process: 291 / 291. Epoch 1131
Loss of epoch 1131 = 2.735891440480026
process: 50 / 291. Epoch 1132
process: 100 / 291. Epoch 1132
process: 150 / 291. Epoch 1132
process: 200 / 291. Epoch 1132
process: 250 / 291. Epoch 1132
process: 291 / 291. Epoch 1132
Loss of epoch 1132 = 2.7330362116757945
process: 50 / 291. Epoch 1133
process: 100 / 291. Epoch 1133
process: 150 / 291. Epoch 1133
process: 200 / 291. Epoch 1133
process: 250 / 291. Epoch 1133
process: 291 / 291. Epoch 1133
Loss of epoch 1133 = 2.7933112600005368
process: 50 / 291. Epoch 1134
process: 100 / 291. Epoch 1134
process: 150 / 291. Epoch 1134
process: 200 / 291. Epoch 1134
process: 250 / 291. Epoch 1134
process: 291 / 291. Epoch 1134
Loss of epoch 1134 = 2.794899642262672
process: 50 / 291. Epoch 1135
process: 100 / 291. Epoch 1135
process: 150 / 291. Epoch 1135
process: 200 / 291. Epoch 1135
process: 250 / 291. Epoch 1135
process: 291 / 291. Epoch 1135
Loss of epoch 1135 = 2.815831344971542
process: 50 / 291. Epoch 1136
process: 100 / 291. Epoch 1136
process: 150 / 291. Epoch 1136
process: 200 / 291. Epoch 1136
process: 250 / 291. Epoch 1136
process: 291 / 291. Epoch 1136
Loss of epoch 1136 = 2.8105668005664732
process: 50 / 291. Epoch 1137
process: 100 / 291. Epoch 1137
process: 150 / 291. Epoch 1137
process: 200 / 291. Epoch 1137
process: 250 / 291. Epoch 1137
process: 291 / 291. Epoch 1137
Loss of epoch 1137 = 2.770115593454682
process: 50 / 291. Epoch 1138
process: 100 / 291. Epoch 1138
process: 150 / 291. Epoch 1138
process: 200 / 291. Epoch 1138
process: 250 / 291. Epoch 1138
process: 291 / 291. Epoch 1138
Loss of epoch 1138 = 2.7635913337628866
process: 50 / 291. Epoch 1139
process: 100 / 291. Epoch 1139
process: 150 / 291. Epoch 1139
process: 200 / 291. Epoch 1139
process: 250 / 291. Epoch 1139
process: 291 / 291. Epoch 1139
Loss of epoch 1139 = 2.7791395678962627
process: 50 / 291. Epoch 1140
process: 100 / 291. Epoch 1140
process: 150 / 291. Epoch 1140
process: 200 / 291. Epoch 1140
process: 250 / 291. Epoch 1140
process: 291 / 291. Epoch 1140
Loss of epoch 1140 = 2.7138592172734106
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1140. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.791578
      epoch  training_loss
1135   1136       2.810567
1136   1137       2.770116
1137   1138       2.763591
1138   1139       2.779140
1139   1140       2.713859
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
109       1100  0.015239  0.074216      0.361518   0.362580
110       1110  0.015286  0.074919      0.363373   0.364580
111       1120  0.015324  0.073233      0.364096   0.365313
112       1130  0.015320  0.073345      0.364798   0.366037
113       1140  0.015276  0.074159      0.365316   0.366565
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
109     1100.0  0.971761  0.979726  ...  0.957241  0.953250  0.941684
110     1110.0  0.972195  0.980048  ...  0.957648  0.953087  0.942173
111     1120.0  0.972395  0.980052  ...  0.957403  0.953250  0.940463
112     1130.0  0.972499  0.980159  ...  0.957403  0.953168  0.941847
113     1140.0  0.972619  0.980063  ...  0.957811  0.953657  0.941929

[5 rows x 13 columns]
process: 50 / 291. Epoch 1141
process: 100 / 291. Epoch 1141
process: 150 / 291. Epoch 1141
process: 200 / 291. Epoch 1141
process: 250 / 291. Epoch 1141
process: 291 / 291. Epoch 1141
Loss of epoch 1141 = 2.8703103606233893
process: 50 / 291. Epoch 1142
process: 100 / 291. Epoch 1142
process: 150 / 291. Epoch 1142
process: 200 / 291. Epoch 1142
process: 250 / 291. Epoch 1142
process: 291 / 291. Epoch 1142
Loss of epoch 1142 = 2.8721860905283507
process: 50 / 291. Epoch 1143
process: 100 / 291. Epoch 1143
process: 150 / 291. Epoch 1143
process: 200 / 291. Epoch 1143
process: 250 / 291. Epoch 1143
process: 291 / 291. Epoch 1143
Loss of epoch 1143 = 2.769986811372423
process: 50 / 291. Epoch 1144
process: 100 / 291. Epoch 1144
process: 150 / 291. Epoch 1144
process: 200 / 291. Epoch 1144
process: 250 / 291. Epoch 1144
process: 291 / 291. Epoch 1144
Loss of epoch 1144 = 2.7379588753087414
process: 50 / 291. Epoch 1145
process: 100 / 291. Epoch 1145
process: 150 / 291. Epoch 1145
process: 200 / 291. Epoch 1145
process: 250 / 291. Epoch 1145
process: 291 / 291. Epoch 1145
Loss of epoch 1145 = 2.7897122832098367
process: 50 / 291. Epoch 1146
process: 100 / 291. Epoch 1146
process: 150 / 291. Epoch 1146
process: 200 / 291. Epoch 1146
process: 250 / 291. Epoch 1146
process: 291 / 291. Epoch 1146
Loss of epoch 1146 = 2.7378206548002577
process: 50 / 291. Epoch 1147
process: 100 / 291. Epoch 1147
process: 150 / 291. Epoch 1147
process: 200 / 291. Epoch 1147
process: 250 / 291. Epoch 1147
process: 291 / 291. Epoch 1147
Loss of epoch 1147 = 2.8628869335266325
process: 50 / 291. Epoch 1148
process: 100 / 291. Epoch 1148
process: 150 / 291. Epoch 1148
process: 200 / 291. Epoch 1148
process: 250 / 291. Epoch 1148
process: 291 / 291. Epoch 1148
Loss of epoch 1148 = 2.77746707876933
process: 50 / 291. Epoch 1149
process: 100 / 291. Epoch 1149
process: 150 / 291. Epoch 1149
process: 200 / 291. Epoch 1149
process: 250 / 291. Epoch 1149
process: 291 / 291. Epoch 1149
Loss of epoch 1149 = 2.789867912371134
process: 50 / 291. Epoch 1150
process: 100 / 291. Epoch 1150
process: 150 / 291. Epoch 1150
process: 200 / 291. Epoch 1150
process: 250 / 291. Epoch 1150
process: 291 / 291. Epoch 1150
Loss of epoch 1150 = 2.7702095582313144
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1150. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.794474
      epoch  training_loss
1145   1146       2.737821
1146   1147       2.862887
1147   1148       2.777467
1148   1149       2.789868
1149   1150       2.770210
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
110       1110  0.015286  0.074919      0.363373   0.364580
111       1120  0.015324  0.073233      0.364096   0.365313
112       1130  0.015320  0.073345      0.364798   0.366037
113       1140  0.015276  0.074159      0.365316   0.366565
114       1150  0.015271  0.074550      0.365672   0.366899
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
110     1110.0  0.972195  0.980048  ...  0.957648  0.953087  0.942173
111     1120.0  0.972395  0.980052  ...  0.957403  0.953250  0.940463
112     1130.0  0.972499  0.980159  ...  0.957403  0.953168  0.941847
113     1140.0  0.972619  0.980063  ...  0.957811  0.953657  0.941929
114     1150.0  0.972308  0.979946  ...  0.957892  0.953331  0.944291

[5 rows x 13 columns]
process: 50 / 291. Epoch 1151
process: 100 / 291. Epoch 1151
process: 150 / 291. Epoch 1151
process: 200 / 291. Epoch 1151
process: 250 / 291. Epoch 1151
process: 291 / 291. Epoch 1151
Loss of epoch 1151 = 2.7768403672680413
process: 50 / 291. Epoch 1152
process: 100 / 291. Epoch 1152
process: 150 / 291. Epoch 1152
process: 200 / 291. Epoch 1152
process: 250 / 291. Epoch 1152
process: 291 / 291. Epoch 1152
Loss of epoch 1152 = 2.8294103039089347
process: 50 / 291. Epoch 1153
process: 100 / 291. Epoch 1153
process: 150 / 291. Epoch 1153
process: 200 / 291. Epoch 1153
process: 250 / 291. Epoch 1153
process: 291 / 291. Epoch 1153
Loss of epoch 1153 = 2.7965440258537373
process: 50 / 291. Epoch 1154
process: 100 / 291. Epoch 1154
process: 150 / 291. Epoch 1154
process: 200 / 291. Epoch 1154
process: 250 / 291. Epoch 1154
process: 291 / 291. Epoch 1154
Loss of epoch 1154 = 2.843625622516645
process: 50 / 291. Epoch 1155
process: 100 / 291. Epoch 1155
process: 150 / 291. Epoch 1155
process: 200 / 291. Epoch 1155
process: 250 / 291. Epoch 1155
process: 291 / 291. Epoch 1155
Loss of epoch 1155 = 2.879858482334622
process: 50 / 291. Epoch 1156
process: 100 / 291. Epoch 1156
process: 150 / 291. Epoch 1156
process: 200 / 291. Epoch 1156
process: 250 / 291. Epoch 1156
process: 291 / 291. Epoch 1156
Loss of epoch 1156 = 2.7261568574151633
process: 50 / 291. Epoch 1157
process: 100 / 291. Epoch 1157
process: 150 / 291. Epoch 1157
process: 200 / 291. Epoch 1157
process: 250 / 291. Epoch 1157
process: 291 / 291. Epoch 1157
Loss of epoch 1157 = 2.7598058956185567
process: 50 / 291. Epoch 1158
process: 100 / 291. Epoch 1158
process: 150 / 291. Epoch 1158
process: 200 / 291. Epoch 1158
process: 250 / 291. Epoch 1158
process: 291 / 291. Epoch 1158
Loss of epoch 1158 = 2.7051213320178267
process: 50 / 291. Epoch 1159
process: 100 / 291. Epoch 1159
process: 150 / 291. Epoch 1159
process: 200 / 291. Epoch 1159
process: 250 / 291. Epoch 1159
process: 291 / 291. Epoch 1159
Loss of epoch 1159 = 2.81353885611308
process: 50 / 291. Epoch 1160
process: 100 / 291. Epoch 1160
process: 150 / 291. Epoch 1160
process: 200 / 291. Epoch 1160
process: 250 / 291. Epoch 1160
process: 291 / 291. Epoch 1160
Loss of epoch 1160 = 2.8010709048136815
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1160. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.784975
      epoch  training_loss
1155   1156       2.726157
1156   1157       2.759806
1157   1158       2.705121
1158   1159       2.813539
1159   1160       2.801071
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
111       1120  0.015324  0.073233      0.364096   0.365313
112       1130  0.015320  0.073345      0.364798   0.366037
113       1140  0.015276  0.074159      0.365316   0.366565
114       1150  0.015271  0.074550      0.365672   0.366899
115       1160  0.015336  0.072958      0.365223   0.366489
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
111     1120.0  0.972395  0.980052  ...  0.957403  0.953250  0.940463
112     1130.0  0.972499  0.980159  ...  0.957403  0.953168  0.941847
113     1140.0  0.972619  0.980063  ...  0.957811  0.953657  0.941929
114     1150.0  0.972308  0.979946  ...  0.957892  0.953331  0.944291
115     1160.0  0.972718  0.980168  ...  0.957648  0.953494  0.939322

[5 rows x 13 columns]
process: 50 / 291. Epoch 1161
process: 100 / 291. Epoch 1161
process: 150 / 291. Epoch 1161
process: 200 / 291. Epoch 1161
process: 250 / 291. Epoch 1161
process: 291 / 291. Epoch 1161
Loss of epoch 1161 = 2.783190959917311
process: 50 / 291. Epoch 1162
process: 100 / 291. Epoch 1162
process: 150 / 291. Epoch 1162
process: 200 / 291. Epoch 1162
process: 250 / 291. Epoch 1162
process: 291 / 291. Epoch 1162
Loss of epoch 1162 = 2.780568335883806
process: 50 / 291. Epoch 1163
process: 100 / 291. Epoch 1163
process: 150 / 291. Epoch 1163
process: 200 / 291. Epoch 1163
process: 250 / 291. Epoch 1163
process: 291 / 291. Epoch 1163
Loss of epoch 1163 = 2.8199974663069156
process: 50 / 291. Epoch 1164
process: 100 / 291. Epoch 1164
process: 150 / 291. Epoch 1164
process: 200 / 291. Epoch 1164
process: 250 / 291. Epoch 1164
process: 291 / 291. Epoch 1164
Loss of epoch 1164 = 2.7472213273195876
process: 50 / 291. Epoch 1165
process: 100 / 291. Epoch 1165
process: 150 / 291. Epoch 1165
process: 200 / 291. Epoch 1165
process: 250 / 291. Epoch 1165
process: 291 / 291. Epoch 1165
Loss of epoch 1165 = 2.7696558372261597
process: 50 / 291. Epoch 1166
process: 100 / 291. Epoch 1166
process: 150 / 291. Epoch 1166
process: 200 / 291. Epoch 1166
process: 250 / 291. Epoch 1166
process: 291 / 291. Epoch 1166
Loss of epoch 1166 = 2.7871297200520835
process: 50 / 291. Epoch 1167
process: 100 / 291. Epoch 1167
process: 150 / 291. Epoch 1167
process: 200 / 291. Epoch 1167
process: 250 / 291. Epoch 1167
process: 291 / 291. Epoch 1167
Loss of epoch 1167 = 2.816554747905928
process: 50 / 291. Epoch 1168
process: 100 / 291. Epoch 1168
process: 150 / 291. Epoch 1168
process: 200 / 291. Epoch 1168
process: 250 / 291. Epoch 1168
process: 291 / 291. Epoch 1168
Loss of epoch 1168 = 2.7590298472401202
process: 50 / 291. Epoch 1169
process: 100 / 291. Epoch 1169
process: 150 / 291. Epoch 1169
process: 200 / 291. Epoch 1169
process: 250 / 291. Epoch 1169
process: 291 / 291. Epoch 1169
Loss of epoch 1169 = 2.776575671848153
process: 50 / 291. Epoch 1170
process: 100 / 291. Epoch 1170
process: 150 / 291. Epoch 1170
process: 200 / 291. Epoch 1170
process: 250 / 291. Epoch 1170
process: 291 / 291. Epoch 1170
Loss of epoch 1170 = 2.771178989475945
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1170. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.790928
      epoch  training_loss
1165   1166       2.787130
1166   1167       2.816555
1167   1168       2.759030
1168   1169       2.776576
1169   1170       2.771179
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
112       1130  0.015320  0.073345      0.364798   0.366037
113       1140  0.015276  0.074159      0.365316   0.366565
114       1150  0.015271  0.074550      0.365672   0.366899
115       1160  0.015336  0.072958      0.365223   0.366489
116       1170  0.015254  0.073295      0.367587   0.368900
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
112     1130.0  0.972499  0.980159  ...  0.957403  0.953168  0.941847
113     1140.0  0.972619  0.980063  ...  0.957811  0.953657  0.941929
114     1150.0  0.972308  0.979946  ...  0.957892  0.953331  0.944291
115     1160.0  0.972718  0.980168  ...  0.957648  0.953494  0.939322
116     1170.0  0.972395  0.980054  ...  0.957403  0.953331  0.941684

[5 rows x 13 columns]
process: 50 / 291. Epoch 1171
process: 100 / 291. Epoch 1171
process: 150 / 291. Epoch 1171
process: 200 / 291. Epoch 1171
process: 250 / 291. Epoch 1171
process: 291 / 291. Epoch 1171
Loss of epoch 1171 = 2.7693403840474655
process: 50 / 291. Epoch 1172
process: 100 / 291. Epoch 1172
process: 150 / 291. Epoch 1172
process: 200 / 291. Epoch 1172
process: 250 / 291. Epoch 1172
process: 291 / 291. Epoch 1172
Loss of epoch 1172 = 2.758019516148518
process: 50 / 291. Epoch 1173
process: 100 / 291. Epoch 1173
process: 150 / 291. Epoch 1173
process: 200 / 291. Epoch 1173
process: 250 / 291. Epoch 1173
process: 291 / 291. Epoch 1173
Loss of epoch 1173 = 2.7550252278645835
process: 50 / 291. Epoch 1174
process: 100 / 291. Epoch 1174
process: 150 / 291. Epoch 1174
process: 200 / 291. Epoch 1174
process: 250 / 291. Epoch 1174
process: 291 / 291. Epoch 1174
Loss of epoch 1174 = 2.758933994778243
process: 50 / 291. Epoch 1175
process: 100 / 291. Epoch 1175
process: 150 / 291. Epoch 1175
process: 200 / 291. Epoch 1175
process: 250 / 291. Epoch 1175
process: 291 / 291. Epoch 1175
Loss of epoch 1175 = 2.7667299250966493
process: 50 / 291. Epoch 1176
process: 100 / 291. Epoch 1176
process: 150 / 291. Epoch 1176
process: 200 / 291. Epoch 1176
process: 250 / 291. Epoch 1176
process: 291 / 291. Epoch 1176
Loss of epoch 1176 = 2.7396823319372854
process: 50 / 291. Epoch 1177
process: 100 / 291. Epoch 1177
process: 150 / 291. Epoch 1177
process: 200 / 291. Epoch 1177
process: 250 / 291. Epoch 1177
process: 291 / 291. Epoch 1177
Loss of epoch 1177 = 2.7291844948050903
process: 50 / 291. Epoch 1178
process: 100 / 291. Epoch 1178
process: 150 / 291. Epoch 1178
process: 200 / 291. Epoch 1178
process: 250 / 291. Epoch 1178
process: 291 / 291. Epoch 1178
Loss of epoch 1178 = 2.754807934318621
process: 50 / 291. Epoch 1179
process: 100 / 291. Epoch 1179
process: 150 / 291. Epoch 1179
process: 200 / 291. Epoch 1179
process: 250 / 291. Epoch 1179
process: 291 / 291. Epoch 1179
Loss of epoch 1179 = 2.759651944399699
process: 50 / 291. Epoch 1180
process: 100 / 291. Epoch 1180
process: 150 / 291. Epoch 1180
process: 200 / 291. Epoch 1180
process: 250 / 291. Epoch 1180
process: 291 / 291. Epoch 1180
Loss of epoch 1180 = 2.7861374268417096
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1180. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.792132
      epoch  training_loss
1175   1176       2.739682
1176   1177       2.729184
1177   1178       2.754808
1178   1179       2.759652
1179   1180       2.786137
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
113       1140  0.015276  0.074159      0.365316   0.366565
114       1150  0.015271  0.074550      0.365672   0.366899
115       1160  0.015336  0.072958      0.365223   0.366489
116       1170  0.015254  0.073295      0.367587   0.368900
117       1180  0.015199  0.073108      0.365860   0.367059
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
113     1140.0  0.972619  0.980063  ...  0.957811  0.953657  0.941929
114     1150.0  0.972308  0.979946  ...  0.957892  0.953331  0.944291
115     1160.0  0.972718  0.980168  ...  0.957648  0.953494  0.939322
116     1170.0  0.972395  0.980054  ...  0.957403  0.953331  0.941684
117     1180.0  0.972093  0.979837  ...  0.957729  0.953331  0.943313

[5 rows x 13 columns]
process: 50 / 291. Epoch 1181
process: 100 / 291. Epoch 1181
process: 150 / 291. Epoch 1181
process: 200 / 291. Epoch 1181
process: 250 / 291. Epoch 1181
process: 291 / 291. Epoch 1181
Loss of epoch 1181 = 2.7837954386812713
process: 50 / 291. Epoch 1182
process: 100 / 291. Epoch 1182
process: 150 / 291. Epoch 1182
process: 200 / 291. Epoch 1182
process: 250 / 291. Epoch 1182
process: 291 / 291. Epoch 1182
Loss of epoch 1182 = 2.828272239449098
process: 50 / 291. Epoch 1183
process: 100 / 291. Epoch 1183
process: 150 / 291. Epoch 1183
process: 200 / 291. Epoch 1183
process: 250 / 291. Epoch 1183
process: 291 / 291. Epoch 1183
Loss of epoch 1183 = 2.819016289465206
process: 50 / 291. Epoch 1184
process: 100 / 291. Epoch 1184
process: 150 / 291. Epoch 1184
process: 200 / 291. Epoch 1184
process: 250 / 291. Epoch 1184
process: 291 / 291. Epoch 1184
Loss of epoch 1184 = 2.7470117942574097
process: 50 / 291. Epoch 1185
process: 100 / 291. Epoch 1185
process: 150 / 291. Epoch 1185
process: 200 / 291. Epoch 1185
process: 250 / 291. Epoch 1185
process: 291 / 291. Epoch 1185
Loss of epoch 1185 = 2.710398670733999
process: 50 / 291. Epoch 1186
process: 100 / 291. Epoch 1186
process: 150 / 291. Epoch 1186
process: 200 / 291. Epoch 1186
process: 250 / 291. Epoch 1186
process: 291 / 291. Epoch 1186
Loss of epoch 1186 = 2.728819752067225
process: 50 / 291. Epoch 1187
process: 100 / 291. Epoch 1187
process: 150 / 291. Epoch 1187
process: 200 / 291. Epoch 1187
process: 250 / 291. Epoch 1187
process: 291 / 291. Epoch 1187
Loss of epoch 1187 = 2.8507977777330327
process: 50 / 291. Epoch 1188
process: 100 / 291. Epoch 1188
process: 150 / 291. Epoch 1188
process: 200 / 291. Epoch 1188
process: 250 / 291. Epoch 1188
process: 291 / 291. Epoch 1188
Loss of epoch 1188 = 2.844031055358677
process: 50 / 291. Epoch 1189
process: 100 / 291. Epoch 1189
process: 150 / 291. Epoch 1189
process: 200 / 291. Epoch 1189
process: 250 / 291. Epoch 1189
process: 291 / 291. Epoch 1189
Loss of epoch 1189 = 2.7460153061909365
process: 50 / 291. Epoch 1190
process: 100 / 291. Epoch 1190
process: 150 / 291. Epoch 1190
process: 200 / 291. Epoch 1190
process: 250 / 291. Epoch 1190
process: 291 / 291. Epoch 1190
Loss of epoch 1190 = 2.730796997489798
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1190. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.780054
      epoch  training_loss
1185   1186       2.728820
1186   1187       2.850798
1187   1188       2.844031
1188   1189       2.746015
1189   1190       2.730797
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
114       1150  0.015271  0.074550      0.365672   0.366899
115       1160  0.015336  0.072958      0.365223   0.366489
116       1170  0.015254  0.073295      0.367587   0.368900
117       1180  0.015199  0.073108      0.365860   0.367059
118       1190  0.015499  0.071057      0.366716   0.367978
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
114     1150.0  0.972308  0.979946  ...  0.957892  0.953331  0.944291
115     1160.0  0.972718  0.980168  ...  0.957648  0.953494  0.939322
116     1170.0  0.972395  0.980054  ...  0.957403  0.953331  0.941684
117     1180.0  0.972093  0.979837  ...  0.957729  0.953331  0.943313
118     1190.0  0.973015  0.981042  ...  0.957159  0.953576  0.934110

[5 rows x 13 columns]
process: 50 / 291. Epoch 1191
process: 100 / 291. Epoch 1191
process: 150 / 291. Epoch 1191
process: 200 / 291. Epoch 1191
process: 250 / 291. Epoch 1191
process: 291 / 291. Epoch 1191
Loss of epoch 1191 = 2.7427521276310136
process: 50 / 291. Epoch 1192
process: 100 / 291. Epoch 1192
process: 150 / 291. Epoch 1192
process: 200 / 291. Epoch 1192
process: 250 / 291. Epoch 1192
process: 291 / 291. Epoch 1192
Loss of epoch 1192 = 2.713913330917096
process: 50 / 291. Epoch 1193
process: 100 / 291. Epoch 1193
process: 150 / 291. Epoch 1193
process: 200 / 291. Epoch 1193
process: 250 / 291. Epoch 1193
process: 291 / 291. Epoch 1193
Loss of epoch 1193 = 2.718248924438896
process: 50 / 291. Epoch 1194
process: 100 / 291. Epoch 1194
process: 150 / 291. Epoch 1194
process: 200 / 291. Epoch 1194
process: 250 / 291. Epoch 1194
process: 291 / 291. Epoch 1194
Loss of epoch 1194 = 2.7397213440990122
process: 50 / 291. Epoch 1195
process: 100 / 291. Epoch 1195
process: 150 / 291. Epoch 1195
process: 200 / 291. Epoch 1195
process: 250 / 291. Epoch 1195
process: 291 / 291. Epoch 1195
Loss of epoch 1195 = 2.7742030612381874
process: 50 / 291. Epoch 1196
process: 100 / 291. Epoch 1196
process: 150 / 291. Epoch 1196
process: 200 / 291. Epoch 1196
process: 250 / 291. Epoch 1196
process: 291 / 291. Epoch 1196
Loss of epoch 1196 = 2.7406905656008376
process: 50 / 291. Epoch 1197
process: 100 / 291. Epoch 1197
process: 150 / 291. Epoch 1197
process: 200 / 291. Epoch 1197
process: 250 / 291. Epoch 1197
process: 291 / 291. Epoch 1197
Loss of epoch 1197 = 2.78497733938735
process: 50 / 291. Epoch 1198
process: 100 / 291. Epoch 1198
process: 150 / 291. Epoch 1198
process: 200 / 291. Epoch 1198
process: 250 / 291. Epoch 1198
process: 291 / 291. Epoch 1198
Loss of epoch 1198 = 2.7751448064325603
process: 50 / 291. Epoch 1199
process: 100 / 291. Epoch 1199
process: 150 / 291. Epoch 1199
process: 200 / 291. Epoch 1199
process: 250 / 291. Epoch 1199
process: 291 / 291. Epoch 1199
Loss of epoch 1199 = 2.7458101777276633
process: 50 / 291. Epoch 1200
process: 100 / 291. Epoch 1200
process: 150 / 291. Epoch 1200
process: 200 / 291. Epoch 1200
process: 250 / 291. Epoch 1200
process: 291 / 291. Epoch 1200
Loss of epoch 1200 = 2.789380050606744
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1200. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.791609
      epoch  training_loss
1195   1196       2.740691
1196   1197       2.784977
1197   1198       2.775145
1198   1199       2.745810
1199   1200       2.789380
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
115       1160  0.015336  0.072958      0.365223   0.366489
116       1170  0.015254  0.073295      0.367587   0.368900
117       1180  0.015199  0.073108      0.365860   0.367059
118       1190  0.015499  0.071057      0.366716   0.367978
119       1200  0.015258  0.072951      0.367018   0.368292
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
115     1160.0  0.972718  0.980168  ...  0.957648  0.953494  0.939322
116     1170.0  0.972395  0.980054  ...  0.957403  0.953331  0.941684
117     1180.0  0.972093  0.979837  ...  0.957729  0.953331  0.943313
118     1190.0  0.973015  0.981042  ...  0.957159  0.953576  0.934110
119     1200.0  0.972188  0.980172  ...  0.957485  0.953657  0.942417

[5 rows x 13 columns]
process: 50 / 291. Epoch 1201
process: 100 / 291. Epoch 1201
process: 150 / 291. Epoch 1201
process: 200 / 291. Epoch 1201
process: 250 / 291. Epoch 1201
process: 291 / 291. Epoch 1201
Loss of epoch 1201 = 2.7426564849119415
process: 50 / 291. Epoch 1202
process: 100 / 291. Epoch 1202
process: 150 / 291. Epoch 1202
process: 200 / 291. Epoch 1202
process: 250 / 291. Epoch 1202
process: 291 / 291. Epoch 1202
Loss of epoch 1202 = 2.7660100877899483
process: 50 / 291. Epoch 1203
process: 100 / 291. Epoch 1203
process: 150 / 291. Epoch 1203
process: 200 / 291. Epoch 1203
process: 250 / 291. Epoch 1203
process: 291 / 291. Epoch 1203
Loss of epoch 1203 = 2.797231562768471
process: 50 / 291. Epoch 1204
process: 100 / 291. Epoch 1204
process: 150 / 291. Epoch 1204
process: 200 / 291. Epoch 1204
process: 250 / 291. Epoch 1204
process: 291 / 291. Epoch 1204
Loss of epoch 1204 = 2.7744344075520835
process: 50 / 291. Epoch 1205
process: 100 / 291. Epoch 1205
process: 150 / 291. Epoch 1205
process: 200 / 291. Epoch 1205
process: 250 / 291. Epoch 1205
process: 291 / 291. Epoch 1205
Loss of epoch 1205 = 2.7387712091924397
process: 50 / 291. Epoch 1206
process: 100 / 291. Epoch 1206
process: 150 / 291. Epoch 1206
process: 200 / 291. Epoch 1206
process: 250 / 291. Epoch 1206
process: 291 / 291. Epoch 1206
Loss of epoch 1206 = 2.7641190466602232
process: 50 / 291. Epoch 1207
process: 100 / 291. Epoch 1207
process: 150 / 291. Epoch 1207
process: 200 / 291. Epoch 1207
process: 250 / 291. Epoch 1207
process: 291 / 291. Epoch 1207
Loss of epoch 1207 = 2.732726421552835
process: 50 / 291. Epoch 1208
process: 100 / 291. Epoch 1208
process: 150 / 291. Epoch 1208
process: 200 / 291. Epoch 1208
process: 250 / 291. Epoch 1208
process: 291 / 291. Epoch 1208
Loss of epoch 1208 = 2.7411136168384878
process: 50 / 291. Epoch 1209
process: 100 / 291. Epoch 1209
process: 150 / 291. Epoch 1209
process: 200 / 291. Epoch 1209
process: 250 / 291. Epoch 1209
process: 291 / 291. Epoch 1209
Loss of epoch 1209 = 2.795509364596757
process: 50 / 291. Epoch 1210
process: 100 / 291. Epoch 1210
process: 150 / 291. Epoch 1210
process: 200 / 291. Epoch 1210
process: 250 / 291. Epoch 1210
process: 291 / 291. Epoch 1210
Loss of epoch 1210 = 2.8100783095736683
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1210. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.793103
      epoch  training_loss
1205   1206       2.764119
1206   1207       2.732726
1207   1208       2.741114
1208   1209       2.795509
1209   1210       2.810078
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
116       1170  0.015254  0.073295      0.367587   0.368900
117       1180  0.015199  0.073108      0.365860   0.367059
118       1190  0.015499  0.071057      0.366716   0.367978
119       1200  0.015258  0.072951      0.367018   0.368292
120       1210  0.015123  0.072993      0.367969   0.369245
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
116     1170.0  0.972395  0.980054  ...  0.957403  0.953331  0.941684
117     1180.0  0.972093  0.979837  ...  0.957729  0.953331  0.943313
118     1190.0  0.973015  0.981042  ...  0.957159  0.953576  0.934110
119     1200.0  0.972188  0.980172  ...  0.957485  0.953657  0.942417
120     1210.0  0.972105  0.979839  ...  0.958055  0.953413  0.942662

[5 rows x 13 columns]
process: 50 / 291. Epoch 1211
process: 100 / 291. Epoch 1211
process: 150 / 291. Epoch 1211
process: 200 / 291. Epoch 1211
process: 250 / 291. Epoch 1211
process: 291 / 291. Epoch 1211
Loss of epoch 1211 = 2.7927791425042954
process: 50 / 291. Epoch 1212
process: 100 / 291. Epoch 1212
process: 150 / 291. Epoch 1212
process: 200 / 291. Epoch 1212
process: 250 / 291. Epoch 1212
process: 291 / 291. Epoch 1212
Loss of epoch 1212 = 2.715966293492268
process: 50 / 291. Epoch 1213
process: 100 / 291. Epoch 1213
process: 150 / 291. Epoch 1213
process: 200 / 291. Epoch 1213
process: 250 / 291. Epoch 1213
process: 291 / 291. Epoch 1213
Loss of epoch 1213 = 2.6583604321037373
process: 50 / 291. Epoch 1214
process: 100 / 291. Epoch 1214
process: 150 / 291. Epoch 1214
process: 200 / 291. Epoch 1214
process: 250 / 291. Epoch 1214
process: 291 / 291. Epoch 1214
Loss of epoch 1214 = 2.72619545009128
process: 50 / 291. Epoch 1215
process: 100 / 291. Epoch 1215
process: 150 / 291. Epoch 1215
process: 200 / 291. Epoch 1215
process: 250 / 291. Epoch 1215
process: 291 / 291. Epoch 1215
Loss of epoch 1215 = 2.713395685674399
process: 50 / 291. Epoch 1216
process: 100 / 291. Epoch 1216
process: 150 / 291. Epoch 1216
process: 200 / 291. Epoch 1216
process: 250 / 291. Epoch 1216
process: 291 / 291. Epoch 1216
Loss of epoch 1216 = 2.727196762242268
process: 50 / 291. Epoch 1217
process: 100 / 291. Epoch 1217
process: 150 / 291. Epoch 1217
process: 200 / 291. Epoch 1217
process: 250 / 291. Epoch 1217
process: 291 / 291. Epoch 1217
Loss of epoch 1217 = 2.8025065943137886
process: 50 / 291. Epoch 1218
process: 100 / 291. Epoch 1218
process: 150 / 291. Epoch 1218
process: 200 / 291. Epoch 1218
process: 250 / 291. Epoch 1218
process: 291 / 291. Epoch 1218
Loss of epoch 1218 = 2.7937821325977232
process: 50 / 291. Epoch 1219
process: 100 / 291. Epoch 1219
process: 150 / 291. Epoch 1219
process: 200 / 291. Epoch 1219
process: 250 / 291. Epoch 1219
process: 291 / 291. Epoch 1219
Loss of epoch 1219 = 2.7717692057291665
process: 50 / 291. Epoch 1220
process: 100 / 291. Epoch 1220
process: 150 / 291. Epoch 1220
process: 200 / 291. Epoch 1220
process: 250 / 291. Epoch 1220
process: 291 / 291. Epoch 1220
Loss of epoch 1220 = 2.636756503704897
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1220. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.787161
      epoch  training_loss
1215   1216       2.727197
1216   1217       2.802507
1217   1218       2.793782
1218   1219       2.771769
1219   1220       2.636757
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
117       1180  0.015199  0.073108      0.365860   0.367059
118       1190  0.015499  0.071057      0.366716   0.367978
119       1200  0.015258  0.072951      0.367018   0.368292
120       1210  0.015123  0.072993      0.367969   0.369245
121       1220  0.015325  0.071726      0.369468   0.370791
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
117     1180.0  0.972093  0.979837  ...  0.957729  0.953331  0.943313
118     1190.0  0.973015  0.981042  ...  0.957159  0.953576  0.934110
119     1200.0  0.972188  0.980172  ...  0.957485  0.953657  0.942417
120     1210.0  0.972105  0.979839  ...  0.958055  0.953413  0.942662
121     1220.0  0.972078  0.980268  ...  0.957322  0.953168  0.940951

[5 rows x 13 columns]
process: 50 / 291. Epoch 1221
process: 100 / 291. Epoch 1221
process: 150 / 291. Epoch 1221
process: 200 / 291. Epoch 1221
process: 250 / 291. Epoch 1221
process: 291 / 291. Epoch 1221
Loss of epoch 1221 = 2.707253157887672
process: 50 / 291. Epoch 1222
process: 100 / 291. Epoch 1222
process: 150 / 291. Epoch 1222
process: 200 / 291. Epoch 1222
process: 250 / 291. Epoch 1222
process: 291 / 291. Epoch 1222
Loss of epoch 1222 = 2.7951800683929338
process: 50 / 291. Epoch 1223
process: 100 / 291. Epoch 1223
process: 150 / 291. Epoch 1223
process: 200 / 291. Epoch 1223
process: 250 / 291. Epoch 1223
process: 291 / 291. Epoch 1223
Loss of epoch 1223 = 2.7588930949312713
process: 50 / 291. Epoch 1224
process: 100 / 291. Epoch 1224
process: 150 / 291. Epoch 1224
process: 200 / 291. Epoch 1224
process: 250 / 291. Epoch 1224
process: 291 / 291. Epoch 1224
Loss of epoch 1224 = 2.7339869758107818
process: 50 / 291. Epoch 1225
process: 100 / 291. Epoch 1225
process: 150 / 291. Epoch 1225
process: 200 / 291. Epoch 1225
process: 250 / 291. Epoch 1225
process: 291 / 291. Epoch 1225
Loss of epoch 1225 = 2.7035570701782645
process: 50 / 291. Epoch 1226
process: 100 / 291. Epoch 1226
process: 150 / 291. Epoch 1226
process: 200 / 291. Epoch 1226
process: 250 / 291. Epoch 1226
process: 291 / 291. Epoch 1226
Loss of epoch 1226 = 2.760518182184278
process: 50 / 291. Epoch 1227
process: 100 / 291. Epoch 1227
process: 150 / 291. Epoch 1227
process: 200 / 291. Epoch 1227
process: 250 / 291. Epoch 1227
process: 291 / 291. Epoch 1227
Loss of epoch 1227 = 2.7818544787639605
process: 50 / 291. Epoch 1228
process: 100 / 291. Epoch 1228
process: 150 / 291. Epoch 1228
process: 200 / 291. Epoch 1228
process: 250 / 291. Epoch 1228
process: 291 / 291. Epoch 1228
Loss of epoch 1228 = 2.7939700621509878
process: 50 / 291. Epoch 1229
process: 100 / 291. Epoch 1229
process: 150 / 291. Epoch 1229
process: 200 / 291. Epoch 1229
process: 250 / 291. Epoch 1229
process: 291 / 291. Epoch 1229
Loss of epoch 1229 = 2.7059263249033507
process: 50 / 291. Epoch 1230
process: 100 / 291. Epoch 1230
process: 150 / 291. Epoch 1230
process: 200 / 291. Epoch 1230
process: 250 / 291. Epoch 1230
process: 291 / 291. Epoch 1230
Loss of epoch 1230 = 2.743543067748604
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1230. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.785444
      epoch  training_loss
1225   1226       2.760518
1226   1227       2.781854
1227   1228       2.793970
1228   1229       2.705926
1229   1230       2.743543
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
118       1190  0.015499  0.071057      0.366716   0.367978
119       1200  0.015258  0.072951      0.367018   0.368292
120       1210  0.015123  0.072993      0.367969   0.369245
121       1220  0.015325  0.071726      0.369468   0.370791
122       1230  0.015273  0.071523      0.368047   0.369310
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
118     1190.0  0.973015  0.981042  ...  0.957159  0.953576  0.934110
119     1200.0  0.972188  0.980172  ...  0.957485  0.953657  0.942417
120     1210.0  0.972105  0.979839  ...  0.958055  0.953413  0.942662
121     1220.0  0.972078  0.980268  ...  0.957322  0.953168  0.940951
122     1230.0  0.972087  0.980942  ...  0.957566  0.953901  0.939648

[5 rows x 13 columns]
process: 50 / 291. Epoch 1231
process: 100 / 291. Epoch 1231
process: 150 / 291. Epoch 1231
process: 200 / 291. Epoch 1231
process: 250 / 291. Epoch 1231
process: 291 / 291. Epoch 1231
Loss of epoch 1231 = 2.711294272511276
process: 50 / 291. Epoch 1232
process: 100 / 291. Epoch 1232
process: 150 / 291. Epoch 1232
process: 200 / 291. Epoch 1232
process: 250 / 291. Epoch 1232
process: 291 / 291. Epoch 1232
Loss of epoch 1232 = 2.7137988113455758
process: 50 / 291. Epoch 1233
process: 100 / 291. Epoch 1233
process: 150 / 291. Epoch 1233
process: 200 / 291. Epoch 1233
process: 250 / 291. Epoch 1233
process: 291 / 291. Epoch 1233
Loss of epoch 1233 = 2.7417166274028135
process: 50 / 291. Epoch 1234
process: 100 / 291. Epoch 1234
process: 150 / 291. Epoch 1234
process: 200 / 291. Epoch 1234
process: 250 / 291. Epoch 1234
process: 291 / 291. Epoch 1234
Loss of epoch 1234 = 2.7565129335803267
process: 50 / 291. Epoch 1235
process: 100 / 291. Epoch 1235
process: 150 / 291. Epoch 1235
process: 200 / 291. Epoch 1235
process: 250 / 291. Epoch 1235
process: 291 / 291. Epoch 1235
Loss of epoch 1235 = 2.78369140625
process: 50 / 291. Epoch 1236
process: 100 / 291. Epoch 1236
process: 150 / 291. Epoch 1236
process: 200 / 291. Epoch 1236
process: 250 / 291. Epoch 1236
process: 291 / 291. Epoch 1236
Loss of epoch 1236 = 2.7011460766349873
process: 50 / 291. Epoch 1237
process: 100 / 291. Epoch 1237
process: 150 / 291. Epoch 1237
process: 200 / 291. Epoch 1237
process: 250 / 291. Epoch 1237
process: 291 / 291. Epoch 1237
Loss of epoch 1237 = 2.7576623241516325
process: 50 / 291. Epoch 1238
process: 100 / 291. Epoch 1238
process: 150 / 291. Epoch 1238
process: 200 / 291. Epoch 1238
process: 250 / 291. Epoch 1238
process: 291 / 291. Epoch 1238
Loss of epoch 1238 = 2.7780222679741193
process: 50 / 291. Epoch 1239
process: 100 / 291. Epoch 1239
process: 150 / 291. Epoch 1239
process: 200 / 291. Epoch 1239
process: 250 / 291. Epoch 1239
process: 291 / 291. Epoch 1239
Loss of epoch 1239 = 2.714945685003222
process: 50 / 291. Epoch 1240
process: 100 / 291. Epoch 1240
process: 150 / 291. Epoch 1240
process: 200 / 291. Epoch 1240
process: 250 / 291. Epoch 1240
process: 291 / 291. Epoch 1240
Loss of epoch 1240 = 2.671537104341173
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1240. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.782499
      epoch  training_loss
1235   1236       2.701146
1236   1237       2.757662
1237   1238       2.778022
1238   1239       2.714946
1239   1240       2.671537
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
119       1200  0.015258  0.072951      0.367018   0.368292
120       1210  0.015123  0.072993      0.367969   0.369245
121       1220  0.015325  0.071726      0.369468   0.370791
122       1230  0.015273  0.071523      0.368047   0.369310
123       1240  0.015461  0.070454      0.370011   0.371361
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
119     1200.0  0.972188  0.980172  ...  0.957485  0.953657  0.942417
120     1210.0  0.972105  0.979839  ...  0.958055  0.953413  0.942662
121     1220.0  0.972078  0.980268  ...  0.957322  0.953168  0.940951
122     1230.0  0.972087  0.980942  ...  0.957566  0.953901  0.939648
123     1240.0  0.972811  0.980822  ...  0.957322  0.953494  0.937042

[5 rows x 13 columns]
process: 50 / 291. Epoch 1241
process: 100 / 291. Epoch 1241
process: 150 / 291. Epoch 1241
process: 200 / 291. Epoch 1241
process: 250 / 291. Epoch 1241
process: 291 / 291. Epoch 1241
Loss of epoch 1241 = 2.7005434855562713
process: 50 / 291. Epoch 1242
process: 100 / 291. Epoch 1242
process: 150 / 291. Epoch 1242
process: 200 / 291. Epoch 1242
process: 250 / 291. Epoch 1242
process: 291 / 291. Epoch 1242
Loss of epoch 1242 = 2.698937065412908
process: 50 / 291. Epoch 1243
process: 100 / 291. Epoch 1243
process: 150 / 291. Epoch 1243
process: 200 / 291. Epoch 1243
process: 250 / 291. Epoch 1243
process: 291 / 291. Epoch 1243
Loss of epoch 1243 = 2.762828289438359
process: 50 / 291. Epoch 1244
process: 100 / 291. Epoch 1244
process: 150 / 291. Epoch 1244
process: 200 / 291. Epoch 1244
process: 250 / 291. Epoch 1244
process: 291 / 291. Epoch 1244
Loss of epoch 1244 = 2.754091662639605
process: 50 / 291. Epoch 1245
process: 100 / 291. Epoch 1245
process: 150 / 291. Epoch 1245
process: 200 / 291. Epoch 1245
process: 250 / 291. Epoch 1245
process: 291 / 291. Epoch 1245
Loss of epoch 1245 = 2.747423519383591
process: 50 / 291. Epoch 1246
process: 100 / 291. Epoch 1246
process: 150 / 291. Epoch 1246
process: 200 / 291. Epoch 1246
process: 250 / 291. Epoch 1246
process: 291 / 291. Epoch 1246
Loss of epoch 1246 = 2.685654263316151
process: 50 / 291. Epoch 1247
process: 100 / 291. Epoch 1247
process: 150 / 291. Epoch 1247
process: 200 / 291. Epoch 1247
process: 250 / 291. Epoch 1247
process: 291 / 291. Epoch 1247
Loss of epoch 1247 = 2.7665273135470363
process: 50 / 291. Epoch 1248
process: 100 / 291. Epoch 1248
process: 150 / 291. Epoch 1248
process: 200 / 291. Epoch 1248
process: 250 / 291. Epoch 1248
process: 291 / 291. Epoch 1248
Loss of epoch 1248 = 2.7323224569104383
process: 50 / 291. Epoch 1249
process: 100 / 291. Epoch 1249
process: 150 / 291. Epoch 1249
process: 200 / 291. Epoch 1249
process: 250 / 291. Epoch 1249
process: 291 / 291. Epoch 1249
Loss of epoch 1249 = 2.6970420391698884
process: 50 / 291. Epoch 1250
process: 100 / 291. Epoch 1250
process: 150 / 291. Epoch 1250
process: 200 / 291. Epoch 1250
process: 250 / 291. Epoch 1250
process: 291 / 291. Epoch 1250
Loss of epoch 1250 = 2.7296536894598367
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1250. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.784757
      epoch  training_loss
1245   1246       2.685654
1246   1247       2.766527
1247   1248       2.732322
1248   1249       2.697042
1249   1250       2.729654
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
120       1210  0.015123  0.072993      0.367969   0.369245
121       1220  0.015325  0.071726      0.369468   0.370791
122       1230  0.015273  0.071523      0.368047   0.369310
123       1240  0.015461  0.070454      0.370011   0.371361
124       1250  0.015345  0.071099      0.369909   0.371249
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
120     1210.0  0.972105  0.979839  ...  0.958055  0.953413  0.942662
121     1220.0  0.972078  0.980268  ...  0.957322  0.953168  0.940951
122     1230.0  0.972087  0.980942  ...  0.957566  0.953901  0.939648
123     1240.0  0.972811  0.980822  ...  0.957322  0.953494  0.937042
124     1250.0  0.972392  0.980601  ...  0.957322  0.953413  0.937856

[5 rows x 13 columns]
process: 50 / 291. Epoch 1251
process: 100 / 291. Epoch 1251
process: 150 / 291. Epoch 1251
process: 200 / 291. Epoch 1251
process: 250 / 291. Epoch 1251
process: 291 / 291. Epoch 1251
Loss of epoch 1251 = 2.700660731784257
process: 50 / 291. Epoch 1252
process: 100 / 291. Epoch 1252
process: 150 / 291. Epoch 1252
process: 200 / 291. Epoch 1252
process: 250 / 291. Epoch 1252
process: 291 / 291. Epoch 1252
Loss of epoch 1252 = 2.716044317815722
process: 50 / 291. Epoch 1253
process: 100 / 291. Epoch 1253
process: 150 / 291. Epoch 1253
process: 200 / 291. Epoch 1253
process: 250 / 291. Epoch 1253
process: 291 / 291. Epoch 1253
Loss of epoch 1253 = 2.7029584642128435
process: 50 / 291. Epoch 1254
process: 100 / 291. Epoch 1254
process: 150 / 291. Epoch 1254
process: 200 / 291. Epoch 1254
process: 250 / 291. Epoch 1254
process: 291 / 291. Epoch 1254
Loss of epoch 1254 = 2.7787060295183634
process: 50 / 291. Epoch 1255
process: 100 / 291. Epoch 1255
process: 150 / 291. Epoch 1255
process: 200 / 291. Epoch 1255
process: 250 / 291. Epoch 1255
process: 291 / 291. Epoch 1255
Loss of epoch 1255 = 2.7385816016967355
process: 50 / 291. Epoch 1256
process: 100 / 291. Epoch 1256
process: 150 / 291. Epoch 1256
process: 200 / 291. Epoch 1256
process: 250 / 291. Epoch 1256
process: 291 / 291. Epoch 1256
Loss of epoch 1256 = 2.7609573836179124
process: 50 / 291. Epoch 1257
process: 100 / 291. Epoch 1257
process: 150 / 291. Epoch 1257
process: 200 / 291. Epoch 1257
process: 250 / 291. Epoch 1257
process: 291 / 291. Epoch 1257
Loss of epoch 1257 = 2.7306828974038875
process: 50 / 291. Epoch 1258
process: 100 / 291. Epoch 1258
process: 150 / 291. Epoch 1258
process: 200 / 291. Epoch 1258
process: 250 / 291. Epoch 1258
process: 291 / 291. Epoch 1258
Loss of epoch 1258 = 2.7216515819641325
process: 50 / 291. Epoch 1259
process: 100 / 291. Epoch 1259
process: 150 / 291. Epoch 1259
process: 200 / 291. Epoch 1259
process: 250 / 291. Epoch 1259
process: 291 / 291. Epoch 1259
Loss of epoch 1259 = 2.7216033411189864
process: 50 / 291. Epoch 1260
process: 100 / 291. Epoch 1260
process: 150 / 291. Epoch 1260
process: 200 / 291. Epoch 1260
process: 250 / 291. Epoch 1260
process: 291 / 291. Epoch 1260
Loss of epoch 1260 = 2.7123721407860826
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1260. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.792192
      epoch  training_loss
1255   1256       2.760957
1256   1257       2.730683
1257   1258       2.721652
1258   1259       2.721603
1259   1260       2.712372
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
121       1220  0.015325  0.071726      0.369468   0.370791
122       1230  0.015273  0.071523      0.368047   0.369310
123       1240  0.015461  0.070454      0.370011   0.371361
124       1250  0.015345  0.071099      0.369909   0.371249
125       1260  0.015205  0.072707      0.370585   0.371925
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
121     1220.0  0.972078  0.980268  ...  0.957322  0.953168  0.940951
122     1230.0  0.972087  0.980942  ...  0.957566  0.953901  0.939648
123     1240.0  0.972811  0.980822  ...  0.957322  0.953494  0.937042
124     1250.0  0.972392  0.980601  ...  0.957322  0.953413  0.937856
125     1260.0  0.971669  0.980399  ...  0.957566  0.953983  0.943069

[5 rows x 13 columns]
process: 50 / 291. Epoch 1261
process: 100 / 291. Epoch 1261
process: 150 / 291. Epoch 1261
process: 200 / 291. Epoch 1261
process: 250 / 291. Epoch 1261
process: 291 / 291. Epoch 1261
Loss of epoch 1261 = 2.7036206222481742
process: 50 / 291. Epoch 1262
process: 100 / 291. Epoch 1262
process: 150 / 291. Epoch 1262
process: 200 / 291. Epoch 1262
process: 250 / 291. Epoch 1262
process: 291 / 291. Epoch 1262
Loss of epoch 1262 = 2.6587100733596434
process: 50 / 291. Epoch 1263
process: 100 / 291. Epoch 1263
process: 150 / 291. Epoch 1263
process: 200 / 291. Epoch 1263
process: 250 / 291. Epoch 1263
process: 291 / 291. Epoch 1263
Loss of epoch 1263 = 2.7182212383886384
process: 50 / 291. Epoch 1264
process: 100 / 291. Epoch 1264
process: 150 / 291. Epoch 1264
process: 200 / 291. Epoch 1264
process: 250 / 291. Epoch 1264
process: 291 / 291. Epoch 1264
Loss of epoch 1264 = 2.7224435707957473
process: 50 / 291. Epoch 1265
process: 100 / 291. Epoch 1265
process: 150 / 291. Epoch 1265
process: 200 / 291. Epoch 1265
process: 250 / 291. Epoch 1265
process: 291 / 291. Epoch 1265
Loss of epoch 1265 = 2.6703195473582473
process: 50 / 291. Epoch 1266
process: 100 / 291. Epoch 1266
process: 150 / 291. Epoch 1266
process: 200 / 291. Epoch 1266
process: 250 / 291. Epoch 1266
process: 291 / 291. Epoch 1266
Loss of epoch 1266 = 2.710289604475408
process: 50 / 291. Epoch 1267
process: 100 / 291. Epoch 1267
process: 150 / 291. Epoch 1267
process: 200 / 291. Epoch 1267
process: 250 / 291. Epoch 1267
process: 291 / 291. Epoch 1267
Loss of epoch 1267 = 2.7439124248281788
process: 50 / 291. Epoch 1268
process: 100 / 291. Epoch 1268
process: 150 / 291. Epoch 1268
process: 200 / 291. Epoch 1268
process: 250 / 291. Epoch 1268
process: 291 / 291. Epoch 1268
Loss of epoch 1268 = 2.703749823816044
process: 50 / 291. Epoch 1269
process: 100 / 291. Epoch 1269
process: 150 / 291. Epoch 1269
process: 200 / 291. Epoch 1269
process: 250 / 291. Epoch 1269
process: 291 / 291. Epoch 1269
Loss of epoch 1269 = 2.705141047841495
process: 50 / 291. Epoch 1270
process: 100 / 291. Epoch 1270
process: 150 / 291. Epoch 1270
process: 200 / 291. Epoch 1270
process: 250 / 291. Epoch 1270
process: 291 / 291. Epoch 1270
Loss of epoch 1270 = 2.7556718649323453
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1270. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.791195
      epoch  training_loss
1265   1266       2.710290
1266   1267       2.743912
1267   1268       2.703750
1268   1269       2.705141
1269   1270       2.755672
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
122       1230  0.015273  0.071523      0.368047   0.369310
123       1240  0.015461  0.070454      0.370011   0.371361
124       1250  0.015345  0.071099      0.369909   0.371249
125       1260  0.015205  0.072707      0.370585   0.371925
126       1270  0.015229  0.071627      0.370363   0.371686
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
122     1230.0  0.972087  0.980942  ...  0.957566  0.953901  0.939648
123     1240.0  0.972811  0.980822  ...  0.957322  0.953494  0.937042
124     1250.0  0.972392  0.980601  ...  0.957322  0.953413  0.937856
125     1260.0  0.971669  0.980399  ...  0.957566  0.953983  0.943069
126     1270.0  0.971970  0.980159  ...  0.957241  0.953168  0.942743

[5 rows x 13 columns]
process: 50 / 291. Epoch 1271
process: 100 / 291. Epoch 1271
process: 150 / 291. Epoch 1271
process: 200 / 291. Epoch 1271
process: 250 / 291. Epoch 1271
process: 291 / 291. Epoch 1271
Loss of epoch 1271 = 2.7746770799774483
process: 50 / 291. Epoch 1272
process: 100 / 291. Epoch 1272
process: 150 / 291. Epoch 1272
process: 200 / 291. Epoch 1272
process: 250 / 291. Epoch 1272
process: 291 / 291. Epoch 1272
Loss of epoch 1272 = 2.702488430586877
process: 50 / 291. Epoch 1273
process: 100 / 291. Epoch 1273
process: 150 / 291. Epoch 1273
process: 200 / 291. Epoch 1273
process: 250 / 291. Epoch 1273
process: 291 / 291. Epoch 1273
Loss of epoch 1273 = 2.702074608032646
process: 50 / 291. Epoch 1274
process: 100 / 291. Epoch 1274
process: 150 / 291. Epoch 1274
process: 200 / 291. Epoch 1274
process: 250 / 291. Epoch 1274
process: 291 / 291. Epoch 1274
Loss of epoch 1274 = 2.658383084326675
process: 50 / 291. Epoch 1275
process: 100 / 291. Epoch 1275
process: 150 / 291. Epoch 1275
process: 200 / 291. Epoch 1275
process: 250 / 291. Epoch 1275
process: 291 / 291. Epoch 1275
Loss of epoch 1275 = 2.6978801714186
process: 50 / 291. Epoch 1276
process: 100 / 291. Epoch 1276
process: 150 / 291. Epoch 1276
process: 200 / 291. Epoch 1276
process: 250 / 291. Epoch 1276
process: 291 / 291. Epoch 1276
Loss of epoch 1276 = 2.761927024605348
process: 50 / 291. Epoch 1277
process: 100 / 291. Epoch 1277
process: 150 / 291. Epoch 1277
process: 200 / 291. Epoch 1277
process: 250 / 291. Epoch 1277
process: 291 / 291. Epoch 1277
Loss of epoch 1277 = 2.7333516648544887
process: 50 / 291. Epoch 1278
process: 100 / 291. Epoch 1278
process: 150 / 291. Epoch 1278
process: 200 / 291. Epoch 1278
process: 250 / 291. Epoch 1278
process: 291 / 291. Epoch 1278
Loss of epoch 1278 = 2.6710272195822595
process: 50 / 291. Epoch 1279
process: 100 / 291. Epoch 1279
process: 150 / 291. Epoch 1279
process: 200 / 291. Epoch 1279
process: 250 / 291. Epoch 1279
process: 291 / 291. Epoch 1279
Loss of epoch 1279 = 2.670826915203501
process: 50 / 291. Epoch 1280
process: 100 / 291. Epoch 1280
process: 150 / 291. Epoch 1280
process: 200 / 291. Epoch 1280
process: 250 / 291. Epoch 1280
process: 291 / 291. Epoch 1280
Loss of epoch 1280 = 2.678491336783183
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1280. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.790313
      epoch  training_loss
1275   1276       2.761927
1276   1277       2.733352
1277   1278       2.671027
1278   1279       2.670827
1279   1280       2.678491
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
123       1240  0.015461  0.070454      0.370011   0.371361
124       1250  0.015345  0.071099      0.369909   0.371249
125       1260  0.015205  0.072707      0.370585   0.371925
126       1270  0.015229  0.071627      0.370363   0.371686
127       1280  0.015302  0.071823      0.371154   0.372474
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
123     1240.0  0.972811  0.980822  ...  0.957322  0.953494  0.937042
124     1250.0  0.972392  0.980601  ...  0.957322  0.953413  0.937856
125     1260.0  0.971669  0.980399  ...  0.957566  0.953983  0.943069
126     1270.0  0.971970  0.980159  ...  0.957241  0.953168  0.942743
127     1280.0  0.972198  0.980388  ...  0.957729  0.953576  0.941929

[5 rows x 13 columns]
process: 50 / 291. Epoch 1281
process: 100 / 291. Epoch 1281
process: 150 / 291. Epoch 1281
process: 200 / 291. Epoch 1281
process: 250 / 291. Epoch 1281
process: 291 / 291. Epoch 1281
Loss of epoch 1281 = 2.7383089360502577
process: 50 / 291. Epoch 1282
process: 100 / 291. Epoch 1282
process: 150 / 291. Epoch 1282
process: 200 / 291. Epoch 1282
process: 250 / 291. Epoch 1282
process: 291 / 291. Epoch 1282
Loss of epoch 1282 = 2.7358740318272123
process: 50 / 291. Epoch 1283
process: 100 / 291. Epoch 1283
process: 150 / 291. Epoch 1283
process: 200 / 291. Epoch 1283
process: 250 / 291. Epoch 1283
process: 291 / 291. Epoch 1283
Loss of epoch 1283 = 2.7055416565990122
process: 50 / 291. Epoch 1284
process: 100 / 291. Epoch 1284
process: 150 / 291. Epoch 1284
process: 200 / 291. Epoch 1284
process: 250 / 291. Epoch 1284
process: 291 / 291. Epoch 1284
Loss of epoch 1284 = 2.799413307425902
process: 50 / 291. Epoch 1285
process: 100 / 291. Epoch 1285
process: 150 / 291. Epoch 1285
process: 200 / 291. Epoch 1285
process: 250 / 291. Epoch 1285
process: 291 / 291. Epoch 1285
Loss of epoch 1285 = 2.6879006087575172
process: 50 / 291. Epoch 1286
process: 100 / 291. Epoch 1286
process: 150 / 291. Epoch 1286
process: 200 / 291. Epoch 1286
process: 250 / 291. Epoch 1286
process: 291 / 291. Epoch 1286
Loss of epoch 1286 = 2.6724064882678267
process: 50 / 291. Epoch 1287
process: 100 / 291. Epoch 1287
process: 150 / 291. Epoch 1287
process: 200 / 291. Epoch 1287
process: 250 / 291. Epoch 1287
process: 291 / 291. Epoch 1287
Loss of epoch 1287 = 2.7051794307748067
process: 50 / 291. Epoch 1288
process: 100 / 291. Epoch 1288
process: 150 / 291. Epoch 1288
process: 200 / 291. Epoch 1288
process: 250 / 291. Epoch 1288
process: 291 / 291. Epoch 1288
Loss of epoch 1288 = 2.6519095823936856
process: 50 / 291. Epoch 1289
process: 100 / 291. Epoch 1289
process: 150 / 291. Epoch 1289
process: 200 / 291. Epoch 1289
process: 250 / 291. Epoch 1289
process: 291 / 291. Epoch 1289
Loss of epoch 1289 = 2.689541426720898
process: 50 / 291. Epoch 1290
process: 100 / 291. Epoch 1290
process: 150 / 291. Epoch 1290
process: 200 / 291. Epoch 1290
process: 250 / 291. Epoch 1290
process: 291 / 291. Epoch 1290
Loss of epoch 1290 = 2.7391456000993344
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1290. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.784715
      epoch  training_loss
1285   1286       2.672406
1286   1287       2.705179
1287   1288       2.651910
1288   1289       2.689541
1289   1290       2.739146
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
124       1250  0.015345  0.071099      0.369909   0.371249
125       1260  0.015205  0.072707      0.370585   0.371925
126       1270  0.015229  0.071627      0.370363   0.371686
127       1280  0.015302  0.071823      0.371154   0.372474
128       1290  0.015363  0.070713      0.371414   0.372768
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
124     1250.0  0.972392  0.980601  ...  0.957322  0.953413  0.937856
125     1260.0  0.971669  0.980399  ...  0.957566  0.953983  0.943069
126     1270.0  0.971970  0.980159  ...  0.957241  0.953168  0.942743
127     1280.0  0.972198  0.980388  ...  0.957729  0.953576  0.941929
128     1290.0  0.972715  0.980603  ...  0.957566  0.953494  0.937531

[5 rows x 13 columns]
process: 50 / 291. Epoch 1291
process: 100 / 291. Epoch 1291
process: 150 / 291. Epoch 1291
process: 200 / 291. Epoch 1291
process: 250 / 291. Epoch 1291
process: 291 / 291. Epoch 1291
Loss of epoch 1291 = 2.7721161203286084
process: 50 / 291. Epoch 1292
process: 100 / 291. Epoch 1292
process: 150 / 291. Epoch 1292
process: 200 / 291. Epoch 1292
process: 250 / 291. Epoch 1292
process: 291 / 291. Epoch 1292
Loss of epoch 1292 = 2.6907122110583117
process: 50 / 291. Epoch 1293
process: 100 / 291. Epoch 1293
process: 150 / 291. Epoch 1293
process: 200 / 291. Epoch 1293
process: 250 / 291. Epoch 1293
process: 291 / 291. Epoch 1293
Loss of epoch 1293 = 2.6678622006550685
process: 50 / 291. Epoch 1294
process: 100 / 291. Epoch 1294
process: 150 / 291. Epoch 1294
process: 200 / 291. Epoch 1294
process: 250 / 291. Epoch 1294
process: 291 / 291. Epoch 1294
Loss of epoch 1294 = 2.769933956185567
process: 50 / 291. Epoch 1295
process: 100 / 291. Epoch 1295
process: 150 / 291. Epoch 1295
process: 200 / 291. Epoch 1295
process: 250 / 291. Epoch 1295
process: 291 / 291. Epoch 1295
Loss of epoch 1295 = 2.652014453796177
process: 50 / 291. Epoch 1296
process: 100 / 291. Epoch 1296
process: 150 / 291. Epoch 1296
process: 200 / 291. Epoch 1296
process: 250 / 291. Epoch 1296
process: 291 / 291. Epoch 1296
Loss of epoch 1296 = 2.694425287934923
process: 50 / 291. Epoch 1297
process: 100 / 291. Epoch 1297
process: 150 / 291. Epoch 1297
process: 200 / 291. Epoch 1297
process: 250 / 291. Epoch 1297
process: 291 / 291. Epoch 1297
Loss of epoch 1297 = 2.681115429016323
process: 50 / 291. Epoch 1298
process: 100 / 291. Epoch 1298
process: 150 / 291. Epoch 1298
process: 200 / 291. Epoch 1298
process: 250 / 291. Epoch 1298
process: 291 / 291. Epoch 1298
Loss of epoch 1298 = 2.684426009450172
process: 50 / 291. Epoch 1299
process: 100 / 291. Epoch 1299
process: 150 / 291. Epoch 1299
process: 200 / 291. Epoch 1299
process: 250 / 291. Epoch 1299
process: 291 / 291. Epoch 1299
Loss of epoch 1299 = 2.7416933459514605
process: 50 / 291. Epoch 1300
process: 100 / 291. Epoch 1300
process: 150 / 291. Epoch 1300
process: 200 / 291. Epoch 1300
process: 250 / 291. Epoch 1300
process: 291 / 291. Epoch 1300
Loss of epoch 1300 = 2.7371326983999142
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1300. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.789760
      epoch  training_loss
1295   1296       2.694425
1296   1297       2.681115
1297   1298       2.684426
1298   1299       2.741693
1299   1300       2.737133
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
125       1260  0.015205  0.072707      0.370585   0.371925
126       1270  0.015229  0.071627      0.370363   0.371686
127       1280  0.015302  0.071823      0.371154   0.372474
128       1290  0.015363  0.070713      0.371414   0.372768
129       1300  0.015294  0.071147      0.371107   0.372432
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
125     1260.0  0.971669  0.980399  ...  0.957566  0.953983  0.943069
126     1270.0  0.971970  0.980159  ...  0.957241  0.953168  0.942743
127     1280.0  0.972198  0.980388  ...  0.957729  0.953576  0.941929
128     1290.0  0.972715  0.980603  ...  0.957566  0.953494  0.937531
129     1300.0  0.972499  0.980390  ...  0.957403  0.953657  0.942173

[5 rows x 13 columns]
process: 50 / 291. Epoch 1301
process: 100 / 291. Epoch 1301
process: 150 / 291. Epoch 1301
process: 200 / 291. Epoch 1301
process: 250 / 291. Epoch 1301
process: 291 / 291. Epoch 1301
Loss of epoch 1301 = 2.6815286223421393
process: 50 / 291. Epoch 1302
process: 100 / 291. Epoch 1302
process: 150 / 291. Epoch 1302
process: 200 / 291. Epoch 1302
process: 250 / 291. Epoch 1302
process: 291 / 291. Epoch 1302
Loss of epoch 1302 = 2.7496748986522768
process: 50 / 291. Epoch 1303
process: 100 / 291. Epoch 1303
process: 150 / 291. Epoch 1303
process: 200 / 291. Epoch 1303
process: 250 / 291. Epoch 1303
process: 291 / 291. Epoch 1303
Loss of epoch 1303 = 2.6884606220468212
process: 50 / 291. Epoch 1304
process: 100 / 291. Epoch 1304
process: 150 / 291. Epoch 1304
process: 200 / 291. Epoch 1304
process: 250 / 291. Epoch 1304
process: 291 / 291. Epoch 1304
Loss of epoch 1304 = 2.6601988277894115
process: 50 / 291. Epoch 1305
process: 100 / 291. Epoch 1305
process: 150 / 291. Epoch 1305
process: 200 / 291. Epoch 1305
process: 250 / 291. Epoch 1305
process: 291 / 291. Epoch 1305
Loss of epoch 1305 = 2.63531578037747
process: 50 / 291. Epoch 1306
process: 100 / 291. Epoch 1306
process: 150 / 291. Epoch 1306
process: 200 / 291. Epoch 1306
process: 250 / 291. Epoch 1306
process: 291 / 291. Epoch 1306
Loss of epoch 1306 = 2.6980135678425685
process: 50 / 291. Epoch 1307
process: 100 / 291. Epoch 1307
process: 150 / 291. Epoch 1307
process: 200 / 291. Epoch 1307
process: 250 / 291. Epoch 1307
process: 291 / 291. Epoch 1307
Loss of epoch 1307 = 2.788121593776847
process: 50 / 291. Epoch 1308
process: 100 / 291. Epoch 1308
process: 150 / 291. Epoch 1308
process: 200 / 291. Epoch 1308
process: 250 / 291. Epoch 1308
process: 291 / 291. Epoch 1308
Loss of epoch 1308 = 2.678796932050043
process: 50 / 291. Epoch 1309
process: 100 / 291. Epoch 1309
process: 150 / 291. Epoch 1309
process: 200 / 291. Epoch 1309
process: 250 / 291. Epoch 1309
process: 291 / 291. Epoch 1309
Loss of epoch 1309 = 2.6991497446171606
process: 50 / 291. Epoch 1310
process: 100 / 291. Epoch 1310
process: 150 / 291. Epoch 1310
process: 200 / 291. Epoch 1310
process: 250 / 291. Epoch 1310
process: 291 / 291. Epoch 1310
Loss of epoch 1310 = 2.643090736415378
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1310. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.784660
      epoch  training_loss
1305   1306       2.698014
1306   1307       2.788122
1307   1308       2.678797
1308   1309       2.699150
1309   1310       2.643091
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
126       1270  0.015229  0.071627      0.370363   0.371686
127       1280  0.015302  0.071823      0.371154   0.372474
128       1290  0.015363  0.070713      0.371414   0.372768
129       1300  0.015294  0.071147      0.371107   0.372432
130       1310  0.015337  0.070399      0.370188   0.371494
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
126     1270.0  0.971970  0.980159  ...  0.957241  0.953168  0.942743
127     1280.0  0.972198  0.980388  ...  0.957729  0.953576  0.941929
128     1290.0  0.972715  0.980603  ...  0.957566  0.953494  0.937531
129     1300.0  0.972499  0.980390  ...  0.957403  0.953657  0.942173
130     1310.0  0.972499  0.980603  ...  0.957403  0.953494  0.938671

[5 rows x 13 columns]
process: 50 / 291. Epoch 1311
process: 100 / 291. Epoch 1311
process: 150 / 291. Epoch 1311
process: 200 / 291. Epoch 1311
process: 250 / 291. Epoch 1311
process: 291 / 291. Epoch 1311
Loss of epoch 1311 = 2.634995922599871
process: 50 / 291. Epoch 1312
process: 100 / 291. Epoch 1312
process: 150 / 291. Epoch 1312
process: 200 / 291. Epoch 1312
process: 250 / 291. Epoch 1312
process: 291 / 291. Epoch 1312
Loss of epoch 1312 = 2.675146358529317
process: 50 / 291. Epoch 1313
process: 100 / 291. Epoch 1313
process: 150 / 291. Epoch 1313
process: 200 / 291. Epoch 1313
process: 250 / 291. Epoch 1313
process: 291 / 291. Epoch 1313
Loss of epoch 1313 = 2.6860989180627146
process: 50 / 291. Epoch 1314
process: 100 / 291. Epoch 1314
process: 150 / 291. Epoch 1314
process: 200 / 291. Epoch 1314
process: 250 / 291. Epoch 1314
process: 291 / 291. Epoch 1314
Loss of epoch 1314 = 2.756091770027921
process: 50 / 291. Epoch 1315
process: 100 / 291. Epoch 1315
process: 150 / 291. Epoch 1315
process: 200 / 291. Epoch 1315
process: 250 / 291. Epoch 1315
process: 291 / 291. Epoch 1315
Loss of epoch 1315 = 2.7328528964642396
process: 50 / 291. Epoch 1316
process: 100 / 291. Epoch 1316
process: 150 / 291. Epoch 1316
process: 200 / 291. Epoch 1316
process: 250 / 291. Epoch 1316
process: 291 / 291. Epoch 1316
Loss of epoch 1316 = 2.6668025800042954
process: 50 / 291. Epoch 1317
process: 100 / 291. Epoch 1317
process: 150 / 291. Epoch 1317
process: 200 / 291. Epoch 1317
process: 250 / 291. Epoch 1317
process: 291 / 291. Epoch 1317
Loss of epoch 1317 = 2.631675274511383
process: 50 / 291. Epoch 1318
process: 100 / 291. Epoch 1318
process: 150 / 291. Epoch 1318
process: 200 / 291. Epoch 1318
process: 250 / 291. Epoch 1318
process: 291 / 291. Epoch 1318
Loss of epoch 1318 = 2.631323745570232
process: 50 / 291. Epoch 1319
process: 100 / 291. Epoch 1319
process: 150 / 291. Epoch 1319
process: 200 / 291. Epoch 1319
process: 250 / 291. Epoch 1319
process: 291 / 291. Epoch 1319
Loss of epoch 1319 = 2.652171341414304
process: 50 / 291. Epoch 1320
process: 100 / 291. Epoch 1320
process: 150 / 291. Epoch 1320
process: 200 / 291. Epoch 1320
process: 250 / 291. Epoch 1320
process: 291 / 291. Epoch 1320
Loss of epoch 1320 = 2.6956986365039732
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1320. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.788549
      epoch  training_loss
1315   1316       2.666803
1316   1317       2.631675
1317   1318       2.631324
1318   1319       2.652171
1319   1320       2.695699
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
127       1280  0.015302  0.071823      0.371154   0.372474
128       1290  0.015363  0.070713      0.371414   0.372768
129       1300  0.015294  0.071147      0.371107   0.372432
130       1310  0.015337  0.070399      0.370188   0.371494
131       1320  0.015265  0.070525      0.372389   0.373738
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
127     1280.0  0.972198  0.980388  ...  0.957729  0.953576  0.941929
128     1290.0  0.972715  0.980603  ...  0.957566  0.953494  0.937531
129     1300.0  0.972499  0.980390  ...  0.957403  0.953657  0.942173
130     1310.0  0.972499  0.980603  ...  0.957403  0.953494  0.938671
131     1320.0  0.972502  0.980286  ...  0.957485  0.953820  0.940055

[5 rows x 13 columns]
process: 50 / 291. Epoch 1321
process: 100 / 291. Epoch 1321
process: 150 / 291. Epoch 1321
process: 200 / 291. Epoch 1321
process: 250 / 291. Epoch 1321
process: 291 / 291. Epoch 1321
Loss of epoch 1321 = 2.7504102569265463
process: 50 / 291. Epoch 1322
process: 100 / 291. Epoch 1322
process: 150 / 291. Epoch 1322
process: 200 / 291. Epoch 1322
process: 250 / 291. Epoch 1322
process: 291 / 291. Epoch 1322
Loss of epoch 1322 = 2.7325095474924828
process: 50 / 291. Epoch 1323
process: 100 / 291. Epoch 1323
process: 150 / 291. Epoch 1323
process: 200 / 291. Epoch 1323
process: 250 / 291. Epoch 1323
process: 291 / 291. Epoch 1323
Loss of epoch 1323 = 2.6881361499275127
process: 50 / 291. Epoch 1324
process: 100 / 291. Epoch 1324
process: 150 / 291. Epoch 1324
process: 200 / 291. Epoch 1324
process: 250 / 291. Epoch 1324
process: 291 / 291. Epoch 1324
Loss of epoch 1324 = 2.7221140648491193
process: 50 / 291. Epoch 1325
process: 100 / 291. Epoch 1325
process: 150 / 291. Epoch 1325
process: 200 / 291. Epoch 1325
process: 250 / 291. Epoch 1325
process: 291 / 291. Epoch 1325
Loss of epoch 1325 = 2.7403740637081184
process: 50 / 291. Epoch 1326
process: 100 / 291. Epoch 1326
process: 150 / 291. Epoch 1326
process: 200 / 291. Epoch 1326
process: 250 / 291. Epoch 1326
process: 291 / 291. Epoch 1326
Loss of epoch 1326 = 2.6903533411189864
process: 50 / 291. Epoch 1327
process: 100 / 291. Epoch 1327
process: 150 / 291. Epoch 1327
process: 200 / 291. Epoch 1327
process: 250 / 291. Epoch 1327
process: 291 / 291. Epoch 1327
Loss of epoch 1327 = 2.6690992637188575
process: 50 / 291. Epoch 1328
process: 100 / 291. Epoch 1328
process: 150 / 291. Epoch 1328
process: 200 / 291. Epoch 1328
process: 250 / 291. Epoch 1328
process: 291 / 291. Epoch 1328
Loss of epoch 1328 = 2.6290574745623925
process: 50 / 291. Epoch 1329
process: 100 / 291. Epoch 1329
process: 150 / 291. Epoch 1329
process: 200 / 291. Epoch 1329
process: 250 / 291. Epoch 1329
process: 291 / 291. Epoch 1329
Loss of epoch 1329 = 2.6507601918223798
process: 50 / 291. Epoch 1330
process: 100 / 291. Epoch 1330
process: 150 / 291. Epoch 1330
process: 200 / 291. Epoch 1330
process: 250 / 291. Epoch 1330
process: 291 / 291. Epoch 1330
Loss of epoch 1330 = 2.7128105032484964
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1330. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.791540
      epoch  training_loss
1325   1326       2.690353
1326   1327       2.669099
1327   1328       2.629057
1328   1329       2.650760
1329   1330       2.712811
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
128       1290  0.015363  0.070713      0.371414   0.372768
129       1300  0.015294  0.071147      0.371107   0.372432
130       1310  0.015337  0.070399      0.370188   0.371494
131       1320  0.015265  0.070525      0.372389   0.373738
132       1330  0.015271  0.070084      0.372127   0.373467
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
128     1290.0  0.972715  0.980603  ...  0.957566  0.953494  0.937531
129     1300.0  0.972499  0.980390  ...  0.957403  0.953657  0.942173
130     1310.0  0.972499  0.980603  ...  0.957403  0.953494  0.938671
131     1320.0  0.972502  0.980286  ...  0.957485  0.953820  0.940055
132     1330.0  0.972502  0.980623  ...  0.957485  0.954227  0.942906

[5 rows x 13 columns]
process: 50 / 291. Epoch 1331
process: 100 / 291. Epoch 1331
process: 150 / 291. Epoch 1331
process: 200 / 291. Epoch 1331
process: 250 / 291. Epoch 1331
process: 291 / 291. Epoch 1331
Loss of epoch 1331 = 2.7170716380745277
process: 50 / 291. Epoch 1332
process: 100 / 291. Epoch 1332
process: 150 / 291. Epoch 1332
process: 200 / 291. Epoch 1332
process: 250 / 291. Epoch 1332
process: 291 / 291. Epoch 1332
Loss of epoch 1332 = 2.68932979623067
process: 50 / 291. Epoch 1333
process: 100 / 291. Epoch 1333
process: 150 / 291. Epoch 1333
process: 200 / 291. Epoch 1333
process: 250 / 291. Epoch 1333
process: 291 / 291. Epoch 1333
Loss of epoch 1333 = 2.6540856639953825
process: 50 / 291. Epoch 1334
process: 100 / 291. Epoch 1334
process: 150 / 291. Epoch 1334
process: 200 / 291. Epoch 1334
process: 250 / 291. Epoch 1334
process: 291 / 291. Epoch 1334
Loss of epoch 1334 = 2.6635599562392613
process: 50 / 291. Epoch 1335
process: 100 / 291. Epoch 1335
process: 150 / 291. Epoch 1335
process: 200 / 291. Epoch 1335
process: 250 / 291. Epoch 1335
process: 291 / 291. Epoch 1335
Loss of epoch 1335 = 2.6370337836930844
process: 50 / 291. Epoch 1336
process: 100 / 291. Epoch 1336
process: 150 / 291. Epoch 1336
process: 200 / 291. Epoch 1336
process: 250 / 291. Epoch 1336
process: 291 / 291. Epoch 1336
Loss of epoch 1336 = 2.720775905753329
process: 50 / 291. Epoch 1337
process: 100 / 291. Epoch 1337
process: 150 / 291. Epoch 1337
process: 200 / 291. Epoch 1337
process: 250 / 291. Epoch 1337
process: 291 / 291. Epoch 1337
Loss of epoch 1337 = 2.6422802902169242
process: 50 / 291. Epoch 1338
process: 100 / 291. Epoch 1338
process: 150 / 291. Epoch 1338
process: 200 / 291. Epoch 1338
process: 250 / 291. Epoch 1338
process: 291 / 291. Epoch 1338
Loss of epoch 1338 = 2.681936152612221
process: 50 / 291. Epoch 1339
process: 100 / 291. Epoch 1339
process: 150 / 291. Epoch 1339
process: 200 / 291. Epoch 1339
process: 250 / 291. Epoch 1339
process: 291 / 291. Epoch 1339
Loss of epoch 1339 = 2.7275199759047464
process: 50 / 291. Epoch 1340
process: 100 / 291. Epoch 1340
process: 150 / 291. Epoch 1340
process: 200 / 291. Epoch 1340
process: 250 / 291. Epoch 1340
process: 291 / 291. Epoch 1340
Loss of epoch 1340 = 2.723960850246993
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1340. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.783082
      epoch  training_loss
1335   1336       2.720776
1336   1337       2.642280
1337   1338       2.681936
1338   1339       2.727520
1339   1340       2.723961
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
129       1300  0.015294  0.071147      0.371107   0.372432
130       1310  0.015337  0.070399      0.370188   0.371494
131       1320  0.015265  0.070525      0.372389   0.373738
132       1330  0.015271  0.070084      0.372127   0.373467
133       1340  0.015379  0.069622      0.373046   0.374398
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
129     1300.0  0.972499  0.980390  ...  0.957403  0.953657  0.942173
130     1310.0  0.972499  0.980603  ...  0.957403  0.953494  0.938671
131     1320.0  0.972502  0.980286  ...  0.957485  0.953820  0.940055
132     1330.0  0.972502  0.980623  ...  0.957485  0.954227  0.942906
133     1340.0  0.972838  0.980713  ...  0.958055  0.953494  0.937856

[5 rows x 13 columns]
process: 50 / 291. Epoch 1341
process: 100 / 291. Epoch 1341
process: 150 / 291. Epoch 1341
process: 200 / 291. Epoch 1341
process: 250 / 291. Epoch 1341
process: 291 / 291. Epoch 1341
Loss of epoch 1341 = 2.6995906239932346
process: 50 / 291. Epoch 1342
process: 100 / 291. Epoch 1342
process: 150 / 291. Epoch 1342
process: 200 / 291. Epoch 1342
process: 250 / 291. Epoch 1342
process: 291 / 291. Epoch 1342
Loss of epoch 1342 = 2.667493892289519
process: 50 / 291. Epoch 1343
process: 100 / 291. Epoch 1343
process: 150 / 291. Epoch 1343
process: 200 / 291. Epoch 1343
process: 250 / 291. Epoch 1343
process: 291 / 291. Epoch 1343
Loss of epoch 1343 = 2.621445069198346
process: 50 / 291. Epoch 1344
process: 100 / 291. Epoch 1344
process: 150 / 291. Epoch 1344
process: 200 / 291. Epoch 1344
process: 250 / 291. Epoch 1344
process: 291 / 291. Epoch 1344
Loss of epoch 1344 = 2.7700736448936856
process: 50 / 291. Epoch 1345
process: 100 / 291. Epoch 1345
process: 150 / 291. Epoch 1345
process: 200 / 291. Epoch 1345
process: 250 / 291. Epoch 1345
process: 291 / 291. Epoch 1345
Loss of epoch 1345 = 2.7450869845360826
process: 50 / 291. Epoch 1346
process: 100 / 291. Epoch 1346
process: 150 / 291. Epoch 1346
process: 200 / 291. Epoch 1346
process: 250 / 291. Epoch 1346
process: 291 / 291. Epoch 1346
Loss of epoch 1346 = 2.723231155028458
process: 50 / 291. Epoch 1347
process: 100 / 291. Epoch 1347
process: 150 / 291. Epoch 1347
process: 200 / 291. Epoch 1347
process: 250 / 291. Epoch 1347
process: 291 / 291. Epoch 1347
Loss of epoch 1347 = 2.68786746939433
process: 50 / 291. Epoch 1348
process: 100 / 291. Epoch 1348
process: 150 / 291. Epoch 1348
process: 200 / 291. Epoch 1348
process: 250 / 291. Epoch 1348
process: 291 / 291. Epoch 1348
Loss of epoch 1348 = 2.6334421479005585
process: 50 / 291. Epoch 1349
process: 100 / 291. Epoch 1349
process: 150 / 291. Epoch 1349
process: 200 / 291. Epoch 1349
process: 250 / 291. Epoch 1349
process: 291 / 291. Epoch 1349
Loss of epoch 1349 = 2.5859802875322164
process: 50 / 291. Epoch 1350
process: 100 / 291. Epoch 1350
process: 150 / 291. Epoch 1350
process: 200 / 291. Epoch 1350
process: 250 / 291. Epoch 1350
process: 291 / 291. Epoch 1350
Loss of epoch 1350 = 2.621482193674828
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1350. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.784899
      epoch  training_loss
1345   1346       2.723231
1346   1347       2.687867
1347   1348       2.633442
1348   1349       2.585980
1349   1350       2.621482
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
130       1310  0.015337  0.070399      0.370188   0.371494
131       1320  0.015265  0.070525      0.372389   0.373738
132       1330  0.015271  0.070084      0.372127   0.373467
133       1340  0.015379  0.069622      0.373046   0.374398
134       1350  0.015379  0.069367      0.372227   0.373550
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
130     1310.0  0.972499  0.980603  ...  0.957403  0.953494  0.938671
131     1320.0  0.972502  0.980286  ...  0.957485  0.953820  0.940055
132     1330.0  0.972502  0.980623  ...  0.957485  0.954227  0.942906
133     1340.0  0.972838  0.980713  ...  0.958055  0.953494  0.937856
134     1350.0  0.972509  0.980952  ...  0.957648  0.954309  0.939241

[5 rows x 13 columns]
process: 50 / 291. Epoch 1351
process: 100 / 291. Epoch 1351
process: 150 / 291. Epoch 1351
process: 200 / 291. Epoch 1351
process: 250 / 291. Epoch 1351
process: 291 / 291. Epoch 1351
Loss of epoch 1351 = 2.6969935885819374
process: 50 / 291. Epoch 1352
process: 100 / 291. Epoch 1352
process: 150 / 291. Epoch 1352
process: 200 / 291. Epoch 1352
process: 250 / 291. Epoch 1352
process: 291 / 291. Epoch 1352
Loss of epoch 1352 = 2.704465885752255
process: 50 / 291. Epoch 1353
process: 100 / 291. Epoch 1353
process: 150 / 291. Epoch 1353
process: 200 / 291. Epoch 1353
process: 250 / 291. Epoch 1353
process: 291 / 291. Epoch 1353
Loss of epoch 1353 = 2.6359447990496134
process: 50 / 291. Epoch 1354
process: 100 / 291. Epoch 1354
process: 150 / 291. Epoch 1354
process: 200 / 291. Epoch 1354
process: 250 / 291. Epoch 1354
process: 291 / 291. Epoch 1354
Loss of epoch 1354 = 2.7144980938573884
process: 50 / 291. Epoch 1355
process: 100 / 291. Epoch 1355
process: 150 / 291. Epoch 1355
process: 200 / 291. Epoch 1355
process: 250 / 291. Epoch 1355
process: 291 / 291. Epoch 1355
Loss of epoch 1355 = 2.6550689382651416
process: 50 / 291. Epoch 1356
process: 100 / 291. Epoch 1356
process: 150 / 291. Epoch 1356
process: 200 / 291. Epoch 1356
process: 250 / 291. Epoch 1356
process: 291 / 291. Epoch 1356
Loss of epoch 1356 = 2.6459675687285222
process: 50 / 291. Epoch 1357
process: 100 / 291. Epoch 1357
process: 150 / 291. Epoch 1357
process: 200 / 291. Epoch 1357
process: 250 / 291. Epoch 1357
process: 291 / 291. Epoch 1357
Loss of epoch 1357 = 2.7425637785921393
process: 50 / 291. Epoch 1358
process: 100 / 291. Epoch 1358
process: 150 / 291. Epoch 1358
process: 200 / 291. Epoch 1358
process: 250 / 291. Epoch 1358
process: 291 / 291. Epoch 1358
Loss of epoch 1358 = 2.641049938922895
process: 50 / 291. Epoch 1359
process: 100 / 291. Epoch 1359
process: 150 / 291. Epoch 1359
process: 200 / 291. Epoch 1359
process: 250 / 291. Epoch 1359
process: 291 / 291. Epoch 1359
Loss of epoch 1359 = 2.626708774632195
process: 50 / 291. Epoch 1360
process: 100 / 291. Epoch 1360
process: 150 / 291. Epoch 1360
process: 200 / 291. Epoch 1360
process: 250 / 291. Epoch 1360
process: 291 / 291. Epoch 1360
Loss of epoch 1360 = 2.7432750164438358
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1360. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.794205
      epoch  training_loss
1355   1356       2.645968
1356   1357       2.742564
1357   1358       2.641050
1358   1359       2.626709
1359   1360       2.743275
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
131       1320  0.015265  0.070525      0.372389   0.373738
132       1330  0.015271  0.070084      0.372127   0.373467
133       1340  0.015379  0.069622      0.373046   0.374398
134       1350  0.015379  0.069367      0.372227   0.373550
135       1360  0.015255  0.070886      0.374735   0.376134
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
131     1320.0  0.972502  0.980286  ...  0.957485  0.953820  0.940055
132     1330.0  0.972502  0.980623  ...  0.957485  0.954227  0.942906
133     1340.0  0.972838  0.980713  ...  0.958055  0.953494  0.937856
134     1350.0  0.972509  0.980952  ...  0.957648  0.954309  0.939241
135     1360.0  0.971985  0.980172  ...  0.957648  0.953657  0.943558

[5 rows x 13 columns]
process: 50 / 291. Epoch 1361
process: 100 / 291. Epoch 1361
process: 150 / 291. Epoch 1361
process: 200 / 291. Epoch 1361
process: 250 / 291. Epoch 1361
process: 291 / 291. Epoch 1361
Loss of epoch 1361 = 2.693676506121134
process: 50 / 291. Epoch 1362
process: 100 / 291. Epoch 1362
process: 150 / 291. Epoch 1362
process: 200 / 291. Epoch 1362
process: 250 / 291. Epoch 1362
process: 291 / 291. Epoch 1362
Loss of epoch 1362 = 2.67748729797573
process: 50 / 291. Epoch 1363
process: 100 / 291. Epoch 1363
process: 150 / 291. Epoch 1363
process: 200 / 291. Epoch 1363
process: 250 / 291. Epoch 1363
process: 291 / 291. Epoch 1363
Loss of epoch 1363 = 2.6921453836447595
process: 50 / 291. Epoch 1364
process: 100 / 291. Epoch 1364
process: 150 / 291. Epoch 1364
process: 200 / 291. Epoch 1364
process: 250 / 291. Epoch 1364
process: 291 / 291. Epoch 1364
Loss of epoch 1364 = 2.6763492335158934
process: 50 / 291. Epoch 1365
process: 100 / 291. Epoch 1365
process: 150 / 291. Epoch 1365
process: 200 / 291. Epoch 1365
process: 250 / 291. Epoch 1365
process: 291 / 291. Epoch 1365
Loss of epoch 1365 = 2.6752841595521906
process: 50 / 291. Epoch 1366
process: 100 / 291. Epoch 1366
process: 150 / 291. Epoch 1366
process: 200 / 291. Epoch 1366
process: 250 / 291. Epoch 1366
process: 291 / 291. Epoch 1366
Loss of epoch 1366 = 2.6424506013745703
process: 50 / 291. Epoch 1367
process: 100 / 291. Epoch 1367
process: 150 / 291. Epoch 1367
process: 200 / 291. Epoch 1367
process: 250 / 291. Epoch 1367
process: 291 / 291. Epoch 1367
Loss of epoch 1367 = 2.736862969152706
process: 50 / 291. Epoch 1368
process: 100 / 291. Epoch 1368
process: 150 / 291. Epoch 1368
process: 200 / 291. Epoch 1368
process: 250 / 291. Epoch 1368
process: 291 / 291. Epoch 1368
Loss of epoch 1368 = 2.653785102555842
process: 50 / 291. Epoch 1369
process: 100 / 291. Epoch 1369
process: 150 / 291. Epoch 1369
process: 200 / 291. Epoch 1369
process: 250 / 291. Epoch 1369
process: 291 / 291. Epoch 1369
Loss of epoch 1369 = 2.692249416076031
process: 50 / 291. Epoch 1370
process: 100 / 291. Epoch 1370
process: 150 / 291. Epoch 1370
process: 200 / 291. Epoch 1370
process: 250 / 291. Epoch 1370
process: 291 / 291. Epoch 1370
Loss of epoch 1370 = 2.674121135698561
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1370. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.789474
      epoch  training_loss
1365   1366       2.642451
1366   1367       2.736863
1367   1368       2.653785
1368   1369       2.692249
1369   1370       2.674121
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
132       1330  0.015271  0.070084      0.372127   0.373467
133       1340  0.015379  0.069622      0.373046   0.374398
134       1350  0.015379  0.069367      0.372227   0.373550
135       1360  0.015255  0.070886      0.374735   0.376134
136       1370  0.015314  0.069553      0.373766   0.375080
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
132     1330.0  0.972502  0.980623  ...  0.957485  0.954227  0.942906
133     1340.0  0.972838  0.980713  ...  0.958055  0.953494  0.937856
134     1350.0  0.972509  0.980952  ...  0.957648  0.954309  0.939241
135     1360.0  0.971985  0.980172  ...  0.957648  0.953657  0.943558
136     1370.0  0.972718  0.980514  ...  0.957648  0.954227  0.941684

[5 rows x 13 columns]
process: 50 / 291. Epoch 1371
process: 100 / 291. Epoch 1371
process: 150 / 291. Epoch 1371
process: 200 / 291. Epoch 1371
process: 250 / 291. Epoch 1371
process: 291 / 291. Epoch 1371
Loss of epoch 1371 = 2.6497244818513748
process: 50 / 291. Epoch 1372
process: 100 / 291. Epoch 1372
process: 150 / 291. Epoch 1372
process: 200 / 291. Epoch 1372
process: 250 / 291. Epoch 1372
process: 291 / 291. Epoch 1372
Loss of epoch 1372 = 2.7035688157753435
process: 50 / 291. Epoch 1373
process: 100 / 291. Epoch 1373
process: 150 / 291. Epoch 1373
process: 200 / 291. Epoch 1373
process: 250 / 291. Epoch 1373
process: 291 / 291. Epoch 1373
Loss of epoch 1373 = 2.605296341414304
process: 50 / 291. Epoch 1374
process: 100 / 291. Epoch 1374
process: 150 / 291. Epoch 1374
process: 200 / 291. Epoch 1374
process: 250 / 291. Epoch 1374
process: 291 / 291. Epoch 1374
Loss of epoch 1374 = 2.629700336259665
process: 50 / 291. Epoch 1375
process: 100 / 291. Epoch 1375
process: 150 / 291. Epoch 1375
process: 200 / 291. Epoch 1375
process: 250 / 291. Epoch 1375
process: 291 / 291. Epoch 1375
Loss of epoch 1375 = 2.699019913820876
process: 50 / 291. Epoch 1376
process: 100 / 291. Epoch 1376
process: 150 / 291. Epoch 1376
process: 200 / 291. Epoch 1376
process: 250 / 291. Epoch 1376
process: 291 / 291. Epoch 1376
Loss of epoch 1376 = 2.689589877308849
process: 50 / 291. Epoch 1377
process: 100 / 291. Epoch 1377
process: 150 / 291. Epoch 1377
process: 200 / 291. Epoch 1377
process: 250 / 291. Epoch 1377
process: 291 / 291. Epoch 1377
Loss of epoch 1377 = 2.6569983623281788
process: 50 / 291. Epoch 1378
process: 100 / 291. Epoch 1378
process: 150 / 291. Epoch 1378
process: 200 / 291. Epoch 1378
process: 250 / 291. Epoch 1378
process: 291 / 291. Epoch 1378
Loss of epoch 1378 = 2.61895835850247
process: 50 / 291. Epoch 1379
process: 100 / 291. Epoch 1379
process: 150 / 291. Epoch 1379
process: 200 / 291. Epoch 1379
process: 250 / 291. Epoch 1379
process: 291 / 291. Epoch 1379
Loss of epoch 1379 = 2.6097932271531357
process: 50 / 291. Epoch 1380
process: 100 / 291. Epoch 1380
process: 150 / 291. Epoch 1380
process: 200 / 291. Epoch 1380
process: 250 / 291. Epoch 1380
process: 291 / 291. Epoch 1380
Loss of epoch 1380 = 2.6274126714857173
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1380. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.787650
      epoch  training_loss
1375   1376       2.689590
1376   1377       2.656998
1377   1378       2.618958
1378   1379       2.609793
1379   1380       2.627413
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
133       1340  0.015379  0.069622      0.373046   0.374398
134       1350  0.015379  0.069367      0.372227   0.373550
135       1360  0.015255  0.070886      0.374735   0.376134
136       1370  0.015314  0.069553      0.373766   0.375080
137       1380  0.015306  0.069612      0.373575   0.374924
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
133     1340.0  0.972838  0.980713  ...  0.958055  0.953494  0.937856
134     1350.0  0.972509  0.980952  ...  0.957648  0.954309  0.939241
135     1360.0  0.971985  0.980172  ...  0.957648  0.953657  0.943558
136     1370.0  0.972718  0.980514  ...  0.957648  0.954227  0.941684
137     1380.0  0.972182  0.980510  ...  0.957322  0.954064  0.941521

[5 rows x 13 columns]
process: 50 / 291. Epoch 1381
process: 100 / 291. Epoch 1381
process: 150 / 291. Epoch 1381
process: 200 / 291. Epoch 1381
process: 250 / 291. Epoch 1381
process: 291 / 291. Epoch 1381
Loss of epoch 1381 = 2.6552673549586556
process: 50 / 291. Epoch 1382
process: 100 / 291. Epoch 1382
process: 150 / 291. Epoch 1382
process: 200 / 291. Epoch 1382
process: 250 / 291. Epoch 1382
process: 291 / 291. Epoch 1382
Loss of epoch 1382 = 2.6609935432774914
process: 50 / 291. Epoch 1383
process: 100 / 291. Epoch 1383
process: 150 / 291. Epoch 1383
process: 200 / 291. Epoch 1383
process: 250 / 291. Epoch 1383
process: 291 / 291. Epoch 1383
Loss of epoch 1383 = 2.6882718535223367
process: 50 / 291. Epoch 1384
process: 100 / 291. Epoch 1384
process: 150 / 291. Epoch 1384
process: 200 / 291. Epoch 1384
process: 250 / 291. Epoch 1384
process: 291 / 291. Epoch 1384
Loss of epoch 1384 = 2.648317736858355
process: 50 / 291. Epoch 1385
process: 100 / 291. Epoch 1385
process: 150 / 291. Epoch 1385
process: 200 / 291. Epoch 1385
process: 250 / 291. Epoch 1385
process: 291 / 291. Epoch 1385
Loss of epoch 1385 = 2.615490261222079
process: 50 / 291. Epoch 1386
process: 100 / 291. Epoch 1386
process: 150 / 291. Epoch 1386
process: 200 / 291. Epoch 1386
process: 250 / 291. Epoch 1386
process: 291 / 291. Epoch 1386
Loss of epoch 1386 = 2.732006164760524
process: 50 / 291. Epoch 1387
process: 100 / 291. Epoch 1387
process: 150 / 291. Epoch 1387
process: 200 / 291. Epoch 1387
process: 250 / 291. Epoch 1387
process: 291 / 291. Epoch 1387
Loss of epoch 1387 = 2.66333217555305
process: 50 / 291. Epoch 1388
process: 100 / 291. Epoch 1388
process: 150 / 291. Epoch 1388
process: 200 / 291. Epoch 1388
process: 250 / 291. Epoch 1388
process: 291 / 291. Epoch 1388
Loss of epoch 1388 = 2.6730407505100944
process: 50 / 291. Epoch 1389
process: 100 / 291. Epoch 1389
process: 150 / 291. Epoch 1389
process: 200 / 291. Epoch 1389
process: 250 / 291. Epoch 1389
process: 291 / 291. Epoch 1389
Loss of epoch 1389 = 2.595265601508806
process: 50 / 291. Epoch 1390
process: 100 / 291. Epoch 1390
process: 150 / 291. Epoch 1390
process: 200 / 291. Epoch 1390
process: 250 / 291. Epoch 1390
process: 291 / 291. Epoch 1390
Loss of epoch 1390 = 2.648852790753866
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1390. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.788329
      epoch  training_loss
1385   1386       2.732006
1386   1387       2.663332
1387   1388       2.673041
1388   1389       2.595266
1389   1390       2.648853
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
134       1350  0.015379  0.069367      0.372227   0.373550
135       1360  0.015255  0.070886      0.374735   0.376134
136       1370  0.015314  0.069553      0.373766   0.375080
137       1380  0.015306  0.069612      0.373575   0.374924
138       1390  0.015245  0.069403      0.374516   0.375893
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
134     1350.0  0.972509  0.980952  ...  0.957648  0.954309  0.939241
135     1360.0  0.971985  0.980172  ...  0.957648  0.953657  0.943558
136     1370.0  0.972718  0.980514  ...  0.957648  0.954227  0.941684
137     1380.0  0.972182  0.980510  ...  0.957322  0.954064  0.941521
138     1390.0  0.972407  0.980070  ...  0.957729  0.953901  0.940870

[5 rows x 13 columns]
process: 50 / 291. Epoch 1391
process: 100 / 291. Epoch 1391
process: 150 / 291. Epoch 1391
process: 200 / 291. Epoch 1391
process: 250 / 291. Epoch 1391
process: 291 / 291. Epoch 1391
Loss of epoch 1391 = 2.6884253852555844
process: 50 / 291. Epoch 1392
process: 100 / 291. Epoch 1392
process: 150 / 291. Epoch 1392
process: 200 / 291. Epoch 1392
process: 250 / 291. Epoch 1392
process: 291 / 291. Epoch 1392
Loss of epoch 1392 = 2.657460215984751
process: 50 / 291. Epoch 1393
process: 100 / 291. Epoch 1393
process: 150 / 291. Epoch 1393
process: 200 / 291. Epoch 1393
process: 250 / 291. Epoch 1393
process: 291 / 291. Epoch 1393
Loss of epoch 1393 = 2.672384255530498
process: 50 / 291. Epoch 1394
process: 100 / 291. Epoch 1394
process: 150 / 291. Epoch 1394
process: 200 / 291. Epoch 1394
process: 250 / 291. Epoch 1394
process: 291 / 291. Epoch 1394
Loss of epoch 1394 = 2.6571476992053267
process: 50 / 291. Epoch 1395
process: 100 / 291. Epoch 1395
process: 150 / 291. Epoch 1395
process: 200 / 291. Epoch 1395
process: 250 / 291. Epoch 1395
process: 291 / 291. Epoch 1395
Loss of epoch 1395 = 2.6558179298217355
process: 50 / 291. Epoch 1396
process: 100 / 291. Epoch 1396
process: 150 / 291. Epoch 1396
process: 200 / 291. Epoch 1396
process: 250 / 291. Epoch 1396
process: 291 / 291. Epoch 1396
Loss of epoch 1396 = 2.7411958360180413
process: 50 / 291. Epoch 1397
process: 100 / 291. Epoch 1397
process: 150 / 291. Epoch 1397
process: 200 / 291. Epoch 1397
process: 250 / 291. Epoch 1397
process: 291 / 291. Epoch 1397
Loss of epoch 1397 = 2.604151565184708
process: 50 / 291. Epoch 1398
process: 100 / 291. Epoch 1398
process: 150 / 291. Epoch 1398
process: 200 / 291. Epoch 1398
process: 250 / 291. Epoch 1398
process: 291 / 291. Epoch 1398
Loss of epoch 1398 = 2.60571582702427
process: 50 / 291. Epoch 1399
process: 100 / 291. Epoch 1399
process: 150 / 291. Epoch 1399
process: 200 / 291. Epoch 1399
process: 250 / 291. Epoch 1399
process: 291 / 291. Epoch 1399
Loss of epoch 1399 = 2.710057419190292
process: 50 / 291. Epoch 1400
process: 100 / 291. Epoch 1400
process: 150 / 291. Epoch 1400
process: 200 / 291. Epoch 1400
process: 250 / 291. Epoch 1400
process: 291 / 291. Epoch 1400
Loss of epoch 1400 = 2.6700968004993557
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1400. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.791543
      epoch  training_loss
1395   1396       2.741196
1396   1397       2.604152
1397   1398       2.605716
1398   1399       2.710057
1399   1400       2.670097
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
135       1360  0.015255  0.070886      0.374735   0.376134
136       1370  0.015314  0.069553      0.373766   0.375080
137       1380  0.015306  0.069612      0.373575   0.374924
138       1390  0.015245  0.069403      0.374516   0.375893
139       1400  0.015172  0.069624      0.373474   0.374780
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
135     1360.0  0.971985  0.980172  ...  0.957648  0.953657  0.943558
136     1370.0  0.972718  0.980514  ...  0.957648  0.954227  0.941684
137     1380.0  0.972182  0.980510  ...  0.957322  0.954064  0.941521
138     1390.0  0.972407  0.980070  ...  0.957729  0.953901  0.940870
139     1400.0  0.971878  0.980505  ...  0.957566  0.953901  0.943395

[5 rows x 13 columns]
process: 50 / 291. Epoch 1401
process: 100 / 291. Epoch 1401
process: 150 / 291. Epoch 1401
process: 200 / 291. Epoch 1401
process: 250 / 291. Epoch 1401
process: 291 / 291. Epoch 1401
Loss of epoch 1401 = 2.6218450487274483
process: 50 / 291. Epoch 1402
process: 100 / 291. Epoch 1402
process: 150 / 291. Epoch 1402
process: 200 / 291. Epoch 1402
process: 250 / 291. Epoch 1402
process: 291 / 291. Epoch 1402
Loss of epoch 1402 = 2.646708380315722
process: 50 / 291. Epoch 1403
process: 100 / 291. Epoch 1403
process: 150 / 291. Epoch 1403
process: 200 / 291. Epoch 1403
process: 250 / 291. Epoch 1403
process: 291 / 291. Epoch 1403
Loss of epoch 1403 = 2.677536797277706
process: 50 / 291. Epoch 1404
process: 100 / 291. Epoch 1404
process: 150 / 291. Epoch 1404
process: 200 / 291. Epoch 1404
process: 250 / 291. Epoch 1404
process: 291 / 291. Epoch 1404
Loss of epoch 1404 = 2.691076953796177
process: 50 / 291. Epoch 1405
process: 100 / 291. Epoch 1405
process: 150 / 291. Epoch 1405
process: 200 / 291. Epoch 1405
process: 250 / 291. Epoch 1405
process: 291 / 291. Epoch 1405
Loss of epoch 1405 = 2.607986922116624
process: 50 / 291. Epoch 1406
process: 100 / 291. Epoch 1406
process: 150 / 291. Epoch 1406
process: 200 / 291. Epoch 1406
process: 250 / 291. Epoch 1406
process: 291 / 291. Epoch 1406
Loss of epoch 1406 = 2.5912511242214347
process: 50 / 291. Epoch 1407
process: 100 / 291. Epoch 1407
process: 150 / 291. Epoch 1407
process: 200 / 291. Epoch 1407
process: 250 / 291. Epoch 1407
process: 291 / 291. Epoch 1407
Loss of epoch 1407 = 2.6517149410706615
process: 50 / 291. Epoch 1408
process: 100 / 291. Epoch 1408
process: 150 / 291. Epoch 1408
process: 200 / 291. Epoch 1408
process: 250 / 291. Epoch 1408
process: 291 / 291. Epoch 1408
Loss of epoch 1408 = 2.681285740173969
process: 50 / 291. Epoch 1409
process: 100 / 291. Epoch 1409
process: 150 / 291. Epoch 1409
process: 200 / 291. Epoch 1409
process: 250 / 291. Epoch 1409
process: 291 / 291. Epoch 1409
Loss of epoch 1409 = 2.669970115845146
process: 50 / 291. Epoch 1410
process: 100 / 291. Epoch 1410
process: 150 / 291. Epoch 1410
process: 200 / 291. Epoch 1410
process: 250 / 291. Epoch 1410
process: 291 / 291. Epoch 1410
Loss of epoch 1410 = 2.6433680164035653
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1410. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.788161
      epoch  training_loss
1405   1406       2.591251
1406   1407       2.651715
1407   1408       2.681286
1408   1409       2.669970
1409   1410       2.643368
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
136       1370  0.015314  0.069553      0.373766   0.375080
137       1380  0.015306  0.069612      0.373575   0.374924
138       1390  0.015245  0.069403      0.374516   0.375893
139       1400  0.015172  0.069624      0.373474   0.374780
140       1410  0.015331  0.068914      0.374532   0.375889
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
136     1370.0  0.972718  0.980514  ...  0.957648  0.954227  0.941684
137     1380.0  0.972182  0.980510  ...  0.957322  0.954064  0.941521
138     1390.0  0.972407  0.980070  ...  0.957729  0.953901  0.940870
139     1400.0  0.971878  0.980505  ...  0.957566  0.953901  0.943395
140     1410.0  0.973048  0.980614  ...  0.958055  0.953901  0.940788

[5 rows x 13 columns]
process: 50 / 291. Epoch 1411
process: 100 / 291. Epoch 1411
process: 150 / 291. Epoch 1411
process: 200 / 291. Epoch 1411
process: 250 / 291. Epoch 1411
process: 291 / 291. Epoch 1411
Loss of epoch 1411 = 2.6585403914304124
process: 50 / 291. Epoch 1412
process: 100 / 291. Epoch 1412
process: 150 / 291. Epoch 1412
process: 200 / 291. Epoch 1412
process: 250 / 291. Epoch 1412
process: 291 / 291. Epoch 1412
Loss of epoch 1412 = 2.6186208823292527
process: 50 / 291. Epoch 1413
process: 100 / 291. Epoch 1413
process: 150 / 291. Epoch 1413
process: 200 / 291. Epoch 1413
process: 250 / 291. Epoch 1413
process: 291 / 291. Epoch 1413
Loss of epoch 1413 = 2.6462419123174397
process: 50 / 291. Epoch 1414
process: 100 / 291. Epoch 1414
process: 150 / 291. Epoch 1414
process: 200 / 291. Epoch 1414
process: 250 / 291. Epoch 1414
process: 291 / 291. Epoch 1414
Loss of epoch 1414 = 2.711914691728415
process: 50 / 291. Epoch 1415
process: 100 / 291. Epoch 1415
process: 150 / 291. Epoch 1415
process: 200 / 291. Epoch 1415
process: 250 / 291. Epoch 1415
process: 291 / 291. Epoch 1415
Loss of epoch 1415 = 2.625852604502255
process: 50 / 291. Epoch 1416
process: 100 / 291. Epoch 1416
process: 150 / 291. Epoch 1416
process: 200 / 291. Epoch 1416
process: 250 / 291. Epoch 1416
process: 291 / 291. Epoch 1416
Loss of epoch 1416 = 2.612144863482603
process: 50 / 291. Epoch 1417
process: 100 / 291. Epoch 1417
process: 150 / 291. Epoch 1417
process: 200 / 291. Epoch 1417
process: 250 / 291. Epoch 1417
process: 291 / 291. Epoch 1417
Loss of epoch 1417 = 2.6738499382517182
process: 50 / 291. Epoch 1418
process: 100 / 291. Epoch 1418
process: 150 / 291. Epoch 1418
process: 200 / 291. Epoch 1418
process: 250 / 291. Epoch 1418
process: 291 / 291. Epoch 1418
Loss of epoch 1418 = 2.6388994459434065
process: 50 / 291. Epoch 1419
process: 100 / 291. Epoch 1419
process: 150 / 291. Epoch 1419
process: 200 / 291. Epoch 1419
process: 250 / 291. Epoch 1419
process: 291 / 291. Epoch 1419
Loss of epoch 1419 = 2.638451645054768
process: 50 / 291. Epoch 1420
process: 100 / 291. Epoch 1420
process: 150 / 291. Epoch 1420
process: 200 / 291. Epoch 1420
process: 250 / 291. Epoch 1420
process: 291 / 291. Epoch 1420
Loss of epoch 1420 = 2.6820345219877577
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1420. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.790185
      epoch  training_loss
1415   1416       2.612145
1416   1417       2.673850
1417   1418       2.638899
1418   1419       2.638452
1419   1420       2.682035
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
137       1380  0.015306  0.069612      0.373575   0.374924
138       1390  0.015245  0.069403      0.374516   0.375893
139       1400  0.015172  0.069624      0.373474   0.374780
140       1410  0.015331  0.068914      0.374532   0.375889
141       1420  0.015276  0.069270      0.375118   0.376478
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
137     1380.0  0.972182  0.980510  ...  0.957322  0.954064  0.941521
138     1390.0  0.972407  0.980070  ...  0.957729  0.953901  0.940870
139     1400.0  0.971878  0.980505  ...  0.957566  0.953901  0.943395
140     1410.0  0.973048  0.980614  ...  0.958055  0.953901  0.940788
141     1420.0  0.972407  0.980397  ...  0.957729  0.953901  0.942092

[5 rows x 13 columns]
process: 50 / 291. Epoch 1421
process: 100 / 291. Epoch 1421
process: 150 / 291. Epoch 1421
process: 200 / 291. Epoch 1421
process: 250 / 291. Epoch 1421
process: 291 / 291. Epoch 1421
Loss of epoch 1421 = 2.7010653256550685
process: 50 / 291. Epoch 1422
process: 100 / 291. Epoch 1422
process: 150 / 291. Epoch 1422
process: 200 / 291. Epoch 1422
process: 250 / 291. Epoch 1422
process: 291 / 291. Epoch 1422
Loss of epoch 1422 = 2.6403972193137886
process: 50 / 291. Epoch 1423
process: 100 / 291. Epoch 1423
process: 150 / 291. Epoch 1423
process: 200 / 291. Epoch 1423
process: 250 / 291. Epoch 1423
process: 291 / 291. Epoch 1423
Loss of epoch 1423 = 2.6566225032216493
process: 50 / 291. Epoch 1424
process: 100 / 291. Epoch 1424
process: 150 / 291. Epoch 1424
process: 200 / 291. Epoch 1424
process: 250 / 291. Epoch 1424
process: 291 / 291. Epoch 1424
Loss of epoch 1424 = 2.618547052861899
process: 50 / 291. Epoch 1425
process: 100 / 291. Epoch 1425
process: 150 / 291. Epoch 1425
process: 200 / 291. Epoch 1425
process: 250 / 291. Epoch 1425
process: 291 / 291. Epoch 1425
Loss of epoch 1425 = 2.5716619852072595
process: 50 / 291. Epoch 1426
process: 100 / 291. Epoch 1426
process: 150 / 291. Epoch 1426
process: 200 / 291. Epoch 1426
process: 250 / 291. Epoch 1426
process: 291 / 291. Epoch 1426
Loss of epoch 1426 = 2.6683152451138317
process: 50 / 291. Epoch 1427
process: 100 / 291. Epoch 1427
process: 150 / 291. Epoch 1427
process: 200 / 291. Epoch 1427
process: 250 / 291. Epoch 1427
process: 291 / 291. Epoch 1427
Loss of epoch 1427 = 2.6257636735529424
process: 50 / 291. Epoch 1428
process: 100 / 291. Epoch 1428
process: 150 / 291. Epoch 1428
process: 200 / 291. Epoch 1428
process: 250 / 291. Epoch 1428
process: 291 / 291. Epoch 1428
Loss of epoch 1428 = 2.687635703594824
process: 50 / 291. Epoch 1429
process: 100 / 291. Epoch 1429
process: 150 / 291. Epoch 1429
process: 200 / 291. Epoch 1429
process: 250 / 291. Epoch 1429
process: 291 / 291. Epoch 1429
Loss of epoch 1429 = 2.6672176610153566
process: 50 / 291. Epoch 1430
process: 100 / 291. Epoch 1430
process: 150 / 291. Epoch 1430
process: 200 / 291. Epoch 1430
process: 250 / 291. Epoch 1430
process: 291 / 291. Epoch 1430
Loss of epoch 1430 = 2.6192454964024914
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1430. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.785089
      epoch  training_loss
1425   1426       2.668315
1426   1427       2.625764
1427   1428       2.687636
1428   1429       2.667218
1429   1430       2.619245
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
138       1390  0.015245  0.069403      0.374516   0.375893
139       1400  0.015172  0.069624      0.373474   0.374780
140       1410  0.015331  0.068914      0.374532   0.375889
141       1420  0.015276  0.069270      0.375118   0.376478
142       1430  0.015340  0.068314      0.375934   0.377300
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
138     1390.0  0.972407  0.980070  ...  0.957729  0.953901  0.940870
139     1400.0  0.971878  0.980505  ...  0.957566  0.953901  0.943395
140     1410.0  0.973048  0.980614  ...  0.958055  0.953901  0.940788
141     1420.0  0.972407  0.980397  ...  0.957729  0.953901  0.942092
142     1430.0  0.972281  0.981064  ...  0.957159  0.954390  0.940870

[5 rows x 13 columns]
process: 50 / 291. Epoch 1431
process: 100 / 291. Epoch 1431
process: 150 / 291. Epoch 1431
process: 200 / 291. Epoch 1431
process: 250 / 291. Epoch 1431
process: 291 / 291. Epoch 1431
Loss of epoch 1431 = 2.605468120771585
process: 50 / 291. Epoch 1432
process: 100 / 291. Epoch 1432
process: 150 / 291. Epoch 1432
process: 200 / 291. Epoch 1432
process: 250 / 291. Epoch 1432
process: 291 / 291. Epoch 1432
Loss of epoch 1432 = 2.627209011222079
process: 50 / 291. Epoch 1433
process: 100 / 291. Epoch 1433
process: 150 / 291. Epoch 1433
process: 200 / 291. Epoch 1433
process: 250 / 291. Epoch 1433
process: 291 / 291. Epoch 1433
Loss of epoch 1433 = 2.741602737059708
process: 50 / 291. Epoch 1434
process: 100 / 291. Epoch 1434
process: 150 / 291. Epoch 1434
process: 200 / 291. Epoch 1434
process: 250 / 291. Epoch 1434
process: 291 / 291. Epoch 1434
Loss of epoch 1434 = 2.7110557949420104
process: 50 / 291. Epoch 1435
process: 100 / 291. Epoch 1435
process: 150 / 291. Epoch 1435
process: 200 / 291. Epoch 1435
process: 250 / 291. Epoch 1435
process: 291 / 291. Epoch 1435
Loss of epoch 1435 = 2.6378622677727663
process: 50 / 291. Epoch 1436
process: 100 / 291. Epoch 1436
process: 150 / 291. Epoch 1436
process: 200 / 291. Epoch 1436
process: 250 / 291. Epoch 1436
process: 291 / 291. Epoch 1436
Loss of epoch 1436 = 2.593516346515249
process: 50 / 291. Epoch 1437
process: 100 / 291. Epoch 1437
process: 150 / 291. Epoch 1437
process: 200 / 291. Epoch 1437
process: 250 / 291. Epoch 1437
process: 291 / 291. Epoch 1437
Loss of epoch 1437 = 2.5480392823104596
process: 50 / 291. Epoch 1438
process: 100 / 291. Epoch 1438
process: 150 / 291. Epoch 1438
process: 200 / 291. Epoch 1438
process: 250 / 291. Epoch 1438
process: 291 / 291. Epoch 1438
Loss of epoch 1438 = 2.5557827769276202
process: 50 / 291. Epoch 1439
process: 100 / 291. Epoch 1439
process: 150 / 291. Epoch 1439
process: 200 / 291. Epoch 1439
process: 250 / 291. Epoch 1439
process: 291 / 291. Epoch 1439
Loss of epoch 1439 = 2.66454784485073
process: 50 / 291. Epoch 1440
process: 100 / 291. Epoch 1440
process: 150 / 291. Epoch 1440
process: 200 / 291. Epoch 1440
process: 250 / 291. Epoch 1440
process: 291 / 291. Epoch 1440
Loss of epoch 1440 = 2.6390647232737328
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1440. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.791087
      epoch  training_loss
1435   1436       2.593516
1436   1437       2.548039
1437   1438       2.555783
1438   1439       2.664548
1439   1440       2.639065
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
139       1400  0.015172  0.069624      0.373474   0.374780
140       1410  0.015331  0.068914      0.374532   0.375889
141       1420  0.015276  0.069270      0.375118   0.376478
142       1430  0.015340  0.068314      0.375934   0.377300
143       1440  0.015275  0.069187      0.374946   0.376313
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
139     1400.0  0.971878  0.980505  ...  0.957566  0.953901  0.943395
140     1410.0  0.973048  0.980614  ...  0.958055  0.953901  0.940788
141     1420.0  0.972407  0.980397  ...  0.957729  0.953901  0.942092
142     1430.0  0.972281  0.981064  ...  0.957159  0.954390  0.940870
143     1440.0  0.972401  0.980517  ...  0.957566  0.954309  0.942743

[5 rows x 13 columns]
process: 50 / 291. Epoch 1441
process: 100 / 291. Epoch 1441
process: 150 / 291. Epoch 1441
process: 200 / 291. Epoch 1441
process: 250 / 291. Epoch 1441
process: 291 / 291. Epoch 1441
Loss of epoch 1441 = 2.6558936469743344
process: 50 / 291. Epoch 1442
process: 100 / 291. Epoch 1442
process: 150 / 291. Epoch 1442
process: 200 / 291. Epoch 1442
process: 250 / 291. Epoch 1442
process: 291 / 291. Epoch 1442
Loss of epoch 1442 = 2.6613975079198884
process: 50 / 291. Epoch 1443
process: 100 / 291. Epoch 1443
process: 150 / 291. Epoch 1443
process: 200 / 291. Epoch 1443
process: 250 / 291. Epoch 1443
process: 291 / 291. Epoch 1443
Loss of epoch 1443 = 2.654065318943299
process: 50 / 291. Epoch 1444
process: 100 / 291. Epoch 1444
process: 150 / 291. Epoch 1444
process: 200 / 291. Epoch 1444
process: 250 / 291. Epoch 1444
process: 291 / 291. Epoch 1444
Loss of epoch 1444 = 2.645031696332689
process: 50 / 291. Epoch 1445
process: 100 / 291. Epoch 1445
process: 150 / 291. Epoch 1445
process: 200 / 291. Epoch 1445
process: 250 / 291. Epoch 1445
process: 291 / 291. Epoch 1445
Loss of epoch 1445 = 2.6700997368986252
process: 50 / 291. Epoch 1446
process: 100 / 291. Epoch 1446
process: 150 / 291. Epoch 1446
process: 200 / 291. Epoch 1446
process: 250 / 291. Epoch 1446
process: 291 / 291. Epoch 1446
Loss of epoch 1446 = 2.6698245543384878
process: 50 / 291. Epoch 1447
process: 100 / 291. Epoch 1447
process: 150 / 291. Epoch 1447
process: 200 / 291. Epoch 1447
process: 250 / 291. Epoch 1447
process: 291 / 291. Epoch 1447
Loss of epoch 1447 = 2.6314382651417527
process: 50 / 291. Epoch 1448
process: 100 / 291. Epoch 1448
process: 150 / 291. Epoch 1448
process: 200 / 291. Epoch 1448
process: 250 / 291. Epoch 1448
process: 291 / 291. Epoch 1448
Loss of epoch 1448 = 2.5918312728200172
process: 50 / 291. Epoch 1449
process: 100 / 291. Epoch 1449
process: 150 / 291. Epoch 1449
process: 200 / 291. Epoch 1449
process: 250 / 291. Epoch 1449
process: 291 / 291. Epoch 1449
Loss of epoch 1449 = 2.568088806781572
process: 50 / 291. Epoch 1450
process: 100 / 291. Epoch 1450
process: 150 / 291. Epoch 1450
process: 200 / 291. Epoch 1450
process: 250 / 291. Epoch 1450
process: 291 / 291. Epoch 1450
Loss of epoch 1450 = 2.6563808795103094
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1450. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.794807
      epoch  training_loss
1445   1446       2.669825
1446   1447       2.631438
1447   1448       2.591831
1448   1449       2.568089
1449   1450       2.656381
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
140       1410  0.015331  0.068914      0.374532   0.375889
141       1420  0.015276  0.069270      0.375118   0.376478
142       1430  0.015340  0.068314      0.375934   0.377300
143       1440  0.015275  0.069187      0.374946   0.376313
144       1450  0.015259  0.069631      0.376227   0.377587
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
140     1410.0  0.973048  0.980614  ...  0.958055  0.953901  0.940788
141     1420.0  0.972407  0.980397  ...  0.957729  0.953901  0.942092
142     1430.0  0.972281  0.981064  ...  0.957159  0.954390  0.940870
143     1440.0  0.972401  0.980517  ...  0.957566  0.954309  0.942743
144     1450.0  0.972213  0.980188  ...  0.958137  0.954227  0.942987

[5 rows x 13 columns]
process: 50 / 291. Epoch 1451
process: 100 / 291. Epoch 1451
process: 150 / 291. Epoch 1451
process: 200 / 291. Epoch 1451
process: 250 / 291. Epoch 1451
process: 291 / 291. Epoch 1451
Loss of epoch 1451 = 2.7168130251959837
process: 50 / 291. Epoch 1452
process: 100 / 291. Epoch 1452
process: 150 / 291. Epoch 1452
process: 200 / 291. Epoch 1452
process: 250 / 291. Epoch 1452
process: 291 / 291. Epoch 1452
Loss of epoch 1452 = 2.6133922039438358
process: 50 / 291. Epoch 1453
process: 100 / 291. Epoch 1453
process: 150 / 291. Epoch 1453
process: 200 / 291. Epoch 1453
process: 250 / 291. Epoch 1453
process: 291 / 291. Epoch 1453
Loss of epoch 1453 = 2.592092402612221
process: 50 / 291. Epoch 1454
process: 100 / 291. Epoch 1454
process: 150 / 291. Epoch 1454
process: 200 / 291. Epoch 1454
process: 250 / 291. Epoch 1454
process: 291 / 291. Epoch 1454
Loss of epoch 1454 = 2.5990543955380154
process: 50 / 291. Epoch 1455
process: 100 / 291. Epoch 1455
process: 150 / 291. Epoch 1455
process: 200 / 291. Epoch 1455
process: 250 / 291. Epoch 1455
process: 291 / 291. Epoch 1455
Loss of epoch 1455 = 2.6277528743153993
process: 50 / 291. Epoch 1456
process: 100 / 291. Epoch 1456
process: 150 / 291. Epoch 1456
process: 200 / 291. Epoch 1456
process: 250 / 291. Epoch 1456
process: 291 / 291. Epoch 1456
Loss of epoch 1456 = 2.6167399088541665
process: 50 / 291. Epoch 1457
process: 100 / 291. Epoch 1457
process: 150 / 291. Epoch 1457
process: 200 / 291. Epoch 1457
process: 250 / 291. Epoch 1457
process: 291 / 291. Epoch 1457
Loss of epoch 1457 = 2.6449037532216493
process: 50 / 291. Epoch 1458
process: 100 / 291. Epoch 1458
process: 150 / 291. Epoch 1458
process: 200 / 291. Epoch 1458
process: 250 / 291. Epoch 1458
process: 291 / 291. Epoch 1458
Loss of epoch 1458 = 2.6304757554096865
process: 50 / 291. Epoch 1459
process: 100 / 291. Epoch 1459
process: 150 / 291. Epoch 1459
process: 200 / 291. Epoch 1459
process: 250 / 291. Epoch 1459
process: 291 / 291. Epoch 1459
Loss of epoch 1459 = 2.6196618358703825
process: 50 / 291. Epoch 1460
process: 100 / 291. Epoch 1460
process: 150 / 291. Epoch 1460
process: 200 / 291. Epoch 1460
process: 250 / 291. Epoch 1460
process: 291 / 291. Epoch 1460
Loss of epoch 1460 = 2.6338486294566152
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1460. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.787820
      epoch  training_loss
1455   1456       2.616740
1456   1457       2.644904
1457   1458       2.630476
1458   1459       2.619662
1459   1460       2.633849
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
141       1420  0.015276  0.069270      0.375118   0.376478
142       1430  0.015340  0.068314      0.375934   0.377300
143       1440  0.015275  0.069187      0.374946   0.376313
144       1450  0.015259  0.069631      0.376227   0.377587
145       1460  0.015288  0.068719      0.375641   0.376982
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
141     1420.0  0.972407  0.980397  ...  0.957729  0.953901  0.942092
142     1430.0  0.972281  0.981064  ...  0.957159  0.954390  0.940870
143     1440.0  0.972401  0.980517  ...  0.957566  0.954309  0.942743
144     1450.0  0.972213  0.980188  ...  0.958137  0.954227  0.942987
145     1460.0  0.972718  0.980514  ...  0.957648  0.954227  0.941440

[5 rows x 13 columns]
process: 50 / 291. Epoch 1461
process: 100 / 291. Epoch 1461
process: 150 / 291. Epoch 1461
process: 200 / 291. Epoch 1461
process: 250 / 291. Epoch 1461
process: 291 / 291. Epoch 1461
Loss of epoch 1461 = 2.64788944205058
process: 50 / 291. Epoch 1462
process: 100 / 291. Epoch 1462
process: 150 / 291. Epoch 1462
process: 200 / 291. Epoch 1462
process: 250 / 291. Epoch 1462
process: 291 / 291. Epoch 1462
Loss of epoch 1462 = 2.6511740143766107
process: 50 / 291. Epoch 1463
process: 100 / 291. Epoch 1463
process: 150 / 291. Epoch 1463
process: 200 / 291. Epoch 1463
process: 250 / 291. Epoch 1463
process: 291 / 291. Epoch 1463
Loss of epoch 1463 = 2.5647765484052836
process: 50 / 291. Epoch 1464
process: 100 / 291. Epoch 1464
process: 150 / 291. Epoch 1464
process: 200 / 291. Epoch 1464
process: 250 / 291. Epoch 1464
process: 291 / 291. Epoch 1464
Loss of epoch 1464 = 2.6499174452319587
process: 50 / 291. Epoch 1465
process: 100 / 291. Epoch 1465
process: 150 / 291. Epoch 1465
process: 200 / 291. Epoch 1465
process: 250 / 291. Epoch 1465
process: 291 / 291. Epoch 1465
Loss of epoch 1465 = 2.600954455608355
process: 50 / 291. Epoch 1466
process: 100 / 291. Epoch 1466
process: 150 / 291. Epoch 1466
process: 200 / 291. Epoch 1466
process: 250 / 291. Epoch 1466
process: 291 / 291. Epoch 1466
Loss of epoch 1466 = 2.6572406152679338
process: 50 / 291. Epoch 1467
process: 100 / 291. Epoch 1467
process: 150 / 291. Epoch 1467
process: 200 / 291. Epoch 1467
process: 250 / 291. Epoch 1467
process: 291 / 291. Epoch 1467
Loss of epoch 1467 = 2.6721002637725517
process: 50 / 291. Epoch 1468
process: 100 / 291. Epoch 1468
process: 150 / 291. Epoch 1468
process: 200 / 291. Epoch 1468
process: 250 / 291. Epoch 1468
process: 291 / 291. Epoch 1468
Loss of epoch 1468 = 2.586508000429553
process: 50 / 291. Epoch 1469
process: 100 / 291. Epoch 1469
process: 150 / 291. Epoch 1469
process: 200 / 291. Epoch 1469
process: 250 / 291. Epoch 1469
process: 291 / 291. Epoch 1469
Loss of epoch 1469 = 2.602931701030928
process: 50 / 291. Epoch 1470
process: 100 / 291. Epoch 1470
process: 150 / 291. Epoch 1470
process: 200 / 291. Epoch 1470
process: 250 / 291. Epoch 1470
process: 291 / 291. Epoch 1470
Loss of epoch 1470 = 2.6591570352770617
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1470. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.782413
      epoch  training_loss
1465   1466       2.657241
1466   1467       2.672100
1467   1468       2.586508
1468   1469       2.602932
1469   1470       2.659157
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
142       1430  0.015340  0.068314      0.375934   0.377300
143       1440  0.015275  0.069187      0.374946   0.376313
144       1450  0.015259  0.069631      0.376227   0.377587
145       1460  0.015288  0.068719      0.375641   0.376982
146       1470  0.015338  0.067202      0.376980   0.378365
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
142     1430.0  0.972281  0.981064  ...  0.957159  0.954390  0.940870
143     1440.0  0.972401  0.980517  ...  0.957566  0.954309  0.942743
144     1450.0  0.972213  0.980188  ...  0.958137  0.954227  0.942987
145     1460.0  0.972718  0.980514  ...  0.957648  0.954227  0.941440
146     1470.0  0.972841  0.980952  ...  0.958137  0.954309  0.938019

[5 rows x 13 columns]
process: 50 / 291. Epoch 1471
process: 100 / 291. Epoch 1471
process: 150 / 291. Epoch 1471
process: 200 / 291. Epoch 1471
process: 250 / 291. Epoch 1471
process: 291 / 291. Epoch 1471
Loss of epoch 1471 = 2.5969053707581615
process: 50 / 291. Epoch 1472
process: 100 / 291. Epoch 1472
process: 150 / 291. Epoch 1472
process: 200 / 291. Epoch 1472
process: 250 / 291. Epoch 1472
process: 291 / 291. Epoch 1472
Loss of epoch 1472 = 2.6527634453527704
process: 50 / 291. Epoch 1473
process: 100 / 291. Epoch 1473
process: 150 / 291. Epoch 1473
process: 200 / 291. Epoch 1473
process: 250 / 291. Epoch 1473
process: 291 / 291. Epoch 1473
Loss of epoch 1473 = 2.628919673539519
process: 50 / 291. Epoch 1474
process: 100 / 291. Epoch 1474
process: 150 / 291. Epoch 1474
process: 200 / 291. Epoch 1474
process: 250 / 291. Epoch 1474
process: 291 / 291. Epoch 1474
Loss of epoch 1474 = 2.6716983965582046
process: 50 / 291. Epoch 1475
process: 100 / 291. Epoch 1475
process: 150 / 291. Epoch 1475
process: 200 / 291. Epoch 1475
process: 250 / 291. Epoch 1475
process: 291 / 291. Epoch 1475
Loss of epoch 1475 = 2.599642094877577
process: 50 / 291. Epoch 1476
process: 100 / 291. Epoch 1476
process: 150 / 291. Epoch 1476
process: 200 / 291. Epoch 1476
process: 250 / 291. Epoch 1476
process: 291 / 291. Epoch 1476
Loss of epoch 1476 = 2.5635034095790377
process: 50 / 291. Epoch 1477
process: 100 / 291. Epoch 1477
process: 150 / 291. Epoch 1477
process: 200 / 291. Epoch 1477
process: 250 / 291. Epoch 1477
process: 291 / 291. Epoch 1477
Loss of epoch 1477 = 2.668648736173754
process: 50 / 291. Epoch 1478
process: 100 / 291. Epoch 1478
process: 150 / 291. Epoch 1478
process: 200 / 291. Epoch 1478
process: 250 / 291. Epoch 1478
process: 291 / 291. Epoch 1478
Loss of epoch 1478 = 2.6591236861710694
process: 50 / 291. Epoch 1479
process: 100 / 291. Epoch 1479
process: 150 / 291. Epoch 1479
process: 200 / 291. Epoch 1479
process: 250 / 291. Epoch 1479
process: 291 / 291. Epoch 1479
Loss of epoch 1479 = 2.5908631000322164
process: 50 / 291. Epoch 1480
process: 100 / 291. Epoch 1480
process: 150 / 291. Epoch 1480
process: 200 / 291. Epoch 1480
process: 250 / 291. Epoch 1480
process: 291 / 291. Epoch 1480
Loss of epoch 1480 = 2.5938544519168816
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1480. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.787352
      epoch  training_loss
1475   1476       2.563503
1476   1477       2.668649
1477   1478       2.659124
1478   1479       2.590863
1479   1480       2.593854
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
143       1440  0.015275  0.069187      0.374946   0.376313
144       1450  0.015259  0.069631      0.376227   0.377587
145       1460  0.015288  0.068719      0.375641   0.376982
146       1470  0.015338  0.067202      0.376980   0.378365
147       1480  0.015327  0.068288      0.377032   0.378415
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
143     1440.0  0.972401  0.980517  ...  0.957566  0.954309  0.942743
144     1450.0  0.972213  0.980188  ...  0.958137  0.954227  0.942987
145     1460.0  0.972718  0.980514  ...  0.957648  0.954227  0.941440
146     1470.0  0.972841  0.980952  ...  0.958137  0.954309  0.938019
147     1480.0  0.972607  0.980606  ...  0.957485  0.953576  0.941359

[5 rows x 13 columns]
process: 50 / 291. Epoch 1481
process: 100 / 291. Epoch 1481
process: 150 / 291. Epoch 1481
process: 200 / 291. Epoch 1481
process: 250 / 291. Epoch 1481
process: 291 / 291. Epoch 1481
Loss of epoch 1481 = 2.6488148273061642
process: 50 / 291. Epoch 1482
process: 100 / 291. Epoch 1482
process: 150 / 291. Epoch 1482
process: 200 / 291. Epoch 1482
process: 250 / 291. Epoch 1482
process: 291 / 291. Epoch 1482
Loss of epoch 1482 = 2.6836130463380585
process: 50 / 291. Epoch 1483
process: 100 / 291. Epoch 1483
process: 150 / 291. Epoch 1483
process: 200 / 291. Epoch 1483
process: 250 / 291. Epoch 1483
process: 291 / 291. Epoch 1483
Loss of epoch 1483 = 2.6041207329923752
process: 50 / 291. Epoch 1484
process: 100 / 291. Epoch 1484
process: 150 / 291. Epoch 1484
process: 200 / 291. Epoch 1484
process: 250 / 291. Epoch 1484
process: 291 / 291. Epoch 1484
Loss of epoch 1484 = 2.5912781810432777
process: 50 / 291. Epoch 1485
process: 100 / 291. Epoch 1485
process: 150 / 291. Epoch 1485
process: 200 / 291. Epoch 1485
process: 250 / 291. Epoch 1485
process: 291 / 291. Epoch 1485
Loss of epoch 1485 = 2.6023859502523625
process: 50 / 291. Epoch 1486
process: 100 / 291. Epoch 1486
process: 150 / 291. Epoch 1486
process: 200 / 291. Epoch 1486
process: 250 / 291. Epoch 1486
process: 291 / 291. Epoch 1486
Loss of epoch 1486 = 2.5914896017907
process: 50 / 291. Epoch 1487
process: 100 / 291. Epoch 1487
process: 150 / 291. Epoch 1487
process: 200 / 291. Epoch 1487
process: 250 / 291. Epoch 1487
process: 291 / 291. Epoch 1487
Loss of epoch 1487 = 2.621166740496134
process: 50 / 291. Epoch 1488
process: 100 / 291. Epoch 1488
process: 150 / 291. Epoch 1488
process: 200 / 291. Epoch 1488
process: 250 / 291. Epoch 1488
process: 291 / 291. Epoch 1488
Loss of epoch 1488 = 2.6180103210239474
process: 50 / 291. Epoch 1489
process: 100 / 291. Epoch 1489
process: 150 / 291. Epoch 1489
process: 200 / 291. Epoch 1489
process: 250 / 291. Epoch 1489
process: 291 / 291. Epoch 1489
Loss of epoch 1489 = 2.6509477018900345
process: 50 / 291. Epoch 1490
process: 100 / 291. Epoch 1490
process: 150 / 291. Epoch 1490
process: 200 / 291. Epoch 1490
process: 250 / 291. Epoch 1490
process: 291 / 291. Epoch 1490
Loss of epoch 1490 = 2.5867961870436
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1490. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.790537
      epoch  training_loss
1485   1486       2.591490
1486   1487       2.621167
1487   1488       2.618010
1488   1489       2.650948
1489   1490       2.586796
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
144       1450  0.015259  0.069631      0.376227   0.377587
145       1460  0.015288  0.068719      0.375641   0.376982
146       1470  0.015338  0.067202      0.376980   0.378365
147       1480  0.015327  0.068288      0.377032   0.378415
148       1490  0.015258  0.068417      0.377491   0.378882
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
144     1450.0  0.972213  0.980188  ...  0.958137  0.954227  0.942987
145     1460.0  0.972718  0.980514  ...  0.957648  0.954227  0.941440
146     1470.0  0.972841  0.980952  ...  0.958137  0.954309  0.938019
147     1480.0  0.972607  0.980606  ...  0.957485  0.953576  0.941359
148     1490.0  0.972413  0.980726  ...  0.957892  0.953983  0.941440

[5 rows x 13 columns]
process: 50 / 291. Epoch 1491
process: 100 / 291. Epoch 1491
process: 150 / 291. Epoch 1491
process: 200 / 291. Epoch 1491
process: 250 / 291. Epoch 1491
process: 291 / 291. Epoch 1491
Loss of epoch 1491 = 2.6551679368690935
process: 50 / 291. Epoch 1492
process: 100 / 291. Epoch 1492
process: 150 / 291. Epoch 1492
process: 200 / 291. Epoch 1492
process: 250 / 291. Epoch 1492
process: 291 / 291. Epoch 1492
Loss of epoch 1492 = 2.5808671774323453
process: 50 / 291. Epoch 1493
process: 100 / 291. Epoch 1493
process: 150 / 291. Epoch 1493
process: 200 / 291. Epoch 1493
process: 250 / 291. Epoch 1493
process: 291 / 291. Epoch 1493
Loss of epoch 1493 = 2.6628025749704682
process: 50 / 291. Epoch 1494
process: 100 / 291. Epoch 1494
process: 150 / 291. Epoch 1494
process: 200 / 291. Epoch 1494
process: 250 / 291. Epoch 1494
process: 291 / 291. Epoch 1494
Loss of epoch 1494 = 2.6294717166022337
process: 50 / 291. Epoch 1495
process: 100 / 291. Epoch 1495
process: 150 / 291. Epoch 1495
process: 200 / 291. Epoch 1495
process: 250 / 291. Epoch 1495
process: 291 / 291. Epoch 1495
Loss of epoch 1495 = 2.545238586635524
process: 50 / 291. Epoch 1496
process: 100 / 291. Epoch 1496
process: 150 / 291. Epoch 1496
process: 200 / 291. Epoch 1496
process: 250 / 291. Epoch 1496
process: 291 / 291. Epoch 1496
Loss of epoch 1496 = 2.5630394584944156
process: 50 / 291. Epoch 1497
process: 100 / 291. Epoch 1497
process: 150 / 291. Epoch 1497
process: 200 / 291. Epoch 1497
process: 250 / 291. Epoch 1497
process: 291 / 291. Epoch 1497
Loss of epoch 1497 = 2.6315754369362114
process: 50 / 291. Epoch 1498
process: 100 / 291. Epoch 1498
process: 150 / 291. Epoch 1498
process: 200 / 291. Epoch 1498
process: 250 / 291. Epoch 1498
process: 291 / 291. Epoch 1498
Loss of epoch 1498 = 2.594714397417311
process: 50 / 291. Epoch 1499
process: 100 / 291. Epoch 1499
process: 150 / 291. Epoch 1499
process: 200 / 291. Epoch 1499
process: 250 / 291. Epoch 1499
process: 291 / 291. Epoch 1499
Loss of epoch 1499 = 2.610094417821091
process: 50 / 291. Epoch 1500
process: 100 / 291. Epoch 1500
process: 150 / 291. Epoch 1500
process: 200 / 291. Epoch 1500
process: 250 / 291. Epoch 1500
process: 291 / 291. Epoch 1500
Loss of epoch 1500 = 2.6994381409740122
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1500. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.784677
      epoch  training_loss
1495   1496       2.563039
1496   1497       2.631575
1497   1498       2.594714
1498   1499       2.610094
1499   1500       2.699438
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
145       1460  0.015288  0.068719      0.375641   0.376982
146       1470  0.015338  0.067202      0.376980   0.378365
147       1480  0.015327  0.068288      0.377032   0.378415
148       1490  0.015258  0.068417      0.377491   0.378882
149       1500  0.015293  0.067397      0.377642   0.379043
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
145     1460.0  0.972718  0.980514  ...  0.957648  0.954227  0.941440
146     1470.0  0.972841  0.980952  ...  0.958137  0.954309  0.938019
147     1480.0  0.972607  0.980606  ...  0.957485  0.953576  0.941359
148     1490.0  0.972413  0.980726  ...  0.957892  0.953983  0.941440
149     1500.0  0.972407  0.980824  ...  0.957729  0.953576  0.939322

[5 rows x 13 columns]
process: 50 / 291. Epoch 1501
process: 100 / 291. Epoch 1501
process: 150 / 291. Epoch 1501
process: 200 / 291. Epoch 1501
process: 250 / 291. Epoch 1501
process: 291 / 291. Epoch 1501
Loss of epoch 1501 = 2.567067359321306
process: 50 / 291. Epoch 1502
process: 100 / 291. Epoch 1502
process: 150 / 291. Epoch 1502
process: 200 / 291. Epoch 1502
process: 250 / 291. Epoch 1502
process: 291 / 291. Epoch 1502
Loss of epoch 1502 = 2.5898982831292954
process: 50 / 291. Epoch 1503
process: 100 / 291. Epoch 1503
process: 150 / 291. Epoch 1503
process: 200 / 291. Epoch 1503
process: 250 / 291. Epoch 1503
process: 291 / 291. Epoch 1503
Loss of epoch 1503 = 2.6587320963541665
process: 50 / 291. Epoch 1504
process: 100 / 291. Epoch 1504
process: 150 / 291. Epoch 1504
process: 200 / 291. Epoch 1504
process: 250 / 291. Epoch 1504
process: 291 / 291. Epoch 1504
Loss of epoch 1504 = 2.602242276430949
process: 50 / 291. Epoch 1505
process: 100 / 291. Epoch 1505
process: 150 / 291. Epoch 1505
process: 200 / 291. Epoch 1505
process: 250 / 291. Epoch 1505
process: 291 / 291. Epoch 1505
Loss of epoch 1505 = 2.5962102831024483
process: 50 / 291. Epoch 1506
process: 100 / 291. Epoch 1506
process: 150 / 291. Epoch 1506
process: 200 / 291. Epoch 1506
process: 250 / 291. Epoch 1506
process: 291 / 291. Epoch 1506
Loss of epoch 1506 = 2.6721524897309923
process: 50 / 291. Epoch 1507
process: 100 / 291. Epoch 1507
process: 150 / 291. Epoch 1507
process: 200 / 291. Epoch 1507
process: 250 / 291. Epoch 1507
process: 291 / 291. Epoch 1507
Loss of epoch 1507 = 2.6104801348394546
process: 50 / 291. Epoch 1508
process: 100 / 291. Epoch 1508
process: 150 / 291. Epoch 1508
process: 200 / 291. Epoch 1508
process: 250 / 291. Epoch 1508
process: 291 / 291. Epoch 1508
Loss of epoch 1508 = 2.5650471166237114
process: 50 / 291. Epoch 1509
process: 100 / 291. Epoch 1509
process: 150 / 291. Epoch 1509
process: 200 / 291. Epoch 1509
process: 250 / 291. Epoch 1509
process: 291 / 291. Epoch 1509
Loss of epoch 1509 = 2.5520476770564864
process: 50 / 291. Epoch 1510
process: 100 / 291. Epoch 1510
process: 150 / 291. Epoch 1510
process: 200 / 291. Epoch 1510
process: 250 / 291. Epoch 1510
process: 291 / 291. Epoch 1510
Loss of epoch 1510 = 2.5846731703715635
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1510. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.788392
      epoch  training_loss
1505   1506       2.672152
1506   1507       2.610480
1507   1508       2.565047
1508   1509       2.552048
1509   1510       2.584673
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
146       1470  0.015338  0.067202      0.376980   0.378365
147       1480  0.015327  0.068288      0.377032   0.378415
148       1490  0.015258  0.068417      0.377491   0.378882
149       1500  0.015293  0.067397      0.377642   0.379043
150       1510  0.015280  0.067681      0.377449   0.378812
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
146     1470.0  0.972841  0.980952  ...  0.958137  0.954309  0.938019
147     1480.0  0.972607  0.980606  ...  0.957485  0.953576  0.941359
148     1490.0  0.972413  0.980726  ...  0.957892  0.953983  0.941440
149     1500.0  0.972407  0.980824  ...  0.957729  0.953576  0.939322
150     1510.0  0.971868  0.980608  ...  0.957322  0.953657  0.941359

[5 rows x 13 columns]
process: 50 / 291. Epoch 1511
process: 100 / 291. Epoch 1511
process: 150 / 291. Epoch 1511
process: 200 / 291. Epoch 1511
process: 250 / 291. Epoch 1511
process: 291 / 291. Epoch 1511
Loss of epoch 1511 = 2.569101445044029
process: 50 / 291. Epoch 1512
process: 100 / 291. Epoch 1512
process: 150 / 291. Epoch 1512
process: 200 / 291. Epoch 1512
process: 250 / 291. Epoch 1512
process: 291 / 291. Epoch 1512
Loss of epoch 1512 = 2.6652781692976806
process: 50 / 291. Epoch 1513
process: 100 / 291. Epoch 1513
process: 150 / 291. Epoch 1513
process: 200 / 291. Epoch 1513
process: 250 / 291. Epoch 1513
process: 291 / 291. Epoch 1513
Loss of epoch 1513 = 2.6141168653350517
process: 50 / 291. Epoch 1514
process: 100 / 291. Epoch 1514
process: 150 / 291. Epoch 1514
process: 200 / 291. Epoch 1514
process: 250 / 291. Epoch 1514
process: 291 / 291. Epoch 1514
Loss of epoch 1514 = 2.599147311600623
process: 50 / 291. Epoch 1515
process: 100 / 291. Epoch 1515
process: 150 / 291. Epoch 1515
process: 200 / 291. Epoch 1515
process: 250 / 291. Epoch 1515
process: 291 / 291. Epoch 1515
Loss of epoch 1515 = 2.5984536921445445
process: 50 / 291. Epoch 1516
process: 100 / 291. Epoch 1516
process: 150 / 291. Epoch 1516
process: 200 / 291. Epoch 1516
process: 250 / 291. Epoch 1516
process: 291 / 291. Epoch 1516
Loss of epoch 1516 = 2.555935469689648
process: 50 / 291. Epoch 1517
process: 100 / 291. Epoch 1517
process: 150 / 291. Epoch 1517
process: 200 / 291. Epoch 1517
process: 250 / 291. Epoch 1517
process: 291 / 291. Epoch 1517
Loss of epoch 1517 = 2.5860021007839347
process: 50 / 291. Epoch 1518
process: 100 / 291. Epoch 1518
process: 150 / 291. Epoch 1518
process: 200 / 291. Epoch 1518
process: 250 / 291. Epoch 1518
process: 291 / 291. Epoch 1518
Loss of epoch 1518 = 2.621264900128866
process: 50 / 291. Epoch 1519
process: 100 / 291. Epoch 1519
process: 150 / 291. Epoch 1519
process: 200 / 291. Epoch 1519
process: 250 / 291. Epoch 1519
process: 291 / 291. Epoch 1519
Loss of epoch 1519 = 2.5782437144276202
process: 50 / 291. Epoch 1520
process: 100 / 291. Epoch 1520
process: 150 / 291. Epoch 1520
process: 200 / 291. Epoch 1520
process: 250 / 291. Epoch 1520
process: 291 / 291. Epoch 1520
Loss of epoch 1520 = 2.595984390101482
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1520. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.787221
      epoch  training_loss
1515   1516       2.555935
1516   1517       2.586002
1517   1518       2.621265
1518   1519       2.578244
1519   1520       2.595984
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
147       1480  0.015327  0.068288      0.377032   0.378415
148       1490  0.015258  0.068417      0.377491   0.378882
149       1500  0.015293  0.067397      0.377642   0.379043
150       1510  0.015280  0.067681      0.377449   0.378812
151       1520  0.015316  0.068040      0.377230   0.378623
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
147     1480.0  0.972607  0.980606  ...  0.957485  0.953576  0.941359
148     1490.0  0.972413  0.980726  ...  0.957892  0.953983  0.941440
149     1500.0  0.972407  0.980824  ...  0.957729  0.953576  0.939322
150     1510.0  0.971868  0.980608  ...  0.957322  0.953657  0.941359
151     1520.0  0.972832  0.980728  ...  0.957892  0.954064  0.941603

[5 rows x 13 columns]
process: 50 / 291. Epoch 1521
process: 100 / 291. Epoch 1521
process: 150 / 291. Epoch 1521
process: 200 / 291. Epoch 1521
process: 250 / 291. Epoch 1521
process: 291 / 291. Epoch 1521
Loss of epoch 1521 = 2.6419264541049183
process: 50 / 291. Epoch 1522
process: 100 / 291. Epoch 1522
process: 150 / 291. Epoch 1522
process: 200 / 291. Epoch 1522
process: 250 / 291. Epoch 1522
process: 291 / 291. Epoch 1522
Loss of epoch 1522 = 2.6180470260148194
process: 50 / 291. Epoch 1523
process: 100 / 291. Epoch 1523
process: 150 / 291. Epoch 1523
process: 200 / 291. Epoch 1523
process: 250 / 291. Epoch 1523
process: 291 / 291. Epoch 1523
Loss of epoch 1523 = 2.5880198265678693
process: 50 / 291. Epoch 1524
process: 100 / 291. Epoch 1524
process: 150 / 291. Epoch 1524
process: 200 / 291. Epoch 1524
process: 250 / 291. Epoch 1524
process: 291 / 291. Epoch 1524
Loss of epoch 1524 = 2.5983207152061856
process: 50 / 291. Epoch 1525
process: 100 / 291. Epoch 1525
process: 150 / 291. Epoch 1525
process: 200 / 291. Epoch 1525
process: 250 / 291. Epoch 1525
process: 291 / 291. Epoch 1525
Loss of epoch 1525 = 2.6390364079950603
process: 50 / 291. Epoch 1526
process: 100 / 291. Epoch 1526
process: 150 / 291. Epoch 1526
process: 200 / 291. Epoch 1526
process: 250 / 291. Epoch 1526
process: 291 / 291. Epoch 1526
Loss of epoch 1526 = 2.5386388195339347
process: 50 / 291. Epoch 1527
process: 100 / 291. Epoch 1527
process: 150 / 291. Epoch 1527
process: 200 / 291. Epoch 1527
process: 250 / 291. Epoch 1527
process: 291 / 291. Epoch 1527
Loss of epoch 1527 = 2.6070479035787155
process: 50 / 291. Epoch 1528
process: 100 / 291. Epoch 1528
process: 150 / 291. Epoch 1528
process: 200 / 291. Epoch 1528
process: 250 / 291. Epoch 1528
process: 291 / 291. Epoch 1528
Loss of epoch 1528 = 2.6063658199769115
process: 50 / 291. Epoch 1529
process: 100 / 291. Epoch 1529
process: 150 / 291. Epoch 1529
process: 200 / 291. Epoch 1529
process: 250 / 291. Epoch 1529
process: 291 / 291. Epoch 1529
Loss of epoch 1529 = 2.6291325624865767
process: 50 / 291. Epoch 1530
process: 100 / 291. Epoch 1530
process: 150 / 291. Epoch 1530
process: 200 / 291. Epoch 1530
process: 250 / 291. Epoch 1530
process: 291 / 291. Epoch 1530
Loss of epoch 1530 = 2.6144635701916883
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1530. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.791261
      epoch  training_loss
1525   1526       2.538639
1526   1527       2.607048
1527   1528       2.606366
1528   1529       2.629133
1529   1530       2.614464
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
148       1490  0.015258  0.068417      0.377491   0.378882
149       1500  0.015293  0.067397      0.377642   0.379043
150       1510  0.015280  0.067681      0.377449   0.378812
151       1520  0.015316  0.068040      0.377230   0.378623
152       1530  0.015276  0.069017      0.377868   0.379241
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
148     1490.0  0.972413  0.980726  ...  0.957892  0.953983  0.941440
149     1500.0  0.972407  0.980824  ...  0.957729  0.953576  0.939322
150     1510.0  0.971868  0.980608  ...  0.957322  0.953657  0.941359
151     1520.0  0.972832  0.980728  ...  0.957892  0.954064  0.941603
152     1530.0  0.972401  0.980614  ...  0.957566  0.953901  0.942987

[5 rows x 13 columns]
process: 50 / 291. Epoch 1531
process: 100 / 291. Epoch 1531
process: 150 / 291. Epoch 1531
process: 200 / 291. Epoch 1531
process: 250 / 291. Epoch 1531
process: 291 / 291. Epoch 1531
Loss of epoch 1531 = 2.5626128416290808
process: 50 / 291. Epoch 1532
process: 100 / 291. Epoch 1532
process: 150 / 291. Epoch 1532
process: 200 / 291. Epoch 1532
process: 250 / 291. Epoch 1532
process: 291 / 291. Epoch 1532
Loss of epoch 1532 = 2.6193398806647337
process: 50 / 291. Epoch 1533
process: 100 / 291. Epoch 1533
process: 150 / 291. Epoch 1533
process: 200 / 291. Epoch 1533
process: 250 / 291. Epoch 1533
process: 291 / 291. Epoch 1533
Loss of epoch 1533 = 2.613281459742805
process: 50 / 291. Epoch 1534
process: 100 / 291. Epoch 1534
process: 150 / 291. Epoch 1534
process: 200 / 291. Epoch 1534
process: 250 / 291. Epoch 1534
process: 291 / 291. Epoch 1534
Loss of epoch 1534 = 2.5774345266859964
process: 50 / 291. Epoch 1535
process: 100 / 291. Epoch 1535
process: 150 / 291. Epoch 1535
process: 200 / 291. Epoch 1535
process: 250 / 291. Epoch 1535
process: 291 / 291. Epoch 1535
Loss of epoch 1535 = 2.6098567792230454
process: 50 / 291. Epoch 1536
process: 100 / 291. Epoch 1536
process: 150 / 291. Epoch 1536
process: 200 / 291. Epoch 1536
process: 250 / 291. Epoch 1536
process: 291 / 291. Epoch 1536
Loss of epoch 1536 = 2.557315157860825
process: 50 / 291. Epoch 1537
process: 100 / 291. Epoch 1537
process: 150 / 291. Epoch 1537
process: 200 / 291. Epoch 1537
process: 250 / 291. Epoch 1537
process: 291 / 291. Epoch 1537
Loss of epoch 1537 = 2.5816075695339347
process: 50 / 291. Epoch 1538
process: 100 / 291. Epoch 1538
process: 150 / 291. Epoch 1538
process: 200 / 291. Epoch 1538
process: 250 / 291. Epoch 1538
process: 291 / 291. Epoch 1538
Loss of epoch 1538 = 2.599329368355348
process: 50 / 291. Epoch 1539
process: 100 / 291. Epoch 1539
process: 150 / 291. Epoch 1539
process: 200 / 291. Epoch 1539
process: 250 / 291. Epoch 1539
process: 291 / 291. Epoch 1539
Loss of epoch 1539 = 2.591445136316044
process: 50 / 291. Epoch 1540
process: 100 / 291. Epoch 1540
process: 150 / 291. Epoch 1540
process: 200 / 291. Epoch 1540
process: 250 / 291. Epoch 1540
process: 291 / 291. Epoch 1540
Loss of epoch 1540 = 2.6073530793599655
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1540. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.783705
      epoch  training_loss
1535   1536       2.557315
1536   1537       2.581608
1537   1538       2.599329
1538   1539       2.591445
1539   1540       2.607353
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
149       1500  0.015293  0.067397      0.377642   0.379043
150       1510  0.015280  0.067681      0.377449   0.378812
151       1520  0.015316  0.068040      0.377230   0.378623
152       1530  0.015276  0.069017      0.377868   0.379241
153       1540  0.015391  0.067295      0.377450   0.378805
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
149     1500.0  0.972407  0.980824  ...  0.957729  0.953576  0.939322
150     1510.0  0.971868  0.980608  ...  0.957322  0.953657  0.941359
151     1520.0  0.972832  0.980728  ...  0.957892  0.954064  0.941603
152     1530.0  0.972401  0.980614  ...  0.957566  0.953901  0.942987
153     1540.0  0.972922  0.981059  ...  0.957485  0.954227  0.938182

[5 rows x 13 columns]
process: 50 / 291. Epoch 1541
process: 100 / 291. Epoch 1541
process: 150 / 291. Epoch 1541
process: 200 / 291. Epoch 1541
process: 250 / 291. Epoch 1541
process: 291 / 291. Epoch 1541
Loss of epoch 1541 = 2.5825983945446733
process: 50 / 291. Epoch 1542
process: 100 / 291. Epoch 1542
process: 150 / 291. Epoch 1542
process: 200 / 291. Epoch 1542
process: 250 / 291. Epoch 1542
process: 291 / 291. Epoch 1542
Loss of epoch 1542 = 2.661939063842354
process: 50 / 291. Epoch 1543
process: 100 / 291. Epoch 1543
process: 150 / 291. Epoch 1543
process: 200 / 291. Epoch 1543
process: 250 / 291. Epoch 1543
process: 291 / 291. Epoch 1543
Loss of epoch 1543 = 2.625304127067225
process: 50 / 291. Epoch 1544
process: 100 / 291. Epoch 1544
process: 150 / 291. Epoch 1544
process: 200 / 291. Epoch 1544
process: 250 / 291. Epoch 1544
process: 291 / 291. Epoch 1544
Loss of epoch 1544 = 2.5797194648034796
process: 50 / 291. Epoch 1545
process: 100 / 291. Epoch 1545
process: 150 / 291. Epoch 1545
process: 200 / 291. Epoch 1545
process: 250 / 291. Epoch 1545
process: 291 / 291. Epoch 1545
Loss of epoch 1545 = 2.581495566876074
process: 50 / 291. Epoch 1546
process: 100 / 291. Epoch 1546
process: 150 / 291. Epoch 1546
process: 200 / 291. Epoch 1546
process: 250 / 291. Epoch 1546
process: 291 / 291. Epoch 1546
Loss of epoch 1546 = 2.5613965431029855
process: 50 / 291. Epoch 1547
process: 100 / 291. Epoch 1547
process: 150 / 291. Epoch 1547
process: 200 / 291. Epoch 1547
process: 250 / 291. Epoch 1547
process: 291 / 291. Epoch 1547
Loss of epoch 1547 = 2.597423016000859
process: 50 / 291. Epoch 1548
process: 100 / 291. Epoch 1548
process: 150 / 291. Epoch 1548
process: 200 / 291. Epoch 1548
process: 250 / 291. Epoch 1548
process: 291 / 291. Epoch 1548
Loss of epoch 1548 = 2.6295379953286084
process: 50 / 291. Epoch 1549
process: 100 / 291. Epoch 1549
process: 150 / 291. Epoch 1549
process: 200 / 291. Epoch 1549
process: 250 / 291. Epoch 1549
process: 291 / 291. Epoch 1549
Loss of epoch 1549 = 2.566576561157646
process: 50 / 291. Epoch 1550
process: 100 / 291. Epoch 1550
process: 150 / 291. Epoch 1550
process: 200 / 291. Epoch 1550
process: 250 / 291. Epoch 1550
process: 291 / 291. Epoch 1550
Loss of epoch 1550 = 2.561301739355133
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1550. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.786177
      epoch  training_loss
1545   1546       2.561397
1546   1547       2.597423
1547   1548       2.629538
1548   1549       2.566577
1549   1550       2.561302
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
150       1510  0.015280  0.067681      0.377449   0.378812
151       1520  0.015316  0.068040      0.377230   0.378623
152       1530  0.015276  0.069017      0.377868   0.379241
153       1540  0.015391  0.067295      0.377450   0.378805
154       1550  0.015348  0.067522      0.378770   0.380143
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
150     1510.0  0.971868  0.980608  ...  0.957322  0.953657  0.941359
151     1520.0  0.972832  0.980728  ...  0.957892  0.954064  0.941603
152     1530.0  0.972401  0.980614  ...  0.957566  0.953901  0.942987
153     1540.0  0.972922  0.981059  ...  0.957485  0.954227  0.938182
154     1550.0  0.972613  0.980946  ...  0.957648  0.954064  0.940544

[5 rows x 13 columns]
process: 50 / 291. Epoch 1551
process: 100 / 291. Epoch 1551
process: 150 / 291. Epoch 1551
process: 200 / 291. Epoch 1551
process: 250 / 291. Epoch 1551
process: 291 / 291. Epoch 1551
Loss of epoch 1551 = 2.604331943996993
process: 50 / 291. Epoch 1552
process: 100 / 291. Epoch 1552
process: 150 / 291. Epoch 1552
process: 200 / 291. Epoch 1552
process: 250 / 291. Epoch 1552
process: 291 / 291. Epoch 1552
Loss of epoch 1552 = 2.6870513601401416
process: 50 / 291. Epoch 1553
process: 100 / 291. Epoch 1553
process: 150 / 291. Epoch 1553
process: 200 / 291. Epoch 1553
process: 250 / 291. Epoch 1553
process: 291 / 291. Epoch 1553
Loss of epoch 1553 = 2.5684663438305413
process: 50 / 291. Epoch 1554
process: 100 / 291. Epoch 1554
process: 150 / 291. Epoch 1554
process: 200 / 291. Epoch 1554
process: 250 / 291. Epoch 1554
process: 291 / 291. Epoch 1554
Loss of epoch 1554 = 2.5926106770833335
process: 50 / 291. Epoch 1555
process: 100 / 291. Epoch 1555
process: 150 / 291. Epoch 1555
process: 200 / 291. Epoch 1555
process: 250 / 291. Epoch 1555
process: 291 / 291. Epoch 1555
Loss of epoch 1555 = 2.5365625755074097
process: 50 / 291. Epoch 1556
process: 100 / 291. Epoch 1556
process: 150 / 291. Epoch 1556
process: 200 / 291. Epoch 1556
process: 250 / 291. Epoch 1556
process: 291 / 291. Epoch 1556
Loss of epoch 1556 = 2.569772622019974
process: 50 / 291. Epoch 1557
process: 100 / 291. Epoch 1557
process: 150 / 291. Epoch 1557
process: 200 / 291. Epoch 1557
process: 250 / 291. Epoch 1557
process: 291 / 291. Epoch 1557
Loss of epoch 1557 = 2.5611398179096865
process: 50 / 291. Epoch 1558
process: 100 / 291. Epoch 1558
process: 150 / 291. Epoch 1558
process: 200 / 291. Epoch 1558
process: 250 / 291. Epoch 1558
process: 291 / 291. Epoch 1558
Loss of epoch 1558 = 2.6317205789572595
process: 50 / 291. Epoch 1559
process: 100 / 291. Epoch 1559
process: 150 / 291. Epoch 1559
process: 200 / 291. Epoch 1559
process: 250 / 291. Epoch 1559
process: 291 / 291. Epoch 1559
Loss of epoch 1559 = 2.6012994825225517
process: 50 / 291. Epoch 1560
process: 100 / 291. Epoch 1560
process: 150 / 291. Epoch 1560
process: 200 / 291. Epoch 1560
process: 250 / 291. Epoch 1560
process: 291 / 291. Epoch 1560
Loss of epoch 1560 = 2.606113918868127
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1560. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.793972
      epoch  training_loss
1555   1556       2.569773
1556   1557       2.561140
1557   1558       2.631721
1558   1559       2.601299
1559   1560       2.606114
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
151       1520  0.015316  0.068040      0.377230   0.378623
152       1530  0.015276  0.069017      0.377868   0.379241
153       1540  0.015391  0.067295      0.377450   0.378805
154       1550  0.015348  0.067522      0.378770   0.380143
155       1560  0.015158  0.068928      0.378267   0.379635
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
151     1520.0  0.972832  0.980728  ...  0.957892  0.954064  0.941603
152     1530.0  0.972401  0.980614  ...  0.957566  0.953901  0.942987
153     1540.0  0.972922  0.981059  ...  0.957485  0.954227  0.938182
154     1550.0  0.972613  0.980946  ...  0.957648  0.954064  0.940544
155     1560.0  0.971976  0.980297  ...  0.957403  0.954227  0.944453

[5 rows x 13 columns]
process: 50 / 291. Epoch 1561
process: 100 / 291. Epoch 1561
process: 150 / 291. Epoch 1561
process: 200 / 291. Epoch 1561
process: 250 / 291. Epoch 1561
process: 291 / 291. Epoch 1561
Loss of epoch 1561 = 2.5421423633483675
process: 50 / 291. Epoch 1562
process: 100 / 291. Epoch 1562
process: 150 / 291. Epoch 1562
process: 200 / 291. Epoch 1562
process: 250 / 291. Epoch 1562
process: 291 / 291. Epoch 1562
Loss of epoch 1562 = 2.5604310969716493
process: 50 / 291. Epoch 1563
process: 100 / 291. Epoch 1563
process: 150 / 291. Epoch 1563
process: 200 / 291. Epoch 1563
process: 250 / 291. Epoch 1563
process: 291 / 291. Epoch 1563
Loss of epoch 1563 = 2.659852122932775
process: 50 / 291. Epoch 1564
process: 100 / 291. Epoch 1564
process: 150 / 291. Epoch 1564
process: 200 / 291. Epoch 1564
process: 250 / 291. Epoch 1564
process: 291 / 291. Epoch 1564
Loss of epoch 1564 = 2.5881389604811
process: 50 / 291. Epoch 1565
process: 100 / 291. Epoch 1565
process: 150 / 291. Epoch 1565
process: 200 / 291. Epoch 1565
process: 250 / 291. Epoch 1565
process: 291 / 291. Epoch 1565
Loss of epoch 1565 = 2.5361911209997854
process: 50 / 291. Epoch 1566
process: 100 / 291. Epoch 1566
process: 150 / 291. Epoch 1566
process: 200 / 291. Epoch 1566
process: 250 / 291. Epoch 1566
process: 291 / 291. Epoch 1566
Loss of epoch 1566 = 2.6078057043331184
process: 50 / 291. Epoch 1567
process: 100 / 291. Epoch 1567
process: 150 / 291. Epoch 1567
process: 200 / 291. Epoch 1567
process: 250 / 291. Epoch 1567
process: 291 / 291. Epoch 1567
Loss of epoch 1567 = 2.5700278790136384
process: 50 / 291. Epoch 1568
process: 100 / 291. Epoch 1568
process: 150 / 291. Epoch 1568
process: 200 / 291. Epoch 1568
process: 250 / 291. Epoch 1568
process: 291 / 291. Epoch 1568
Loss of epoch 1568 = 2.613504416344502
process: 50 / 291. Epoch 1569
process: 100 / 291. Epoch 1569
process: 150 / 291. Epoch 1569
process: 200 / 291. Epoch 1569
process: 250 / 291. Epoch 1569
process: 291 / 291. Epoch 1569
Loss of epoch 1569 = 2.581165221958226
process: 50 / 291. Epoch 1570
process: 100 / 291. Epoch 1570
process: 150 / 291. Epoch 1570
process: 200 / 291. Epoch 1570
process: 250 / 291. Epoch 1570
process: 291 / 291. Epoch 1570
Loss of epoch 1570 = 2.5812614939057132
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1570. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.785375
      epoch  training_loss
1565   1566       2.607806
1566   1567       2.570028
1567   1568       2.613504
1568   1569       2.581165
1569   1570       2.581261
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
152       1530  0.015276  0.069017      0.377868   0.379241
153       1540  0.015391  0.067295      0.377450   0.378805
154       1550  0.015348  0.067522      0.378770   0.380143
155       1560  0.015158  0.068928      0.378267   0.379635
156       1570  0.015314  0.066792      0.378790   0.380182
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
152     1530.0  0.972401  0.980614  ...  0.957566  0.953901  0.942987
153     1540.0  0.972922  0.981059  ...  0.957485  0.954227  0.938182
154     1550.0  0.972613  0.980946  ...  0.957648  0.954064  0.940544
155     1560.0  0.971976  0.980297  ...  0.957403  0.954227  0.944453
156     1570.0  0.972506  0.980817  ...  0.957566  0.953331  0.939648

[5 rows x 13 columns]
process: 50 / 291. Epoch 1571
process: 100 / 291. Epoch 1571
process: 150 / 291. Epoch 1571
process: 200 / 291. Epoch 1571
process: 250 / 291. Epoch 1571
process: 291 / 291. Epoch 1571
Loss of epoch 1571 = 2.537279686157646
process: 50 / 291. Epoch 1572
process: 100 / 291. Epoch 1572
process: 150 / 291. Epoch 1572
process: 200 / 291. Epoch 1572
process: 250 / 291. Epoch 1572
process: 291 / 291. Epoch 1572
Loss of epoch 1572 = 2.5462822668331184
process: 50 / 291. Epoch 1573
process: 100 / 291. Epoch 1573
process: 150 / 291. Epoch 1573
process: 200 / 291. Epoch 1573
process: 250 / 291. Epoch 1573
process: 291 / 291. Epoch 1573
Loss of epoch 1573 = 2.6427952088031574
process: 50 / 291. Epoch 1574
process: 100 / 291. Epoch 1574
process: 150 / 291. Epoch 1574
process: 200 / 291. Epoch 1574
process: 250 / 291. Epoch 1574
process: 291 / 291. Epoch 1574
Loss of epoch 1574 = 2.625498978133054
process: 50 / 291. Epoch 1575
process: 100 / 291. Epoch 1575
process: 150 / 291. Epoch 1575
process: 200 / 291. Epoch 1575
process: 250 / 291. Epoch 1575
process: 291 / 291. Epoch 1575
Loss of epoch 1575 = 2.5535339145725944
process: 50 / 291. Epoch 1576
process: 100 / 291. Epoch 1576
process: 150 / 291. Epoch 1576
process: 200 / 291. Epoch 1576
process: 250 / 291. Epoch 1576
process: 291 / 291. Epoch 1576
Loss of epoch 1576 = 2.602369800056379
process: 50 / 291. Epoch 1577
process: 100 / 291. Epoch 1577
process: 150 / 291. Epoch 1577
process: 200 / 291. Epoch 1577
process: 250 / 291. Epoch 1577
process: 291 / 291. Epoch 1577
Loss of epoch 1577 = 2.556443886248926
process: 50 / 291. Epoch 1578
process: 100 / 291. Epoch 1578
process: 150 / 291. Epoch 1578
process: 200 / 291. Epoch 1578
process: 250 / 291. Epoch 1578
process: 291 / 291. Epoch 1578
Loss of epoch 1578 = 2.5028606821171606
process: 50 / 291. Epoch 1579
process: 100 / 291. Epoch 1579
process: 150 / 291. Epoch 1579
process: 200 / 291. Epoch 1579
process: 250 / 291. Epoch 1579
process: 291 / 291. Epoch 1579
Loss of epoch 1579 = 2.541283256819158
process: 50 / 291. Epoch 1580
process: 100 / 291. Epoch 1580
process: 150 / 291. Epoch 1580
process: 200 / 291. Epoch 1580
process: 250 / 291. Epoch 1580
process: 291 / 291. Epoch 1580
Loss of epoch 1580 = 2.5562807063466493
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1580. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.788930
      epoch  training_loss
1575   1576       2.602370
1576   1577       2.556444
1577   1578       2.502861
1578   1579       2.541283
1579   1580       2.556281
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
153       1540  0.015391  0.067295      0.377450   0.378805
154       1550  0.015348  0.067522      0.378770   0.380143
155       1560  0.015158  0.068928      0.378267   0.379635
156       1570  0.015314  0.066792      0.378790   0.380182
157       1580  0.015226  0.067423      0.377853   0.379226
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
153     1540.0  0.972922  0.981059  ...  0.957485  0.954227  0.938182
154     1550.0  0.972613  0.980946  ...  0.957648  0.954064  0.940544
155     1560.0  0.971976  0.980297  ...  0.957403  0.954227  0.944453
156     1570.0  0.972506  0.980817  ...  0.957566  0.953331  0.939648
157     1580.0  0.972650  0.980512  ...  0.958625  0.954146  0.942336

[5 rows x 13 columns]
process: 50 / 291. Epoch 1581
process: 100 / 291. Epoch 1581
process: 150 / 291. Epoch 1581
process: 200 / 291. Epoch 1581
process: 250 / 291. Epoch 1581
process: 291 / 291. Epoch 1581
Loss of epoch 1581 = 2.6154382450064433
process: 50 / 291. Epoch 1582
process: 100 / 291. Epoch 1582
process: 150 / 291. Epoch 1582
process: 200 / 291. Epoch 1582
process: 250 / 291. Epoch 1582
process: 291 / 291. Epoch 1582
Loss of epoch 1582 = 2.6301001060459623
process: 50 / 291. Epoch 1583
process: 100 / 291. Epoch 1583
process: 150 / 291. Epoch 1583
process: 200 / 291. Epoch 1583
process: 250 / 291. Epoch 1583
process: 291 / 291. Epoch 1583
Loss of epoch 1583 = 2.620385238804768
process: 50 / 291. Epoch 1584
process: 100 / 291. Epoch 1584
process: 150 / 291. Epoch 1584
process: 200 / 291. Epoch 1584
process: 250 / 291. Epoch 1584
process: 291 / 291. Epoch 1584
Loss of epoch 1584 = 2.5624685385792527
process: 50 / 291. Epoch 1585
process: 100 / 291. Epoch 1585
process: 150 / 291. Epoch 1585
process: 200 / 291. Epoch 1585
process: 250 / 291. Epoch 1585
process: 291 / 291. Epoch 1585
Loss of epoch 1585 = 2.6641453484079682
process: 50 / 291. Epoch 1586
process: 100 / 291. Epoch 1586
process: 150 / 291. Epoch 1586
process: 200 / 291. Epoch 1586
process: 250 / 291. Epoch 1586
process: 291 / 291. Epoch 1586
Loss of epoch 1586 = 2.578779607294351
process: 50 / 291. Epoch 1587
process: 100 / 291. Epoch 1587
process: 150 / 291. Epoch 1587
process: 200 / 291. Epoch 1587
process: 250 / 291. Epoch 1587
process: 291 / 291. Epoch 1587
Loss of epoch 1587 = 2.516587929217676
process: 50 / 291. Epoch 1588
process: 100 / 291. Epoch 1588
process: 150 / 291. Epoch 1588
process: 200 / 291. Epoch 1588
process: 250 / 291. Epoch 1588
process: 291 / 291. Epoch 1588
Loss of epoch 1588 = 2.558755671445447
process: 50 / 291. Epoch 1589
process: 100 / 291. Epoch 1589
process: 150 / 291. Epoch 1589
process: 200 / 291. Epoch 1589
process: 250 / 291. Epoch 1589
process: 291 / 291. Epoch 1589
Loss of epoch 1589 = 2.5412098468374142
process: 50 / 291. Epoch 1590
process: 100 / 291. Epoch 1590
process: 150 / 291. Epoch 1590
process: 200 / 291. Epoch 1590
process: 250 / 291. Epoch 1590
process: 291 / 291. Epoch 1590
Loss of epoch 1590 = 2.5758409008537373
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1590. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.790305
      epoch  training_loss
1585   1586       2.578780
1586   1587       2.516588
1587   1588       2.558756
1588   1589       2.541210
1589   1590       2.575841
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
154       1550  0.015348  0.067522      0.378770   0.380143
155       1560  0.015158  0.068928      0.378267   0.379635
156       1570  0.015314  0.066792      0.378790   0.380182
157       1580  0.015226  0.067423      0.377853   0.379226
158       1590  0.015234  0.067317      0.379500   0.380918
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
154     1550.0  0.972613  0.980946  ...  0.957648  0.954064  0.940544
155     1560.0  0.971976  0.980297  ...  0.957403  0.954227  0.944453
156     1570.0  0.972506  0.980817  ...  0.957566  0.953331  0.939648
157     1580.0  0.972650  0.980512  ...  0.958625  0.954146  0.942336
158     1590.0  0.972216  0.980521  ...  0.958218  0.954471  0.942743

[5 rows x 13 columns]
process: 50 / 291. Epoch 1591
process: 100 / 291. Epoch 1591
process: 150 / 291. Epoch 1591
process: 200 / 291. Epoch 1591
process: 250 / 291. Epoch 1591
process: 291 / 291. Epoch 1591
Loss of epoch 1591 = 2.5209291857952105
process: 50 / 291. Epoch 1592
process: 100 / 291. Epoch 1592
process: 150 / 291. Epoch 1592
process: 200 / 291. Epoch 1592
process: 250 / 291. Epoch 1592
process: 291 / 291. Epoch 1592
Loss of epoch 1592 = 2.5777768269437287
process: 50 / 291. Epoch 1593
process: 100 / 291. Epoch 1593
process: 150 / 291. Epoch 1593
process: 200 / 291. Epoch 1593
process: 250 / 291. Epoch 1593
process: 291 / 291. Epoch 1593
Loss of epoch 1593 = 2.611472218307023
process: 50 / 291. Epoch 1594
process: 100 / 291. Epoch 1594
process: 150 / 291. Epoch 1594
process: 200 / 291. Epoch 1594
process: 250 / 291. Epoch 1594
process: 291 / 291. Epoch 1594
Loss of epoch 1594 = 2.640957652088703
process: 50 / 291. Epoch 1595
process: 100 / 291. Epoch 1595
process: 150 / 291. Epoch 1595
process: 200 / 291. Epoch 1595
process: 250 / 291. Epoch 1595
process: 291 / 291. Epoch 1595
Loss of epoch 1595 = 2.6378723354274056
process: 50 / 291. Epoch 1596
process: 100 / 291. Epoch 1596
process: 150 / 291. Epoch 1596
process: 200 / 291. Epoch 1596
process: 250 / 291. Epoch 1596
process: 291 / 291. Epoch 1596
Loss of epoch 1596 = 2.5421083850139605
process: 50 / 291. Epoch 1597
process: 100 / 291. Epoch 1597
process: 150 / 291. Epoch 1597
process: 200 / 291. Epoch 1597
process: 250 / 291. Epoch 1597
process: 291 / 291. Epoch 1597
Loss of epoch 1597 = 2.527419676895404
process: 50 / 291. Epoch 1598
process: 100 / 291. Epoch 1598
process: 150 / 291. Epoch 1598
process: 200 / 291. Epoch 1598
process: 250 / 291. Epoch 1598
process: 291 / 291. Epoch 1598
Loss of epoch 1598 = 2.5630931526524914
process: 50 / 291. Epoch 1599
process: 100 / 291. Epoch 1599
process: 150 / 291. Epoch 1599
process: 200 / 291. Epoch 1599
process: 250 / 291. Epoch 1599
process: 291 / 291. Epoch 1599
Loss of epoch 1599 = 2.5941493503006874
process: 50 / 291. Epoch 1600
process: 100 / 291. Epoch 1600
process: 150 / 291. Epoch 1600
process: 200 / 291. Epoch 1600
process: 250 / 291. Epoch 1600
process: 291 / 291. Epoch 1600
Loss of epoch 1600 = 2.5869771950843
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1600. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.785334
      epoch  training_loss
1595   1596       2.542108
1596   1597       2.527420
1597   1598       2.563093
1598   1599       2.594149
1599   1600       2.586977
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
155       1560  0.015158  0.068928      0.378267   0.379635
156       1570  0.015314  0.066792      0.378790   0.380182
157       1580  0.015226  0.067423      0.377853   0.379226
158       1590  0.015234  0.067317      0.379500   0.380918
159       1600  0.015385  0.066457      0.379564   0.380955
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
155     1560.0  0.971976  0.980297  ...  0.957403  0.954227  0.944453
156     1570.0  0.972506  0.980817  ...  0.957566  0.953331  0.939648
157     1580.0  0.972650  0.980512  ...  0.958625  0.954146  0.942336
158     1590.0  0.972216  0.980521  ...  0.958218  0.954471  0.942743
159     1600.0  0.972524  0.980935  ...  0.958055  0.953657  0.939811

[5 rows x 13 columns]
process: 50 / 291. Epoch 1601
process: 100 / 291. Epoch 1601
process: 150 / 291. Epoch 1601
process: 200 / 291. Epoch 1601
process: 250 / 291. Epoch 1601
process: 291 / 291. Epoch 1601
Loss of epoch 1601 = 2.56017982509128
process: 50 / 291. Epoch 1602
process: 100 / 291. Epoch 1602
process: 150 / 291. Epoch 1602
process: 200 / 291. Epoch 1602
process: 250 / 291. Epoch 1602
process: 291 / 291. Epoch 1602
Loss of epoch 1602 = 2.530234635081078
process: 50 / 291. Epoch 1603
process: 100 / 291. Epoch 1603
process: 150 / 291. Epoch 1603
process: 200 / 291. Epoch 1603
process: 250 / 291. Epoch 1603
process: 291 / 291. Epoch 1603
Loss of epoch 1603 = 2.54272586783183
process: 50 / 291. Epoch 1604
process: 100 / 291. Epoch 1604
process: 150 / 291. Epoch 1604
process: 200 / 291. Epoch 1604
process: 250 / 291. Epoch 1604
process: 291 / 291. Epoch 1604
Loss of epoch 1604 = 2.5472240120274914
process: 50 / 291. Epoch 1605
process: 100 / 291. Epoch 1605
process: 150 / 291. Epoch 1605
process: 200 / 291. Epoch 1605
process: 250 / 291. Epoch 1605
process: 291 / 291. Epoch 1605
Loss of epoch 1605 = 2.534937278511598
process: 50 / 291. Epoch 1606
process: 100 / 291. Epoch 1606
process: 150 / 291. Epoch 1606
process: 200 / 291. Epoch 1606
process: 250 / 291. Epoch 1606
process: 291 / 291. Epoch 1606
Loss of epoch 1606 = 2.604551334971005
process: 50 / 291. Epoch 1607
process: 100 / 291. Epoch 1607
process: 150 / 291. Epoch 1607
process: 200 / 291. Epoch 1607
process: 250 / 291. Epoch 1607
process: 291 / 291. Epoch 1607
Loss of epoch 1607 = 2.558215583722616
process: 50 / 291. Epoch 1608
process: 100 / 291. Epoch 1608
process: 150 / 291. Epoch 1608
process: 200 / 291. Epoch 1608
process: 250 / 291. Epoch 1608
process: 291 / 291. Epoch 1608
Loss of epoch 1608 = 2.6249110690506874
process: 50 / 291. Epoch 1609
process: 100 / 291. Epoch 1609
process: 150 / 291. Epoch 1609
process: 200 / 291. Epoch 1609
process: 250 / 291. Epoch 1609
process: 291 / 291. Epoch 1609
Loss of epoch 1609 = 2.5744039528968
process: 50 / 291. Epoch 1610
process: 100 / 291. Epoch 1610
process: 150 / 291. Epoch 1610
process: 200 / 291. Epoch 1610
process: 250 / 291. Epoch 1610
process: 291 / 291. Epoch 1610
Loss of epoch 1610 = 2.506677371939433
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1610. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.783206
      epoch  training_loss
1605   1606       2.604551
1606   1607       2.558216
1607   1608       2.624911
1608   1609       2.574404
1609   1610       2.506677
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
156       1570  0.015314  0.066792      0.378790   0.380182
157       1580  0.015226  0.067423      0.377853   0.379226
158       1590  0.015234  0.067317      0.379500   0.380918
159       1600  0.015385  0.066457      0.379564   0.380955
160       1610  0.015387  0.065524      0.379985   0.381418
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
156     1570.0  0.972506  0.980817  ...  0.957566  0.953331  0.939648
157     1580.0  0.972650  0.980512  ...  0.958625  0.954146  0.942336
158     1590.0  0.972216  0.980521  ...  0.958218  0.954471  0.942743
159     1600.0  0.972524  0.980935  ...  0.958055  0.953657  0.939811
160     1610.0  0.972601  0.980837  ...  0.957322  0.954064  0.939648

[5 rows x 13 columns]
process: 50 / 291. Epoch 1611
process: 100 / 291. Epoch 1611
process: 150 / 291. Epoch 1611
process: 200 / 291. Epoch 1611
process: 250 / 291. Epoch 1611
process: 291 / 291. Epoch 1611
Loss of epoch 1611 = 2.52245884007195
process: 50 / 291. Epoch 1612
process: 100 / 291. Epoch 1612
process: 150 / 291. Epoch 1612
process: 200 / 291. Epoch 1612
process: 250 / 291. Epoch 1612
process: 291 / 291. Epoch 1612
Loss of epoch 1612 = 2.527429954292848
process: 50 / 291. Epoch 1613
process: 100 / 291. Epoch 1613
process: 150 / 291. Epoch 1613
process: 200 / 291. Epoch 1613
process: 250 / 291. Epoch 1613
process: 291 / 291. Epoch 1613
Loss of epoch 1613 = 2.5938401894061425
process: 50 / 291. Epoch 1614
process: 100 / 291. Epoch 1614
process: 150 / 291. Epoch 1614
process: 200 / 291. Epoch 1614
process: 250 / 291. Epoch 1614
process: 291 / 291. Epoch 1614
Loss of epoch 1614 = 2.5633494583601806
process: 50 / 291. Epoch 1615
process: 100 / 291. Epoch 1615
process: 150 / 291. Epoch 1615
process: 200 / 291. Epoch 1615
process: 250 / 291. Epoch 1615
process: 291 / 291. Epoch 1615
Loss of epoch 1615 = 2.5688287793975517
process: 50 / 291. Epoch 1616
process: 100 / 291. Epoch 1616
process: 150 / 291. Epoch 1616
process: 200 / 291. Epoch 1616
process: 250 / 291. Epoch 1616
process: 291 / 291. Epoch 1616
Loss of epoch 1616 = 2.5842301935674397
process: 50 / 291. Epoch 1617
process: 100 / 291. Epoch 1617
process: 150 / 291. Epoch 1617
process: 200 / 291. Epoch 1617
process: 250 / 291. Epoch 1617
process: 291 / 291. Epoch 1617
Loss of epoch 1617 = 2.5404648403941152
process: 50 / 291. Epoch 1618
process: 100 / 291. Epoch 1618
process: 150 / 291. Epoch 1618
process: 200 / 291. Epoch 1618
process: 250 / 291. Epoch 1618
process: 291 / 291. Epoch 1618
Loss of epoch 1618 = 2.5597632758805844
process: 50 / 291. Epoch 1619
process: 100 / 291. Epoch 1619
process: 150 / 291. Epoch 1619
process: 200 / 291. Epoch 1619
process: 250 / 291. Epoch 1619
process: 291 / 291. Epoch 1619
Loss of epoch 1619 = 2.6252361703984106
process: 50 / 291. Epoch 1620
process: 100 / 291. Epoch 1620
process: 150 / 291. Epoch 1620
process: 200 / 291. Epoch 1620
process: 250 / 291. Epoch 1620
process: 291 / 291. Epoch 1620
Loss of epoch 1620 = 2.655261062674506
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1620. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.785577
      epoch  training_loss
1615   1616       2.584230
1616   1617       2.540465
1617   1618       2.559763
1618   1619       2.625236
1619   1620       2.655261
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
157       1580  0.015226  0.067423      0.377853   0.379226
158       1590  0.015234  0.067317      0.379500   0.380918
159       1600  0.015385  0.066457      0.379564   0.380955
160       1610  0.015387  0.065524      0.379985   0.381418
161       1620  0.015414  0.066395      0.379210   0.380605
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
157     1580.0  0.972650  0.980512  ...  0.958625  0.954146  0.942336
158     1590.0  0.972216  0.980521  ...  0.958218  0.954471  0.942743
159     1600.0  0.972524  0.980935  ...  0.958055  0.953657  0.939811
160     1610.0  0.972601  0.980837  ...  0.957322  0.954064  0.939648
161     1620.0  0.971970  0.980723  ...  0.957241  0.953901  0.939567

[5 rows x 13 columns]
process: 50 / 291. Epoch 1621
process: 100 / 291. Epoch 1621
process: 150 / 291. Epoch 1621
process: 200 / 291. Epoch 1621
process: 250 / 291. Epoch 1621
process: 291 / 291. Epoch 1621
Loss of epoch 1621 = 2.54357868207689
process: 50 / 291. Epoch 1622
process: 100 / 291. Epoch 1622
process: 150 / 291. Epoch 1622
process: 200 / 291. Epoch 1622
process: 250 / 291. Epoch 1622
process: 291 / 291. Epoch 1622
Loss of epoch 1622 = 2.495092857334622
process: 50 / 291. Epoch 1623
process: 100 / 291. Epoch 1623
process: 150 / 291. Epoch 1623
process: 200 / 291. Epoch 1623
process: 250 / 291. Epoch 1623
process: 291 / 291. Epoch 1623
Loss of epoch 1623 = 2.5889961793250644
process: 50 / 291. Epoch 1624
process: 100 / 291. Epoch 1624
process: 150 / 291. Epoch 1624
process: 200 / 291. Epoch 1624
process: 250 / 291. Epoch 1624
process: 291 / 291. Epoch 1624
Loss of epoch 1624 = 2.576270873603952
process: 50 / 291. Epoch 1625
process: 100 / 291. Epoch 1625
process: 150 / 291. Epoch 1625
process: 200 / 291. Epoch 1625
process: 250 / 291. Epoch 1625
process: 291 / 291. Epoch 1625
Loss of epoch 1625 = 2.5006896343427836
process: 50 / 291. Epoch 1626
process: 100 / 291. Epoch 1626
process: 150 / 291. Epoch 1626
process: 200 / 291. Epoch 1626
process: 250 / 291. Epoch 1626
process: 291 / 291. Epoch 1626
Loss of epoch 1626 = 2.5603941822379723
process: 50 / 291. Epoch 1627
process: 100 / 291. Epoch 1627
process: 150 / 291. Epoch 1627
process: 200 / 291. Epoch 1627
process: 250 / 291. Epoch 1627
process: 291 / 291. Epoch 1627
Loss of epoch 1627 = 2.613449463729596
process: 50 / 291. Epoch 1628
process: 100 / 291. Epoch 1628
process: 150 / 291. Epoch 1628
process: 200 / 291. Epoch 1628
process: 250 / 291. Epoch 1628
process: 291 / 291. Epoch 1628
Loss of epoch 1628 = 2.572181727878007
process: 50 / 291. Epoch 1629
process: 100 / 291. Epoch 1629
process: 150 / 291. Epoch 1629
process: 200 / 291. Epoch 1629
process: 250 / 291. Epoch 1629
process: 291 / 291. Epoch 1629
Loss of epoch 1629 = 2.502772590139068
process: 50 / 291. Epoch 1630
process: 100 / 291. Epoch 1630
process: 150 / 291. Epoch 1630
process: 200 / 291. Epoch 1630
process: 250 / 291. Epoch 1630
process: 291 / 291. Epoch 1630
Loss of epoch 1630 = 2.548167435164304
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1630. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.784254
      epoch  training_loss
1625   1626       2.560394
1626   1627       2.613449
1627   1628       2.572182
1628   1629       2.502773
1629   1630       2.548167
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
158       1590  0.015234  0.067317      0.379500   0.380918
159       1600  0.015385  0.066457      0.379564   0.380955
160       1610  0.015387  0.065524      0.379985   0.381418
161       1620  0.015414  0.066395      0.379210   0.380605
162       1630  0.015379  0.065581      0.380751   0.382156
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
158     1590.0  0.972216  0.980521  ...  0.958218  0.954471  0.942743
159     1600.0  0.972524  0.980935  ...  0.958055  0.953657  0.939811
160     1610.0  0.972601  0.980837  ...  0.957322  0.954064  0.939648
161     1620.0  0.971970  0.980723  ...  0.957241  0.953901  0.939567
162     1630.0  0.972604  0.980606  ...  0.957403  0.953576  0.938834

[5 rows x 13 columns]
process: 50 / 291. Epoch 1631
process: 100 / 291. Epoch 1631
process: 150 / 291. Epoch 1631
process: 200 / 291. Epoch 1631
process: 250 / 291. Epoch 1631
process: 291 / 291. Epoch 1631
Loss of epoch 1631 = 2.513952930358677
process: 50 / 291. Epoch 1632
process: 100 / 291. Epoch 1632
process: 150 / 291. Epoch 1632
process: 200 / 291. Epoch 1632
process: 250 / 291. Epoch 1632
process: 291 / 291. Epoch 1632
Loss of epoch 1632 = 2.635862370127255
process: 50 / 291. Epoch 1633
process: 100 / 291. Epoch 1633
process: 150 / 291. Epoch 1633
process: 200 / 291. Epoch 1633
process: 250 / 291. Epoch 1633
process: 291 / 291. Epoch 1633
Loss of epoch 1633 = 2.610037787263746
process: 50 / 291. Epoch 1634
process: 100 / 291. Epoch 1634
process: 150 / 291. Epoch 1634
process: 200 / 291. Epoch 1634
process: 250 / 291. Epoch 1634
process: 291 / 291. Epoch 1634
Loss of epoch 1634 = 2.5454802103468643
process: 50 / 291. Epoch 1635
process: 100 / 291. Epoch 1635
process: 150 / 291. Epoch 1635
process: 200 / 291. Epoch 1635
process: 250 / 291. Epoch 1635
process: 291 / 291. Epoch 1635
Loss of epoch 1635 = 2.5596657454762672
process: 50 / 291. Epoch 1636
process: 100 / 291. Epoch 1636
process: 150 / 291. Epoch 1636
process: 200 / 291. Epoch 1636
process: 250 / 291. Epoch 1636
process: 291 / 291. Epoch 1636
Loss of epoch 1636 = 2.5318051892047895
process: 50 / 291. Epoch 1637
process: 100 / 291. Epoch 1637
process: 150 / 291. Epoch 1637
process: 200 / 291. Epoch 1637
process: 250 / 291. Epoch 1637
process: 291 / 291. Epoch 1637
Loss of epoch 1637 = 2.5332962508054124
process: 50 / 291. Epoch 1638
process: 100 / 291. Epoch 1638
process: 150 / 291. Epoch 1638
process: 200 / 291. Epoch 1638
process: 250 / 291. Epoch 1638
process: 291 / 291. Epoch 1638
Loss of epoch 1638 = 2.52795703796177
process: 50 / 291. Epoch 1639
process: 100 / 291. Epoch 1639
process: 150 / 291. Epoch 1639
process: 200 / 291. Epoch 1639
process: 250 / 291. Epoch 1639
process: 291 / 291. Epoch 1639
Loss of epoch 1639 = 2.569675720844072
process: 50 / 291. Epoch 1640
process: 100 / 291. Epoch 1640
process: 150 / 291. Epoch 1640
process: 200 / 291. Epoch 1640
process: 250 / 291. Epoch 1640
process: 291 / 291. Epoch 1640
Loss of epoch 1640 = 2.617203230710374
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1640. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.788107
      epoch  training_loss
1635   1636       2.531805
1636   1637       2.533296
1637   1638       2.527957
1638   1639       2.569676
1639   1640       2.617203
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
159       1600  0.015385  0.066457      0.379564   0.380955
160       1610  0.015387  0.065524      0.379985   0.381418
161       1620  0.015414  0.066395      0.379210   0.380605
162       1630  0.015379  0.065581      0.380751   0.382156
163       1640  0.015288  0.066942      0.380603   0.382018
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
159     1600.0  0.972524  0.980935  ...  0.958055  0.953657  0.939811
160     1610.0  0.972601  0.980837  ...  0.957322  0.954064  0.939648
161     1620.0  0.971970  0.980723  ...  0.957241  0.953901  0.939567
162     1630.0  0.972604  0.980606  ...  0.957403  0.953576  0.938834
163     1640.0  0.972398  0.980399  ...  0.957485  0.953983  0.941766

[5 rows x 13 columns]
process: 50 / 291. Epoch 1641
process: 100 / 291. Epoch 1641
process: 150 / 291. Epoch 1641
process: 200 / 291. Epoch 1641
process: 250 / 291. Epoch 1641
process: 291 / 291. Epoch 1641
Loss of epoch 1641 = 2.5293035867697595
process: 50 / 291. Epoch 1642
process: 100 / 291. Epoch 1642
process: 150 / 291. Epoch 1642
process: 200 / 291. Epoch 1642
process: 250 / 291. Epoch 1642
process: 291 / 291. Epoch 1642
Loss of epoch 1642 = 2.5403037579198884
process: 50 / 291. Epoch 1643
process: 100 / 291. Epoch 1643
process: 150 / 291. Epoch 1643
process: 200 / 291. Epoch 1643
process: 250 / 291. Epoch 1643
process: 291 / 291. Epoch 1643
Loss of epoch 1643 = 2.5076228925042954
process: 50 / 291. Epoch 1644
process: 100 / 291. Epoch 1644
process: 150 / 291. Epoch 1644
process: 200 / 291. Epoch 1644
process: 250 / 291. Epoch 1644
process: 291 / 291. Epoch 1644
Loss of epoch 1644 = 2.559249406008376
process: 50 / 291. Epoch 1645
process: 100 / 291. Epoch 1645
process: 150 / 291. Epoch 1645
process: 200 / 291. Epoch 1645
process: 250 / 291. Epoch 1645
process: 291 / 291. Epoch 1645
Loss of epoch 1645 = 2.5890918220441366
process: 50 / 291. Epoch 1646
process: 100 / 291. Epoch 1646
process: 150 / 291. Epoch 1646
process: 200 / 291. Epoch 1646
process: 250 / 291. Epoch 1646
process: 291 / 291. Epoch 1646
Loss of epoch 1646 = 2.582213726240335
process: 50 / 291. Epoch 1647
process: 100 / 291. Epoch 1647
process: 150 / 291. Epoch 1647
process: 200 / 291. Epoch 1647
process: 250 / 291. Epoch 1647
process: 291 / 291. Epoch 1647
Loss of epoch 1647 = 2.599718651001396
process: 50 / 291. Epoch 1648
process: 100 / 291. Epoch 1648
process: 150 / 291. Epoch 1648
process: 200 / 291. Epoch 1648
process: 250 / 291. Epoch 1648
process: 291 / 291. Epoch 1648
Loss of epoch 1648 = 2.537924855025773
process: 50 / 291. Epoch 1649
process: 100 / 291. Epoch 1649
process: 150 / 291. Epoch 1649
process: 200 / 291. Epoch 1649
process: 250 / 291. Epoch 1649
process: 291 / 291. Epoch 1649
Loss of epoch 1649 = 2.518408287022122
process: 50 / 291. Epoch 1650
process: 100 / 291. Epoch 1650
process: 150 / 291. Epoch 1650
process: 200 / 291. Epoch 1650
process: 250 / 291. Epoch 1650
process: 291 / 291. Epoch 1650
Loss of epoch 1650 = 2.5255059835427405
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1650. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.791776
      epoch  training_loss
1645   1646       2.582214
1646   1647       2.599719
1647   1648       2.537925
1648   1649       2.518408
1649   1650       2.525506
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
160       1610  0.015387  0.065524      0.379985   0.381418
161       1620  0.015414  0.066395      0.379210   0.380605
162       1630  0.015379  0.065581      0.380751   0.382156
163       1640  0.015288  0.066942      0.380603   0.382018
164       1650  0.015268  0.066603      0.381008   0.382433
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
160     1610.0  0.972601  0.980837  ...  0.957322  0.954064  0.939648
161     1620.0  0.971970  0.980723  ...  0.957241  0.953901  0.939567
162     1630.0  0.972604  0.980606  ...  0.957403  0.953576  0.938834
163     1640.0  0.972398  0.980399  ...  0.957485  0.953983  0.941766
164     1650.0  0.972434  0.980628  ...  0.958462  0.954390  0.943395

[5 rows x 13 columns]
process: 50 / 291. Epoch 1651
process: 100 / 291. Epoch 1651
process: 150 / 291. Epoch 1651
process: 200 / 291. Epoch 1651
process: 250 / 291. Epoch 1651
process: 291 / 291. Epoch 1651
Loss of epoch 1651 = 2.588881659753544
process: 50 / 291. Epoch 1652
process: 100 / 291. Epoch 1652
process: 150 / 291. Epoch 1652
process: 200 / 291. Epoch 1652
process: 250 / 291. Epoch 1652
process: 291 / 291. Epoch 1652
Loss of epoch 1652 = 2.5445950957098367
process: 50 / 291. Epoch 1653
process: 100 / 291. Epoch 1653
process: 150 / 291. Epoch 1653
process: 200 / 291. Epoch 1653
process: 250 / 291. Epoch 1653
process: 291 / 291. Epoch 1653
Loss of epoch 1653 = 2.5504829957313144
process: 50 / 291. Epoch 1654
process: 100 / 291. Epoch 1654
process: 150 / 291. Epoch 1654
process: 200 / 291. Epoch 1654
process: 250 / 291. Epoch 1654
process: 291 / 291. Epoch 1654
Loss of epoch 1654 = 2.571507195017182
process: 50 / 291. Epoch 1655
process: 100 / 291. Epoch 1655
process: 150 / 291. Epoch 1655
process: 200 / 291. Epoch 1655
process: 250 / 291. Epoch 1655
process: 291 / 291. Epoch 1655
Loss of epoch 1655 = 2.633506958427298
process: 50 / 291. Epoch 1656
process: 100 / 291. Epoch 1656
process: 150 / 291. Epoch 1656
process: 200 / 291. Epoch 1656
process: 250 / 291. Epoch 1656
process: 291 / 291. Epoch 1656
Loss of epoch 1656 = 2.4979107519195662
process: 50 / 291. Epoch 1657
process: 100 / 291. Epoch 1657
process: 150 / 291. Epoch 1657
process: 200 / 291. Epoch 1657
process: 250 / 291. Epoch 1657
process: 291 / 291. Epoch 1657
Loss of epoch 1657 = 2.6354680536538875
process: 50 / 291. Epoch 1658
process: 100 / 291. Epoch 1658
process: 150 / 291. Epoch 1658
process: 200 / 291. Epoch 1658
process: 250 / 291. Epoch 1658
process: 291 / 291. Epoch 1658
Loss of epoch 1658 = 2.5461966917686856
process: 50 / 291. Epoch 1659
process: 100 / 291. Epoch 1659
process: 150 / 291. Epoch 1659
process: 200 / 291. Epoch 1659
process: 250 / 291. Epoch 1659
process: 291 / 291. Epoch 1659
Loss of epoch 1659 = 2.4919376963192654
process: 50 / 291. Epoch 1660
process: 100 / 291. Epoch 1660
process: 150 / 291. Epoch 1660
process: 200 / 291. Epoch 1660
process: 250 / 291. Epoch 1660
process: 291 / 291. Epoch 1660
Loss of epoch 1660 = 2.553500565466602
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1660. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.796445
      epoch  training_loss
1655   1656       2.497911
1656   1657       2.635468
1657   1658       2.546197
1658   1659       2.491938
1659   1660       2.553501
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
161       1620  0.015414  0.066395      0.379210   0.380605
162       1630  0.015379  0.065581      0.380751   0.382156
163       1640  0.015288  0.066942      0.380603   0.382018
164       1650  0.015268  0.066603      0.381008   0.382433
165       1660  0.015180  0.067115      0.380816   0.382221
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
161     1620.0  0.971970  0.980723  ...  0.957241  0.953901  0.939567
162     1630.0  0.972604  0.980606  ...  0.957403  0.953576  0.938834
163     1640.0  0.972398  0.980399  ...  0.957485  0.953983  0.941766
164     1650.0  0.972434  0.980628  ...  0.958462  0.954390  0.943395
165     1660.0  0.971887  0.980188  ...  0.957811  0.954227  0.944942

[5 rows x 13 columns]
process: 50 / 291. Epoch 1661
process: 100 / 291. Epoch 1661
process: 150 / 291. Epoch 1661
process: 200 / 291. Epoch 1661
process: 250 / 291. Epoch 1661
process: 291 / 291. Epoch 1661
Loss of epoch 1661 = 2.589503547170318
process: 50 / 291. Epoch 1662
process: 100 / 291. Epoch 1662
process: 150 / 291. Epoch 1662
process: 200 / 291. Epoch 1662
process: 250 / 291. Epoch 1662
process: 291 / 291. Epoch 1662
Loss of epoch 1662 = 2.5570871674318085
process: 50 / 291. Epoch 1663
process: 100 / 291. Epoch 1663
process: 150 / 291. Epoch 1663
process: 200 / 291. Epoch 1663
process: 250 / 291. Epoch 1663
process: 291 / 291. Epoch 1663
Loss of epoch 1663 = 2.555310226387994
process: 50 / 291. Epoch 1664
process: 100 / 291. Epoch 1664
process: 150 / 291. Epoch 1664
process: 200 / 291. Epoch 1664
process: 250 / 291. Epoch 1664
process: 291 / 291. Epoch 1664
Loss of epoch 1664 = 2.504430607012457
process: 50 / 291. Epoch 1665
process: 100 / 291. Epoch 1665
process: 150 / 291. Epoch 1665
process: 200 / 291. Epoch 1665
process: 250 / 291. Epoch 1665
process: 291 / 291. Epoch 1665
Loss of epoch 1665 = 2.549095756819158
process: 50 / 291. Epoch 1666
process: 100 / 291. Epoch 1666
process: 150 / 291. Epoch 1666
process: 200 / 291. Epoch 1666
process: 250 / 291. Epoch 1666
process: 291 / 291. Epoch 1666
Loss of epoch 1666 = 2.546682246362221
process: 50 / 291. Epoch 1667
process: 100 / 291. Epoch 1667
process: 150 / 291. Epoch 1667
process: 200 / 291. Epoch 1667
process: 250 / 291. Epoch 1667
process: 291 / 291. Epoch 1667
Loss of epoch 1667 = 2.5416096166237114
process: 50 / 291. Epoch 1668
process: 100 / 291. Epoch 1668
process: 150 / 291. Epoch 1668
process: 200 / 291. Epoch 1668
process: 250 / 291. Epoch 1668
process: 291 / 291. Epoch 1668
Loss of epoch 1668 = 2.6443275897363616
process: 50 / 291. Epoch 1669
process: 100 / 291. Epoch 1669
process: 150 / 291. Epoch 1669
process: 200 / 291. Epoch 1669
process: 250 / 291. Epoch 1669
process: 291 / 291. Epoch 1669
Loss of epoch 1669 = 2.6124168999006656
process: 50 / 291. Epoch 1670
process: 100 / 291. Epoch 1670
process: 150 / 291. Epoch 1670
process: 200 / 291. Epoch 1670
process: 250 / 291. Epoch 1670
process: 291 / 291. Epoch 1670
Loss of epoch 1670 = 2.51373207118503
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1670. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.788332
      epoch  training_loss
1665   1666       2.546682
1666   1667       2.541610
1667   1668       2.644328
1668   1669       2.612417
1669   1670       2.513732
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
162       1630  0.015379  0.065581      0.380751   0.382156
163       1640  0.015288  0.066942      0.380603   0.382018
164       1650  0.015268  0.066603      0.381008   0.382433
165       1660  0.015180  0.067115      0.380816   0.382221
166       1670  0.015281  0.066161      0.382551   0.384005
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
162     1630.0  0.972604  0.980606  ...  0.957403  0.953576  0.938834
163     1640.0  0.972398  0.980399  ...  0.957485  0.953983  0.941766
164     1650.0  0.972434  0.980628  ...  0.958462  0.954390  0.943395
165     1660.0  0.971887  0.980188  ...  0.957811  0.954227  0.944942
166     1670.0  0.971988  0.980505  ...  0.957729  0.953901  0.940300

[5 rows x 13 columns]
process: 50 / 291. Epoch 1671
process: 100 / 291. Epoch 1671
process: 150 / 291. Epoch 1671
process: 200 / 291. Epoch 1671
process: 250 / 291. Epoch 1671
process: 291 / 291. Epoch 1671
Loss of epoch 1671 = 2.487620769907109
process: 50 / 291. Epoch 1672
process: 100 / 291. Epoch 1672
process: 150 / 291. Epoch 1672
process: 200 / 291. Epoch 1672
process: 250 / 291. Epoch 1672
process: 291 / 291. Epoch 1672
Loss of epoch 1672 = 2.507275558419244
process: 50 / 291. Epoch 1673
process: 100 / 291. Epoch 1673
process: 150 / 291. Epoch 1673
process: 200 / 291. Epoch 1673
process: 250 / 291. Epoch 1673
process: 291 / 291. Epoch 1673
Loss of epoch 1673 = 2.529917503959944
process: 50 / 291. Epoch 1674
process: 100 / 291. Epoch 1674
process: 150 / 291. Epoch 1674
process: 200 / 291. Epoch 1674
process: 250 / 291. Epoch 1674
process: 291 / 291. Epoch 1674
Loss of epoch 1674 = 2.4868977864583335
process: 50 / 291. Epoch 1675
process: 100 / 291. Epoch 1675
process: 150 / 291. Epoch 1675
process: 200 / 291. Epoch 1675
process: 250 / 291. Epoch 1675
process: 291 / 291. Epoch 1675
Loss of epoch 1675 = 2.5863313969877577
process: 50 / 291. Epoch 1676
process: 100 / 291. Epoch 1676
process: 150 / 291. Epoch 1676
process: 200 / 291. Epoch 1676
process: 250 / 291. Epoch 1676
process: 291 / 291. Epoch 1676
Loss of epoch 1676 = 2.616879178076675
process: 50 / 291. Epoch 1677
process: 100 / 291. Epoch 1677
process: 150 / 291. Epoch 1677
process: 200 / 291. Epoch 1677
process: 250 / 291. Epoch 1677
process: 291 / 291. Epoch 1677
Loss of epoch 1677 = 2.543261131470146
process: 50 / 291. Epoch 1678
process: 100 / 291. Epoch 1678
process: 150 / 291. Epoch 1678
process: 200 / 291. Epoch 1678
process: 250 / 291. Epoch 1678
process: 291 / 291. Epoch 1678
Loss of epoch 1678 = 2.541373446225301
process: 50 / 291. Epoch 1679
process: 100 / 291. Epoch 1679
process: 150 / 291. Epoch 1679
process: 200 / 291. Epoch 1679
process: 250 / 291. Epoch 1679
process: 291 / 291. Epoch 1679
Loss of epoch 1679 = 2.552938664492053
process: 50 / 291. Epoch 1680
process: 100 / 291. Epoch 1680
process: 150 / 291. Epoch 1680
process: 200 / 291. Epoch 1680
process: 250 / 291. Epoch 1680
process: 291 / 291. Epoch 1680
Loss of epoch 1680 = 2.5185328742482818
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1680. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.786841
      epoch  training_loss
1675   1676       2.616879
1676   1677       2.543261
1677   1678       2.541373
1678   1679       2.552939
1679   1680       2.518533
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
163       1640  0.015288  0.066942      0.380603   0.382018
164       1650  0.015268  0.066603      0.381008   0.382433
165       1660  0.015180  0.067115      0.380816   0.382221
166       1670  0.015281  0.066161      0.382551   0.384005
167       1680  0.015278  0.065601      0.380580   0.381976
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
163     1640.0  0.972398  0.980399  ...  0.957485  0.953983  0.941766
164     1650.0  0.972434  0.980628  ...  0.958462  0.954390  0.943395
165     1660.0  0.971887  0.980188  ...  0.957811  0.954227  0.944942
166     1670.0  0.971988  0.980505  ...  0.957729  0.953901  0.940300
167     1680.0  0.972413  0.980835  ...  0.957892  0.953983  0.941277

[5 rows x 13 columns]
process: 50 / 291. Epoch 1681
process: 100 / 291. Epoch 1681
process: 150 / 291. Epoch 1681
process: 200 / 291. Epoch 1681
process: 250 / 291. Epoch 1681
process: 291 / 291. Epoch 1681
Loss of epoch 1681 = 2.4944632094340635
process: 50 / 291. Epoch 1682
process: 100 / 291. Epoch 1682
process: 150 / 291. Epoch 1682
process: 200 / 291. Epoch 1682
process: 250 / 291. Epoch 1682
process: 291 / 291. Epoch 1682
Loss of epoch 1682 = 2.579857895054768
process: 50 / 291. Epoch 1683
process: 100 / 291. Epoch 1683
process: 150 / 291. Epoch 1683
process: 200 / 291. Epoch 1683
process: 250 / 291. Epoch 1683
process: 291 / 291. Epoch 1683
Loss of epoch 1683 = 2.5067788874570445
process: 50 / 291. Epoch 1684
process: 100 / 291. Epoch 1684
process: 150 / 291. Epoch 1684
process: 200 / 291. Epoch 1684
process: 250 / 291. Epoch 1684
process: 291 / 291. Epoch 1684
Loss of epoch 1684 = 2.5274674982549397
process: 50 / 291. Epoch 1685
process: 100 / 291. Epoch 1685
process: 150 / 291. Epoch 1685
process: 200 / 291. Epoch 1685
process: 250 / 291. Epoch 1685
process: 291 / 291. Epoch 1685
Loss of epoch 1685 = 2.52764976475247
process: 50 / 291. Epoch 1686
process: 100 / 291. Epoch 1686
process: 150 / 291. Epoch 1686
process: 200 / 291. Epoch 1686
process: 250 / 291. Epoch 1686
process: 291 / 291. Epoch 1686
Loss of epoch 1686 = 2.5525401531625858
process: 50 / 291. Epoch 1687
process: 100 / 291. Epoch 1687
process: 150 / 291. Epoch 1687
process: 200 / 291. Epoch 1687
process: 250 / 291. Epoch 1687
process: 291 / 291. Epoch 1687
Loss of epoch 1687 = 2.6098320295720576
process: 50 / 291. Epoch 1688
process: 100 / 291. Epoch 1688
process: 150 / 291. Epoch 1688
process: 200 / 291. Epoch 1688
process: 250 / 291. Epoch 1688
process: 291 / 291. Epoch 1688
Loss of epoch 1688 = 2.5121432694372854
process: 50 / 291. Epoch 1689
process: 100 / 291. Epoch 1689
process: 150 / 291. Epoch 1689
process: 200 / 291. Epoch 1689
process: 250 / 291. Epoch 1689
process: 291 / 291. Epoch 1689
Loss of epoch 1689 = 2.578493098622745
process: 50 / 291. Epoch 1690
process: 100 / 291. Epoch 1690
process: 150 / 291. Epoch 1690
process: 200 / 291. Epoch 1690
process: 250 / 291. Epoch 1690
process: 291 / 291. Epoch 1690
Loss of epoch 1690 = 2.5627873476428267
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1690. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.788012
      epoch  training_loss
1685   1686       2.552540
1686   1687       2.609832
1687   1688       2.512143
1688   1689       2.578493
1689   1690       2.562787
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
164       1650  0.015268  0.066603      0.381008   0.382433
165       1660  0.015180  0.067115      0.380816   0.382221
166       1670  0.015281  0.066161      0.382551   0.384005
167       1680  0.015278  0.065601      0.380580   0.381976
168       1690  0.015219  0.066435      0.382325   0.383744
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
164     1650.0  0.972434  0.980628  ...  0.958462  0.954390  0.943395
165     1660.0  0.971887  0.980188  ...  0.957811  0.954227  0.944942
166     1670.0  0.971988  0.980505  ...  0.957729  0.953901  0.940300
167     1680.0  0.972413  0.980835  ...  0.957892  0.953983  0.941277
168     1690.0  0.972299  0.980619  ...  0.957648  0.954064  0.942173

[5 rows x 13 columns]
process: 50 / 291. Epoch 1691
process: 100 / 291. Epoch 1691
process: 150 / 291. Epoch 1691
process: 200 / 291. Epoch 1691
process: 250 / 291. Epoch 1691
process: 291 / 291. Epoch 1691
Loss of epoch 1691 = 2.541982539330971
process: 50 / 291. Epoch 1692
process: 100 / 291. Epoch 1692
process: 150 / 291. Epoch 1692
process: 200 / 291. Epoch 1692
process: 250 / 291. Epoch 1692
process: 291 / 291. Epoch 1692
Loss of epoch 1692 = 2.5168492687526847
process: 50 / 291. Epoch 1693
process: 100 / 291. Epoch 1693
process: 150 / 291. Epoch 1693
process: 200 / 291. Epoch 1693
process: 250 / 291. Epoch 1693
process: 291 / 291. Epoch 1693
Loss of epoch 1693 = 2.4737601263826248
process: 50 / 291. Epoch 1694
process: 100 / 291. Epoch 1694
process: 150 / 291. Epoch 1694
process: 200 / 291. Epoch 1694
process: 250 / 291. Epoch 1694
process: 291 / 291. Epoch 1694
Loss of epoch 1694 = 2.5269980938573884
process: 50 / 291. Epoch 1695
process: 100 / 291. Epoch 1695
process: 150 / 291. Epoch 1695
process: 200 / 291. Epoch 1695
process: 250 / 291. Epoch 1695
process: 291 / 291. Epoch 1695
Loss of epoch 1695 = 2.6208420586340204
process: 50 / 291. Epoch 1696
process: 100 / 291. Epoch 1696
process: 150 / 291. Epoch 1696
process: 200 / 291. Epoch 1696
process: 250 / 291. Epoch 1696
process: 291 / 291. Epoch 1696
Loss of epoch 1696 = 2.5495402018229165
process: 50 / 291. Epoch 1697
process: 100 / 291. Epoch 1697
process: 150 / 291. Epoch 1697
process: 200 / 291. Epoch 1697
process: 250 / 291. Epoch 1697
process: 291 / 291. Epoch 1697
Loss of epoch 1697 = 2.514123241516323
process: 50 / 291. Epoch 1698
process: 100 / 291. Epoch 1698
process: 150 / 291. Epoch 1698
process: 200 / 291. Epoch 1698
process: 250 / 291. Epoch 1698
process: 291 / 291. Epoch 1698
Loss of epoch 1698 = 2.5420400088595363
process: 50 / 291. Epoch 1699
process: 100 / 291. Epoch 1699
process: 150 / 291. Epoch 1699
process: 200 / 291. Epoch 1699
process: 250 / 291. Epoch 1699
process: 291 / 291. Epoch 1699
Loss of epoch 1699 = 2.4741284347481742
process: 50 / 291. Epoch 1700
process: 100 / 291. Epoch 1700
process: 150 / 291. Epoch 1700
process: 200 / 291. Epoch 1700
process: 250 / 291. Epoch 1700
process: 291 / 291. Epoch 1700
Loss of epoch 1700 = 2.5404337984589778
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1700. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.789495
      epoch  training_loss
1695   1696       2.549540
1696   1697       2.514123
1697   1698       2.542040
1698   1699       2.474128
1699   1700       2.540434
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
165       1660  0.015180  0.067115      0.380816   0.382221
166       1670  0.015281  0.066161      0.382551   0.384005
167       1680  0.015278  0.065601      0.380580   0.381976
168       1690  0.015219  0.066435      0.382325   0.383744
169       1700  0.015303  0.065675      0.382396   0.383835
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
165     1660.0  0.971887  0.980188  ...  0.957811  0.954227  0.944942
166     1670.0  0.971988  0.980505  ...  0.957729  0.953901  0.940300
167     1680.0  0.972413  0.980835  ...  0.957892  0.953983  0.941277
168     1690.0  0.972299  0.980619  ...  0.957648  0.954064  0.942173
169     1700.0  0.971982  0.980841  ...  0.957566  0.954227  0.943069

[5 rows x 13 columns]
process: 50 / 291. Epoch 1701
process: 100 / 291. Epoch 1701
process: 150 / 291. Epoch 1701
process: 200 / 291. Epoch 1701
process: 250 / 291. Epoch 1701
process: 291 / 291. Epoch 1701
Loss of epoch 1701 = 2.56360156921177
process: 50 / 291. Epoch 1702
process: 100 / 291. Epoch 1702
process: 150 / 291. Epoch 1702
process: 200 / 291. Epoch 1702
process: 250 / 291. Epoch 1702
process: 291 / 291. Epoch 1702
Loss of epoch 1702 = 2.6083552304821733
process: 50 / 291. Epoch 1703
process: 100 / 291. Epoch 1703
process: 150 / 291. Epoch 1703
process: 200 / 291. Epoch 1703
process: 250 / 291. Epoch 1703
process: 291 / 291. Epoch 1703
Loss of epoch 1703 = 2.5613204064647768
process: 50 / 291. Epoch 1704
process: 100 / 291. Epoch 1704
process: 150 / 291. Epoch 1704
process: 200 / 291. Epoch 1704
process: 250 / 291. Epoch 1704
process: 291 / 291. Epoch 1704
Loss of epoch 1704 = 2.5183814399430844
process: 50 / 291. Epoch 1705
process: 100 / 291. Epoch 1705
process: 150 / 291. Epoch 1705
process: 200 / 291. Epoch 1705
process: 250 / 291. Epoch 1705
process: 291 / 291. Epoch 1705
Loss of epoch 1705 = 2.518201270873604
process: 50 / 291. Epoch 1706
process: 100 / 291. Epoch 1706
process: 150 / 291. Epoch 1706
process: 200 / 291. Epoch 1706
process: 250 / 291. Epoch 1706
process: 291 / 291. Epoch 1706
Loss of epoch 1706 = 2.5865403008215204
process: 50 / 291. Epoch 1707
process: 100 / 291. Epoch 1707
process: 150 / 291. Epoch 1707
process: 200 / 291. Epoch 1707
process: 250 / 291. Epoch 1707
process: 291 / 291. Epoch 1707
Loss of epoch 1707 = 2.5386402877335694
process: 50 / 291. Epoch 1708
process: 100 / 291. Epoch 1708
process: 150 / 291. Epoch 1708
process: 200 / 291. Epoch 1708
process: 250 / 291. Epoch 1708
process: 291 / 291. Epoch 1708
Loss of epoch 1708 = 2.4872247754913017
process: 50 / 291. Epoch 1709
process: 100 / 291. Epoch 1709
process: 150 / 291. Epoch 1709
process: 200 / 291. Epoch 1709
process: 250 / 291. Epoch 1709
process: 291 / 291. Epoch 1709
Loss of epoch 1709 = 2.471373463004725
process: 50 / 291. Epoch 1710
process: 100 / 291. Epoch 1710
process: 150 / 291. Epoch 1710
process: 200 / 291. Epoch 1710
process: 250 / 291. Epoch 1710
process: 291 / 291. Epoch 1710
Loss of epoch 1710 = 2.4884083541398194
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1710. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.793356
      epoch  training_loss
1705   1706       2.586540
1706   1707       2.538640
1707   1708       2.487225
1708   1709       2.471373
1709   1710       2.488408
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
166       1670  0.015281  0.066161      0.382551   0.384005
167       1680  0.015278  0.065601      0.380580   0.381976
168       1690  0.015219  0.066435      0.382325   0.383744
169       1700  0.015303  0.065675      0.382396   0.383835
170       1710  0.015207  0.066410      0.382401   0.383811
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
166     1670.0  0.971988  0.980505  ...  0.957729  0.953901  0.940300
167     1680.0  0.972413  0.980835  ...  0.957892  0.953983  0.941277
168     1690.0  0.972299  0.980619  ...  0.957648  0.954064  0.942173
169     1700.0  0.971982  0.980841  ...  0.957566  0.954227  0.943069
170     1710.0  0.972324  0.980417  ...  0.958299  0.954634  0.943558

[5 rows x 13 columns]
process: 50 / 291. Epoch 1711
process: 100 / 291. Epoch 1711
process: 150 / 291. Epoch 1711
process: 200 / 291. Epoch 1711
process: 250 / 291. Epoch 1711
process: 291 / 291. Epoch 1711
Loss of epoch 1711 = 2.533616737811426
process: 50 / 291. Epoch 1712
process: 100 / 291. Epoch 1712
process: 150 / 291. Epoch 1712
process: 200 / 291. Epoch 1712
process: 250 / 291. Epoch 1712
process: 291 / 291. Epoch 1712
Loss of epoch 1712 = 2.5192424341575386
process: 50 / 291. Epoch 1713
process: 100 / 291. Epoch 1713
process: 150 / 291. Epoch 1713
process: 200 / 291. Epoch 1713
process: 250 / 291. Epoch 1713
process: 291 / 291. Epoch 1713
Loss of epoch 1713 = 2.49866016296177
process: 50 / 291. Epoch 1714
process: 100 / 291. Epoch 1714
process: 150 / 291. Epoch 1714
process: 200 / 291. Epoch 1714
process: 250 / 291. Epoch 1714
process: 291 / 291. Epoch 1714
Loss of epoch 1714 = 2.5303443305680844
process: 50 / 291. Epoch 1715
process: 100 / 291. Epoch 1715
process: 150 / 291. Epoch 1715
process: 200 / 291. Epoch 1715
process: 250 / 291. Epoch 1715
process: 291 / 291. Epoch 1715
Loss of epoch 1715 = 2.5456488435620703
process: 50 / 291. Epoch 1716
process: 100 / 291. Epoch 1716
process: 150 / 291. Epoch 1716
process: 200 / 291. Epoch 1716
process: 250 / 291. Epoch 1716
process: 291 / 291. Epoch 1716
Loss of epoch 1716 = 2.5295120711179124
process: 50 / 291. Epoch 1717
process: 100 / 291. Epoch 1717
process: 150 / 291. Epoch 1717
process: 200 / 291. Epoch 1717
process: 250 / 291. Epoch 1717
process: 291 / 291. Epoch 1717
Loss of epoch 1717 = 2.515420710507947
process: 50 / 291. Epoch 1718
process: 100 / 291. Epoch 1718
process: 150 / 291. Epoch 1718
process: 200 / 291. Epoch 1718
process: 250 / 291. Epoch 1718
process: 291 / 291. Epoch 1718
Loss of epoch 1718 = 2.5127766927083335
process: 50 / 291. Epoch 1719
process: 100 / 291. Epoch 1719
process: 150 / 291. Epoch 1719
process: 200 / 291. Epoch 1719
process: 250 / 291. Epoch 1719
process: 291 / 291. Epoch 1719
Loss of epoch 1719 = 2.543984324661727
process: 50 / 291. Epoch 1720
process: 100 / 291. Epoch 1720
process: 150 / 291. Epoch 1720
process: 200 / 291. Epoch 1720
process: 250 / 291. Epoch 1720
process: 291 / 291. Epoch 1720
Loss of epoch 1720 = 2.5864207474226806
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1720. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.787566
      epoch  training_loss
1715   1716       2.529512
1716   1717       2.515421
1717   1718       2.512777
1718   1719       2.543984
1719   1720       2.586421
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
167       1680  0.015278  0.065601      0.380580   0.381976
168       1690  0.015219  0.066435      0.382325   0.383744
169       1700  0.015303  0.065675      0.382396   0.383835
170       1710  0.015207  0.066410      0.382401   0.383811
171       1720  0.015297  0.065499      0.383529   0.384975
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
167     1680.0  0.972413  0.980835  ...  0.957892  0.953983  0.941277
168     1690.0  0.972299  0.980619  ...  0.957648  0.954064  0.942173
169     1700.0  0.971982  0.980841  ...  0.957566  0.954227  0.943069
170     1710.0  0.972324  0.980417  ...  0.958299  0.954634  0.943558
171     1720.0  0.972506  0.980828  ...  0.957566  0.953738  0.940707

[5 rows x 13 columns]
process: 50 / 291. Epoch 1721
process: 100 / 291. Epoch 1721
process: 150 / 291. Epoch 1721
process: 200 / 291. Epoch 1721
process: 250 / 291. Epoch 1721
process: 291 / 291. Epoch 1721
Loss of epoch 1721 = 2.5099585883805844
process: 50 / 291. Epoch 1722
process: 100 / 291. Epoch 1722
process: 150 / 291. Epoch 1722
process: 200 / 291. Epoch 1722
process: 250 / 291. Epoch 1722
process: 291 / 291. Epoch 1722
Loss of epoch 1722 = 2.536582081588273
process: 50 / 291. Epoch 1723
process: 100 / 291. Epoch 1723
process: 150 / 291. Epoch 1723
process: 200 / 291. Epoch 1723
process: 250 / 291. Epoch 1723
process: 291 / 291. Epoch 1723
Loss of epoch 1723 = 2.5389330886893258
process: 50 / 291. Epoch 1724
process: 100 / 291. Epoch 1724
process: 150 / 291. Epoch 1724
process: 200 / 291. Epoch 1724
process: 250 / 291. Epoch 1724
process: 291 / 291. Epoch 1724
Loss of epoch 1724 = 2.535353198493879
process: 50 / 291. Epoch 1725
process: 100 / 291. Epoch 1725
process: 150 / 291. Epoch 1725
process: 200 / 291. Epoch 1725
process: 250 / 291. Epoch 1725
process: 291 / 291. Epoch 1725
Loss of epoch 1725 = 2.5536484341441152
process: 50 / 291. Epoch 1726
process: 100 / 291. Epoch 1726
process: 150 / 291. Epoch 1726
process: 200 / 291. Epoch 1726
process: 250 / 291. Epoch 1726
process: 291 / 291. Epoch 1726
Loss of epoch 1726 = 2.5079041576057777
process: 50 / 291. Epoch 1727
process: 100 / 291. Epoch 1727
process: 150 / 291. Epoch 1727
process: 200 / 291. Epoch 1727
process: 250 / 291. Epoch 1727
process: 291 / 291. Epoch 1727
Loss of epoch 1727 = 2.511522011248926
process: 50 / 291. Epoch 1728
process: 100 / 291. Epoch 1728
process: 150 / 291. Epoch 1728
process: 200 / 291. Epoch 1728
process: 250 / 291. Epoch 1728
process: 291 / 291. Epoch 1728
Loss of epoch 1728 = 2.50524608703823
process: 50 / 291. Epoch 1729
process: 100 / 291. Epoch 1729
process: 150 / 291. Epoch 1729
process: 200 / 291. Epoch 1729
process: 250 / 291. Epoch 1729
process: 291 / 291. Epoch 1729
Loss of epoch 1729 = 2.5319404733140036
process: 50 / 291. Epoch 1730
process: 100 / 291. Epoch 1730
process: 150 / 291. Epoch 1730
process: 200 / 291. Epoch 1730
process: 250 / 291. Epoch 1730
process: 291 / 291. Epoch 1730
Loss of epoch 1730 = 2.5358106475515463
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1730. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.787334
      epoch  training_loss
1725   1726       2.507904
1726   1727       2.511522
1727   1728       2.505246
1728   1729       2.531940
1729   1730       2.535811
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
168       1690  0.015219  0.066435      0.382325   0.383744
169       1700  0.015303  0.065675      0.382396   0.383835
170       1710  0.015207  0.066410      0.382401   0.383811
171       1720  0.015297  0.065499      0.383529   0.384975
172       1730  0.015247  0.065487      0.382113   0.383533
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
168     1690.0  0.972299  0.980619  ...  0.957648  0.954064  0.942173
169     1700.0  0.971982  0.980841  ...  0.957566  0.954227  0.943069
170     1710.0  0.972324  0.980417  ...  0.958299  0.954634  0.943558
171     1720.0  0.972506  0.980828  ...  0.957566  0.953738  0.940707
172     1730.0  0.971669  0.980955  ...  0.957566  0.954390  0.941114

[5 rows x 13 columns]
process: 50 / 291. Epoch 1731
process: 100 / 291. Epoch 1731
process: 150 / 291. Epoch 1731
process: 200 / 291. Epoch 1731
process: 250 / 291. Epoch 1731
process: 291 / 291. Epoch 1731
Loss of epoch 1731 = 2.552717595575601
process: 50 / 291. Epoch 1732
process: 100 / 291. Epoch 1732
process: 150 / 291. Epoch 1732
process: 200 / 291. Epoch 1732
process: 250 / 291. Epoch 1732
process: 291 / 291. Epoch 1732
Loss of epoch 1732 = 2.555454948923432
process: 50 / 291. Epoch 1733
process: 100 / 291. Epoch 1733
process: 150 / 291. Epoch 1733
process: 200 / 291. Epoch 1733
process: 250 / 291. Epoch 1733
process: 291 / 291. Epoch 1733
Loss of epoch 1733 = 2.4786796438734964
process: 50 / 291. Epoch 1734
process: 100 / 291. Epoch 1734
process: 150 / 291. Epoch 1734
process: 200 / 291. Epoch 1734
process: 250 / 291. Epoch 1734
process: 291 / 291. Epoch 1734
Loss of epoch 1734 = 2.484657313815507
process: 50 / 291. Epoch 1735
process: 100 / 291. Epoch 1735
process: 150 / 291. Epoch 1735
process: 200 / 291. Epoch 1735
process: 250 / 291. Epoch 1735
process: 291 / 291. Epoch 1735
Loss of epoch 1735 = 2.5544576218857387
process: 50 / 291. Epoch 1736
process: 100 / 291. Epoch 1736
process: 150 / 291. Epoch 1736
process: 200 / 291. Epoch 1736
process: 250 / 291. Epoch 1736
process: 291 / 291. Epoch 1736
Loss of epoch 1736 = 2.592509161565722
process: 50 / 291. Epoch 1737
process: 100 / 291. Epoch 1737
process: 150 / 291. Epoch 1737
process: 200 / 291. Epoch 1737
process: 250 / 291. Epoch 1737
process: 291 / 291. Epoch 1737
Loss of epoch 1737 = 2.495519893685567
process: 50 / 291. Epoch 1738
process: 100 / 291. Epoch 1738
process: 150 / 291. Epoch 1738
process: 200 / 291. Epoch 1738
process: 250 / 291. Epoch 1738
process: 291 / 291. Epoch 1738
Loss of epoch 1738 = 2.4795991563305413
process: 50 / 291. Epoch 1739
process: 100 / 291. Epoch 1739
process: 150 / 291. Epoch 1739
process: 200 / 291. Epoch 1739
process: 250 / 291. Epoch 1739
process: 291 / 291. Epoch 1739
Loss of epoch 1739 = 2.529236469072165
process: 50 / 291. Epoch 1740
process: 100 / 291. Epoch 1740
process: 150 / 291. Epoch 1740
process: 200 / 291. Epoch 1740
process: 250 / 291. Epoch 1740
process: 291 / 291. Epoch 1740
Loss of epoch 1740 = 2.564246947822702
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1740. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.785068
      epoch  training_loss
1735   1736       2.592509
1736   1737       2.495520
1737   1738       2.479599
1738   1739       2.529236
1739   1740       2.564247
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
169       1700  0.015303  0.065675      0.382396   0.383835
170       1710  0.015207  0.066410      0.382401   0.383811
171       1720  0.015297  0.065499      0.383529   0.384975
172       1730  0.015247  0.065487      0.382113   0.383533
173       1740  0.015390  0.064795      0.383747   0.385214
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
169     1700.0  0.971982  0.980841  ...  0.957566  0.954227  0.943069
170     1710.0  0.972324  0.980417  ...  0.958299  0.954634  0.943558
171     1720.0  0.972506  0.980828  ...  0.957566  0.953738  0.940707
172     1730.0  0.971669  0.980955  ...  0.957566  0.954390  0.941114
173     1740.0  0.972493  0.980929  ...  0.957241  0.953413  0.940055

[5 rows x 13 columns]
process: 50 / 291. Epoch 1741
process: 100 / 291. Epoch 1741
process: 150 / 291. Epoch 1741
process: 200 / 291. Epoch 1741
process: 250 / 291. Epoch 1741
process: 291 / 291. Epoch 1741
Loss of epoch 1741 = 2.512646652169244
process: 50 / 291. Epoch 1742
process: 100 / 291. Epoch 1742
process: 150 / 291. Epoch 1742
process: 200 / 291. Epoch 1742
process: 250 / 291. Epoch 1742
process: 291 / 291. Epoch 1742
Loss of epoch 1742 = 2.488901249731529
process: 50 / 291. Epoch 1743
process: 100 / 291. Epoch 1743
process: 150 / 291. Epoch 1743
process: 200 / 291. Epoch 1743
process: 250 / 291. Epoch 1743
process: 291 / 291. Epoch 1743
Loss of epoch 1743 = 2.512612044606422
process: 50 / 291. Epoch 1744
process: 100 / 291. Epoch 1744
process: 150 / 291. Epoch 1744
process: 200 / 291. Epoch 1744
process: 250 / 291. Epoch 1744
process: 291 / 291. Epoch 1744
Loss of epoch 1744 = 2.5112862603361252
process: 50 / 291. Epoch 1745
process: 100 / 291. Epoch 1745
process: 150 / 291. Epoch 1745
process: 200 / 291. Epoch 1745
process: 250 / 291. Epoch 1745
process: 291 / 291. Epoch 1745
Loss of epoch 1745 = 2.5210976092676116
process: 50 / 291. Epoch 1746
process: 100 / 291. Epoch 1746
process: 150 / 291. Epoch 1746
process: 200 / 291. Epoch 1746
process: 250 / 291. Epoch 1746
process: 291 / 291. Epoch 1746
Loss of epoch 1746 = 2.504318814097401
process: 50 / 291. Epoch 1747
process: 100 / 291. Epoch 1747
process: 150 / 291. Epoch 1747
process: 200 / 291. Epoch 1747
process: 250 / 291. Epoch 1747
process: 291 / 291. Epoch 1747
Loss of epoch 1747 = 2.5605754000214778
process: 50 / 291. Epoch 1748
process: 100 / 291. Epoch 1748
process: 150 / 291. Epoch 1748
process: 200 / 291. Epoch 1748
process: 250 / 291. Epoch 1748
process: 291 / 291. Epoch 1748
Loss of epoch 1748 = 2.5367951802781357
process: 50 / 291. Epoch 1749
process: 100 / 291. Epoch 1749
process: 150 / 291. Epoch 1749
process: 200 / 291. Epoch 1749
process: 250 / 291. Epoch 1749
process: 291 / 291. Epoch 1749
Loss of epoch 1749 = 2.506799022766323
process: 50 / 291. Epoch 1750
process: 100 / 291. Epoch 1750
process: 150 / 291. Epoch 1750
process: 200 / 291. Epoch 1750
process: 250 / 291. Epoch 1750
process: 291 / 291. Epoch 1750
Loss of epoch 1750 = 2.53185909310567
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1750. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.789112
      epoch  training_loss
1745   1746       2.504319
1746   1747       2.560575
1747   1748       2.536795
1748   1749       2.506799
1749   1750       2.531859
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
170       1710  0.015207  0.066410      0.382401   0.383811
171       1720  0.015297  0.065499      0.383529   0.384975
172       1730  0.015247  0.065487      0.382113   0.383533
173       1740  0.015390  0.064795      0.383747   0.385214
174       1750  0.015292  0.065667      0.384100   0.385547
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
170     1710.0  0.972324  0.980417  ...  0.958299  0.954634  0.943558
171     1720.0  0.972506  0.980828  ...  0.957566  0.953738  0.940707
172     1730.0  0.971669  0.980955  ...  0.957566  0.954390  0.941114
173     1740.0  0.972493  0.980929  ...  0.957241  0.953413  0.940055
174     1750.0  0.972281  0.980839  ...  0.957159  0.954146  0.942499

[5 rows x 13 columns]
process: 50 / 291. Epoch 1751
process: 100 / 291. Epoch 1751
process: 150 / 291. Epoch 1751
process: 200 / 291. Epoch 1751
process: 250 / 291. Epoch 1751
process: 291 / 291. Epoch 1751
Loss of epoch 1751 = 2.5166032404424397
process: 50 / 291. Epoch 1752
process: 100 / 291. Epoch 1752
process: 150 / 291. Epoch 1752
process: 200 / 291. Epoch 1752
process: 250 / 291. Epoch 1752
process: 291 / 291. Epoch 1752
Loss of epoch 1752 = 2.6086388027545104
process: 50 / 291. Epoch 1753
process: 100 / 291. Epoch 1753
process: 150 / 291. Epoch 1753
process: 200 / 291. Epoch 1753
process: 250 / 291. Epoch 1753
process: 291 / 291. Epoch 1753
Loss of epoch 1753 = 2.4919968437902704
process: 50 / 291. Epoch 1754
process: 100 / 291. Epoch 1754
process: 150 / 291. Epoch 1754
process: 200 / 291. Epoch 1754
process: 250 / 291. Epoch 1754
process: 291 / 291. Epoch 1754
Loss of epoch 1754 = 2.491647622019974
process: 50 / 291. Epoch 1755
process: 100 / 291. Epoch 1755
process: 150 / 291. Epoch 1755
process: 200 / 291. Epoch 1755
process: 250 / 291. Epoch 1755
process: 291 / 291. Epoch 1755
Loss of epoch 1755 = 2.533090702856529
process: 50 / 291. Epoch 1756
process: 100 / 291. Epoch 1756
process: 150 / 291. Epoch 1756
process: 200 / 291. Epoch 1756
process: 250 / 291. Epoch 1756
process: 291 / 291. Epoch 1756
Loss of epoch 1756 = 2.540876775263101
process: 50 / 291. Epoch 1757
process: 100 / 291. Epoch 1757
process: 150 / 291. Epoch 1757
process: 200 / 291. Epoch 1757
process: 250 / 291. Epoch 1757
process: 291 / 291. Epoch 1757
Loss of epoch 1757 = 2.4861519410438144
process: 50 / 291. Epoch 1758
process: 100 / 291. Epoch 1758
process: 150 / 291. Epoch 1758
process: 200 / 291. Epoch 1758
process: 250 / 291. Epoch 1758
process: 291 / 291. Epoch 1758
Loss of epoch 1758 = 2.5309624426143684
process: 50 / 291. Epoch 1759
process: 100 / 291. Epoch 1759
process: 150 / 291. Epoch 1759
process: 200 / 291. Epoch 1759
process: 250 / 291. Epoch 1759
process: 291 / 291. Epoch 1759
Loss of epoch 1759 = 2.549146934063574
process: 50 / 291. Epoch 1760
process: 100 / 291. Epoch 1760
process: 150 / 291. Epoch 1760
process: 200 / 291. Epoch 1760
process: 250 / 291. Epoch 1760
process: 291 / 291. Epoch 1760
Loss of epoch 1760 = 2.47460727757195
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1760. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.791870
      epoch  training_loss
1755   1756       2.540877
1756   1757       2.486152
1757   1758       2.530962
1758   1759       2.549147
1759   1760       2.474607
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
171       1720  0.015297  0.065499      0.383529   0.384975
172       1730  0.015247  0.065487      0.382113   0.383533
173       1740  0.015390  0.064795      0.383747   0.385214
174       1750  0.015292  0.065667      0.384100   0.385547
175       1760  0.015297  0.065761      0.383236   0.384682
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
171     1720.0  0.972506  0.980828  ...  0.957566  0.953738  0.940707
172     1730.0  0.971669  0.980955  ...  0.957566  0.954390  0.941114
173     1740.0  0.972493  0.980929  ...  0.957241  0.953413  0.940055
174     1750.0  0.972281  0.980839  ...  0.957159  0.954146  0.942499
175     1760.0  0.971868  0.980959  ...  0.957322  0.954553  0.943476

[5 rows x 13 columns]
process: 50 / 291. Epoch 1761
process: 100 / 291. Epoch 1761
process: 150 / 291. Epoch 1761
process: 200 / 291. Epoch 1761
process: 250 / 291. Epoch 1761
process: 291 / 291. Epoch 1761
Loss of epoch 1761 = 2.493992546579682
process: 50 / 291. Epoch 1762
process: 100 / 291. Epoch 1762
process: 150 / 291. Epoch 1762
process: 200 / 291. Epoch 1762
process: 250 / 291. Epoch 1762
process: 291 / 291. Epoch 1762
Loss of epoch 1762 = 2.5362301331615122
process: 50 / 291. Epoch 1763
process: 100 / 291. Epoch 1763
process: 150 / 291. Epoch 1763
process: 200 / 291. Epoch 1763
process: 250 / 291. Epoch 1763
process: 291 / 291. Epoch 1763
Loss of epoch 1763 = 2.574073398236147
process: 50 / 291. Epoch 1764
process: 100 / 291. Epoch 1764
process: 150 / 291. Epoch 1764
process: 200 / 291. Epoch 1764
process: 250 / 291. Epoch 1764
process: 291 / 291. Epoch 1764
Loss of epoch 1764 = 2.529382869550043
process: 50 / 291. Epoch 1765
process: 100 / 291. Epoch 1765
process: 150 / 291. Epoch 1765
process: 200 / 291. Epoch 1765
process: 250 / 291. Epoch 1765
process: 291 / 291. Epoch 1765
Loss of epoch 1765 = 2.4168015312902704
process: 50 / 291. Epoch 1766
process: 100 / 291. Epoch 1766
process: 150 / 291. Epoch 1766
process: 200 / 291. Epoch 1766
process: 250 / 291. Epoch 1766
process: 291 / 291. Epoch 1766
Loss of epoch 1766 = 2.559537592622423
process: 50 / 291. Epoch 1767
process: 100 / 291. Epoch 1767
process: 150 / 291. Epoch 1767
process: 200 / 291. Epoch 1767
process: 250 / 291. Epoch 1767
process: 291 / 291. Epoch 1767
Loss of epoch 1767 = 2.5555604495543385
process: 50 / 291. Epoch 1768
process: 100 / 291. Epoch 1768
process: 150 / 291. Epoch 1768
process: 200 / 291. Epoch 1768
process: 250 / 291. Epoch 1768
process: 291 / 291. Epoch 1768
Loss of epoch 1768 = 2.514307395699098
process: 50 / 291. Epoch 1769
process: 100 / 291. Epoch 1769
process: 150 / 291. Epoch 1769
process: 200 / 291. Epoch 1769
process: 250 / 291. Epoch 1769
process: 291 / 291. Epoch 1769
Loss of epoch 1769 = 2.483165203500859
process: 50 / 291. Epoch 1770
process: 100 / 291. Epoch 1770
process: 150 / 291. Epoch 1770
process: 200 / 291. Epoch 1770
process: 250 / 291. Epoch 1770
process: 291 / 291. Epoch 1770
Loss of epoch 1770 = 2.5216242734509233
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1770. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.783533
      epoch  training_loss
1765   1766       2.559538
1766   1767       2.555560
1767   1768       2.514307
1768   1769       2.483165
1769   1770       2.521624
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
172       1730  0.015247  0.065487      0.382113   0.383533
173       1740  0.015390  0.064795      0.383747   0.385214
174       1750  0.015292  0.065667      0.384100   0.385547
175       1760  0.015297  0.065761      0.383236   0.384682
176       1770  0.015402  0.064755      0.383896   0.385360
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
172     1730.0  0.971669  0.980955  ...  0.957566  0.954390  0.941114
173     1740.0  0.972493  0.980929  ...  0.957241  0.953413  0.940055
174     1750.0  0.972281  0.980839  ...  0.957159  0.954146  0.942499
175     1760.0  0.971868  0.980959  ...  0.957322  0.954553  0.943476
176     1770.0  0.972823  0.981059  ...  0.957648  0.954227  0.939078

[5 rows x 13 columns]
process: 50 / 291. Epoch 1771
process: 100 / 291. Epoch 1771
process: 150 / 291. Epoch 1771
process: 200 / 291. Epoch 1771
process: 250 / 291. Epoch 1771
process: 291 / 291. Epoch 1771
Loss of epoch 1771 = 2.4966457930627146
process: 50 / 291. Epoch 1772
process: 100 / 291. Epoch 1772
process: 150 / 291. Epoch 1772
process: 200 / 291. Epoch 1772
process: 250 / 291. Epoch 1772
process: 291 / 291. Epoch 1772
Loss of epoch 1772 = 2.5451957991033076
process: 50 / 291. Epoch 1773
process: 100 / 291. Epoch 1773
process: 150 / 291. Epoch 1773
process: 200 / 291. Epoch 1773
process: 250 / 291. Epoch 1773
process: 291 / 291. Epoch 1773
Loss of epoch 1773 = 2.4877967441204896
process: 50 / 291. Epoch 1774
process: 100 / 291. Epoch 1774
process: 150 / 291. Epoch 1774
process: 200 / 291. Epoch 1774
process: 250 / 291. Epoch 1774
process: 291 / 291. Epoch 1774
Loss of epoch 1774 = 2.463867816728415
process: 50 / 291. Epoch 1775
process: 100 / 291. Epoch 1775
process: 150 / 291. Epoch 1775
process: 200 / 291. Epoch 1775
process: 250 / 291. Epoch 1775
process: 291 / 291. Epoch 1775
Loss of epoch 1775 = 2.515601718548647
process: 50 / 291. Epoch 1776
process: 100 / 291. Epoch 1776
process: 150 / 291. Epoch 1776
process: 200 / 291. Epoch 1776
process: 250 / 291. Epoch 1776
process: 291 / 291. Epoch 1776
Loss of epoch 1776 = 2.498438674559708
process: 50 / 291. Epoch 1777
process: 100 / 291. Epoch 1777
process: 150 / 291. Epoch 1777
process: 200 / 291. Epoch 1777
process: 250 / 291. Epoch 1777
process: 291 / 291. Epoch 1777
Loss of epoch 1777 = 2.5357397544834623
process: 50 / 291. Epoch 1778
process: 100 / 291. Epoch 1778
process: 150 / 291. Epoch 1778
process: 200 / 291. Epoch 1778
process: 250 / 291. Epoch 1778
process: 291 / 291. Epoch 1778
Loss of epoch 1778 = 2.5106901712843643
process: 50 / 291. Epoch 1779
process: 100 / 291. Epoch 1779
process: 150 / 291. Epoch 1779
process: 200 / 291. Epoch 1779
process: 250 / 291. Epoch 1779
process: 291 / 291. Epoch 1779
Loss of epoch 1779 = 2.488073185137457
process: 50 / 291. Epoch 1780
process: 100 / 291. Epoch 1780
process: 150 / 291. Epoch 1780
process: 200 / 291. Epoch 1780
process: 250 / 291. Epoch 1780
process: 291 / 291. Epoch 1780
Loss of epoch 1780 = 2.509317194882947
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1780. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.785230
      epoch  training_loss
1775   1776       2.498439
1776   1777       2.535740
1777   1778       2.510690
1778   1779       2.488073
1779   1780       2.509317
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
173       1740  0.015390  0.064795      0.383747   0.385214
174       1750  0.015292  0.065667      0.384100   0.385547
175       1760  0.015297  0.065761      0.383236   0.384682
176       1770  0.015402  0.064755      0.383896   0.385360
177       1780  0.015396  0.064363      0.384877   0.386322
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
173     1740.0  0.972493  0.980929  ...  0.957241  0.953413  0.940055
174     1750.0  0.972281  0.980839  ...  0.957159  0.954146  0.942499
175     1760.0  0.971868  0.980959  ...  0.957322  0.954553  0.943476
176     1770.0  0.972823  0.981059  ...  0.957648  0.954227  0.939078
177     1780.0  0.972619  0.980942  ...  0.957811  0.953901  0.940544

[5 rows x 13 columns]
process: 50 / 291. Epoch 1781
process: 100 / 291. Epoch 1781
process: 150 / 291. Epoch 1781
process: 200 / 291. Epoch 1781
process: 250 / 291. Epoch 1781
process: 291 / 291. Epoch 1781
Loss of epoch 1781 = 2.5860125879241838
process: 50 / 291. Epoch 1782
process: 100 / 291. Epoch 1782
process: 150 / 291. Epoch 1782
process: 200 / 291. Epoch 1782
process: 250 / 291. Epoch 1782
process: 291 / 291. Epoch 1782
Loss of epoch 1782 = 2.5037787263745703
process: 50 / 291. Epoch 1783
process: 100 / 291. Epoch 1783
process: 150 / 291. Epoch 1783
process: 200 / 291. Epoch 1783
process: 250 / 291. Epoch 1783
process: 291 / 291. Epoch 1783
Loss of epoch 1783 = 2.4768989274591924
process: 50 / 291. Epoch 1784
process: 100 / 291. Epoch 1784
process: 150 / 291. Epoch 1784
process: 200 / 291. Epoch 1784
process: 250 / 291. Epoch 1784
process: 291 / 291. Epoch 1784
Loss of epoch 1784 = 2.5137847166290808
process: 50 / 291. Epoch 1785
process: 100 / 291. Epoch 1785
process: 150 / 291. Epoch 1785
process: 200 / 291. Epoch 1785
process: 250 / 291. Epoch 1785
process: 291 / 291. Epoch 1785
Loss of epoch 1785 = 2.4782983314540377
process: 50 / 291. Epoch 1786
process: 100 / 291. Epoch 1786
process: 150 / 291. Epoch 1786
process: 200 / 291. Epoch 1786
process: 250 / 291. Epoch 1786
process: 291 / 291. Epoch 1786
Loss of epoch 1786 = 2.5749843112381874
process: 50 / 291. Epoch 1787
process: 100 / 291. Epoch 1787
process: 150 / 291. Epoch 1787
process: 200 / 291. Epoch 1787
process: 250 / 291. Epoch 1787
process: 291 / 291. Epoch 1787
Loss of epoch 1787 = 2.5225158901149056
process: 50 / 291. Epoch 1788
process: 100 / 291. Epoch 1788
process: 150 / 291. Epoch 1788
process: 200 / 291. Epoch 1788
process: 250 / 291. Epoch 1788
process: 291 / 291. Epoch 1788
Loss of epoch 1788 = 2.4992247905927836
process: 50 / 291. Epoch 1789
process: 100 / 291. Epoch 1789
process: 150 / 291. Epoch 1789
process: 200 / 291. Epoch 1789
process: 250 / 291. Epoch 1789
process: 291 / 291. Epoch 1789
Loss of epoch 1789 = 2.5982968045264174
process: 50 / 291. Epoch 1790
process: 100 / 291. Epoch 1790
process: 150 / 291. Epoch 1790
process: 200 / 291. Epoch 1790
process: 250 / 291. Epoch 1790
process: 291 / 291. Epoch 1790
Loss of epoch 1790 = 2.5410932298378435
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1790. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.787226
      epoch  training_loss
1785   1786       2.574984
1786   1787       2.522516
1787   1788       2.499225
1788   1789       2.598297
1789   1790       2.541093
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
174       1750  0.015292  0.065667      0.384100   0.385547
175       1760  0.015297  0.065761      0.383236   0.384682
176       1770  0.015402  0.064755      0.383896   0.385360
177       1780  0.015396  0.064363      0.384877   0.386322
178       1790  0.015357  0.064887      0.384085   0.385530
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
174     1750.0  0.972281  0.980839  ...  0.957159  0.954146  0.942499
175     1760.0  0.971868  0.980959  ...  0.957322  0.954553  0.943476
176     1770.0  0.972823  0.981059  ...  0.957648  0.954227  0.939078
177     1780.0  0.972619  0.980942  ...  0.957811  0.953901  0.940544
178     1790.0  0.972074  0.980617  ...  0.957241  0.953983  0.941684

[5 rows x 13 columns]
process: 50 / 291. Epoch 1791
process: 100 / 291. Epoch 1791
process: 150 / 291. Epoch 1791
process: 200 / 291. Epoch 1791
process: 250 / 291. Epoch 1791
process: 291 / 291. Epoch 1791
Loss of epoch 1791 = 2.452086353629725
process: 50 / 291. Epoch 1792
process: 100 / 291. Epoch 1792
process: 150 / 291. Epoch 1792
process: 200 / 291. Epoch 1792
process: 250 / 291. Epoch 1792
process: 291 / 291. Epoch 1792
Loss of epoch 1792 = 2.427879936506658
process: 50 / 291. Epoch 1793
process: 100 / 291. Epoch 1793
process: 150 / 291. Epoch 1793
process: 200 / 291. Epoch 1793
process: 250 / 291. Epoch 1793
process: 291 / 291. Epoch 1793
Loss of epoch 1793 = 2.479555529827105
process: 50 / 291. Epoch 1794
process: 100 / 291. Epoch 1794
process: 150 / 291. Epoch 1794
process: 200 / 291. Epoch 1794
process: 250 / 291. Epoch 1794
process: 291 / 291. Epoch 1794
Loss of epoch 1794 = 2.502831108381658
process: 50 / 291. Epoch 1795
process: 100 / 291. Epoch 1795
process: 150 / 291. Epoch 1795
process: 200 / 291. Epoch 1795
process: 250 / 291. Epoch 1795
process: 291 / 291. Epoch 1795
Loss of epoch 1795 = 2.5081250167794242
process: 50 / 291. Epoch 1796
process: 100 / 291. Epoch 1796
process: 150 / 291. Epoch 1796
process: 200 / 291. Epoch 1796
process: 250 / 291. Epoch 1796
process: 291 / 291. Epoch 1796
Loss of epoch 1796 = 2.5091605170076248
process: 50 / 291. Epoch 1797
process: 100 / 291. Epoch 1797
process: 150 / 291. Epoch 1797
process: 200 / 291. Epoch 1797
process: 250 / 291. Epoch 1797
process: 291 / 291. Epoch 1797
Loss of epoch 1797 = 2.537709029679446
process: 50 / 291. Epoch 1798
process: 100 / 291. Epoch 1798
process: 150 / 291. Epoch 1798
process: 200 / 291. Epoch 1798
process: 250 / 291. Epoch 1798
process: 291 / 291. Epoch 1798
Loss of epoch 1798 = 2.5352598629456615
process: 50 / 291. Epoch 1799
process: 100 / 291. Epoch 1799
process: 150 / 291. Epoch 1799
process: 200 / 291. Epoch 1799
process: 250 / 291. Epoch 1799
process: 291 / 291. Epoch 1799
Loss of epoch 1799 = 2.528749446278995
process: 50 / 291. Epoch 1800
process: 100 / 291. Epoch 1800
process: 150 / 291. Epoch 1800
process: 200 / 291. Epoch 1800
process: 250 / 291. Epoch 1800
process: 291 / 291. Epoch 1800
Loss of epoch 1800 = 2.460885903269974
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1800. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.787372
      epoch  training_loss
1795   1796       2.509161
1796   1797       2.537709
1797   1798       2.535260
1798   1799       2.528749
1799   1800       2.460886
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
175       1760  0.015297  0.065761      0.383236   0.384682
176       1770  0.015402  0.064755      0.383896   0.385360
177       1780  0.015396  0.064363      0.384877   0.386322
178       1790  0.015357  0.064887      0.384085   0.385530
179       1800  0.015299  0.064890      0.385438   0.386918
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
175     1760.0  0.971868  0.980959  ...  0.957322  0.954553  0.943476
176     1770.0  0.972823  0.981059  ...  0.957648  0.954227  0.939078
177     1780.0  0.972619  0.980942  ...  0.957811  0.953901  0.940544
178     1790.0  0.972074  0.980617  ...  0.957241  0.953983  0.941684
179     1800.0  0.972838  0.981389  ...  0.958055  0.954309  0.942417

[5 rows x 13 columns]
process: 50 / 291. Epoch 1801
process: 100 / 291. Epoch 1801
process: 150 / 291. Epoch 1801
process: 200 / 291. Epoch 1801
process: 250 / 291. Epoch 1801
process: 291 / 291. Epoch 1801
Loss of epoch 1801 = 2.4371614751127577
process: 50 / 291. Epoch 1802
process: 100 / 291. Epoch 1802
process: 150 / 291. Epoch 1802
process: 200 / 291. Epoch 1802
process: 250 / 291. Epoch 1802
process: 291 / 291. Epoch 1802
Loss of epoch 1802 = 2.4765559979730454
process: 50 / 291. Epoch 1803
process: 100 / 291. Epoch 1803
process: 150 / 291. Epoch 1803
process: 200 / 291. Epoch 1803
process: 250 / 291. Epoch 1803
process: 291 / 291. Epoch 1803
Loss of epoch 1803 = 2.5348074477153135
process: 50 / 291. Epoch 1804
process: 100 / 291. Epoch 1804
process: 150 / 291. Epoch 1804
process: 200 / 291. Epoch 1804
process: 250 / 291. Epoch 1804
process: 291 / 291. Epoch 1804
Loss of epoch 1804 = 2.4985055825144973
process: 50 / 291. Epoch 1805
process: 100 / 291. Epoch 1805
process: 150 / 291. Epoch 1805
process: 200 / 291. Epoch 1805
process: 250 / 291. Epoch 1805
process: 291 / 291. Epoch 1805
Loss of epoch 1805 = 2.5378719998389174
process: 50 / 291. Epoch 1806
process: 100 / 291. Epoch 1806
process: 150 / 291. Epoch 1806
process: 200 / 291. Epoch 1806
process: 250 / 291. Epoch 1806
process: 291 / 291. Epoch 1806
Loss of epoch 1806 = 2.4909779132436642
process: 50 / 291. Epoch 1807
process: 100 / 291. Epoch 1807
process: 150 / 291. Epoch 1807
process: 200 / 291. Epoch 1807
process: 250 / 291. Epoch 1807
process: 291 / 291. Epoch 1807
Loss of epoch 1807 = 2.4611967421069587
process: 50 / 291. Epoch 1808
process: 100 / 291. Epoch 1808
process: 150 / 291. Epoch 1808
process: 200 / 291. Epoch 1808
process: 250 / 291. Epoch 1808
process: 291 / 291. Epoch 1808
Loss of epoch 1808 = 2.522291465313574
process: 50 / 291. Epoch 1809
process: 100 / 291. Epoch 1809
process: 150 / 291. Epoch 1809
process: 200 / 291. Epoch 1809
process: 250 / 291. Epoch 1809
process: 291 / 291. Epoch 1809
Loss of epoch 1809 = 2.5257497046821307
process: 50 / 291. Epoch 1810
process: 100 / 291. Epoch 1810
process: 150 / 291. Epoch 1810
process: 200 / 291. Epoch 1810
process: 250 / 291. Epoch 1810
process: 291 / 291. Epoch 1810
Loss of epoch 1810 = 2.4834735254241838
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1810. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.791684
      epoch  training_loss
1805   1806       2.490978
1806   1807       2.461197
1807   1808       2.522291
1808   1809       2.525750
1809   1810       2.483474
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
176       1770  0.015402  0.064755      0.383896   0.385360
177       1780  0.015396  0.064363      0.384877   0.386322
178       1790  0.015357  0.064887      0.384085   0.385530
179       1800  0.015299  0.064890      0.385438   0.386918
180       1810  0.015260  0.065633      0.386552   0.388053
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
176     1770.0  0.972823  0.981059  ...  0.957648  0.954227  0.939078
177     1780.0  0.972619  0.980942  ...  0.957811  0.953901  0.940544
178     1790.0  0.972074  0.980617  ...  0.957241  0.953983  0.941684
179     1800.0  0.972838  0.981389  ...  0.958055  0.954309  0.942417
180     1810.0  0.972425  0.981057  ...  0.958218  0.954146  0.943639

[5 rows x 13 columns]
process: 50 / 291. Epoch 1811
process: 100 / 291. Epoch 1811
process: 150 / 291. Epoch 1811
process: 200 / 291. Epoch 1811
process: 250 / 291. Epoch 1811
process: 291 / 291. Epoch 1811
Loss of epoch 1811 = 2.5061353965313575
process: 50 / 291. Epoch 1812
process: 100 / 291. Epoch 1812
process: 150 / 291. Epoch 1812
process: 200 / 291. Epoch 1812
process: 250 / 291. Epoch 1812
process: 291 / 291. Epoch 1812
Loss of epoch 1812 = 2.522866160599227
process: 50 / 291. Epoch 1813
process: 100 / 291. Epoch 1813
process: 150 / 291. Epoch 1813
process: 200 / 291. Epoch 1813
process: 250 / 291. Epoch 1813
process: 291 / 291. Epoch 1813
Loss of epoch 1813 = 2.51000766819695
process: 50 / 291. Epoch 1814
process: 100 / 291. Epoch 1814
process: 150 / 291. Epoch 1814
process: 200 / 291. Epoch 1814
process: 250 / 291. Epoch 1814
process: 291 / 291. Epoch 1814
Loss of epoch 1814 = 2.512245833668922
process: 50 / 291. Epoch 1815
process: 100 / 291. Epoch 1815
process: 150 / 291. Epoch 1815
process: 200 / 291. Epoch 1815
process: 250 / 291. Epoch 1815
process: 291 / 291. Epoch 1815
Loss of epoch 1815 = 2.5108606921848153
process: 50 / 291. Epoch 1816
process: 100 / 291. Epoch 1816
process: 150 / 291. Epoch 1816
process: 200 / 291. Epoch 1816
process: 250 / 291. Epoch 1816
process: 291 / 291. Epoch 1816
Loss of epoch 1816 = 2.4699023269705758
process: 50 / 291. Epoch 1817
process: 100 / 291. Epoch 1817
process: 150 / 291. Epoch 1817
process: 200 / 291. Epoch 1817
process: 250 / 291. Epoch 1817
process: 291 / 291. Epoch 1817
Loss of epoch 1817 = 2.481759926707474
process: 50 / 291. Epoch 1818
process: 100 / 291. Epoch 1818
process: 150 / 291. Epoch 1818
process: 200 / 291. Epoch 1818
process: 250 / 291. Epoch 1818
process: 291 / 291. Epoch 1818
Loss of epoch 1818 = 2.4808429311640894
process: 50 / 291. Epoch 1819
process: 100 / 291. Epoch 1819
process: 150 / 291. Epoch 1819
process: 200 / 291. Epoch 1819
process: 250 / 291. Epoch 1819
process: 291 / 291. Epoch 1819
Loss of epoch 1819 = 2.472115323305949
process: 50 / 291. Epoch 1820
process: 100 / 291. Epoch 1820
process: 150 / 291. Epoch 1820
process: 200 / 291. Epoch 1820
process: 250 / 291. Epoch 1820
process: 291 / 291. Epoch 1820
Loss of epoch 1820 = 2.5021041398195876
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1820. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.787602
      epoch  training_loss
1815   1816       2.469902
1816   1817       2.481760
1817   1818       2.480843
1818   1819       2.472115
1819   1820       2.502104
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
177       1780  0.015396  0.064363      0.384877   0.386322
178       1790  0.015357  0.064887      0.384085   0.385530
179       1800  0.015299  0.064890      0.385438   0.386918
180       1810  0.015260  0.065633      0.386552   0.388053
181       1820  0.015321  0.064897      0.385918   0.387411
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
177     1780.0  0.972619  0.980942  ...  0.957811  0.953901  0.940544
178     1790.0  0.972074  0.980617  ...  0.957241  0.953983  0.941684
179     1800.0  0.972838  0.981389  ...  0.958055  0.954309  0.942417
180     1810.0  0.972425  0.981057  ...  0.958218  0.954146  0.943639
181     1820.0  0.972385  0.981066  ...  0.957159  0.954471  0.940707

[5 rows x 13 columns]
process: 50 / 291. Epoch 1821
process: 100 / 291. Epoch 1821
process: 150 / 291. Epoch 1821
process: 200 / 291. Epoch 1821
process: 250 / 291. Epoch 1821
process: 291 / 291. Epoch 1821
Loss of epoch 1821 = 2.496326564513531
process: 50 / 291. Epoch 1822
process: 100 / 291. Epoch 1822
process: 150 / 291. Epoch 1822
process: 200 / 291. Epoch 1822
process: 250 / 291. Epoch 1822
process: 291 / 291. Epoch 1822
Loss of epoch 1822 = 2.553330883537371
process: 50 / 291. Epoch 1823
process: 100 / 291. Epoch 1823
process: 150 / 291. Epoch 1823
process: 200 / 291. Epoch 1823
process: 250 / 291. Epoch 1823
process: 291 / 291. Epoch 1823
Loss of epoch 1823 = 2.4954762671821307
process: 50 / 291. Epoch 1824
process: 100 / 291. Epoch 1824
process: 150 / 291. Epoch 1824
process: 200 / 291. Epoch 1824
process: 250 / 291. Epoch 1824
process: 291 / 291. Epoch 1824
Loss of epoch 1824 = 2.490537663096005
process: 50 / 291. Epoch 1825
process: 100 / 291. Epoch 1825
process: 150 / 291. Epoch 1825
process: 200 / 291. Epoch 1825
process: 250 / 291. Epoch 1825
process: 291 / 291. Epoch 1825
Loss of epoch 1825 = 2.4917541713649056
process: 50 / 291. Epoch 1826
process: 100 / 291. Epoch 1826
process: 150 / 291. Epoch 1826
process: 200 / 291. Epoch 1826
process: 250 / 291. Epoch 1826
process: 291 / 291. Epoch 1826
Loss of epoch 1826 = 2.478159062231529
process: 50 / 291. Epoch 1827
process: 100 / 291. Epoch 1827
process: 150 / 291. Epoch 1827
process: 200 / 291. Epoch 1827
process: 250 / 291. Epoch 1827
process: 291 / 291. Epoch 1827
Loss of epoch 1827 = 2.458594253382732
process: 50 / 291. Epoch 1828
process: 100 / 291. Epoch 1828
process: 150 / 291. Epoch 1828
process: 200 / 291. Epoch 1828
process: 250 / 291. Epoch 1828
process: 291 / 291. Epoch 1828
Loss of epoch 1828 = 2.5919839655820445
process: 50 / 291. Epoch 1829
process: 100 / 291. Epoch 1829
process: 150 / 291. Epoch 1829
process: 200 / 291. Epoch 1829
process: 250 / 291. Epoch 1829
process: 291 / 291. Epoch 1829
Loss of epoch 1829 = 2.485889552794781
process: 50 / 291. Epoch 1830
process: 100 / 291. Epoch 1830
process: 150 / 291. Epoch 1830
process: 200 / 291. Epoch 1830
process: 250 / 291. Epoch 1830
process: 291 / 291. Epoch 1830
Loss of epoch 1830 = 2.4397543156679555
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1830. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.790177
      epoch  training_loss
1825   1826       2.478159
1826   1827       2.458594
1827   1828       2.591984
1828   1829       2.485890
1829   1830       2.439754
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
178       1790  0.015357  0.064887      0.384085   0.385530
179       1800  0.015299  0.064890      0.385438   0.386918
180       1810  0.015260  0.065633      0.386552   0.388053
181       1820  0.015321  0.064897      0.385918   0.387411
182       1830  0.015195  0.064921      0.386214   0.387702
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
178     1790.0  0.972074  0.980617  ...  0.957241  0.953983  0.941684
179     1800.0  0.972838  0.981389  ...  0.958055  0.954309  0.942417
180     1810.0  0.972425  0.981057  ...  0.958218  0.954146  0.943639
181     1820.0  0.972385  0.981066  ...  0.957159  0.954471  0.940707
182     1830.0  0.972204  0.980730  ...  0.957892  0.954146  0.943395

[5 rows x 13 columns]
process: 50 / 291. Epoch 1831
process: 100 / 291. Epoch 1831
process: 150 / 291. Epoch 1831
process: 200 / 291. Epoch 1831
process: 250 / 291. Epoch 1831
process: 291 / 291. Epoch 1831
Loss of epoch 1831 = 2.554653731408398
process: 50 / 291. Epoch 1832
process: 100 / 291. Epoch 1832
process: 150 / 291. Epoch 1832
process: 200 / 291. Epoch 1832
process: 250 / 291. Epoch 1832
process: 291 / 291. Epoch 1832
Loss of epoch 1832 = 2.526624122436104
process: 50 / 291. Epoch 1833
process: 100 / 291. Epoch 1833
process: 150 / 291. Epoch 1833
process: 200 / 291. Epoch 1833
process: 250 / 291. Epoch 1833
process: 291 / 291. Epoch 1833
Loss of epoch 1833 = 2.4918284203178693
process: 50 / 291. Epoch 1834
process: 100 / 291. Epoch 1834
process: 150 / 291. Epoch 1834
process: 200 / 291. Epoch 1834
process: 250 / 291. Epoch 1834
process: 291 / 291. Epoch 1834
Loss of epoch 1834 = 2.4739310667686856
process: 50 / 291. Epoch 1835
process: 100 / 291. Epoch 1835
process: 150 / 291. Epoch 1835
process: 200 / 291. Epoch 1835
process: 250 / 291. Epoch 1835
process: 291 / 291. Epoch 1835
Loss of epoch 1835 = 2.4864078272658934
process: 50 / 291. Epoch 1836
process: 100 / 291. Epoch 1836
process: 150 / 291. Epoch 1836
process: 200 / 291. Epoch 1836
process: 250 / 291. Epoch 1836
process: 291 / 291. Epoch 1836
Loss of epoch 1836 = 2.4819530998308634
process: 50 / 291. Epoch 1837
process: 100 / 291. Epoch 1837
process: 150 / 291. Epoch 1837
process: 200 / 291. Epoch 1837
process: 250 / 291. Epoch 1837
process: 291 / 291. Epoch 1837
Loss of epoch 1837 = 2.482225136248926
process: 50 / 291. Epoch 1838
process: 100 / 291. Epoch 1838
process: 150 / 291. Epoch 1838
process: 200 / 291. Epoch 1838
process: 250 / 291. Epoch 1838
process: 291 / 291. Epoch 1838
Loss of epoch 1838 = 2.477797046150129
process: 50 / 291. Epoch 1839
process: 100 / 291. Epoch 1839
process: 150 / 291. Epoch 1839
process: 200 / 291. Epoch 1839
process: 250 / 291. Epoch 1839
process: 291 / 291. Epoch 1839
Loss of epoch 1839 = 2.475110660303909
process: 50 / 291. Epoch 1840
process: 100 / 291. Epoch 1840
process: 150 / 291. Epoch 1840
process: 200 / 291. Epoch 1840
process: 250 / 291. Epoch 1840
process: 291 / 291. Epoch 1840
Loss of epoch 1840 = 2.5290227411538875
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1840. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.790931
      epoch  training_loss
1835   1836       2.481953
1836   1837       2.482225
1837   1838       2.477797
1838   1839       2.475111
1839   1840       2.529023
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
179       1800  0.015299  0.064890      0.385438   0.386918
180       1810  0.015260  0.065633      0.386552   0.388053
181       1820  0.015321  0.064897      0.385918   0.387411
182       1830  0.015195  0.064921      0.386214   0.387702
183       1840  0.015311  0.064945      0.385950   0.387406
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
179     1800.0  0.972838  0.981389  ...  0.958055  0.954309  0.942417
180     1810.0  0.972425  0.981057  ...  0.958218  0.954146  0.943639
181     1820.0  0.972385  0.981066  ...  0.957159  0.954471  0.940707
182     1830.0  0.972204  0.980730  ...  0.957892  0.954146  0.943395
183     1840.0  0.971967  0.980503  ...  0.957159  0.953820  0.942906

[5 rows x 13 columns]
process: 50 / 291. Epoch 1841
process: 100 / 291. Epoch 1841
process: 150 / 291. Epoch 1841
process: 200 / 291. Epoch 1841
process: 250 / 291. Epoch 1841
process: 291 / 291. Epoch 1841
Loss of epoch 1841 = 2.4750464790055844
process: 50 / 291. Epoch 1842
process: 100 / 291. Epoch 1842
process: 150 / 291. Epoch 1842
process: 200 / 291. Epoch 1842
process: 250 / 291. Epoch 1842
process: 291 / 291. Epoch 1842
Loss of epoch 1842 = 2.4892737529531788
process: 50 / 291. Epoch 1843
process: 100 / 291. Epoch 1843
process: 150 / 291. Epoch 1843
process: 200 / 291. Epoch 1843
process: 250 / 291. Epoch 1843
process: 291 / 291. Epoch 1843
Loss of epoch 1843 = 2.4775659095790377
process: 50 / 291. Epoch 1844
process: 100 / 291. Epoch 1844
process: 150 / 291. Epoch 1844
process: 200 / 291. Epoch 1844
process: 250 / 291. Epoch 1844
process: 291 / 291. Epoch 1844
Loss of epoch 1844 = 2.4952803674022768
process: 50 / 291. Epoch 1845
process: 100 / 291. Epoch 1845
process: 150 / 291. Epoch 1845
process: 200 / 291. Epoch 1845
process: 250 / 291. Epoch 1845
process: 291 / 291. Epoch 1845
Loss of epoch 1845 = 2.4764827977341066
process: 50 / 291. Epoch 1846
process: 100 / 291. Epoch 1846
process: 150 / 291. Epoch 1846
process: 200 / 291. Epoch 1846
process: 250 / 291. Epoch 1846
process: 291 / 291. Epoch 1846
Loss of epoch 1846 = 2.486647982777599
process: 50 / 291. Epoch 1847
process: 100 / 291. Epoch 1847
process: 150 / 291. Epoch 1847
process: 200 / 291. Epoch 1847
process: 250 / 291. Epoch 1847
process: 291 / 291. Epoch 1847
Loss of epoch 1847 = 2.487802407176224
process: 50 / 291. Epoch 1848
process: 100 / 291. Epoch 1848
process: 150 / 291. Epoch 1848
process: 200 / 291. Epoch 1848
process: 250 / 291. Epoch 1848
process: 291 / 291. Epoch 1848
Loss of epoch 1848 = 2.483121576997423
process: 50 / 291. Epoch 1849
process: 100 / 291. Epoch 1849
process: 150 / 291. Epoch 1849
process: 200 / 291. Epoch 1849
process: 250 / 291. Epoch 1849
process: 291 / 291. Epoch 1849
Loss of epoch 1849 = 2.510351646397122
process: 50 / 291. Epoch 1850
process: 100 / 291. Epoch 1850
process: 150 / 291. Epoch 1850
process: 200 / 291. Epoch 1850
process: 250 / 291. Epoch 1850
process: 291 / 291. Epoch 1850
Loss of epoch 1850 = 2.502343246617268
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1850. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.791961
      epoch  training_loss
1845   1846       2.486648
1846   1847       2.487802
1847   1848       2.483122
1848   1849       2.510352
1849   1850       2.502343
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
180       1810  0.015260  0.065633      0.386552   0.388053
181       1820  0.015321  0.064897      0.385918   0.387411
182       1830  0.015195  0.064921      0.386214   0.387702
183       1840  0.015311  0.064945      0.385950   0.387406
184       1850  0.015350  0.064865      0.386762   0.388264
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
180     1810.0  0.972425  0.981057  ...  0.958218  0.954146  0.943639
181     1820.0  0.972385  0.981066  ...  0.957159  0.954471  0.940707
182     1830.0  0.972204  0.980730  ...  0.957892  0.954146  0.943395
183     1840.0  0.971967  0.980503  ...  0.957159  0.953820  0.942906
184     1850.0  0.971441  0.980852  ...  0.957078  0.954634  0.942662

[5 rows x 13 columns]
process: 50 / 291. Epoch 1851
process: 100 / 291. Epoch 1851
process: 150 / 291. Epoch 1851
process: 200 / 291. Epoch 1851
process: 250 / 291. Epoch 1851
process: 291 / 291. Epoch 1851
Loss of epoch 1851 = 2.4971328158558848
process: 50 / 291. Epoch 1852
process: 100 / 291. Epoch 1852
process: 150 / 291. Epoch 1852
process: 200 / 291. Epoch 1852
process: 250 / 291. Epoch 1852
process: 291 / 291. Epoch 1852
Loss of epoch 1852 = 2.476159374328823
process: 50 / 291. Epoch 1853
process: 100 / 291. Epoch 1853
process: 150 / 291. Epoch 1853
process: 200 / 291. Epoch 1853
process: 250 / 291. Epoch 1853
process: 291 / 291. Epoch 1853
Loss of epoch 1853 = 2.5061079202239047
process: 50 / 291. Epoch 1854
process: 100 / 291. Epoch 1854
process: 150 / 291. Epoch 1854
process: 200 / 291. Epoch 1854
process: 250 / 291. Epoch 1854
process: 291 / 291. Epoch 1854
Loss of epoch 1854 = 2.4600137926868557
process: 50 / 291. Epoch 1855
process: 100 / 291. Epoch 1855
process: 150 / 291. Epoch 1855
process: 200 / 291. Epoch 1855
process: 250 / 291. Epoch 1855
process: 291 / 291. Epoch 1855
Loss of epoch 1855 = 2.4737278259906574
process: 50 / 291. Epoch 1856
process: 100 / 291. Epoch 1856
process: 150 / 291. Epoch 1856
process: 200 / 291. Epoch 1856
process: 250 / 291. Epoch 1856
process: 291 / 291. Epoch 1856
Loss of epoch 1856 = 2.463902843776847
process: 50 / 291. Epoch 1857
process: 100 / 291. Epoch 1857
process: 150 / 291. Epoch 1857
process: 200 / 291. Epoch 1857
process: 250 / 291. Epoch 1857
process: 291 / 291. Epoch 1857
Loss of epoch 1857 = 2.5417931415780712
process: 50 / 291. Epoch 1858
process: 100 / 291. Epoch 1858
process: 150 / 291. Epoch 1858
process: 200 / 291. Epoch 1858
process: 250 / 291. Epoch 1858
process: 291 / 291. Epoch 1858
Loss of epoch 1858 = 2.5017861697272337
process: 50 / 291. Epoch 1859
process: 100 / 291. Epoch 1859
process: 150 / 291. Epoch 1859
process: 200 / 291. Epoch 1859
process: 250 / 291. Epoch 1859
process: 291 / 291. Epoch 1859
Loss of epoch 1859 = 2.49688594857442
process: 50 / 291. Epoch 1860
process: 100 / 291. Epoch 1860
process: 150 / 291. Epoch 1860
process: 200 / 291. Epoch 1860
process: 250 / 291. Epoch 1860
process: 291 / 291. Epoch 1860
Loss of epoch 1860 = 2.5192772514631656
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1860. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.790209
      epoch  training_loss
1855   1856       2.463903
1856   1857       2.541793
1857   1858       2.501786
1858   1859       2.496886
1859   1860       2.519277
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
181       1820  0.015321  0.064897      0.385918   0.387411
182       1830  0.015195  0.064921      0.386214   0.387702
183       1840  0.015311  0.064945      0.385950   0.387406
184       1850  0.015350  0.064865      0.386762   0.388264
185       1860  0.015324  0.064677      0.386406   0.387899
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
181     1820.0  0.972385  0.981066  ...  0.957159  0.954471  0.940707
182     1830.0  0.972204  0.980730  ...  0.957892  0.954146  0.943395
183     1840.0  0.971967  0.980503  ...  0.957159  0.953820  0.942906
184     1850.0  0.971441  0.980852  ...  0.957078  0.954634  0.942662
185     1860.0  0.972407  0.980837  ...  0.957729  0.954064  0.943069

[5 rows x 13 columns]
process: 50 / 291. Epoch 1861
process: 100 / 291. Epoch 1861
process: 150 / 291. Epoch 1861
process: 200 / 291. Epoch 1861
process: 250 / 291. Epoch 1861
process: 291 / 291. Epoch 1861
Loss of epoch 1861 = 2.5062524330165377
process: 50 / 291. Epoch 1862
process: 100 / 291. Epoch 1862
process: 150 / 291. Epoch 1862
process: 200 / 291. Epoch 1862
process: 250 / 291. Epoch 1862
process: 291 / 291. Epoch 1862
Loss of epoch 1862 = 2.4500577212199315
process: 50 / 291. Epoch 1863
process: 100 / 291. Epoch 1863
process: 150 / 291. Epoch 1863
process: 200 / 291. Epoch 1863
process: 250 / 291. Epoch 1863
process: 291 / 291. Epoch 1863
Loss of epoch 1863 = 2.4788887574500644
process: 50 / 291. Epoch 1864
process: 100 / 291. Epoch 1864
process: 150 / 291. Epoch 1864
process: 200 / 291. Epoch 1864
process: 250 / 291. Epoch 1864
process: 291 / 291. Epoch 1864
Loss of epoch 1864 = 2.435838207756121
process: 50 / 291. Epoch 1865
process: 100 / 291. Epoch 1865
process: 150 / 291. Epoch 1865
process: 200 / 291. Epoch 1865
process: 250 / 291. Epoch 1865
process: 291 / 291. Epoch 1865
Loss of epoch 1865 = 2.4879133611200603
process: 50 / 291. Epoch 1866
process: 100 / 291. Epoch 1866
process: 150 / 291. Epoch 1866
process: 200 / 291. Epoch 1866
process: 250 / 291. Epoch 1866
process: 291 / 291. Epoch 1866
Loss of epoch 1866 = 2.5277133168223798
process: 50 / 291. Epoch 1867
process: 100 / 291. Epoch 1867
process: 150 / 291. Epoch 1867
process: 200 / 291. Epoch 1867
process: 250 / 291. Epoch 1867
process: 291 / 291. Epoch 1867
Loss of epoch 1867 = 2.480383174935567
process: 50 / 291. Epoch 1868
process: 100 / 291. Epoch 1868
process: 150 / 291. Epoch 1868
process: 200 / 291. Epoch 1868
process: 250 / 291. Epoch 1868
process: 291 / 291. Epoch 1868
Loss of epoch 1868 = 2.4695237412075817
process: 50 / 291. Epoch 1869
process: 100 / 291. Epoch 1869
process: 150 / 291. Epoch 1869
process: 200 / 291. Epoch 1869
process: 250 / 291. Epoch 1869
process: 291 / 291. Epoch 1869
Loss of epoch 1869 = 2.4943799415404855
process: 50 / 291. Epoch 1870
process: 100 / 291. Epoch 1870
process: 150 / 291. Epoch 1870
process: 200 / 291. Epoch 1870
process: 250 / 291. Epoch 1870
process: 291 / 291. Epoch 1870
Loss of epoch 1870 = 2.494189704816366
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1870. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.784452
      epoch  training_loss
1865   1866       2.527713
1866   1867       2.480383
1867   1868       2.469524
1868   1869       2.494380
1869   1870       2.494190
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
182       1830  0.015195  0.064921      0.386214   0.387702
183       1840  0.015311  0.064945      0.385950   0.387406
184       1850  0.015350  0.064865      0.386762   0.388264
185       1860  0.015324  0.064677      0.386406   0.387899
186       1870  0.015464  0.062979      0.386143   0.387601
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
182     1830.0  0.972204  0.980730  ...  0.957892  0.954146  0.943395
183     1840.0  0.971967  0.980503  ...  0.957159  0.953820  0.942906
184     1850.0  0.971441  0.980852  ...  0.957078  0.954634  0.942662
185     1860.0  0.972407  0.980837  ...  0.957729  0.954064  0.943069
186     1870.0  0.972173  0.980942  ...  0.957078  0.953901  0.938589

[5 rows x 13 columns]
process: 50 / 291. Epoch 1871
process: 100 / 291. Epoch 1871
process: 150 / 291. Epoch 1871
process: 200 / 291. Epoch 1871
process: 250 / 291. Epoch 1871
process: 291 / 291. Epoch 1871
Loss of epoch 1871 = 2.4901571896477663
process: 50 / 291. Epoch 1872
process: 100 / 291. Epoch 1872
process: 150 / 291. Epoch 1872
process: 200 / 291. Epoch 1872
process: 250 / 291. Epoch 1872
process: 291 / 291. Epoch 1872
Loss of epoch 1872 = 2.4515783565560567
process: 50 / 291. Epoch 1873
process: 100 / 291. Epoch 1873
process: 150 / 291. Epoch 1873
process: 200 / 291. Epoch 1873
process: 250 / 291. Epoch 1873
process: 291 / 291. Epoch 1873
Loss of epoch 1873 = 2.4529056090259878
process: 50 / 291. Epoch 1874
process: 100 / 291. Epoch 1874
process: 150 / 291. Epoch 1874
process: 200 / 291. Epoch 1874
process: 250 / 291. Epoch 1874
process: 291 / 291. Epoch 1874
Loss of epoch 1874 = 2.462935929445876
process: 50 / 291. Epoch 1875
process: 100 / 291. Epoch 1875
process: 150 / 291. Epoch 1875
process: 200 / 291. Epoch 1875
process: 250 / 291. Epoch 1875
process: 291 / 291. Epoch 1875
Loss of epoch 1875 = 2.5157038632946733
process: 50 / 291. Epoch 1876
process: 100 / 291. Epoch 1876
process: 150 / 291. Epoch 1876
process: 200 / 291. Epoch 1876
process: 250 / 291. Epoch 1876
process: 291 / 291. Epoch 1876
Loss of epoch 1876 = 2.508828913632947
process: 50 / 291. Epoch 1877
process: 100 / 291. Epoch 1877
process: 150 / 291. Epoch 1877
process: 200 / 291. Epoch 1877
process: 250 / 291. Epoch 1877
process: 291 / 291. Epoch 1877
Loss of epoch 1877 = 2.538425720844072
process: 50 / 291. Epoch 1878
process: 100 / 291. Epoch 1878
process: 150 / 291. Epoch 1878
process: 200 / 291. Epoch 1878
process: 250 / 291. Epoch 1878
process: 291 / 291. Epoch 1878
Loss of epoch 1878 = 2.494821450144974
process: 50 / 291. Epoch 1879
process: 100 / 291. Epoch 1879
process: 150 / 291. Epoch 1879
process: 200 / 291. Epoch 1879
process: 250 / 291. Epoch 1879
process: 291 / 291. Epoch 1879
Loss of epoch 1879 = 2.491648880476804
process: 50 / 291. Epoch 1880
process: 100 / 291. Epoch 1880
process: 150 / 291. Epoch 1880
process: 200 / 291. Epoch 1880
process: 250 / 291. Epoch 1880
process: 291 / 291. Epoch 1880
Loss of epoch 1880 = 2.437549499301976
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1880. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.785638
      epoch  training_loss
1875   1876       2.508829
1876   1877       2.538426
1877   1878       2.494821
1878   1879       2.491649
1879   1880       2.437549
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
183       1840  0.015311  0.064945      0.385950   0.387406
184       1850  0.015350  0.064865      0.386762   0.388264
185       1860  0.015324  0.064677      0.386406   0.387899
186       1870  0.015464  0.062979      0.386143   0.387601
187       1880  0.015315  0.063877      0.386747   0.388255
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
183     1840.0  0.971967  0.980503  ...  0.957159  0.953820  0.942906
184     1850.0  0.971441  0.980852  ...  0.957078  0.954634  0.942662
185     1860.0  0.972407  0.980837  ...  0.957729  0.954064  0.943069
186     1870.0  0.972173  0.980942  ...  0.957078  0.953901  0.938589
187     1880.0  0.972385  0.980942  ...  0.957159  0.953901  0.941114

[5 rows x 13 columns]
process: 50 / 291. Epoch 1881
process: 100 / 291. Epoch 1881
process: 150 / 291. Epoch 1881
process: 200 / 291. Epoch 1881
process: 250 / 291. Epoch 1881
process: 291 / 291. Epoch 1881
Loss of epoch 1881 = 2.417210320017182
process: 50 / 291. Epoch 1882
process: 100 / 291. Epoch 1882
process: 150 / 291. Epoch 1882
process: 200 / 291. Epoch 1882
process: 250 / 291. Epoch 1882
process: 291 / 291. Epoch 1882
Loss of epoch 1882 = 2.4621250637618126
process: 50 / 291. Epoch 1883
process: 100 / 291. Epoch 1883
process: 150 / 291. Epoch 1883
process: 200 / 291. Epoch 1883
process: 250 / 291. Epoch 1883
process: 291 / 291. Epoch 1883
Loss of epoch 1883 = 2.4670347233408507
process: 50 / 291. Epoch 1884
process: 100 / 291. Epoch 1884
process: 150 / 291. Epoch 1884
process: 200 / 291. Epoch 1884
process: 250 / 291. Epoch 1884
process: 291 / 291. Epoch 1884
Loss of epoch 1884 = 2.4954586487865122
process: 50 / 291. Epoch 1885
process: 100 / 291. Epoch 1885
process: 150 / 291. Epoch 1885
process: 200 / 291. Epoch 1885
process: 250 / 291. Epoch 1885
process: 291 / 291. Epoch 1885
Loss of epoch 1885 = 2.4808869771531357
process: 50 / 291. Epoch 1886
process: 100 / 291. Epoch 1886
process: 150 / 291. Epoch 1886
process: 200 / 291. Epoch 1886
process: 250 / 291. Epoch 1886
process: 291 / 291. Epoch 1886
Loss of epoch 1886 = 2.504893719125859
process: 50 / 291. Epoch 1887
process: 100 / 291. Epoch 1887
process: 150 / 291. Epoch 1887
process: 200 / 291. Epoch 1887
process: 250 / 291. Epoch 1887
process: 291 / 291. Epoch 1887
Loss of epoch 1887 = 2.4327702997476375
process: 50 / 291. Epoch 1888
process: 100 / 291. Epoch 1888
process: 150 / 291. Epoch 1888
process: 200 / 291. Epoch 1888
process: 250 / 291. Epoch 1888
process: 291 / 291. Epoch 1888
Loss of epoch 1888 = 2.510353743825172
process: 50 / 291. Epoch 1889
process: 100 / 291. Epoch 1889
process: 150 / 291. Epoch 1889
process: 200 / 291. Epoch 1889
process: 250 / 291. Epoch 1889
process: 291 / 291. Epoch 1889
Loss of epoch 1889 = 2.515713301720898
process: 50 / 291. Epoch 1890
process: 100 / 291. Epoch 1890
process: 150 / 291. Epoch 1890
process: 200 / 291. Epoch 1890
process: 250 / 291. Epoch 1890
process: 291 / 291. Epoch 1890
Loss of epoch 1890 = 2.480161267047895
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1890. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.791794
      epoch  training_loss
1885   1886       2.504894
1886   1887       2.432770
1887   1888       2.510354
1888   1889       2.515713
1889   1890       2.480161
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
184       1850  0.015350  0.064865      0.386762   0.388264
185       1860  0.015324  0.064677      0.386406   0.387899
186       1870  0.015464  0.062979      0.386143   0.387601
187       1880  0.015315  0.063877      0.386747   0.388255
188       1890  0.015288  0.064195      0.387813   0.389318
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
184     1850.0  0.971441  0.980852  ...  0.957078  0.954634  0.942662
185     1860.0  0.972407  0.980837  ...  0.957729  0.954064  0.943069
186     1870.0  0.972173  0.980942  ...  0.957078  0.953901  0.938589
187     1880.0  0.972385  0.980942  ...  0.957159  0.953901  0.941114
188     1890.0  0.971872  0.980728  ...  0.957403  0.954064  0.942987

[5 rows x 13 columns]
process: 50 / 291. Epoch 1891
process: 100 / 291. Epoch 1891
process: 150 / 291. Epoch 1891
process: 200 / 291. Epoch 1891
process: 250 / 291. Epoch 1891
process: 291 / 291. Epoch 1891
Loss of epoch 1891 = 2.5190618456024483
process: 50 / 291. Epoch 1892
process: 100 / 291. Epoch 1892
process: 150 / 291. Epoch 1892
process: 200 / 291. Epoch 1892
process: 250 / 291. Epoch 1892
process: 291 / 291. Epoch 1892
Loss of epoch 1892 = 2.486412441607603
process: 50 / 291. Epoch 1893
process: 100 / 291. Epoch 1893
process: 150 / 291. Epoch 1893
process: 200 / 291. Epoch 1893
process: 250 / 291. Epoch 1893
process: 291 / 291. Epoch 1893
Loss of epoch 1893 = 2.4824898316688144
process: 50 / 291. Epoch 1894
process: 100 / 291. Epoch 1894
process: 150 / 291. Epoch 1894
process: 200 / 291. Epoch 1894
process: 250 / 291. Epoch 1894
process: 291 / 291. Epoch 1894
Loss of epoch 1894 = 2.4075617315023625
process: 50 / 291. Epoch 1895
process: 100 / 291. Epoch 1895
process: 150 / 291. Epoch 1895
process: 200 / 291. Epoch 1895
process: 250 / 291. Epoch 1895
process: 291 / 291. Epoch 1895
Loss of epoch 1895 = 2.4779459635416665
process: 50 / 291. Epoch 1896
process: 100 / 291. Epoch 1896
process: 150 / 291. Epoch 1896
process: 200 / 291. Epoch 1896
process: 250 / 291. Epoch 1896
process: 291 / 291. Epoch 1896
Loss of epoch 1896 = 2.4580132658129297
process: 50 / 291. Epoch 1897
process: 100 / 291. Epoch 1897
process: 150 / 291. Epoch 1897
process: 200 / 291. Epoch 1897
process: 250 / 291. Epoch 1897
process: 291 / 291. Epoch 1897
Loss of epoch 1897 = 2.522128285411297
process: 50 / 291. Epoch 1898
process: 100 / 291. Epoch 1898
process: 150 / 291. Epoch 1898
process: 200 / 291. Epoch 1898
process: 250 / 291. Epoch 1898
process: 291 / 291. Epoch 1898
Loss of epoch 1898 = 2.490927994456078
process: 50 / 291. Epoch 1899
process: 100 / 291. Epoch 1899
process: 150 / 291. Epoch 1899
process: 200 / 291. Epoch 1899
process: 250 / 291. Epoch 1899
process: 291 / 291. Epoch 1899
Loss of epoch 1899 = 2.50891406921177
process: 50 / 291. Epoch 1900
process: 100 / 291. Epoch 1900
process: 150 / 291. Epoch 1900
process: 200 / 291. Epoch 1900
process: 250 / 291. Epoch 1900
process: 291 / 291. Epoch 1900
Loss of epoch 1900 = 2.4528884101159796
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1900. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.783748
      epoch  training_loss
1895   1896       2.458013
1896   1897       2.522128
1897   1898       2.490928
1898   1899       2.508914
1899   1900       2.452888
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
185       1860  0.015324  0.064677      0.386406   0.387899
186       1870  0.015464  0.062979      0.386143   0.387601
187       1880  0.015315  0.063877      0.386747   0.388255
188       1890  0.015288  0.064195      0.387813   0.389318
189       1900  0.015375  0.063963      0.386547   0.388016
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
185     1860.0  0.972407  0.980837  ...  0.957729  0.954064  0.943069
186     1870.0  0.972173  0.980942  ...  0.957078  0.953901  0.938589
187     1880.0  0.972385  0.980942  ...  0.957159  0.953901  0.941114
188     1890.0  0.971872  0.980728  ...  0.957403  0.954064  0.942987
189     1900.0  0.972715  0.980939  ...  0.957566  0.953820  0.939648

[5 rows x 13 columns]
process: 50 / 291. Epoch 1901
process: 100 / 291. Epoch 1901
process: 150 / 291. Epoch 1901
process: 200 / 291. Epoch 1901
process: 250 / 291. Epoch 1901
process: 291 / 291. Epoch 1901
Loss of epoch 1901 = 2.4654226401417527
process: 50 / 291. Epoch 1902
process: 100 / 291. Epoch 1902
process: 150 / 291. Epoch 1902
process: 200 / 291. Epoch 1902
process: 250 / 291. Epoch 1902
process: 291 / 291. Epoch 1902
Loss of epoch 1902 = 2.4441280823802622
process: 50 / 291. Epoch 1903
process: 100 / 291. Epoch 1903
process: 150 / 291. Epoch 1903
process: 200 / 291. Epoch 1903
process: 250 / 291. Epoch 1903
process: 291 / 291. Epoch 1903
Loss of epoch 1903 = 2.496043411726804
process: 50 / 291. Epoch 1904
process: 100 / 291. Epoch 1904
process: 150 / 291. Epoch 1904
process: 200 / 291. Epoch 1904
process: 250 / 291. Epoch 1904
process: 291 / 291. Epoch 1904
Loss of epoch 1904 = 2.486837380530498
process: 50 / 291. Epoch 1905
process: 100 / 291. Epoch 1905
process: 150 / 291. Epoch 1905
process: 200 / 291. Epoch 1905
process: 250 / 291. Epoch 1905
process: 291 / 291. Epoch 1905
Loss of epoch 1905 = 2.483420670237328
process: 50 / 291. Epoch 1906
process: 100 / 291. Epoch 1906
process: 150 / 291. Epoch 1906
process: 200 / 291. Epoch 1906
process: 250 / 291. Epoch 1906
process: 291 / 291. Epoch 1906
Loss of epoch 1906 = 2.490867588528243
process: 50 / 291. Epoch 1907
process: 100 / 291. Epoch 1907
process: 150 / 291. Epoch 1907
process: 200 / 291. Epoch 1907
process: 250 / 291. Epoch 1907
process: 291 / 291. Epoch 1907
Loss of epoch 1907 = 2.4809731814459837
process: 50 / 291. Epoch 1908
process: 100 / 291. Epoch 1908
process: 150 / 291. Epoch 1908
process: 200 / 291. Epoch 1908
process: 250 / 291. Epoch 1908
process: 291 / 291. Epoch 1908
Loss of epoch 1908 = 2.4780437036887886
process: 50 / 291. Epoch 1909
process: 100 / 291. Epoch 1909
process: 150 / 291. Epoch 1909
process: 200 / 291. Epoch 1909
process: 250 / 291. Epoch 1909
process: 291 / 291. Epoch 1909
Loss of epoch 1909 = 2.4692651283290377
process: 50 / 291. Epoch 1910
process: 100 / 291. Epoch 1910
process: 150 / 291. Epoch 1910
process: 200 / 291. Epoch 1910
process: 250 / 291. Epoch 1910
process: 291 / 291. Epoch 1910
Loss of epoch 1910 = 2.44958412196628
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1910. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.789304
      epoch  training_loss
1905   1906       2.490868
1906   1907       2.480973
1907   1908       2.478044
1908   1909       2.469265
1909   1910       2.449584
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
186       1870  0.015464  0.062979      0.386143   0.387601
187       1880  0.015315  0.063877      0.386747   0.388255
188       1890  0.015288  0.064195      0.387813   0.389318
189       1900  0.015375  0.063963      0.386547   0.388016
190       1910  0.015324  0.064235      0.387568   0.389060
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
186     1870.0  0.972173  0.980942  ...  0.957078  0.953901  0.938589
187     1880.0  0.972385  0.980942  ...  0.957159  0.953901  0.941114
188     1890.0  0.971872  0.980728  ...  0.957403  0.954064  0.942987
189     1900.0  0.972715  0.980939  ...  0.957566  0.953820  0.939648
190     1910.0  0.972401  0.980710  ...  0.957566  0.953413  0.942662

[5 rows x 13 columns]
process: 50 / 291. Epoch 1911
process: 100 / 291. Epoch 1911
process: 150 / 291. Epoch 1911
process: 200 / 291. Epoch 1911
process: 250 / 291. Epoch 1911
process: 291 / 291. Epoch 1911
Loss of epoch 1911 = 2.4058403723018684
process: 50 / 291. Epoch 1912
process: 100 / 291. Epoch 1912
process: 150 / 291. Epoch 1912
process: 200 / 291. Epoch 1912
process: 250 / 291. Epoch 1912
process: 291 / 291. Epoch 1912
Loss of epoch 1912 = 2.4818530525128866
process: 50 / 291. Epoch 1913
process: 100 / 291. Epoch 1913
process: 150 / 291. Epoch 1913
process: 200 / 291. Epoch 1913
process: 250 / 291. Epoch 1913
process: 291 / 291. Epoch 1913
Loss of epoch 1913 = 2.4949703675365122
process: 50 / 291. Epoch 1914
process: 100 / 291. Epoch 1914
process: 150 / 291. Epoch 1914
process: 200 / 291. Epoch 1914
process: 250 / 291. Epoch 1914
process: 291 / 291. Epoch 1914
Loss of epoch 1914 = 2.434559405874141
process: 50 / 291. Epoch 1915
process: 100 / 291. Epoch 1915
process: 150 / 291. Epoch 1915
process: 200 / 291. Epoch 1915
process: 250 / 291. Epoch 1915
process: 291 / 291. Epoch 1915
Loss of epoch 1915 = 2.4945385071010526
process: 50 / 291. Epoch 1916
process: 100 / 291. Epoch 1916
process: 150 / 291. Epoch 1916
process: 200 / 291. Epoch 1916
process: 250 / 291. Epoch 1916
process: 291 / 291. Epoch 1916
Loss of epoch 1916 = 2.5576585068325817
process: 50 / 291. Epoch 1917
process: 100 / 291. Epoch 1917
process: 150 / 291. Epoch 1917
process: 200 / 291. Epoch 1917
process: 250 / 291. Epoch 1917
process: 291 / 291. Epoch 1917
Loss of epoch 1917 = 2.5498244033236683
process: 50 / 291. Epoch 1918
process: 100 / 291. Epoch 1918
process: 150 / 291. Epoch 1918
process: 200 / 291. Epoch 1918
process: 250 / 291. Epoch 1918
process: 291 / 291. Epoch 1918
Loss of epoch 1918 = 2.4827012524162373
process: 50 / 291. Epoch 1919
process: 100 / 291. Epoch 1919
process: 150 / 291. Epoch 1919
process: 200 / 291. Epoch 1919
process: 250 / 291. Epoch 1919
process: 291 / 291. Epoch 1919
Loss of epoch 1919 = 2.4671345609160222
process: 50 / 291. Epoch 1920
process: 100 / 291. Epoch 1920
process: 150 / 291. Epoch 1920
process: 200 / 291. Epoch 1920
process: 250 / 291. Epoch 1920
process: 291 / 291. Epoch 1920
Loss of epoch 1920 = 2.4144721276981316
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1920. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.788458
      epoch  training_loss
1915   1916       2.557659
1916   1917       2.549824
1917   1918       2.482701
1918   1919       2.467135
1919   1920       2.414472
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
187       1880  0.015315  0.063877      0.386747   0.388255
188       1890  0.015288  0.064195      0.387813   0.389318
189       1900  0.015375  0.063963      0.386547   0.388016
190       1910  0.015324  0.064235      0.387568   0.389060
191       1920  0.015284  0.064266      0.387822   0.389316
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
187     1880.0  0.972385  0.980942  ...  0.957159  0.953901  0.941114
188     1890.0  0.971872  0.980728  ...  0.957403  0.954064  0.942987
189     1900.0  0.972715  0.980939  ...  0.957566  0.953820  0.939648
190     1910.0  0.972401  0.980710  ...  0.957566  0.953413  0.942662
191     1920.0  0.972410  0.980837  ...  0.957811  0.954064  0.941766

[5 rows x 13 columns]
process: 50 / 291. Epoch 1921
process: 100 / 291. Epoch 1921
process: 150 / 291. Epoch 1921
process: 200 / 291. Epoch 1921
process: 250 / 291. Epoch 1921
process: 291 / 291. Epoch 1921
Loss of epoch 1921 = 2.486536609348153
process: 50 / 291. Epoch 1922
process: 100 / 291. Epoch 1922
process: 150 / 291. Epoch 1922
process: 200 / 291. Epoch 1922
process: 250 / 291. Epoch 1922
process: 291 / 291. Epoch 1922
Loss of epoch 1922 = 2.4791683446091066
process: 50 / 291. Epoch 1923
process: 100 / 291. Epoch 1923
process: 150 / 291. Epoch 1923
process: 200 / 291. Epoch 1923
process: 250 / 291. Epoch 1923
process: 291 / 291. Epoch 1923
Loss of epoch 1923 = 2.488316906276847
process: 50 / 291. Epoch 1924
process: 100 / 291. Epoch 1924
process: 150 / 291. Epoch 1924
process: 200 / 291. Epoch 1924
process: 250 / 291. Epoch 1924
process: 291 / 291. Epoch 1924
Loss of epoch 1924 = 2.5133627141054555
process: 50 / 291. Epoch 1925
process: 100 / 291. Epoch 1925
process: 150 / 291. Epoch 1925
process: 200 / 291. Epoch 1925
process: 250 / 291. Epoch 1925
process: 291 / 291. Epoch 1925
Loss of epoch 1925 = 2.4643223293868126
process: 50 / 291. Epoch 1926
process: 100 / 291. Epoch 1926
process: 150 / 291. Epoch 1926
process: 200 / 291. Epoch 1926
process: 250 / 291. Epoch 1926
process: 291 / 291. Epoch 1926
Loss of epoch 1926 = 2.398351924935567
process: 50 / 291. Epoch 1927
process: 100 / 291. Epoch 1927
process: 150 / 291. Epoch 1927
process: 200 / 291. Epoch 1927
process: 250 / 291. Epoch 1927
process: 291 / 291. Epoch 1927
Loss of epoch 1927 = 2.4169489804821733
process: 50 / 291. Epoch 1928
process: 100 / 291. Epoch 1928
process: 150 / 291. Epoch 1928
process: 200 / 291. Epoch 1928
process: 250 / 291. Epoch 1928
process: 291 / 291. Epoch 1928
Loss of epoch 1928 = 2.5294348857656788
process: 50 / 291. Epoch 1929
process: 100 / 291. Epoch 1929
process: 150 / 291. Epoch 1929
process: 200 / 291. Epoch 1929
process: 250 / 291. Epoch 1929
process: 291 / 291. Epoch 1929
Loss of epoch 1929 = 2.495341192815722
process: 50 / 291. Epoch 1930
process: 100 / 291. Epoch 1930
process: 150 / 291. Epoch 1930
process: 200 / 291. Epoch 1930
process: 250 / 291. Epoch 1930
process: 291 / 291. Epoch 1930
Loss of epoch 1930 = 2.446450983945447
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1930. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.786611
      epoch  training_loss
1925   1926       2.398352
1926   1927       2.416949
1927   1928       2.529435
1928   1929       2.495341
1929   1930       2.446451
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
188       1890  0.015288  0.064195      0.387813   0.389318
189       1900  0.015375  0.063963      0.386547   0.388016
190       1910  0.015324  0.064235      0.387568   0.389060
191       1920  0.015284  0.064266      0.387822   0.389316
192       1930  0.015372  0.063252      0.388522   0.390068
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
188     1890.0  0.971872  0.980728  ...  0.957403  0.954064  0.942987
189     1900.0  0.972715  0.980939  ...  0.957566  0.953820  0.939648
190     1910.0  0.972401  0.980710  ...  0.957566  0.953413  0.942662
191     1920.0  0.972410  0.980837  ...  0.957811  0.954064  0.941766
192     1930.0  0.973051  0.980721  ...  0.958137  0.953820  0.940544

[5 rows x 13 columns]
process: 50 / 291. Epoch 1931
process: 100 / 291. Epoch 1931
process: 150 / 291. Epoch 1931
process: 200 / 291. Epoch 1931
process: 250 / 291. Epoch 1931
process: 291 / 291. Epoch 1931
Loss of epoch 1931 = 2.4219815493449315
process: 50 / 291. Epoch 1932
process: 100 / 291. Epoch 1932
process: 150 / 291. Epoch 1932
process: 200 / 291. Epoch 1932
process: 250 / 291. Epoch 1932
process: 291 / 291. Epoch 1932
Loss of epoch 1932 = 2.4761260252228308
process: 50 / 291. Epoch 1933
process: 100 / 291. Epoch 1933
process: 150 / 291. Epoch 1933
process: 200 / 291. Epoch 1933
process: 250 / 291. Epoch 1933
process: 291 / 291. Epoch 1933
Loss of epoch 1933 = 2.474622798539519
process: 50 / 291. Epoch 1934
process: 100 / 291. Epoch 1934
process: 150 / 291. Epoch 1934
process: 200 / 291. Epoch 1934
process: 250 / 291. Epoch 1934
process: 291 / 291. Epoch 1934
Loss of epoch 1934 = 2.479355225448346
process: 50 / 291. Epoch 1935
process: 100 / 291. Epoch 1935
process: 150 / 291. Epoch 1935
process: 200 / 291. Epoch 1935
process: 250 / 291. Epoch 1935
process: 291 / 291. Epoch 1935
Loss of epoch 1935 = 2.486499484871671
process: 50 / 291. Epoch 1936
process: 100 / 291. Epoch 1936
process: 150 / 291. Epoch 1936
process: 200 / 291. Epoch 1936
process: 250 / 291. Epoch 1936
process: 291 / 291. Epoch 1936
Loss of epoch 1936 = 2.5160992284820662
process: 50 / 291. Epoch 1937
process: 100 / 291. Epoch 1937
process: 150 / 291. Epoch 1937
process: 200 / 291. Epoch 1937
process: 250 / 291. Epoch 1937
process: 291 / 291. Epoch 1937
Loss of epoch 1937 = 2.4524466917686856
process: 50 / 291. Epoch 1938
process: 100 / 291. Epoch 1938
process: 150 / 291. Epoch 1938
process: 200 / 291. Epoch 1938
process: 250 / 291. Epoch 1938
process: 291 / 291. Epoch 1938
Loss of epoch 1938 = 2.460826755798969
process: 50 / 291. Epoch 1939
process: 100 / 291. Epoch 1939
process: 150 / 291. Epoch 1939
process: 200 / 291. Epoch 1939
process: 250 / 291. Epoch 1939
process: 291 / 291. Epoch 1939
Loss of epoch 1939 = 2.4258215206185567
process: 50 / 291. Epoch 1940
process: 100 / 291. Epoch 1940
process: 150 / 291. Epoch 1940
process: 200 / 291. Epoch 1940
process: 250 / 291. Epoch 1940
process: 291 / 291. Epoch 1940
Loss of epoch 1940 = 2.462733108153458
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1940. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.793010
      epoch  training_loss
1935   1936       2.516099
1936   1937       2.452447
1937   1938       2.460827
1938   1939       2.425822
1939   1940       2.462733
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
189       1900  0.015375  0.063963      0.386547   0.388016
190       1910  0.015324  0.064235      0.387568   0.389060
191       1920  0.015284  0.064266      0.387822   0.389316
192       1930  0.015372  0.063252      0.388522   0.390068
193       1940  0.015267  0.064352      0.387450   0.388930
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
189     1900.0  0.972715  0.980939  ...  0.957566  0.953820  0.939648
190     1910.0  0.972401  0.980710  ...  0.957566  0.953413  0.942662
191     1920.0  0.972410  0.980837  ...  0.957811  0.954064  0.941766
192     1930.0  0.973051  0.980721  ...  0.958137  0.953820  0.940544
193     1940.0  0.971334  0.980523  ...  0.956996  0.954553  0.942987

[5 rows x 13 columns]
process: 50 / 291. Epoch 1941
process: 100 / 291. Epoch 1941
process: 150 / 291. Epoch 1941
process: 200 / 291. Epoch 1941
process: 250 / 291. Epoch 1941
process: 291 / 291. Epoch 1941
Loss of epoch 1941 = 2.4413638819533934
process: 50 / 291. Epoch 1942
process: 100 / 291. Epoch 1942
process: 150 / 291. Epoch 1942
process: 200 / 291. Epoch 1942
process: 250 / 291. Epoch 1942
process: 291 / 291. Epoch 1942
Loss of epoch 1942 = 2.489493563412801
process: 50 / 291. Epoch 1943
process: 100 / 291. Epoch 1943
process: 150 / 291. Epoch 1943
process: 200 / 291. Epoch 1943
process: 250 / 291. Epoch 1943
process: 291 / 291. Epoch 1943
Loss of epoch 1943 = 2.4746571963595363
process: 50 / 291. Epoch 1944
process: 100 / 291. Epoch 1944
process: 150 / 291. Epoch 1944
process: 200 / 291. Epoch 1944
process: 250 / 291. Epoch 1944
process: 291 / 291. Epoch 1944
Loss of epoch 1944 = 2.4108081306378866
process: 50 / 291. Epoch 1945
process: 100 / 291. Epoch 1945
process: 150 / 291. Epoch 1945
process: 200 / 291. Epoch 1945
process: 250 / 291. Epoch 1945
process: 291 / 291. Epoch 1945
Loss of epoch 1945 = 2.5156073816043816
process: 50 / 291. Epoch 1946
process: 100 / 291. Epoch 1946
process: 150 / 291. Epoch 1946
process: 200 / 291. Epoch 1946
process: 250 / 291. Epoch 1946
process: 291 / 291. Epoch 1946
Loss of epoch 1946 = 2.5063449295935354
process: 50 / 291. Epoch 1947
process: 100 / 291. Epoch 1947
process: 150 / 291. Epoch 1947
process: 200 / 291. Epoch 1947
process: 250 / 291. Epoch 1947
process: 291 / 291. Epoch 1947
Loss of epoch 1947 = 2.4475500362435567
process: 50 / 291. Epoch 1948
process: 100 / 291. Epoch 1948
process: 150 / 291. Epoch 1948
process: 200 / 291. Epoch 1948
process: 250 / 291. Epoch 1948
process: 291 / 291. Epoch 1948
Loss of epoch 1948 = 2.479383121241409
process: 50 / 291. Epoch 1949
process: 100 / 291. Epoch 1949
process: 150 / 291. Epoch 1949
process: 200 / 291. Epoch 1949
process: 250 / 291. Epoch 1949
process: 291 / 291. Epoch 1949
Loss of epoch 1949 = 2.4733958031303693
process: 50 / 291. Epoch 1950
process: 100 / 291. Epoch 1950
process: 150 / 291. Epoch 1950
process: 200 / 291. Epoch 1950
process: 250 / 291. Epoch 1950
process: 291 / 291. Epoch 1950
Loss of epoch 1950 = 2.447611700628222
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1950. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.791678
      epoch  training_loss
1945   1946       2.506345
1946   1947       2.447550
1947   1948       2.479383
1948   1949       2.473396
1949   1950       2.447612
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
190       1910  0.015324  0.064235      0.387568   0.389060
191       1920  0.015284  0.064266      0.387822   0.389316
192       1930  0.015372  0.063252      0.388522   0.390068
193       1940  0.015267  0.064352      0.387450   0.388930
194       1950  0.015284  0.064423      0.389159   0.390706
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
190     1910.0  0.972401  0.980710  ...  0.957566  0.953413  0.942662
191     1920.0  0.972410  0.980837  ...  0.957811  0.954064  0.941766
192     1930.0  0.973051  0.980721  ...  0.958137  0.953820  0.940544
193     1940.0  0.971334  0.980523  ...  0.956996  0.954553  0.942987
194     1950.0  0.971992  0.980739  ...  0.957811  0.954471  0.943313

[5 rows x 13 columns]
process: 50 / 291. Epoch 1951
process: 100 / 291. Epoch 1951
process: 150 / 291. Epoch 1951
process: 200 / 291. Epoch 1951
process: 250 / 291. Epoch 1951
process: 291 / 291. Epoch 1951
Loss of epoch 1951 = 2.538721877684708
process: 50 / 291. Epoch 1952
process: 100 / 291. Epoch 1952
process: 150 / 291. Epoch 1952
process: 200 / 291. Epoch 1952
process: 250 / 291. Epoch 1952
process: 291 / 291. Epoch 1952
Loss of epoch 1952 = 2.451879756966817
process: 50 / 291. Epoch 1953
process: 100 / 291. Epoch 1953
process: 150 / 291. Epoch 1953
process: 200 / 291. Epoch 1953
process: 250 / 291. Epoch 1953
process: 291 / 291. Epoch 1953
Loss of epoch 1953 = 2.411535518685567
process: 50 / 291. Epoch 1954
process: 100 / 291. Epoch 1954
process: 150 / 291. Epoch 1954
process: 200 / 291. Epoch 1954
process: 250 / 291. Epoch 1954
process: 291 / 291. Epoch 1954
Loss of epoch 1954 = 2.4852007574232173
process: 50 / 291. Epoch 1955
process: 100 / 291. Epoch 1955
process: 150 / 291. Epoch 1955
process: 200 / 291. Epoch 1955
process: 250 / 291. Epoch 1955
process: 291 / 291. Epoch 1955
Loss of epoch 1955 = 2.45361621764927
process: 50 / 291. Epoch 1956
process: 100 / 291. Epoch 1956
process: 150 / 291. Epoch 1956
process: 200 / 291. Epoch 1956
process: 250 / 291. Epoch 1956
process: 291 / 291. Epoch 1956
Loss of epoch 1956 = 2.467734425338273
process: 50 / 291. Epoch 1957
process: 100 / 291. Epoch 1957
process: 150 / 291. Epoch 1957
process: 200 / 291. Epoch 1957
process: 250 / 291. Epoch 1957
process: 291 / 291. Epoch 1957
Loss of epoch 1957 = 2.4595729133107818
process: 50 / 291. Epoch 1958
process: 100 / 291. Epoch 1958
process: 150 / 291. Epoch 1958
process: 200 / 291. Epoch 1958
process: 250 / 291. Epoch 1958
process: 291 / 291. Epoch 1958
Loss of epoch 1958 = 2.4136392390195445
process: 50 / 291. Epoch 1959
process: 100 / 291. Epoch 1959
process: 150 / 291. Epoch 1959
process: 200 / 291. Epoch 1959
process: 250 / 291. Epoch 1959
process: 291 / 291. Epoch 1959
Loss of epoch 1959 = 2.4767403618986252
process: 50 / 291. Epoch 1960
process: 100 / 291. Epoch 1960
process: 150 / 291. Epoch 1960
process: 200 / 291. Epoch 1960
process: 250 / 291. Epoch 1960
process: 291 / 291. Epoch 1960
Loss of epoch 1960 = 2.4952734458897123
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1960. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.786382
      epoch  training_loss
1955   1956       2.467734
1956   1957       2.459573
1957   1958       2.413639
1958   1959       2.476740
1959   1960       2.495273
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
191       1920  0.015284  0.064266      0.387822   0.389316
192       1930  0.015372  0.063252      0.388522   0.390068
193       1940  0.015267  0.064352      0.387450   0.388930
194       1950  0.015284  0.064423      0.389159   0.390706
195       1960  0.015375  0.063439      0.389217   0.390783
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
191     1920.0  0.972410  0.980837  ...  0.957811  0.954064  0.941766
192     1930.0  0.973051  0.980721  ...  0.958137  0.953820  0.940544
193     1940.0  0.971334  0.980523  ...  0.956996  0.954553  0.942987
194     1950.0  0.971992  0.980739  ...  0.957811  0.954471  0.943313
195     1960.0  0.972524  0.980715  ...  0.958055  0.953576  0.940626

[5 rows x 13 columns]
process: 50 / 291. Epoch 1961
process: 100 / 291. Epoch 1961
process: 150 / 291. Epoch 1961
process: 200 / 291. Epoch 1961
process: 250 / 291. Epoch 1961
process: 291 / 291. Epoch 1961
Loss of epoch 1961 = 2.453346698144867
process: 50 / 291. Epoch 1962
process: 100 / 291. Epoch 1962
process: 150 / 291. Epoch 1962
process: 200 / 291. Epoch 1962
process: 250 / 291. Epoch 1962
process: 291 / 291. Epoch 1962
Loss of epoch 1962 = 2.4017665378006874
process: 50 / 291. Epoch 1963
process: 100 / 291. Epoch 1963
process: 150 / 291. Epoch 1963
process: 200 / 291. Epoch 1963
process: 250 / 291. Epoch 1963
process: 291 / 291. Epoch 1963
Loss of epoch 1963 = 2.4661701634987114
process: 50 / 291. Epoch 1964
process: 100 / 291. Epoch 1964
process: 150 / 291. Epoch 1964
process: 200 / 291. Epoch 1964
process: 250 / 291. Epoch 1964
process: 291 / 291. Epoch 1964
Loss of epoch 1964 = 2.43975872026686
process: 50 / 291. Epoch 1965
process: 100 / 291. Epoch 1965
process: 150 / 291. Epoch 1965
process: 200 / 291. Epoch 1965
process: 250 / 291. Epoch 1965
process: 291 / 291. Epoch 1965
Loss of epoch 1965 = 2.4701099723475086
process: 50 / 291. Epoch 1966
process: 100 / 291. Epoch 1966
process: 150 / 291. Epoch 1966
process: 200 / 291. Epoch 1966
process: 250 / 291. Epoch 1966
process: 291 / 291. Epoch 1966
Loss of epoch 1966 = 2.5433416727072595
process: 50 / 291. Epoch 1967
process: 100 / 291. Epoch 1967
process: 150 / 291. Epoch 1967
process: 200 / 291. Epoch 1967
process: 250 / 291. Epoch 1967
process: 291 / 291. Epoch 1967
Loss of epoch 1967 = 2.467501820567547
process: 50 / 291. Epoch 1968
process: 100 / 291. Epoch 1968
process: 150 / 291. Epoch 1968
process: 200 / 291. Epoch 1968
process: 250 / 291. Epoch 1968
process: 291 / 291. Epoch 1968
Loss of epoch 1968 = 2.451527598797251
process: 50 / 291. Epoch 1969
process: 100 / 291. Epoch 1969
process: 150 / 291. Epoch 1969
process: 200 / 291. Epoch 1969
process: 250 / 291. Epoch 1969
process: 291 / 291. Epoch 1969
Loss of epoch 1969 = 2.4396557365496134
process: 50 / 291. Epoch 1970
process: 100 / 291. Epoch 1970
process: 150 / 291. Epoch 1970
process: 200 / 291. Epoch 1970
process: 250 / 291. Epoch 1970
process: 291 / 291. Epoch 1970
Loss of epoch 1970 = 2.464645752792096
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1970. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.790980
      epoch  training_loss
1965   1966       2.543342
1966   1967       2.467502
1967   1968       2.451528
1968   1969       2.439656
1969   1970       2.464646
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
192       1930  0.015372  0.063252      0.388522   0.390068
193       1940  0.015267  0.064352      0.387450   0.388930
194       1950  0.015284  0.064423      0.389159   0.390706
195       1960  0.015375  0.063439      0.389217   0.390783
196       1970  0.015278  0.063699      0.389327   0.390859
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
192     1930.0  0.973051  0.980721  ...  0.958137  0.953820  0.940544
193     1940.0  0.971334  0.980523  ...  0.956996  0.954553  0.942987
194     1950.0  0.971992  0.980739  ...  0.957811  0.954471  0.943313
195     1960.0  0.972524  0.980715  ...  0.958055  0.953576  0.940626
196     1970.0  0.971546  0.980830  ...  0.957078  0.953820  0.942987

[5 rows x 13 columns]
process: 50 / 291. Epoch 1971
process: 100 / 291. Epoch 1971
process: 150 / 291. Epoch 1971
process: 200 / 291. Epoch 1971
process: 250 / 291. Epoch 1971
process: 291 / 291. Epoch 1971
Loss of epoch 1971 = 2.453054526417526
process: 50 / 291. Epoch 1972
process: 100 / 291. Epoch 1972
process: 150 / 291. Epoch 1972
process: 200 / 291. Epoch 1972
process: 250 / 291. Epoch 1972
process: 291 / 291. Epoch 1972
Loss of epoch 1972 = 2.420800697352878
process: 50 / 291. Epoch 1973
process: 100 / 291. Epoch 1973
process: 150 / 291. Epoch 1973
process: 200 / 291. Epoch 1973
process: 250 / 291. Epoch 1973
process: 291 / 291. Epoch 1973
Loss of epoch 1973 = 2.454429180761383
process: 50 / 291. Epoch 1974
process: 100 / 291. Epoch 1974
process: 150 / 291. Epoch 1974
process: 200 / 291. Epoch 1974
process: 250 / 291. Epoch 1974
process: 291 / 291. Epoch 1974
Loss of epoch 1974 = 2.487902035008591
process: 50 / 291. Epoch 1975
process: 100 / 291. Epoch 1975
process: 150 / 291. Epoch 1975
process: 200 / 291. Epoch 1975
process: 250 / 291. Epoch 1975
process: 291 / 291. Epoch 1975
Loss of epoch 1975 = 2.4475642987542954
process: 50 / 291. Epoch 1976
process: 100 / 291. Epoch 1976
process: 150 / 291. Epoch 1976
process: 200 / 291. Epoch 1976
process: 250 / 291. Epoch 1976
process: 291 / 291. Epoch 1976
Loss of epoch 1976 = 2.511572349522122
process: 50 / 291. Epoch 1977
process: 100 / 291. Epoch 1977
process: 150 / 291. Epoch 1977
process: 200 / 291. Epoch 1977
process: 250 / 291. Epoch 1977
process: 291 / 291. Epoch 1977
Loss of epoch 1977 = 2.4424243415753866
process: 50 / 291. Epoch 1978
process: 100 / 291. Epoch 1978
process: 150 / 291. Epoch 1978
process: 200 / 291. Epoch 1978
process: 250 / 291. Epoch 1978
process: 291 / 291. Epoch 1978
Loss of epoch 1978 = 2.413913163122852
process: 50 / 291. Epoch 1979
process: 100 / 291. Epoch 1979
process: 150 / 291. Epoch 1979
process: 200 / 291. Epoch 1979
process: 250 / 291. Epoch 1979
process: 291 / 291. Epoch 1979
Loss of epoch 1979 = 2.460851295707152
process: 50 / 291. Epoch 1980
process: 100 / 291. Epoch 1980
process: 150 / 291. Epoch 1980
process: 200 / 291. Epoch 1980
process: 250 / 291. Epoch 1980
process: 291 / 291. Epoch 1980
Loss of epoch 1980 = 2.438148105267397
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1980. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.789277
      epoch  training_loss
1975   1976       2.511572
1976   1977       2.442424
1977   1978       2.413913
1978   1979       2.460851
1979   1980       2.438148
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
193       1940  0.015267  0.064352      0.387450   0.388930
194       1950  0.015284  0.064423      0.389159   0.390706
195       1960  0.015375  0.063439      0.389217   0.390783
196       1970  0.015278  0.063699      0.389327   0.390859
197       1980  0.015262  0.063619      0.389328   0.390843
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
193     1940.0  0.971334  0.980523  ...  0.956996  0.954553  0.942987
194     1950.0  0.971992  0.980739  ...  0.957811  0.954471  0.943313
195     1960.0  0.972524  0.980715  ...  0.958055  0.953576  0.940626
196     1970.0  0.971546  0.980830  ...  0.957078  0.953820  0.942987
197     1980.0  0.971985  0.980822  ...  0.957648  0.953494  0.942499

[5 rows x 13 columns]
process: 50 / 291. Epoch 1981
process: 100 / 291. Epoch 1981
process: 150 / 291. Epoch 1981
process: 200 / 291. Epoch 1981
process: 250 / 291. Epoch 1981
process: 291 / 291. Epoch 1981
Loss of epoch 1981 = 2.4371606361415377
process: 50 / 291. Epoch 1982
process: 100 / 291. Epoch 1982
process: 150 / 291. Epoch 1982
process: 200 / 291. Epoch 1982
process: 250 / 291. Epoch 1982
process: 291 / 291. Epoch 1982
Loss of epoch 1982 = 2.4300469991677405
process: 50 / 291. Epoch 1983
process: 100 / 291. Epoch 1983
process: 150 / 291. Epoch 1983
process: 200 / 291. Epoch 1983
process: 250 / 291. Epoch 1983
process: 291 / 291. Epoch 1983
Loss of epoch 1983 = 2.4696011363026202
process: 50 / 291. Epoch 1984
process: 100 / 291. Epoch 1984
process: 150 / 291. Epoch 1984
process: 200 / 291. Epoch 1984
process: 250 / 291. Epoch 1984
process: 291 / 291. Epoch 1984
Loss of epoch 1984 = 2.431571200131551
process: 50 / 291. Epoch 1985
process: 100 / 291. Epoch 1985
process: 150 / 291. Epoch 1985
process: 200 / 291. Epoch 1985
process: 250 / 291. Epoch 1985
process: 291 / 291. Epoch 1985
Loss of epoch 1985 = 2.484849857710481
process: 50 / 291. Epoch 1986
process: 100 / 291. Epoch 1986
process: 150 / 291. Epoch 1986
process: 200 / 291. Epoch 1986
process: 250 / 291. Epoch 1986
process: 291 / 291. Epoch 1986
Loss of epoch 1986 = 2.4902129812338916
process: 50 / 291. Epoch 1987
process: 100 / 291. Epoch 1987
process: 150 / 291. Epoch 1987
process: 200 / 291. Epoch 1987
process: 250 / 291. Epoch 1987
process: 291 / 291. Epoch 1987
Loss of epoch 1987 = 2.4596339484670318
process: 50 / 291. Epoch 1988
process: 100 / 291. Epoch 1988
process: 150 / 291. Epoch 1988
process: 200 / 291. Epoch 1988
process: 250 / 291. Epoch 1988
process: 291 / 291. Epoch 1988
Loss of epoch 1988 = 2.402577403484751
process: 50 / 291. Epoch 1989
process: 100 / 291. Epoch 1989
process: 150 / 291. Epoch 1989
process: 200 / 291. Epoch 1989
process: 250 / 291. Epoch 1989
process: 291 / 291. Epoch 1989
Loss of epoch 1989 = 2.4352209346810567
process: 50 / 291. Epoch 1990
process: 100 / 291. Epoch 1990
process: 150 / 291. Epoch 1990
process: 200 / 291. Epoch 1990
process: 250 / 291. Epoch 1990
process: 291 / 291. Epoch 1990
Loss of epoch 1990 = 2.465259460239476
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-1990. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.793606
      epoch  training_loss
1985   1986       2.490213
1986   1987       2.459634
1987   1988       2.402577
1988   1989       2.435221
1989   1990       2.465259
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
194       1950  0.015284  0.064423      0.389159   0.390706
195       1960  0.015375  0.063439      0.389217   0.390783
196       1970  0.015278  0.063699      0.389327   0.390859
197       1980  0.015262  0.063619      0.389328   0.390843
198       1990  0.015210  0.064535      0.389271   0.390782
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
194     1950.0  0.971992  0.980739  ...  0.957811  0.954471  0.943313
195     1960.0  0.972524  0.980715  ...  0.958055  0.953576  0.940626
196     1970.0  0.971546  0.980830  ...  0.957078  0.953820  0.942987
197     1980.0  0.971985  0.980822  ...  0.957648  0.953494  0.942499
198     1990.0  0.972105  0.980399  ...  0.958055  0.953983  0.944128

[5 rows x 13 columns]
process: 50 / 291. Epoch 1991
process: 100 / 291. Epoch 1991
process: 150 / 291. Epoch 1991
process: 200 / 291. Epoch 1991
process: 250 / 291. Epoch 1991
process: 291 / 291. Epoch 1991
Loss of epoch 1991 = 2.466236232482281
process: 50 / 291. Epoch 1992
process: 100 / 291. Epoch 1992
process: 150 / 291. Epoch 1992
process: 200 / 291. Epoch 1992
process: 250 / 291. Epoch 1992
process: 291 / 291. Epoch 1992
Loss of epoch 1992 = 2.4486467813708117
process: 50 / 291. Epoch 1993
process: 100 / 291. Epoch 1993
process: 150 / 291. Epoch 1993
process: 200 / 291. Epoch 1993
process: 250 / 291. Epoch 1993
process: 291 / 291. Epoch 1993
Loss of epoch 1993 = 2.4025247580407
process: 50 / 291. Epoch 1994
process: 100 / 291. Epoch 1994
process: 150 / 291. Epoch 1994
process: 200 / 291. Epoch 1994
process: 250 / 291. Epoch 1994
process: 291 / 291. Epoch 1994
Loss of epoch 1994 = 2.4640433714561856
process: 50 / 291. Epoch 1995
process: 100 / 291. Epoch 1995
process: 150 / 291. Epoch 1995
process: 200 / 291. Epoch 1995
process: 250 / 291. Epoch 1995
process: 291 / 291. Epoch 1995
Loss of epoch 1995 = 2.4604425069802405
process: 50 / 291. Epoch 1996
process: 100 / 291. Epoch 1996
process: 150 / 291. Epoch 1996
process: 200 / 291. Epoch 1996
process: 250 / 291. Epoch 1996
process: 291 / 291. Epoch 1996
Loss of epoch 1996 = 2.468175304714347
process: 50 / 291. Epoch 1997
process: 100 / 291. Epoch 1997
process: 150 / 291. Epoch 1997
process: 200 / 291. Epoch 1997
process: 250 / 291. Epoch 1997
process: 291 / 291. Epoch 1997
Loss of epoch 1997 = 2.4942293462065077
process: 50 / 291. Epoch 1998
process: 100 / 291. Epoch 1998
process: 150 / 291. Epoch 1998
process: 200 / 291. Epoch 1998
process: 250 / 291. Epoch 1998
process: 291 / 291. Epoch 1998
Loss of epoch 1998 = 2.4554153914304124
process: 50 / 291. Epoch 1999
process: 100 / 291. Epoch 1999
process: 150 / 291. Epoch 1999
process: 200 / 291. Epoch 1999
process: 250 / 291. Epoch 1999
process: 291 / 291. Epoch 1999
Loss of epoch 1999 = 2.4654096360878435
process: 50 / 291. Epoch 2000
process: 100 / 291. Epoch 2000
process: 150 / 291. Epoch 2000
process: 200 / 291. Epoch 2000
process: 250 / 291. Epoch 2000
process: 291 / 291. Epoch 2000
Loss of epoch 2000 = 2.4416193486898625
VALIDATE AND SAVE MODELS:
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin-2000. Data saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/data.bin
The mean of prediced scores: 0.783100
      epoch  training_loss
1995   1996       2.468175
1996   1997       2.494229
1997   1998       2.455415
1998   1999       2.465410
1999   2000       2.441619
     val_epoch       mse   mse_neg  ndcg(linear)  ndcg(exp)
195       1960  0.015375  0.063439      0.389217   0.390783
196       1970  0.015278  0.063699      0.389327   0.390859
197       1980  0.015262  0.063619      0.389328   0.390843
198       1990  0.015210  0.064535      0.389271   0.390782
199       2000  0.015414  0.062509      0.390058   0.391625
     val_epoch     P_0.5     P_0.6  ...   Acc_0.5   Acc_0.6   Acc_0.7
195     1960.0  0.972524  0.980715  ...  0.958055  0.953576  0.940626
196     1970.0  0.971546  0.980830  ...  0.957078  0.953820  0.942987
197     1980.0  0.971985  0.980822  ...  0.957648  0.953494  0.942499
198     1990.0  0.972105  0.980399  ...  0.958055  0.953983  0.944128
199     2000.0  0.972724  0.980811  ...  0.957811  0.953087  0.939567

[5 rows x 13 columns]
Model saved in file: train_model_d512_b512/nl27k/DistMult_VAE_1001/model.bin
